<!DOCTYPE html>
<html lang="en-us">
  <head>
    
<meta charset="UTF-8">
<title>Web crawler API (beta) reference | Elastic App Search Documentation [7.16] | Elastic</title>
<link rel="home" href="index.html" title="Elastic App Search Documentation [7.16]"/>
<link rel="up" href="api-reference.html" title="API Reference"/>
<link rel="prev" href="synonyms.html" title="Synonyms API"/>
<link rel="next" href="api-clients.html" title="API Clients"/>
<meta name="DC.type" content="Learn/Docs/App Search/Guide/7.16"/>
<meta name="DC.subject" content="App Search"/>
<meta name="DC.identifier" content="7.16"/>
<meta name="robots" content="noindex,nofollow"/>

    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <script src="https://cdn.optimizely.com/js/18132920325.js"></script>
    <link rel="apple-touch-icon" sizes="57x57" href="/apple-icon-57x57.png">
    <link rel="apple-touch-icon" sizes="60x60" href="/apple-icon-60x60.png">
    <link rel="apple-touch-icon" sizes="72x72" href="/apple-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="76x76" href="/apple-icon-76x76.png">
    <link rel="apple-touch-icon" sizes="114x114" href="/apple-icon-114x114.png">
    <link rel="apple-touch-icon" sizes="120x120" href="/apple-icon-120x120.png">
    <link rel="apple-touch-icon" sizes="144x144" href="/apple-icon-144x144.png">
    <link rel="apple-touch-icon" sizes="152x152" href="/apple-icon-152x152.png">
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-icon-180x180.png">
    <link rel="icon" type="image/png" href="/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="/android-chrome-192x192.png" sizes="192x192">
    <link rel="icon" type="image/png" href="/favicon-96x96.png" sizes="96x96">
    <link rel="icon" type="image/png" href="/favicon-16x16.png" sizes="16x16">
    <link rel="manifest" href="/manifest.json">
    <meta name="apple-mobile-web-app-title" content="Elastic">
    <meta name="application-name" content="Elastic">
    <meta name="msapplication-TileColor" content="#ffffff">
    <meta name="msapplication-TileImage" content="/mstile-144x144.png">
    <meta name="theme-color" content="#ffffff">
    <meta name="naver-site-verification" content="936882c1853b701b3cef3721758d80535413dbfd" />
    <meta name="yandex-verification" content="d8a47e95d0972434" />
    <meta name="localized" content="true" />
    <meta name="st:robots" content="follow,index" />
    <meta property="og:image" content="https://www.elastic.co/static/images/elastic-logo-200.png" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <link rel="apple-touch-icon-precomposed" sizes="64x64" href="/favicon_64x64_16bit.png">
    <link rel="apple-touch-icon-precomposed" sizes="32x32" href="/favicon_32x32.png">
    <link rel="apple-touch-icon-precomposed" sizes="16x16" href="/favicon_16x16.png">
    <!-- Give IE8 a fighting chance -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    <link rel="stylesheet" type="text/css" href="/guide/static/styles.css" />
  </head>

  <!--© 2015-2022 Elasticsearch B.V. -->
  <!-- All Elastic documentation is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License. -->
  <!-- http://creativecommons.org/licenses/by-nc-nd/4.0/ -->

  <body>
    <!-- Google Tag Manager -->
    <script>dataLayer = [];</script><noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-58RLH5" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start': new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0], j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src= '//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f); })(window,document,'script','dataLayer','GTM-58RLH5');</script>
    <!-- End Google Tag Manager -->

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-12395217-16"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-12395217-16');
    </script>

    <!--BEGIN QUALTRICS WEBSITE FEEDBACK SNIPPET-->
    <script type='text/javascript'>
      (function(){var g=function(e,h,f,g){
      this.get=function(a){for(var a=a+"=",c=document.cookie.split(";"),b=0,e=c.length;b<e;b++){for(var d=c[b];" "==d.charAt(0);)d=d.substring(1,d.length);if(0==d.indexOf(a))return d.substring(a.length,d.length)}return null};
      this.set=function(a,c){var b="",b=new Date;b.setTime(b.getTime()+6048E5);b="; expires="+b.toGMTString();document.cookie=a+"="+c+b+"; path=/; "};
      this.check=function(){var a=this.get(f);if(a)a=a.split(":");else if(100!=e)"v"==h&&(e=Math.random()>=e/100?0:100),a=[h,e,0],this.set(f,a.join(":"));else return!0;var c=a[1];if(100==c)return!0;switch(a[0]){case "v":return!1;case "r":return c=a[2]%Math.floor(100/c),a[2]++,this.set(f,a.join(":")),!c}return!0};
      this.go=function(){if(this.check()){var a=document.createElement("script");a.type="text/javascript";a.src=g;document.body&&document.body.appendChild(a)}};
      this.start=function(){var a=this;window.addEventListener?window.addEventListener("load",function(){a.go()},!1):window.attachEvent&&window.attachEvent("onload",function(){a.go()})}};
      try{(new g(100,"r","QSI_S_ZN_emkP0oSe9Qrn7kF","https://znemkp0ose9qrn7kf-elastic.siteintercept.qualtrics.com/WRSiteInterceptEngine/?Q_ZID=ZN_emkP0oSe9Qrn7kF")).start()}catch(i){}})();
    </script><div id='ZN_emkP0oSe9Qrn7kF'><!--DO NOT REMOVE-CONTENTS PLACED HERE--></div>
    <!--END WEBSITE FEEDBACK SNIPPET-->

    <div id='elastic-nav' style="display:none;"></div>
    <script src='https://www.elastic.co/elastic-nav.js'></script>

    <div class="main-container">
      <section id="content" >
        <div class="content-wrapper">

          <section id="guide" lang="en">
            <div class="container-fluid">
              <div class="row pb-3">
                <div class="col-12 order-2 col-md-4 order-md-1 col-lg-3 h-almost-full-md sticky-top-md" id="left_col">
                  <!-- The TOC is appended here -->
                </div>

                <div class="col-12 order-1 col-md-8 order-md-2 col-lg-7 order-lg-2 guide-section" id="middle_col">
                  <!-- start body -->
                  <div class="page_header">
<strong>IMPORTANT</strong>: No additional bug fixes or documentation updates
will be released for this version. For the latest information, see the
<a href="../current/index.html">current release documentation</a>.
</div>
<div id="content">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span><span class="chevron-right">›</span>
<span class="breadcrumb-link"><a href="index.html">Elastic App Search Documentation [7.16]</a></span><span class="chevron-right">›</span>
<span class="breadcrumb-link"><a href="api-reference.html">API Reference</a></span>
</div>
<div class="navheader">
<span class="prev">
<a href="synonyms.html">« Synonyms API</a>
</span>
<span class="next">
<a href="api-clients.html">API Clients »</a>
</span>
</div>
<div class="section">
<div class="titlepage"><div><div>
<h2 class="title"><a id="web-crawler-api-reference"></a>Web crawler API (beta) reference<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/7.16/app-search-docs/api-reference/web-crawler-api-reference.asciidoc">edit</a></h2>
</div></div></div>
<div class="caution admon">
<div class="icon"></div>
<div class="admon_content">
<p>The Elastic Enterprise Search web crawler API is a <span class="strong strong"><strong>beta</strong></span> feature.
Beta features are subject to change and are not covered by the support SLA of general release (GA) features.
Elastic plans to promote this feature to GA in a future release.</p>
</div>
</div>
<p>App Search provides API operations for the <a class="xref" href="web-crawler.html" title="Web crawler">web crawler</a>.
This document provides a reference for each API operation, as well as shared concerns:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<p><a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-shared-concerns" title="Shared concerns">Shared concerns</a></p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-shared-concerns-engine" title="Engine">Engine</a>
</li>
<li class="listitem">
<a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-shared-concerns-access" title="Access">Access</a>
</li>
</ul>
</div>
</li>
<li class="listitem">
<a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-get-crawler" title="Crawler">Crawler</a>
</li>
<li class="listitem">
<p><a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-crawl-requests" title="Crawl requests">Crawl requests</a></p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-get-crawler-crawl-requests-active" title="Get current active crawl request">Get current active crawl request</a>
</li>
<li class="listitem">
<a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-post-crawler-crawl-requests-active-cancel" title="Cancel an active crawl">Cancel an active crawl</a>
</li>
<li class="listitem">
<a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-get-crawler-crawl-requests" title="List crawl requests">List crawl requests</a>
</li>
<li class="listitem">
<a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-post-crawler-crawl-requests" title="Create a new crawl request">Create a new crawl request</a>
</li>
<li class="listitem">
<a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-get-crawler-crawl-requests-id" title="View details for a crawl request">View details for a crawl request</a>
</li>
</ul>
</div>
</li>
<li class="listitem">
<p><a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-crawl-schedules" title="Crawl schedules">Crawl schedules</a></p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-get-crawler-crawl-schedule" title="Get current crawl schedule">Get current crawl schedule</a>
</li>
<li class="listitem">
<a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-put-crawler-crawl-schedule" title="Create or update a crawl schedule">Create or update a crawl schedule</a>
</li>
<li class="listitem">
<a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-delete-crawler-crawl-schedule" title="Delete a crawl schedule">Delete a crawl schedule</a>
</li>
</ul>
</div>
</li>
<li class="listitem">
<p><a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-process-crawls" title="Process crawls">Process crawls</a></p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-get-crawler-process-crawls" title="List process crawls">List process crawls</a>
</li>
<li class="listitem">
<a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-get-crawler-process-crawls-id" title="View details for a process crawl">View details for a process crawl</a>
</li>
<li class="listitem">
<a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-get-crawler-process-crawls-id-denied-urls" title="View denied URLs for a process crawl">View denied URLs for a process crawl</a>
</li>
<li class="listitem">
<a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-post-crawler-process-crawls" title="Create a new process crawl">Create a new process crawl</a>
</li>
</ul>
</div>
</li>
<li class="listitem">
<p><a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-troubleshooting" title="URL validation and debugging">URL validation and debugging</a></p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-post-crawler-validate-domain" title="Validate a domain">Validate a domain</a>
</li>
<li class="listitem">
<a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-post-crawler-validate-url" title="Validate a URL">Validate a URL</a>
</li>
<li class="listitem">
<a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-post-crawler-extract-url" title="Extract content from a URL">Extract content from a URL</a>
</li>
<li class="listitem">
<a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-post-crawler-trace-url" title="Trace a URL">Trace a URL</a>
</li>
</ul>
</div>
</li>
<li class="listitem">
<a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-user-agent" title="User agent">User agent</a>
</li>
<li class="listitem">
<p><a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-domains" title="Domains">Domains</a></p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-get-crawler-domains" title="List domains">List domains</a>
</li>
<li class="listitem">
<a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-post-crawler-domains" title="Create a new domain">Create a new domain</a>
</li>
<li class="listitem">
<a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-get-crawler-domain" title="View details for a domain">View details for a domain</a>
</li>
<li class="listitem">
<a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-put-crawler-domain" title="Update a domain">Update a domain</a>
</li>
<li class="listitem">
<a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-delete-crawler-domain" title="Delete a domain">Delete a domain</a>
</li>
</ul>
</div>
</li>
<li class="listitem">
<p><a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-entry-points" title="Entry points">Entry points</a></p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-post-entry-points" title="Create a new entry point">Create a new entry point</a>
</li>
<li class="listitem">
<a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-put-entry-point" title="Update an entry point">Update an entry point</a>
</li>
<li class="listitem">
<a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-delete-entry-point" title="Delete an entry point">Delete an entry point</a>
</li>
</ul>
</div>
</li>
<li class="listitem">
<p><a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-crawl-rules" title="Crawl rules">Crawl rules</a></p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-post-crawl-rules" title="Create a new crawl rule">Create a new crawl rule</a>
</li>
<li class="listitem">
<a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-put-crawl-rule" title="Update a crawl rule">Update a crawl rule</a>
</li>
<li class="listitem">
<a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-delete-crawl-rule" title="Delete a crawl rule">Delete a crawl rule</a>
</li>
</ul>
</div>
</li>
<li class="listitem">
<p><a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-sitemaps" title="Sitemaps">Sitemaps</a></p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-post-sitemaps" title="Create a new sitemap">Create a new sitemap</a>
</li>
<li class="listitem">
<a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-put-sitemap" title="Update a sitemap">Update a sitemap</a>
</li>
<li class="listitem">
<a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-delete-sitemap" title="Delete a sitemap">Delete a sitemap</a>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="web-crawler-apis-shared-concerns"></a>Shared concerns<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/7.16/app-search-docs/api-reference/web-crawler-api-reference.asciidoc">edit</a></h3>
</div></div></div>
<p>All web crawler API operations share the following concerns.</p>
<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="web-crawler-apis-shared-concerns-engine"></a>Engine<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/7.16/app-search-docs/api-reference/web-crawler-api-reference.asciidoc">edit</a></h4>
</div></div></div>
<p>Most endpoints within the crawler API are scoped to a particular App Search engine.
The engine is identified by the engine name value provided in the URL of the request.
If an engine could not be found for any API request, an empty HTTP 404 response will be returned.</p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="web-crawler-apis-shared-concerns-access"></a>Access<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/7.16/app-search-docs/api-reference/web-crawler-api-reference.asciidoc">edit</a></h4>
</div></div></div>
<p>Unless security is disabled, you must provide credentials to access API operations.</p>
<p>See <a class="xref" href="authentication.html" title="Authentication"><em>Authentication</em></a>.</p>
</div>

</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="web-crawler-apis-get-crawler"></a>Crawler<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/7.16/app-search-docs/api-reference/web-crawler-api-reference.asciidoc">edit</a></h3>
</div></div></div>
<p>Responds with domain objects configured for a given App Search engine.</p>
<div class="pre_wrapper lang-bash">
<pre class="programlisting prettyprint lang-bash">GET /api/as/v0/engines/{ENGINE_NAME}/crawler</pre>
</div>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json"># 200 OK
{
  "domains": [
    {
      "id": "{DOMAIN_ID}",
      "name": "{DOMAIN_NAME}",
      "document_count": 0,
      "entry_points": [
        {
          "id": "6087cec06dda9bdfb4a49e39",
          "value": "/"
        }
      ],
      "crawl_rules": [],
      "default_crawl_rule": {
        "id": "-",
        "order": 0,
        "policy": "allow",
        "rule": "regex",
        "pattern": ".*"
      },
      "sitemaps": []
    }
  ]
}</pre>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="web-crawler-apis-crawl-requests"></a>Crawl requests<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/7.16/app-search-docs/api-reference/web-crawler-api-reference.asciidoc">edit</a></h3>
</div></div></div>
<p>Each crawl performed by the Enterprise Search web crawler has an associated <span class="strong strong"><strong>crawl request</strong></span> object.
The crawl requests API allows operators to create new crawl requests and to view and control the state of existing crawl requests.</p>
<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="web-crawler-apis-get-crawler-crawl-requests-active"></a>Get current active crawl request<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/7.16/app-search-docs/api-reference/web-crawler-api-reference.asciidoc">edit</a></h4>
</div></div></div>
<p>Returns a crawl request object for an active crawl or returns an HTTP 404 response if there is no active crawl for a given App Search engine.</p>
<div class="pre_wrapper lang-bash">
<pre class="programlisting prettyprint lang-bash">GET /api/as/v0/engines/{ENGINE_NAME}/crawler/crawl_requests/active</pre>
</div>
<p>For successful calls, the response is going to look like this:</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json"># 200 OK
{
  "id": "601b21adbeae67679b3b760a",
  "status": "running",
  "created_at": "Wed, 03 Feb 2021 22:20:29 +0000",
  "begun_at": "Wed, 03 Feb 2021 22:20:31 +0000",
  "completed_at": null
}</pre>
</div>
<p>For cases when there is no active crawl for a given engine, the API responds with a 404 error:</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json"># 404 Not Found
{
  "error": "There are no active crawl requests for this engine"
}</pre>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="web-crawler-apis-post-crawler-crawl-requests-active-cancel"></a>Cancel an active crawl<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/7.16/app-search-docs/api-reference/web-crawler-api-reference.asciidoc">edit</a></h4>
</div></div></div>
<p>Cancels an active crawl for a given App Search engine or returns an HTTP 404 response if there is no active crawl for a given App Search engine.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>It may take some time for the crawler to detect the cancellation request and gracefully stop the crawl.
During the time, the status of the crawl request will remain <code class="literal">canceling</code>.</p>
</div>
</div>
<div class="pre_wrapper lang-bash">
<pre class="programlisting prettyprint lang-bash">POST /api/as/v0/engines/{ENGINE_NAME}/crawler/crawl_requests/active/cancel</pre>
</div>
<p>In case of success, the response contains a single crawl request object with a <code class="literal">canceling</code> state:</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json"># 200 OK
{
  "id": "601b21adbeae67679b3b760a",
  "status": "canceling",
  "created_at": "Wed, 03 Feb 2021 22:20:29 +0000",
  "begun_at": "Wed, 03 Feb 2021 22:20:31 +0000",
  "completed_at": null
}</pre>
</div>
<p>For cases when there is no active crawl for a given engine, the API responds with a 404 error:</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json"># 404 Not Found
{
  "error": "There are no active crawl requests for this engine"
}</pre>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="web-crawler-apis-get-crawler-crawl-requests"></a>List crawl requests<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/7.16/app-search-docs/api-reference/web-crawler-api-reference.asciidoc">edit</a></h4>
</div></div></div>
<p>Returns a list of crawl requests for a given engine.</p>
<div class="pre_wrapper lang-bash">
<pre class="programlisting prettyprint lang-bash">GET /api/as/v0/engines/{ENGINE_NAME}/crawler/crawl_requests</pre>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">page[current]</code> (optional)
</span>
</dt>
<dd>
Current page number (default: 1).
</dd>
<dt>
<span class="term">
<code class="literal">page[size]</code> (optional)
</span>
</dt>
<dd>
Page size (default: 25). The maximum is 100, and be will truncated if a larger size is requested.
</dd>
</dl>
</div>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json"># 200 OK
{
  "meta": {
    "page": {
      "current": 1,
      "total_pages": 1,
      "total_results": 3,
      "size": 25
    }
  },
  "results": [
    {
      "id": "601b21adbeae67679b3b760a",
      "status": "running",
      "created_at": "Wed, 03 Feb 2021 22:20:29 +0000",
      "begun_at": "Wed, 03 Feb 2021 22:20:31 +0000",
      "completed_at": null
    },
    {
      "id": "60147e93beae67bf7ef72e86",
      "status": "success",
      "created_at": "Fri, 29 Jan 2021 21:30:59 +0000",
      "begun_at": "Fri, 29 Jan 2021 21:31:00 +0000",
      "completed_at": "Fri, 29 Jan 2021 21:35:20 +0000"
    },
    {
      "id": "60146c07beae67f397300128",
      "status": "canceled",
      "created_at": "Fri, 29 Jan 2021 20:11:51 +0000",
      "begun_at": "Fri, 29 Jan 2021 20:11:52 +0000",
      "completed_at": "Fri, 29 Jan 2021 20:12:51 +0000"
    }
  ]
}</pre>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="web-crawler-apis-post-crawler-crawl-requests"></a>Create a new crawl request<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/7.16/app-search-docs/api-reference/web-crawler-api-reference.asciidoc">edit</a></h4>
</div></div></div>
<p>Requests a new crawl for a given App Search engine.
If there is already an active crawl, the request returns an HTTP 400 response with an error message.</p>
<div class="pre_wrapper lang-bash">
<pre class="programlisting prettyprint lang-bash">POST /api/as/v0/engines/{ENGINE_NAME}/crawler/crawl_requests</pre>
</div>
<p>In case of success, the response contains a single crawl request object with a <code class="literal">pending</code> state:</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json"># 200 OK
{
  "id": "601b21adbeae67679b3b760a",
  "status": "pending",
  "created_at": "Wed, 03 Feb 2021 22:20:29 +0000",
  "begun_at": null,
  "completed_at": null
}</pre>
</div>
<p>When there is already an active crawl, the API returns an HTTP 400 response:</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json"># 400 Bad Request
{
  "error": "There is an active crawl for the engine \"your-engine\", please wait for it to finish or abort it before requesting another one"
}</pre>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="web-crawler-apis-get-crawler-crawl-requests-id"></a>View details for a crawl request<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/7.16/app-search-docs/api-reference/web-crawler-api-reference.asciidoc">edit</a></h4>
</div></div></div>
<p>Returns details of a given crawl request.
The crawl request is identified with a unique Crawl Request ID value.</p>
<div class="pre_wrapper lang-bash">
<pre class="programlisting prettyprint lang-bash">GET /api/as/v0/engines/{ENGINE_NAME}/crawler/crawl_requests/{CRAWL_REQUEST_ID}</pre>
</div>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json"># 200 OK
{
  "id": "60147e93beae67bf7ef72e86",
  "status": "success",
  "created_at": "Fri, 29 Jan 2021 21:30:59 +0000",
  "begun_at": "Fri, 29 Jan 2021 21:31:00 +0000",
  "completed_at": "Fri, 29 Jan 2021 21:35:20 +0000"
}</pre>
</div>
</div>

</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="web-crawler-apis-crawl-schedules"></a>Crawl schedules<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/7.16/app-search-docs/api-reference/web-crawler-api-reference.asciidoc">edit</a></h3>
</div></div></div>
<p>Each engine using the Enterprise Search web crawler has an associated <span class="strong strong"><strong>crawl schedule</strong></span> object.
The crawl schedule API allows operators to specify a frequency at which new crawls will be started.
If there is an active crawl, new crawls will be skipped.</p>
<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="web-crawler-apis-get-crawler-crawl-schedule"></a>Get current crawl schedule<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/7.16/app-search-docs/api-reference/web-crawler-api-reference.asciidoc">edit</a></h4>
</div></div></div>
<p>Returns a crawl schedule object or returns an HTTP 404 response if there is no crawl schedule object for a given App Search engine.</p>
<div class="pre_wrapper lang-bash">
<pre class="programlisting prettyprint lang-bash">GET /api/as/v0/engines/{ENGINE_NAME}/crawler/crawl_schedule</pre>
</div>
<p>For successful calls, the response is going to look like this:</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json"># 200 OK
{
  "engine": {ENGINE_NAME},
  "frequency": 2,
  "unit": "week"
}</pre>
</div>
<p>For cases when there is no crawl schedule for a given engine, the API responds with a 404 error:</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json"># 404 Not Found
{
  "errors": ["No crawl schedule found"]
}</pre>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="web-crawler-apis-put-crawler-crawl-schedule"></a>Create or update a crawl schedule<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/7.16/app-search-docs/api-reference/web-crawler-api-reference.asciidoc">edit</a></h4>
</div></div></div>
<p>Upserts a crawl schedule for a given App Search engine.</p>
<div class="pre_wrapper lang-bash">
<pre class="programlisting prettyprint lang-bash">PUT /api/as/v0/engines/{ENGINE_NAME}/crawler/crawl_schedule
{
  "frequency": {INTEGER},
  "unit": {ENUM}
}</pre>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">frequency</code> (required)
</span>
</dt>
<dd>
A positive integer.
</dd>
<dt>
<span class="term">
<code class="literal">unit</code> (required)
</span>
</dt>
<dd>
Should be one of: <code class="literal">hour</code>, <code class="literal">day</code>, <code class="literal">week</code>, <code class="literal">month</code>.
</dd>
</dl>
</div>
<p>In case of success, the response contains the crawl schedule object:</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json"># 200 OK
{
  "engine": {ENGINE_NAME},
  "frequency": 2,
  "unit": "week"
}</pre>
</div>
<p>When the parameters are invalid, the API returns an HTTP 400 response:</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json"># 400 Bad Request
{
  "errors": [
    "Crawl schedule frequency must be an integer",
    "Crawl schedule unit must be one of hour, day, week, month"
  ]
}</pre>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="web-crawler-apis-delete-crawler-crawl-schedule"></a>Delete a crawl schedule<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/7.16/app-search-docs/api-reference/web-crawler-api-reference.asciidoc">edit</a></h4>
</div></div></div>
<p>Deletes a crawl schedule for a given App Search engine.</p>
<div class="pre_wrapper lang-bash">
<pre class="programlisting prettyprint lang-bash">DELETE /api/as/v0/engines/{ENGINE_NAME}/crawler/crawl_schedule</pre>
</div>
<p>In case of success, the response contains an object showing the crawl schedule has been deleted:</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json"># 200 OK
{
  "deleted": true
}</pre>
</div>
<p>For cases when there is no crawl schedule for a given engine, the API responds with a 404 error:</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json"># 404 Not Found
{
  "errors": ["No crawl schedule found"]
}</pre>
</div>
</div>

</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="web-crawler-apis-process-crawls"></a>Process crawls<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/7.16/app-search-docs/api-reference/web-crawler-api-reference.asciidoc">edit</a></h3>
</div></div></div>
<p>A <em>process crawl</em> is an operation that re-processes the documents in your engine using the current <a class="xref" href="web-crawler-reference.html#web-crawler-reference-crawl-rule" title="Crawl rule">crawl rules</a>, without waiting for a full re-crawl.
See <a class="xref" href="web-crawler-reference.html#web-crawler-reference-process-crawl" title="Process crawl">Process crawl</a>.</p>
<p>Use the following operations to manage process crawls for a given engine.</p>
<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="web-crawler-apis-get-crawler-process-crawls"></a>List process crawls<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/7.16/app-search-docs/api-reference/web-crawler-api-reference.asciidoc">edit</a></h4>
</div></div></div>
<p>Returns a list of <a class="xref" href="web-crawler-reference.html#web-crawler-reference-process-crawl" title="Process crawl">process crawls</a> for the given engine.</p>
<div class="pre_wrapper lang-bash">
<pre class="programlisting prettyprint lang-bash">GET /api/as/v0/engines/{ENGINE_NAME}/crawler/process_crawls</pre>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">page[current]</code> (optional)
</span>
</dt>
<dd>
Current page number (default: 1).
</dd>
<dt>
<span class="term">
<code class="literal">page[size]</code> (optional)
</span>
</dt>
<dd>
Page size (default: 25). The maximum is 100, and be will truncated if a larger size is requested.
</dd>
</dl>
</div>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json"># 200 OK
{
  "meta": {
    "page": {
      "current": 1,
      "total_pages": 1,
      "total_results": 3,
      "size": 25
    }
  },
  "results": [
    {
      "id": "61421fe6e725695876d72d2e",
      "dry_run": true,
      "total_url_count": 167,
      "denied_url_count": 92,
      "domains": [
        "https://swiftype.com"
      ],
      "process_all_domains": false,
      "created_at": "2021-09-15T16:31:34Z",
      "begun_at": "2021-09-15T16:31:35Z",
      "completed_at": "2021-09-15T16:31:52Z"
    },
    {
      "id": "61421e15e72569a22ad6f549",
      "dry_run": false,
      "total_url_count": 7793,
      "denied_url_count": 1028,
      "domains": [
        "https://swiftype.com",
        "https://www.elastic.co"
      ],
      "process_all_domains": true,
      "created_at": "2021-09-15T16:23:49Z",
      "begun_at": "2021-09-15T16:23:49Z",
      "completed_at": "2021-09-15T16:25:48Z"
    },
    {
      "id": "61421b93e725694296d664f0",
      "dry_run": false,
      "total_url_count": 8525,
      "denied_url_count": 930,
      "domains": [
        "https://www.elastic.co"
      ],
      "process_all_domains": true,
      "created_at": "2021-09-15T16:13:07Z",
      "begun_at": "2021-09-15T16:13:07Z",
      "completed_at": "2021-09-15T16:15:29Z"
    }
  ]
}</pre>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="web-crawler-apis-get-crawler-process-crawls-id"></a>View details for a process crawl<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/7.16/app-search-docs/api-reference/web-crawler-api-reference.asciidoc">edit</a></h4>
</div></div></div>
<p>View the details of the <a class="xref" href="web-crawler-reference.html#web-crawler-reference-process-crawl" title="Process crawl">process crawl</a> with the given ID.</p>
<div class="pre_wrapper lang-bash">
<pre class="programlisting prettyprint lang-bash">GET /api/as/v0/engines/{ENGINE_NAME}/crawler/process_crawls/{PROCESS_CRAWL_ID}</pre>
</div>
<p>The response includes summary information of the process crawl, identifying the total number of URLs that were re-processed along with the number of URLs identified for deletion.</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json">{
  "id": "61421fe6e725695876d72d2e",
  "dry_run": true,
  "total_url_count": 167,
  "denied_url_count": 92,
  "domains": [
    "https://swiftype.com"
  ],
  "process_all_domains": false,
  "created_at": "2021-09-15T16:31:34Z",
  "begun_at": "2021-09-15T16:31:35Z",
  "completed_at": "2021-09-15T16:31:52Z"
}</pre>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="web-crawler-apis-get-crawler-process-crawls-id-denied-urls"></a>View denied URLs for a process crawl<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/7.16/app-search-docs/api-reference/web-crawler-api-reference.asciidoc">edit</a></h4>
</div></div></div>
<p>View a sample of 100 URLs identified for deletion by a given process crawl. This API complements the <code class="literal">dry run</code> capability of a process crawl to test configuration before committing to deletion.
See <a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-post-crawler-process-crawls" title="Create a new process crawl">Create a new process crawl</a>.</p>
<div class="pre_wrapper lang-bash">
<pre class="programlisting prettyprint lang-bash">GET /api/as/v0/engines/{ENGINE_NAME}/crawler/process_crawls/{PROCESS_CRAWL_ID}/denied_urls</pre>
</div>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json">{
  "total_url_count": 167,
  "denied_url_count": 92,
  "sample_size": 100,
  "denied_urls_sample": [
    "https://swiftype.com/documentation",
    "https://swiftype.com/documentation/site-search/site_search",
    "https://swiftype.com/documentation/site-search/guides/crawler-optimization",
    "https://swiftype.com/documentation/site-search/guides/multiple-domains",
    "https://swiftype.com/documentation/site-search/guides/engine-cloning",
    ...
  ]
}</pre>
</div>
<p>The denied URLs API reads from event logs generated during the process crawl. If the logs for a given process crawl have been deleted or are otherwise unavailable, an empty array is returned.</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json">{
  "total_url_count": 167,
  "denied_url_count": 92,
  "sample_size": 100,
  "denied_urls_sample": []
}</pre>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="web-crawler-apis-post-crawler-process-crawls"></a>Create a new process crawl<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/7.16/app-search-docs/api-reference/web-crawler-api-reference.asciidoc">edit</a></h4>
</div></div></div>
<p>Request a new <a class="xref" href="web-crawler-reference.html#web-crawler-reference-process-crawl" title="Process crawl">process crawl</a> for the given engine.</p>
<div class="pre_wrapper lang-bash">
<pre class="programlisting prettyprint lang-bash">POST /api/as/v0/engines/{ENGINE_NAME}/crawler/process_crawls
{
  "dry_run": {BOOLEAN}
  "domains": {ARRAY}
}</pre>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">dry_run</code> (optional)
</span>
</dt>
<dd>
If <code class="literal">true</code>, the process crawl identifies but does not delete documents that are no longer permitted by the current crawl configuration. Defaults to <code class="literal">false</code>.
</dd>
<dt>
<span class="term">
<code class="literal">domains</code> (optional)
</span>
</dt>
<dd>
Limits the process crawl to a subset of <a class="xref" href="web-crawler-reference.html#web-crawler-reference-domain" title="Domain">crawler domains</a>. By default, the process crawl will apply to all crawler domains on the engine.
</dd>
</dl>
</div>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json">{
  "id": "61421b93e725694296d664f0",
  "dry_run": false,
  "total_url_count": 0,
  "denied_url_count": 0,
  "domains": [
    "https://www.elastic.co"
  ],
  "process_all_domains": true,
  "created_at": "2021-09-15T16:13:07Z",
  "begun_at": null,
  "completed_at": null
}</pre>
</div>
</div>

</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="web-crawler-apis-troubleshooting"></a>URL validation and debugging<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/7.16/app-search-docs/api-reference/web-crawler-api-reference.asciidoc">edit</a></h3>
</div></div></div>
<p>The web crawler provides several API operations to help you <a class="xref" href="crawl-web-content.html#crawl-web-content-troubleshoot-crawl" title="Troubleshoot crawl">troubleshoot crawls</a>.
Use the following operations to validate and debug specific URLs from the perspective of the web crawler.</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-post-crawler-validate-domain" title="Validate a domain">Validate a domain</a>
</li>
<li class="listitem">
<a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-post-crawler-validate-url" title="Validate a URL">Validate a URL</a>
</li>
<li class="listitem">
<a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-post-crawler-extract-url" title="Extract content from a URL">Extract content from a URL</a>
</li>
<li class="listitem">
<a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-post-crawler-trace-url" title="Trace a URL">Trace a URL</a>
</li>
</ul>
</div>
<h5><a id="web-crawler-apis-post-crawler-validate-domain"></a>Validate a domain<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/7.16/app-search-docs/api-reference/web-crawler-api-reference.asciidoc">edit</a></h5>
<p>Validate the given domain from the perspective of the web crawler.</p>
<p>Optionally, use the <code class="literal">checks</code> parameter to choose the specific validations to perform.
The response includes an ordered set of results.
Each provides the detailed results of a specific check.
If any checks fail, the crawler skips remaining checks.</p>
<p>Use this operation to validate a domain before adding it to the crawl configuration for an engine, or troubleshoot issues crawling a specific domain.
This operation visits the domain as the web crawler, without starting a full crawl.
The results reflect how the web crawler sees that domain <span class="strong strong"><strong>now</strong></span>.
It does not represent the states of previous crawls.
For historical information, see <a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-post-crawler-trace-url" title="Trace a URL">Trace a URL</a>.</p>
<p>You can use this operation to identify issues with a domain.
The domain owner can fix the issues, and you can verfiy the fixes.
Repeat this process until all checks pass.
This process is more convenient than requesting a new crawl to confirm the fixes.</p>
<div class="pre_wrapper lang-bash">
<pre class="programlisting prettyprint lang-bash">POST /api/as/v0/crawler/validate_url
{
  "url": {URL},
  "checks": {CHECKS}
}</pre>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">url</code> (required)
</span>
</dt>
<dd>
The URL of the domain to validate.
</dd>
<dt>
<span class="term">
<code class="literal">checks</code> (optional)
</span>
</dt>
<dd>
<p>
Checks to perform. Array including any of the following supported values.
To run additional checks, validate a specific page within the context of an engine.
See <a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-post-crawler-validate-url" title="Validate a URL">Validate a URL</a>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">dns</code>
</li>
<li class="listitem">
<code class="literal">robots_txt</code>
</li>
<li class="listitem">
<code class="literal">tcp</code>
</li>
<li class="listitem">
<code class="literal">url</code>
</li>
<li class="listitem">
<code class="literal">url_content</code>
</li>
<li class="listitem">
<code class="literal">url_request</code>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<p>Example response for <code class="literal">url: https://www.elastic.co</code> and <code class="literal">checks: ["url", "tcp", "url_request"]</code>:</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json"># 200 OK
{
  "url": "https://www.elastic.co",
  "normalized_url": "https://www.elastic.co/",
  "valid": true,
  "results": [
    {
      "result": "ok",
      "name": "url",
      "details": {},
      "comment": "URL structure looks valid"
    },
    {
      "result": "ok",
      "name": "tcp",
      "details": {
        "host": "www.elastic.co",
        "port": 443
      },
      "comment": "TCP connection successful"
    },
    {
      "result": "ok",
      "name": "url_request",
      "details": {
        "status_code": 200,
        "content_type": "text/html; charset=utf-8",
        "request_time_msec": 166
      },
      "comment": "Successfully fetched https://www.elastic.co: HTTP 200."
    }
  ]
}</pre>
</div>
<h5><a id="web-crawler-apis-post-crawler-validate-url"></a>Validate a URL<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/7.16/app-search-docs/api-reference/web-crawler-api-reference.asciidoc">edit</a></h5>
<p>Validate the given URL from the perspective of the web crawler.
The given URL is assumed to be a web page or other web content.
To validate a domain, see <a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-post-crawler-validate-domain" title="Validate a domain">Validate a domain</a>.</p>
<p>Optionally, use the <code class="literal">checks</code> parameter to choose the specific validations to perform.
The response includes an ordered set of results.
Each provides the detailed results of a specific check.
If any checks fail, the crawler skips remaining checks.</p>
<p>Use this operation to troubleshoot issues crawling web content at a specific URL.
This operation visits the URL as the web crawler, without starting a full crawl.
The results reflect how the web crawler sees that URL <span class="strong strong"><strong>now</strong></span>.
It does not represent the states of previous crawls.
For historical information, see <a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-post-crawler-trace-url" title="Trace a URL">Trace a URL</a>.</p>
<p>You can use this operation to identify issues with a specific URL.
The domain owner can fix the issues, and you can verfiy the fixes.
Repeat this process until all checks pass.
After fixing all issues, start a new crawl to discover and extract the content at the URL.
See <a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-post-crawler-crawl-requests" title="Create a new crawl request">Create a new crawl request</a>.</p>
<p>To troubleshoot content extraction issues at a specific URL, see <a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-post-crawler-extract-url" title="Extract content from a URL">Extract content from a URL</a>.
The <code class="literal">url_content</code> check for this operation confirms that content was extracted, but it does not include the content within the response.</p>
<div class="pre_wrapper lang-bash">
<pre class="programlisting prettyprint lang-bash">POST /api/as/v0/engines/{ENGINE_NAME}/crawler/validate_url</pre>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">url</code> (required)
</span>
</dt>
<dd>
The URL to validate.
</dd>
<dt>
<span class="term">
<code class="literal">checks</code> (optional)
</span>
</dt>
<dd>
<p>
Checks to perform. Array including any of the following supported values.
This operation offers more checks than the operation to <a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-post-crawler-validate-domain" title="Validate a domain">validate a domain</a>, since this operation runs in the context of a specific engine.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">crawl_rules</code>
</li>
<li class="listitem">
<code class="literal">domain_access</code>
</li>
<li class="listitem">
<code class="literal">dns</code>
</li>
<li class="listitem">
<code class="literal">robots_txt</code>
</li>
<li class="listitem">
<code class="literal">tcp</code>
</li>
<li class="listitem">
<code class="literal">url</code>
</li>
<li class="listitem">
<code class="literal">url_content</code>
</li>
<li class="listitem">
<code class="literal">url_request</code>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<p>Example response for <code class="literal">url: https://www.elastic.co</code> and <code class="literal">checks: ["url", "domain_access", "crawl_rules"]</code>:</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json"># 200 OK
{
  "url": "https://www.elastic.co",
  "normalized_url": "https://www.elastic.co/",
  "valid": true,
  "results": [
    {
      "result": "ok",
      "name": "url",
      "details": {},
      "comment": "URL structure looks valid"
    },
    {
      "result": "ok",
      "name": "domain_access",
      "details": {
        "domain": "https://www.elastic.co"
      },
      "comment": "The URL matches one of the domains configured for the engine"
    },
    {
      "result": "ok",
      "name": "crawl_rules",
      "details": {
        "rule": "domain=https://www.elastic.co, default allow all rule"
      },
      "comment": "The URL is allowed by one of the crawl rules"
    }
  ]
}</pre>
</div>
<h5><a id="web-crawler-apis-post-crawler-extract-url"></a>Extract content from a URL<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/7.16/app-search-docs/api-reference/web-crawler-api-reference.asciidoc">edit</a></h5>
<p>Use the web crawler to extract content from the given URL.</p>
<p>Use this operation to troubleshoot issues with content extraction at a specific URL.
For general URL validation, see <a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-post-crawler-validate-url" title="Validate a URL">Validate a URL</a>.</p>
<p>This operation visits the URL as the web crawler, without starting a full crawl, and extracts content.
The results reflect the current crawl configuration for the engine, and reveal how the web crawler sees the content at that URL <span class="strong strong"><strong>right now</strong></span>.
However, if the content is already indexed, the response includes that information as well.</p>
<p>This operation does not make changes to any documents in the engine.
Use this operation to identify and fix context extraction issues at a specific URL.
The content owner can fix the issues, and you can verfiy the fixes.
Repeat this process until the desired content is extracted.
After fixing all issues, start a new crawl to discover and extract the content at the URL.
See <a class="xref" href="web-crawler-api-reference.html#web-crawler-apis-post-crawler-crawl-requests" title="Create a new crawl request">Create a new crawl request</a>.</p>
<div class="pre_wrapper lang-bash">
<pre class="programlisting prettyprint lang-bash">POST /api/as/v0/engines/{ENGINE_NAME}/crawler/extract_url
{
  "url": {URL}
}</pre>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">url</code> (required)
</span>
</dt>
<dd>
The URL to crawl to extract content.
</dd>
</dl>
</div>
<p>For successful calls, the response is going to look like this:</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json"># 200 OK
{
  "url": "https://www.example.com",
  "normalized_url": "https://www.example.com/",
  "results": {
    "download": {
      "status_code": 200
    },
    "extraction": {
      "content_hash": "fb38982491c4a9377f8cf0c57e75e067bca65daf",
      "content_hash_fields": [
        "title",
        "body_content",
        "meta_keywords",
        "meta_description",
        "links",
        "headings"
      ],
      "content_fields": {
        "title": "Example Domain",
        "body_content": "Example Domain This domain is for use in illustrative examples in documents. You may use this domain in literature without prior coordination or asking for permission. More information...",
        "links": [
          "https://www.iana.org/domains/example"
        ],
        "headings": [
          "Example Domain"
        ]
      }
    },
    "indexing": {
      "document_id": null,
      "document_fields": null
    },
    "deduplication": {
      "urls_count": 0,
      "urls_sample": []
    }
  }
}</pre>
</div>
<p>Details for selected response fields:</p>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">results.deduplication</code>
</span>
</dt>
<dd>
The total count of URLs with this same content and a sample of those URLs.
See <a class="xref" href="web-crawler-reference.html#web-crawler-reference-content-deduplication" title="Duplicate document handling">Duplicate document handling</a>.
</dd>
<dt>
<span class="term">
<code class="literal">results.extraction.content_fields</code>
</span>
</dt>
<dd>
The content fields extracted by the crawler&#8212;&#8203;what the crawler will extract for the <span class="strong strong"><strong>next</strong></span> crawl.
</dd>
<dt>
<span class="term">
<code class="literal">results.extraction.content_hash</code>
</span>
</dt>
<dd>
The hash used to uniquely identify this content.
See <a class="xref" href="web-crawler-reference.html#web-crawler-reference-content-deduplication" title="Duplicate document handling">Duplicate document handling</a>.
</dd>
<dt>
<span class="term">
<code class="literal">results.extraction.content_hash_fields</code>
</span>
</dt>
<dd>
The document schema fields used to create the content hash.
See <a class="xref" href="web-crawler-reference.html#web-crawler-reference-content-deduplication" title="Duplicate document handling">Duplicate document handling</a>.
</dd>
<dt>
<span class="term">
<code class="literal">results.indexing</code>
</span>
</dt>
<dd>
The fields that are currently indexed&#8212;&#8203;what the crawler extracted during a <span class="strong strong"><strong>previous</strong></span> crawl (if any).
</dd>
</dl>
</div>
<h5><a id="web-crawler-apis-post-crawler-trace-url"></a>Trace a URL<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/7.16/app-search-docs/api-reference/web-crawler-api-reference.asciidoc">edit</a></h5>
<p>Trace the recent history of the given URL from the perspective of the web crawler.
Determine if the web crawler saw the URL, how it discovered it, and other events specific to that URL.
Use the response to see the history of a specific URL from the perspective of the web crawler, and debug any issues crawling the URL.</p>
<p>This operation provides a view of the <a class="xref" href="web-crawler-reference.html#web-crawler-reference-web-crawler-events-logs" title="Web crawler events logs">web crawler events logs</a> for a specific engine and URL.
The response returns an array of recent crawl requests, where each indicates if the URL was found.
This is followed by specific crawler events, grouped by type.
For details on each crawler event, see <a class="xref" href="web-crawler-events-logs-reference.html" title="Web crawler events logs reference">Web crawler events logs reference</a>.</p>
<div class="pre_wrapper lang-bash">
<pre class="programlisting prettyprint lang-bash">POST /api/as/v0/engines/{ENGINE_NAME}/crawler/trace_url
{
  "url": {URL}
}</pre>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">url</code> (required)
</span>
</dt>
<dd>
The URL to trace.
</dd>
</dl>
</div>
<p>For successful calls, the response is going to look like this:</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json"># 200 OK
{
  "url": "https://www.elastic.co/blog",
  "normalized_url": "https://www.elastic.co/blog",
  "crawl_requests": [
    {
      "crawl_request": {
        "id": "61240b9d2a02b14c1df12f98",
        "status": "running",
        "created_at": "2021-08-23T20:57:01Z",
        "begun_at": "2021-08-23T20:57:02Z",
        "completed_at": null
      },
      "found": true,
      "discover": [
        {
          "timestamp": "Mon, 23 Aug 2021 20:57:02 +0000",
          "event_id": "61240b9e2a02b11895f12f9e",
          "message": null,
          "event_type": "allowed",
          "deny_reason": null,
          "crawl_depth": 1,
          "source_url": null
        }
      ],
      "seed": {
        "timestamp": "Mon, 23 Aug 2021 20:57:02 +0000",
        "event_id": "61240b9e2a02b11895f12f9f",
        "message": null,
        "url_type": "content",
        "source_type": "seed-list",
        "source_url": null
      },
      "fetch": {
        "timestamp": "Mon, 23 Aug 2021 20:57:03 +0000",
        "event_id": "61240b9f2a02b1f7caf12fab",
        "message": null,
        "event_outcome": "failure",
        "duration_msec": 152.537107,
        "http_response": {
          "status_code": "301",
          "body_bytes": null
        },
        "redirect": {
          "location": "https://www.elastic.co/blog/",
          "chain": [],
          "count": 1
        }
      },
      "output": {
        "timestamp": "Mon, 23 Aug 2021 20:57:03 +0000",
        "event_id": "61240b9f2a02b1f7caf12fae",
        "message": "Successfully processed the 301 response",
        "event_outcome": "success",
        "event_module": "app_search",
        "duration_msec": 36.45282,
        "engine": {
          "id": "61240b592a02b19de7f12f8e",
          "name": "elastic-blog"
        },
        "document": {
          "id": null
        }
      }
    }
  ]
}</pre>
</div>
<p>If the given URL was not seen during the recent crawls, the response will look like this:</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json"># 200 OK
{
  "url": "https://github.com",
  "normalized_url": "https://github.com/",
  "crawl_requests": [
    {
      "crawl_request": {
        "id": "61240b9d2a02b14c1df12f98",
        "status": "canceled",
        "created_at": "2021-08-23T20:57:01Z",
        "begun_at": "2021-08-23T20:57:02Z",
        "completed_at": "2021-08-23T21:04:39Z"
      },
      "found": false,
      "discover": [],
      "seed": null,
      "fetch": null,
      "output": null
    }
  ]
}</pre>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="web-crawler-apis-user-agent"></a>User agent<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/7.16/app-search-docs/api-reference/web-crawler-api-reference.asciidoc">edit</a></h3>
</div></div></div>
<p>Responds with the User-Agent header used by the crawler.</p>
<div class="pre_wrapper lang-bash">
<pre class="programlisting prettyprint lang-bash">GET /api/as/v0/crawler/user_agent</pre>
</div>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json"># 200 OK
{
  "user_agent": "Elastic Crawler (0.0.1)"
}</pre>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="web-crawler-apis-domains"></a>Domains<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/7.16/app-search-docs/api-reference/web-crawler-api-reference.asciidoc">edit</a></h3>
</div></div></div>
<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="web-crawler-apis-get-crawler-domains"></a>List domains<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/7.16/app-search-docs/api-reference/web-crawler-api-reference.asciidoc">edit</a></h4>
</div></div></div>
<p>Returns a list of <a class="xref" href="web-crawler-reference.html#web-crawler-reference-domain" title="Domain">domains</a> for the given engine.</p>
<div class="pre_wrapper lang-bash">
<pre class="programlisting prettyprint lang-bash">GET /api/as/v0/engines/{ENGINE_NAME}/crawler/domains</pre>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">page[current]</code> (optional)
</span>
</dt>
<dd>
Current page number (default: 1).
</dd>
<dt>
<span class="term">
<code class="literal">page[size]</code> (optional)
</span>
</dt>
<dd>
Page size (default: 25). The maximum is 100, and be will truncated if a larger size is requested.
</dd>
</dl>
</div>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json"># 200 OK
{
  "meta": {
    "page": {
      "current": 1,
      "total_pages": 1,
      "total_results": 2,
      "size": 25
    }
  },
  "results": [
    {
      "id": "61a8eb863932dd78141fb0df",
      "name": "https://www.elastic.co",
      "document_count": 0,
      "entry_points": [
        {
          "id": "61a8a1ed3932ddd80cc4b719",
          "value": "/"
        }
      ],
      "crawl_rules": [],
      "default_crawl_rule": {
        "id": "-",
        "order": 0,
        "policy": "allow",
        "rule": "regex",
        "pattern": ".*"
      },
      "sitemaps": []
    },
    {
      "id": "61a8a1ed3932ddd80cc4b718",
      "name": "https://swiftype.com",
      "document_count": 0,
      "entry_points": [
        {
          "id": "61a8eb863932dd78141fb0e0",
          "value": "/"
        }
      ],
      "crawl_rules": [],
      "default_crawl_rule": {
        "id": "-",
        "order": 0,
        "policy": "allow",
        "rule": "regex",
        "pattern": ".*"
      },
      "sitemaps": []
    }
  ]
}</pre>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="web-crawler-apis-post-crawler-domains"></a>Create a new domain<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/7.16/app-search-docs/api-reference/web-crawler-api-reference.asciidoc">edit</a></h4>
</div></div></div>
<p>Create a (crawler) domain for a given App Search engine.</p>
<div class="pre_wrapper lang-bash">
<pre class="programlisting prettyprint lang-bash">POST /api/as/v0/engines/{ENGINE_NAME}/crawler/domains
{
  "name": {STRING}
}</pre>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">name</code> (required)
</span>
</dt>
<dd>
The domain URL.
</dd>
</dl>
</div>
<p>For successful calls, the response is going to look like this:</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json"># 200 OK
{
  "id": "{DOMAIN_ID}",
  "name": "{DOMAIN_NAME}",
  "document_count": 0,
  "entry_points": [
    {
      "id": "6087cec06dda9bdfb4a49e39",
      "value": "/"
    }
  ],
  "crawl_rules": [],
  "default_crawl_rule": {
    "id": "-",
    "order": 0,
    "policy": "allow",
    "rule": "regex",
    "pattern": ".*"
  },
  "sitemaps": []
}</pre>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="web-crawler-apis-get-crawler-domain"></a>View details for a domain<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/7.16/app-search-docs/api-reference/web-crawler-api-reference.asciidoc">edit</a></h4>
</div></div></div>
<p>Get domain object for a given App Search engine.</p>
<div class="pre_wrapper lang-bash">
<pre class="programlisting prettyprint lang-bash">GET /api/as/v0/engines/{ENGINE_NAME}/crawler/domains/{DOMAIN_ID}</pre>
</div>
<p>For successful calls, the response is going to look like this:</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json"># 200 OK
{
  "id": "{DOMAIN_ID}",
  "name": "{DOMAIN_NAME}",
  "document_count": 0,
  "entry_points": [
    {
      "id": "6087cec06dda9bdfb4a49e39",
      "value": "/"
    }
  ],
  "crawl_rules": [],
  "default_crawl_rule": {
    "id": "-",
    "order": 0,
    "policy": "allow",
    "rule": "regex",
    "pattern": ".*"
  },
  "sitemaps": []
}</pre>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="web-crawler-apis-put-crawler-domain"></a>Update a domain<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/7.16/app-search-docs/api-reference/web-crawler-api-reference.asciidoc">edit</a></h4>
</div></div></div>
<p>Updates a domain for a given App Search engine.</p>
<div class="pre_wrapper lang-bash">
<pre class="programlisting prettyprint lang-bash">PUT /api/as/v0/engines/{ENGINE_NAME}/crawler/domains/{DOMAIN_ID}
{
  "name": {STRING}
}</pre>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">name</code>
</span>
</dt>
<dd>
The domain URL.
</dd>
</dl>
</div>
<p>For successful calls, the response is going to look like this:</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json"># 200 OK
{
  "id": "{DOMAIN_ID}",
  "name": "{DOMAIN_NAME}",
  "document_count": 0,
  "entry_points": [
    {
      "id": "6087cec06dda9bdfb4a49e39",
      "value": "/"
    }
  ],
  "crawl_rules": [],
  "default_crawl_rule": {
    "id": "-",
    "order": 0,
    "policy": "allow",
    "rule": "regex",
    "pattern": ".*"
  },
  "sitemaps": []
}</pre>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="web-crawler-apis-delete-crawler-domain"></a>Delete a domain<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/7.16/app-search-docs/api-reference/web-crawler-api-reference.asciidoc">edit</a></h4>
</div></div></div>
<p>Deletes a domain for a given App Search engine.</p>
<div class="pre_wrapper lang-bash">
<pre class="programlisting prettyprint lang-bash">DELETE /api/as/v0/engines/{ENGINE_NAME}/crawler/domains/{DOMAIN_ID}</pre>
</div>
<p>In case of success, the response contains an object showing the domain has been deleted:</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json"># 200 OK
{
  "deleted": true
}</pre>
</div>
</div>

</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="web-crawler-apis-entry-points"></a>Entry points<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/7.16/app-search-docs/api-reference/web-crawler-api-reference.asciidoc">edit</a></h3>
</div></div></div>
<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="web-crawler-apis-post-entry-points"></a>Create a new entry point<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/7.16/app-search-docs/api-reference/web-crawler-api-reference.asciidoc">edit</a></h4>
</div></div></div>
<p>Create an entry point for a domain.</p>
<div class="pre_wrapper lang-bash">
<pre class="programlisting prettyprint lang-bash">POST /api/as/v0/engines/{ENGINE_NAME}/crawler/domains/{DOMAIN_ID}/entry_points
{
  "value": {STRING}
}</pre>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">value</code> (required)
</span>
</dt>
<dd>
The entry point path.
</dd>
</dl>
</div>
<p>For successful calls, the response is going to look like this:</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json"># 200 OK
{
  "id": "{ENTRY_POINT_ID}",
  "value": "/blog"
}</pre>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="web-crawler-apis-put-entry-point"></a>Update an entry point<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/7.16/app-search-docs/api-reference/web-crawler-api-reference.asciidoc">edit</a></h4>
</div></div></div>
<p>Updates an entry point for a domain.</p>
<div class="pre_wrapper lang-bash">
<pre class="programlisting prettyprint lang-bash">PUT /api/as/v0/engines/{ENGINE_NAME}/crawler/domains/{DOMAIN_ID}/entry_points/{ENTRY_POINT_ID}
{
  "value": {STRING}
}</pre>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">value</code>
</span>
</dt>
<dd>
The entry point path.
</dd>
</dl>
</div>
<p>For successful calls, the response is going to look like this:</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json"># 200 OK
{
  "id": "{ENTRY_POINT_ID}",
  "value": "/blog"
}</pre>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="web-crawler-apis-delete-entry-point"></a>Delete an entry point<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/7.16/app-search-docs/api-reference/web-crawler-api-reference.asciidoc">edit</a></h4>
</div></div></div>
<p>Deletes an entry point for a domain.</p>
<div class="pre_wrapper lang-bash">
<pre class="programlisting prettyprint lang-bash">DELETE /api/as/v0/engines/{ENGINE_NAME}/crawler/domains/{DOMAIN_ID}/entry_points/{ENTRY_POINT_ID}</pre>
</div>
<p>In case of success, the response contains an object showing the entry point has been deleted:</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json"># 200 OK
{
  "deleted": true
}</pre>
</div>
</div>

</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="web-crawler-apis-crawl-rules"></a>Crawl rules<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/7.16/app-search-docs/api-reference/web-crawler-api-reference.asciidoc">edit</a></h3>
</div></div></div>
<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="web-crawler-apis-post-crawl-rules"></a>Create a new crawl rule<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/7.16/app-search-docs/api-reference/web-crawler-api-reference.asciidoc">edit</a></h4>
</div></div></div>
<p>Create a crawl rule for a domain.</p>
<div class="pre_wrapper lang-bash">
<pre class="programlisting prettyprint lang-bash">POST /api/as/v0/engines/{ENGINE_NAME}/crawler/domains/{DOMAIN_ID}/crawl_rules
{
  "policy": {ENUM},
  "rule": {ENUM},
  "pattern": {STRING},
  "order": {INTEGER}
}</pre>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">policy</code> (required)
</span>
</dt>
<dd>
Accepted values are <code class="literal">allow</code> and <code class="literal">deny</code>.
</dd>
<dt>
<span class="term">
<code class="literal">rule</code> (required)
</span>
</dt>
<dd>
Accepted values are <code class="literal">begins</code>, <code class="literal">ends</code>, <code class="literal">contains</code> and <code class="literal">regex</code>.
</dd>
<dt>
<span class="term">
<code class="literal">pattern</code> (required)
</span>
</dt>
<dd>
The path pattern to match against.
</dd>
<dt>
<span class="term">
<code class="literal">order</code> (optional)
</span>
</dt>
<dd>
An integer representing this crawl rule&#8217;s position within the list of crawl rules for the domain. The <a class="xref" href="web-crawler-reference.html#web-crawler-reference-crawl-rule-order" title="Crawl rule order">order of crawl rules</a> is significant.
</dd>
</dl>
</div>
<p>For successful calls, the response is going to look like this:</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json"># 200 OK
{
  "id": "{CRAWL_RULE_ID}",
  "order": 0,
  "policy": "allow",
  "rule": "begins",
  "pattern": "/ignore"
}</pre>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="web-crawler-apis-put-crawl-rule"></a>Update a crawl rule<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/7.16/app-search-docs/api-reference/web-crawler-api-reference.asciidoc">edit</a></h4>
</div></div></div>
<p>Updates a crawl rule for a domain.</p>
<div class="pre_wrapper lang-bash">
<pre class="programlisting prettyprint lang-bash">PUT /api/as/v0/engines/{ENGINE_NAME}/crawler/domains/{DOMAIN_ID}/crawl_rules/{CRAWL_RULE_ID}
{
  "policy": {ENUM},
  "rule": {ENUM},
  "pattern": {STRING},
  "order": {INTEGER}
}</pre>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">policy</code>
</span>
</dt>
<dd>
Accepted values are <code class="literal">allow</code> and <code class="literal">deny</code>.
</dd>
<dt>
<span class="term">
<code class="literal">rule</code>
</span>
</dt>
<dd>
Accepted values are <code class="literal">begins</code>, <code class="literal">ends</code>, <code class="literal">contains</code> and <code class="literal">regex</code>.
</dd>
<dt>
<span class="term">
<code class="literal">pattern</code>
</span>
</dt>
<dd>
The path pattern to match against.
</dd>
<dt>
<span class="term">
<code class="literal">order</code>
</span>
</dt>
<dd>
An integer representing this crawl rule&#8217;s position within the list of crawl rules for the domain. The <a class="xref" href="web-crawler-reference.html#web-crawler-reference-crawl-rule-order" title="Crawl rule order">order of crawl rules</a> is significant.
</dd>
</dl>
</div>
<p>For successful calls, the response is going to look like this:</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json"># 200 OK
{
  "id": "{CRAWL_RULE_ID}",
  "order": 0,
  "policy": "allow",
  "rule": "begins",
  "pattern": "/ignore"
}</pre>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="web-crawler-apis-delete-crawl-rule"></a>Delete a crawl rule<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/7.16/app-search-docs/api-reference/web-crawler-api-reference.asciidoc">edit</a></h4>
</div></div></div>
<p>Deletes a crawl rule for a domain.</p>
<div class="pre_wrapper lang-bash">
<pre class="programlisting prettyprint lang-bash">DELETE /api/as/v0/engines/{ENGINE_NAME}/crawler/domains/{DOMAIN_ID}/crawl_rules/{CRAWL_RULE_ID}</pre>
</div>
<p>In case of success, the response contains an object showing the crawl rule has been deleted:</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json"># 200 OK
{
  "deleted": true
}</pre>
</div>
</div>

</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="web-crawler-apis-sitemaps"></a>Sitemaps<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/7.16/app-search-docs/api-reference/web-crawler-api-reference.asciidoc">edit</a></h3>
</div></div></div>
<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="web-crawler-apis-post-sitemaps"></a>Create a new sitemap<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/7.16/app-search-docs/api-reference/web-crawler-api-reference.asciidoc">edit</a></h4>
</div></div></div>
<p>Create a sitemap for a domain.</p>
<div class="pre_wrapper lang-bash">
<pre class="programlisting prettyprint lang-bash">POST /api/as/v0/engines/{ENGINE_NAME}/crawler/domains/{DOMAIN_ID}/sitemaps
{
  "url": {STRING}
}</pre>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">url</code> (required)
</span>
</dt>
<dd>
The sitemap URL.
</dd>
</dl>
</div>
<p>For successful calls, the response is going to look like this:</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json"># 200 OK
{
  "id": "{SITEMAP_ID}",
  "url": "https://elastic.co/sitemap2.xml"
}</pre>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="web-crawler-apis-put-sitemap"></a>Update a sitemap<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/7.16/app-search-docs/api-reference/web-crawler-api-reference.asciidoc">edit</a></h4>
</div></div></div>
<p>Updates a sitemap for a domain.</p>
<div class="pre_wrapper lang-bash">
<pre class="programlisting prettyprint lang-bash">PUT /api/as/v0/engines/{ENGINE_NAME}/crawler/domains/{DOMAIN_ID}/sitemaps/{SITEMAP_ID}
{
  "url": {STRING}
}</pre>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">url</code>
</span>
</dt>
<dd>
The sitemap URL.
</dd>
</dl>
</div>
<p>For successful calls, the response is going to look like this:</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json"># 200 OK
{
  "id": "{SITEMAP_ID}",
  "url": "https://elastic.co/sitemap2.xml"
}</pre>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="web-crawler-apis-delete-sitemap"></a>Delete a sitemap<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/7.16/app-search-docs/api-reference/web-crawler-api-reference.asciidoc">edit</a></h4>
</div></div></div>
<p>Deletes a sitemap for a domain.</p>
<div class="pre_wrapper lang-bash">
<pre class="programlisting prettyprint lang-bash">DELETE /api/as/v0/engines/{ENGINE_NAME}/crawler/domains/{DOMAIN_ID}/sitemaps/{SITEMAP_ID}</pre>
</div>
<p>In case of success, the response contains an object showing the sitemap has been deleted:</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json"># 200 OK
{
  "deleted": true
}</pre>
</div>
</div>

</div>

</div>
<div class="navfooter">
<span class="prev">
<a href="synonyms.html">« Synonyms API</a>
</span>
<span class="next">
<a href="api-clients.html">API Clients »</a>
</span>
</div>
</div>

                  <!-- end body -->
                </div>

                <div class="col-12 order-3 col-lg-2 order-lg-3 h-almost-full-lg sticky-top-lg" id="right_col">
                  <div id="sticky_content">
                    <!-- The OTP is appended here -->
                    <div class="row">
                      <div class="col-0 col-md-4 col-lg-0" id="bottom_left_col"></div>
                      <div class="col-12 col-md-8 col-lg-12">
                        <div id="rtpcontainer">
                          <div class="mktg-promo" id="most-popular">
                            <p class="aside-heading">Most Popular</p>
                            <div class="pb-2">
                              <p class="media-type">Video</p>
                              <a href="https://www.elastic.co/webinars/getting-started-elasticsearch?baymax=default&elektra=docs&storm=top-video">
                                <p class="mb-0">Get Started with Elasticsearch</p>
                              </a>
                            </div>
                            <div class="pb-2">
                              <p class="media-type">Video</p>
                              <a href="https://www.elastic.co/webinars/getting-started-kibana?baymax=default&elektra=docs&storm=top-video">
                                <p class="mb-0">Intro to Kibana</p>
                              </a>
                            </div>
                            <div class="pb-2">
                              <p class="media-type">Video</p>
                              <a href="https://www.elastic.co/webinars/introduction-elk-stack?baymax=default&elektra=docs&storm=top-video">
                                <p class="mb-0">ELK for Logs & Metrics</p>
                              </a>
                            </div>
                          </div>
                        </div>
                      </div>
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </section>

        </div>


<div id='elastic-footer'></div>
<script src='https://www.elastic.co/elastic-footer.js'></script>
<!-- Footer Section end-->

      </section>
    </div>

<script src="/guide/static/jquery.js"></script>
<script type="text/javascript" src="/guide/static/docs.js"></script>
<script type="text/javascript">
  window.initial_state = {}</script>
  </body>
</html>
