<!DOCTYPE html>
<html lang="en-us">
  <head>
    
<meta charset="UTF-8">
<title>Using failure stores to address ingestion issues | Elasticsearch Guide [8.19] | Elastic</title>
<meta class="elastic" name="content" content="Using failure stores to address ingestion issues | Elasticsearch Guide [8.19]">

<link rel="home" href="index.html" title="Elasticsearch Guide [8.19]"/>
<link rel="up" href="failure-store.html" title="Failure store"/>
<link rel="prev" href="failure-store.html" title="Failure store"/>
<link rel="next" href="ingest.html" title="Ingest pipelines"/>
<meta class="elastic" name="product_version" content="8.19"/>
<meta class="elastic" name="product_name" content="Elasticsearch"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/Elasticsearch/Reference/8.19"/>
<meta name="DC.subject" content="Elasticsearch"/>
<meta name="DC.identifier" content="8.19"/>

    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <script src="https://cdn.optimizely.com/js/18132920325.js"></script>
    <link rel="apple-touch-icon" sizes="57x57" href="/apple-icon-57x57.png">
    <link rel="apple-touch-icon" sizes="60x60" href="/apple-icon-60x60.png">
    <link rel="apple-touch-icon" sizes="72x72" href="/apple-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="76x76" href="/apple-icon-76x76.png">
    <link rel="apple-touch-icon" sizes="114x114" href="/apple-icon-114x114.png">
    <link rel="apple-touch-icon" sizes="120x120" href="/apple-icon-120x120.png">
    <link rel="apple-touch-icon" sizes="144x144" href="/apple-icon-144x144.png">
    <link rel="apple-touch-icon" sizes="152x152" href="/apple-icon-152x152.png">
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-icon-180x180.png">
    <link rel="icon" type="image/png" href="/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="/android-chrome-192x192.png" sizes="192x192">
    <link rel="icon" type="image/png" href="/favicon-96x96.png" sizes="96x96">
    <link rel="icon" type="image/png" href="/favicon-16x16.png" sizes="16x16">
    <link rel="manifest" href="/manifest.json">
    <meta name="apple-mobile-web-app-title" content="Elastic">
    <meta name="application-name" content="Elastic">
    <meta name="msapplication-TileColor" content="#ffffff">
    <meta name="msapplication-TileImage" content="/mstile-144x144.png">
    <meta name="theme-color" content="#ffffff">
    <meta name="naver-site-verification" content="936882c1853b701b3cef3721758d80535413dbfd" />
    <meta name="yandex-verification" content="d8a47e95d0972434" />
    <meta name="localized" content="true" />
    <meta name="st:robots" content="follow,index" />
    <meta property="og:image" content="https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/blt280217a63b82a734/6202d3378b1f312528798412/elastic-logo.svg" />
    <meta property="og:image:width" content="500" />
    <meta property="og:image:height" content="172" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <link rel="apple-touch-icon-precomposed" sizes="64x64" href="/favicon_64x64_16bit.png">
    <link rel="apple-touch-icon-precomposed" sizes="32x32" href="/favicon_32x32.png">
    <link rel="apple-touch-icon-precomposed" sizes="16x16" href="/favicon_16x16.png">
    <!-- Give IE8 a fighting chance -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    <link rel="stylesheet" type="text/css" href="/guide/static/styles-v1.css" />
  </head>

  <!--© 2015-2025 Elasticsearch B.V. -->
  <!-- All Elastic documentation is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License. -->
  <!-- http://creativecommons.org/licenses/by-nc-nd/4.0/ -->

  <body>
    <!-- Google Tag Manager -->
    <script>dataLayer = [];</script><noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-58RLH5" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start': new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0], j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src= '//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f); })(window,document,'script','dataLayer','GTM-58RLH5');</script>
    <!-- End Google Tag Manager -->

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-12395217-16"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-12395217-16');
    </script>

    <!-- Google Tag Manager for GA4 -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start': new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0], j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-KNJMG2M');</script>
    <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-KNJMG2M" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    <!-- End Google Tag Manager for GA4-->

    <div id='elastic-nav' style="display:none;"></div>
    <script src='https://www.elastic.co/elastic-nav.js'></script>

    <div class="main-container">
      <section id="content" >
        <div class="content-wrapper">

          <section id="guide" lang="en">
            <div class="container-fluid">
              <div class="row pb-3">
                <div class="col-12 order-2 col-md-4 order-md-1 col-lg-3 h-almost-full-md sticky-top-md" id="left_col">
                  <!-- The TOC is appended here -->
                </div>

                <div class="col-12 order-1 col-md-8 order-md-2 col-lg-7 order-lg-2 guide-section" id="middle_col">
                  <!-- start body -->
                  
<div class="navheader">
<span class="prev">
<a href="failure-store.html">« Failure store</a>
</span>
<span class="next">
<a href="ingest.html">Ingest pipelines »</a>
</span>
</div>
<div class="book" lang="en">
<div class="titlepage">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Elasticsearch Guide [8.19]</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="data-streams.html">Data streams</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="failure-store.html">Failure store</a></span>
</div>
<div>
<div><h1 class="title"><a id="id-1"></a>Using failure stores to address ingestion issues</h1><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.19/docs/reference/data-streams/failure-store-recipes.asciidoc">edit</a></div>
</div>
<!--EXTRA-->
</div>
<div id="content">
<div id="url-to-v3" class="version-warning">
    <strong>IMPORTANT</strong>: This documentation is no longer updated. Refer to <a href="https://www.elastic.co/support/eol">Elastic's version policy</a> and the <a href="https://www.elastic.co/docs/manage-data/data-store/data-streams/failure-store-recipes">latest documentation</a>.
</div>
<div class="section">
<div class="titlepage"><div><div>
<div class="position-relative"><h2 class="title"><a id="failure-store-recipes"></a>Using failure stores to address ingestion issues</h2><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.19/docs/reference/data-streams/failure-store-recipes.asciidoc">edit</a></div>
</div></div></div>
<p>When something goes wrong during ingestion it is often not an isolated event. Included for your convenience are some examples of how you can use the failure store to quickly respond to ingestion failures and get your indexing back on track.</p>
<div class="section">
<div class="titlepage"><div><div>
<div class="position-relative"><h3 class="title"><a id="failure-store-examples-nested-ingest-troubleshoot"></a>Troubleshooting nested ingest pipelines</h3><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.19/docs/reference/data-streams/failure-store-recipes.asciidoc">edit</a></div>
</div></div></div>
<p>When a document fails in an ingest pipeline it can be difficult to figure out exactly what went wrong and where. When these failures are captured by the failure store during this part of the ingestion process, they will contain additional debugging information. Failed documents will note the type of processor and which pipeline was executing when the failure occurred. Failed documents will also contain a pipeline trace which keeps track of any nested pipeline calls that the document was in at time of failure.</p>
<p>To demonstrate this, we will follow a failed document through an unfamiliar data stream and ingest pipeline:</p>
<a id="10326e9a0a29ccb94c2d25bfbf063450"></a>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">POST my-datastream-ingest/_doc?refresh=true
{
    "@timestamp": "2025-04-21T00:00:00Z",
    "important": {
      "info": "The rain in Spain falls mainly on the plain"
    }
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/814.console"></div>
<a id="5f4ec7300c1fceb6a07070a221e8f192"></a>
<div class="pre_wrapper lang-console-result">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console-result">{
  "_index": ".fs-my-datastream-ingest-2025.05.09-000001",
  "_id": "F3S3s5YBwrYNjPmayMr9",
  "_version": 1,
  "result": "created",
  "_shards": {
    "total": 1,
    "successful": 1,
    "failed": 0
  },
  "_seq_no": 2,
  "_primary_term": 1,
  "failure_store": "used", <a id="CO265-1"></a><i class="conum" data-value="1"></i>
  "forced_refresh": true
}</pre>
</div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO265-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>The document was sent to the failure store.</p>
</td>
</tr>
</table>
</div>
<p>Now we search the failure store to check the failure document to see what went wrong.</p>
<a id="8203c7e97fb51c9a7e20cbb9f95db9af"></a>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">GET my-datastream-ingest::failures/_search</pre>
</div>
<div class="console_widget" data-snippet="snippets/815.console"></div>
<a id="2d8af4eb25029e13dce6d3dc34682b48"></a>
<div class="pre_wrapper lang-console-result">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console-result">{
  "took": 0,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 1,
      "relation": "eq"
    },
    "max_score": 1.0,
    "hits": [
      {
        "_index": ".fs-my-datastream-ingest-2025.05.09-000001",
        "_id": "F3S3s5YBwrYNjPmayMr9",
        "_score": 1.0,
        "_source": {
          "@timestamp": "2025-05-09T06:24:48.381Z",
          "document": {
            "index": "my-datastream-ingest",
            "source": { <a id="CO266-1"></a><i class="conum" data-value="1"></i>
              "important": {
                "info": "The rain in Spain falls mainly on the plain" <a id="CO266-2"></a><i class="conum" data-value="2"></i>
              },
              "@timestamp": "2025-04-21T00:00:00Z"
            }
          },
          "error": {
            "type": "illegal_argument_exception",
            "message": "field [info] not present as part of path [important.info]", <a id="CO266-3"></a><i class="conum" data-value="3"></i>
            "stack_trace": "j.l.IllegalArgumentException: field [info] not present as part of path [important.info]\n\tat o.e.i.IngestDocument.getFieldValue(IngestDocument.java:201)\n\tat o.e.i.c.SetProcessor.execute(SetProcessor.java:85)\n\t... 19 more\n",
            "pipeline_trace": [ <a id="CO266-4"></a><i class="conum" data-value="4"></i>
              "ingest-step-1",
              "ingest-step-2"
            ],
            "pipeline": "ingest-step-2", <a id="CO266-5"></a><i class="conum" data-value="5"></i>
            "processor_type": "set" <a id="CO266-6"></a><i class="conum" data-value="6"></i>
          }
        }
      }
    ]
  }
}</pre>
</div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO266-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>When an ingest pipeline fails, the document stored is what was originally sent to the cluster.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO266-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p>The important information that we failed to find was originally present in the document.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO266-3"><i class="conum" data-value="3"></i></a></p>
</td>
<td align="left" valign="top">
<p>The info field was not present when the failure occurred.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO266-4"><i class="conum" data-value="4"></i></a></p>
</td>
<td align="left" valign="top">
<p>The first pipeline called the second pipeline.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO266-5"><i class="conum" data-value="5"></i></a></p>
</td>
<td align="left" valign="top">
<p>The document failed in the second pipeline.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO266-6"><i class="conum" data-value="6"></i></a></p>
</td>
<td align="left" valign="top">
<p>It failed in the pipeline&#8217;s set processor.</p>
</td>
</tr>
</table>
</div>
<p>Despite not knowing the pipelines beforehand, we have some places to start looking. The <code class="literal">ingest-step-2</code> pipeline cannot find the <code class="literal">important.info</code> field despite it being present in the document that was sent to the cluster. If we pull that pipeline definition we find the following:</p>
<a id="4ffe95418e2506a53e61f899c6fa65fe"></a>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">GET _ingest/pipeline/ingest-step-2</pre>
</div>
<div class="console_widget" data-snippet="snippets/816.console"></div>
<a id="3740ebe598522e30aece09ceb6a35754"></a>
<div class="pre_wrapper lang-console-result">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console-result">{
  "ingest-step-2": {
    "processors": [
      {
        "set": { <a id="CO267-1"></a><i class="conum" data-value="1"></i>
          "field": "copy.info",
          "copy_from": "important.info" <a id="CO267-2"></a><i class="conum" data-value="2"></i>
        }
      }
    ]
  }
}</pre>
</div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO267-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>There is only one processor here.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO267-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p>This field was missing from the document at this point.</p>
</td>
</tr>
</table>
</div>
<p>There is only a set processor in the <code class="literal">ingest-step-2</code> pipeline so this is likely not where the root problem is. Remembering the <code class="literal">pipeline_trace</code> field on the failure we find that <code class="literal">ingest-step-1</code> was the original pipeline called for this document. It is likely the data stream&#8217;s default pipeline. Pulling its definition we find the following:</p>
<a id="b8e2313bb122506a943e99dcbb1c2114"></a>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">GET _ingest/pipeline/ingest-step-1</pre>
</div>
<div class="console_widget" data-snippet="snippets/817.console"></div>
<a id="92d6bc06d54f0b4cbc026560a36349f8"></a>
<div class="pre_wrapper lang-console-result">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console-result">{
  "ingest-step-1": {
    "processors": [
      {
        "remove": {
          "field": "important.info" <a id="CO268-1"></a><i class="conum" data-value="1"></i>
        }
      },
      {
        "pipeline": {
          "name": "ingest-step-2" <a id="CO268-2"></a><i class="conum" data-value="2"></i>
        }
      }
    ]
  }
}</pre>
</div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO268-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>A remove processor that is incorrectly removing our important field.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO268-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p>The call to the second pipeline.</p>
</td>
</tr>
</table>
</div>
<p>We find a remove processor in the first pipeline that is the root cause of the problem! The pipeline should be updated to not remove important data, or the downstream pipeline should be changed to not expect the important data to be always present.</p>
<a id="3898028040335d36f2daae9eee6b550b"></a>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">PUT _ingest/pipeline/ingest-step-2
{
  "processors": [
    {
      "set": {
        "field": "copy.info",
        "copy_from": "important.info",
        "ignore_empty_value": true
      }
    }
  ]
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/818.console"></div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<div class="position-relative"><h3 class="title"><a id="failure-store-examples-complicated-ingest-troubleshoot"></a>Troubleshooting complicated ingest pipelines</h3><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.19/docs/reference/data-streams/failure-store-recipes.asciidoc">edit</a></div>
</div></div></div>
<p>Ingest processors can be labeled with tags. These tags are user-provided information that names or describes the processor&#8217;s purpose in the pipeline. When documents are redirected to the failure store due to a processor issue, they capture the tag from the processor in which the failure occurred, if it exists. Because of this behavior, it is a good practice to tag the processors in your pipeline so that the location of a failure can be identified quickly.</p>
<p>Here we have a needlessly complicated pipeline. It is made up of several set and remove processors. Beneficially, they are all tagged with descriptive names.</p>
<a id="b3506229aa2d84acb7cc06a9586b8318"></a>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">PUT _ingest/pipeline/complicated-processor
{
  "processors": [
    {
      "set": {
        "tag": "initialize counter",
        "field": "counter",
        "value": "1"
      }
    },
    {
      "set": {
        "tag": "copy counter to new",
        "field": "new_counter",
        "copy_from": "counter"
      }
    },
    {
      "remove": {
        "tag": "remove old counter",
        "field": "counter"
      }
    },
    {
      "set": {
        "tag": "transfer counter back",
        "field": "counter",
        "copy_from": "new_counter"
      }
    },
    {
      "remove": {
        "tag": "remove counter again",
        "field": "counter"
      }
    },
    {
      "set": {
        "tag": "copy to new counter again",
        "field": "new_counter",
        "copy_from": "counter"
      }
    }
  ]
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/819.console"></div>
<p>We ingest some data and find that it was sent to the failure store.</p>
<a id="bc4299ad1c9e910815f1acbea7aa2645"></a>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">POST my-datastream-ingest/_doc?refresh=true
{
    "@timestamp": "2025-04-21T00:00:00Z",
    "counter_name": "test"
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/820.console"></div>
<a id="0ea8af7cbd34ff0625e68b3317e83a53"></a>
<div class="pre_wrapper lang-console-result">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console-result">{
  "_index": ".fs-my-datastream-ingest-2025.05.09-000001",
  "_id": "HnTJs5YBwrYNjPmaFcri",
  "_version": 1,
  "result": "created",
  "_shards": {
    "total": 1,
    "successful": 1,
    "failed": 0
  },
  "_seq_no": 1,
  "_primary_term": 1,
  "failure_store": "used",
  "forced_refresh": true
}</pre>
</div>
<p>On checking the failure, we can quickly identify the tagged processor that caused the problem.</p>
<a id="8203c7e97fb51c9a7e20cbb9f95db9af"></a>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">GET my-datastream-ingest::failures/_search</pre>
</div>
<div class="console_widget" data-snippet="snippets/821.console"></div>
<a id="a5f7f7bbe299490526f425e4a834bf4f"></a>
<div class="pre_wrapper lang-console-result">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console-result">{
  "took": 0,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 1,
      "relation": "eq"
    },
    "max_score": 1.0,
    "hits": [
      {
        "_index": ".fs-my-datastream-ingest-2025.05.09-000001",
        "_id": "HnTJs5YBwrYNjPmaFcri",
        "_score": 1.0,
        "_source": {
          "@timestamp": "2025-05-09T06:41:24.775Z",
          "document": {
            "index": "my-datastream-ingest",
            "source": {
              "@timestamp": "2025-04-21T00:00:00Z",
              "counter_name": "test"
            }
          },
          "error": {
            "type": "illegal_argument_exception",
            "message": "field [counter] not present as part of path [counter]",
            "stack_trace": "j.l.IllegalArgumentException: field [counter] not present as part of path [counter]\n\tat o.e.i.IngestDocument.getFieldValue(IngestDocument.java:201)\n\tat o.e.i.c.SetProcessor.execute(SetProcessor.java:85)\n\t... 14 more\n",
            "pipeline_trace": [
              "complicated-processor"
            ],
            "pipeline": "complicated-processor",
            "processor_type": "set", <a id="CO269-1"></a><i class="conum" data-value="1"></i>
            "processor_tag": "copy to new counter again" <a id="CO269-2"></a><i class="conum" data-value="2"></i>
          }
        }
      }
    ]
  }
}</pre>
</div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO269-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>Helpful, but which set processor on the pipeline could it be?</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO269-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p>The tag of the exact processor that the document failed on.</p>
</td>
</tr>
</table>
</div>
<p>Without tags in place it would not be as clear where in the pipeline the indexing problem occurred. Tags provide a unique identifier for a processor that can be quickly referenced in case of an ingest failure.</p>
<a id="a73782426586c00b79a30ae55850f8b0"></a>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">PUT _ingest/pipeline/complicated-processor
{
  "processors": [
    {
      "set": {
        "tag": "initialize counter",
        "field": "counter",
        "value": "1"
      }
    },
    {
      "set": {
        "tag": "copy counter to new",
        "field": "new_counter",
        "copy_from": "counter"
      }
    },
    {
      "remove": {
        "tag": "remove old counter",
        "field": "counter"
      }
    },
    {
      "set": {
        "tag": "transfer counter back",
        "field": "counter",
        "copy_from": "new_counter"
      }
    },
    {
      "remove": {
        "tag": "remove counter again",
        "field": "new_counter" <a id="CO270-1"></a><i class="conum" data-value="1"></i>
      }
    },
    {
      "set": {
        "tag": "copy to new counter again",
        "field": "new_counter",
        "copy_from": "counter"
      }
    }
  ]
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/822.console"></div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO270-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>Fixing the field name on the broken processor</p>
</td>
</tr>
</table>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<div class="position-relative"><h3 class="title"><a id="failure-store-examples-alerting"></a>Alerting on failed ingestion</h3><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.19/docs/reference/data-streams/failure-store-recipes.asciidoc">edit</a></div>
</div></div></div>
<p>Since failure stores can be searched just like a normal data stream, we can use them as inputs to <a href="/guide/en/kibana/8.19/alerting-getting-started.html" class="ulink" target="_top">alerting rules</a> in Kibana. Here is a simple alerting example that is triggered when more than ten indexing failures have occurred in the last five minutes for a data stream:</p>
<div class="section">
<div class="titlepage"><div><div>
<div class="position-relative"><h4 class="title"><a id="_step_1_create_a_failure_store_data_view"></a>Step 1: Create a failure store data view</h4><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.19/docs/reference/data-streams/failure-store-recipes.asciidoc">edit</a></div>
</div></div></div>
<p>If you want to use KQL or Lucene query types, you should first create a data view for your failure store data.
If you plan to use ES|QL or the Query DSL query types, this step is not required.
Navigate to the data view page in Kibana and add a new data view. Set the index pattern to your failure store using the selector syntax.</p>
<div class="imageblock">
<div class="content">
<img src="images/data-streams/failure_store_alerting_create_data_view.png" alt="create a data view using the failure store syntax in the index name">
</div>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<div class="position-relative"><h4 class="title"><a id="_step_2_create_new_rule"></a>Step 2: Create new rule</h4><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.19/docs/reference/data-streams/failure-store-recipes.asciidoc">edit</a></div>
</div></div></div>
<p>Navigate to Management / Alerts and Insights / Rules. Create a new rule. Choose the Elasticsearch query option.</p>
<div class="imageblock">
<div class="content">
<img src="images/data-streams/failure_store_alerting_create_rule.png" alt="create a new alerting rule and select the elasticsearch query option">
</div>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<div class="position-relative"><h4 class="title"><a id="_step_3_pick_your_query_type"></a>Step 3: Pick your query type</h4><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.19/docs/reference/data-streams/failure-store-recipes.asciidoc">edit</a></div>
</div></div></div>
<p>Choose which query type you wish to use
For KQL/Lucene queries, reference the data view that contains your failure store.</p>
<div class="imageblock">
<div class="content">
<img src="images/data-streams/failure_store_alerting_kql.png" alt="use the data view created in the previous step as the input to the kql query">
</div>
</div>
<p>For Query DSL queries, use the <code class="literal">::failures</code> suffix on your data stream name.</p>
<div class="imageblock">
<div class="content">
<img src="images/data-streams/failure_store_alerting_dsl.png" alt="use the ::failures suffix in the data stream name in the query dsl">
</div>
</div>
<p>For ES|QL queries, use the <code class="literal">::failures</code> suffix on your data stream name in the <code class="literal">FROM</code> command.</p>
<div class="imageblock">
<div class="content">
<img src="images/data-streams/failure_store_alerting_esql.png" alt="use the ::failures suffix in the data stream name in the from command">
</div>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<div class="position-relative"><h4 class="title"><a id="_step_4_test"></a>Step 4: Test</h4><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.19/docs/reference/data-streams/failure-store-recipes.asciidoc">edit</a></div>
</div></div></div>
<p>Configure schedule, actions, and details of the alert before saving the rule.</p>
<div class="imageblock">
<div class="content">
<img src="images/data-streams/failure_store_alerting_finish.png" alt="complete the rule configuration and save it">
</div>
</div>
</div>

</div>

<div class="section">
<div class="titlepage"><div><div>
<div class="position-relative"><h3 class="title"><a id="data-remediation"></a>Data remediation</h3><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.19/docs/reference/data-streams/failure-store-recipes.asciidoc">edit</a></div>
</div></div></div>
<p>If you&#8217;ve encountered a long span of ingestion failures you may find that a sizeable gap of events has appeared in your data stream. If the failure store is enabled, the documents that should fill those gaps would be tucked away in the data stream&#8217;s failure store. Because failure stores are made up of regular indices and the failure documents contain the document source that failed, the failure documents can often times be replayed into your production data streams.</p>
<div class="warning admon">
<div class="icon"></div>
<div class="admon_content">
<p>Care should be taken when replaying data into a data stream from a failure store. Any failures during the replay process may generate new failures in the failure store which can duplicate and obscure the original events.</p>
</div>
</div>
<p>We recommend a few best practices for remediating failure data.</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<span class="strong strong"><strong>Separate your failures beforehand.</strong></span> As described in the previous <a class="xref" href="failure-store.html#use-failure-store-document-source" title="Failure document source">failure document source</a> section, failure documents are structured differently depending on when the document failed during ingestion. We recommend to separate documents by ingest pipeline failures and indexing failures at minimum. Ingest pipeline failures often need to have the original pipeline re-run, while index failures should skip any pipelines. Further separating failures by index or specific failure type may also be beneficial.
</li>
<li class="listitem">
<span class="strong strong"><strong>Perform a failure store rollover.</strong></span> Consider <a class="xref" href="failure-store.html#manage-failure-store-rollover" title="Failure store rollover">rolling over the failure store</a> before attempting to remediate failures. This will create a new failure index that will collect any new failures during the remediation process.
</li>
<li class="listitem">
<span class="strong strong"><strong>Use an ingest pipeline to convert failure documents back into their original document.</strong></span> Failure documents store failure information along with the document that failed ingestion. The first step for remediating documents should be to use an ingest pipeline to extract the original source from the failure document and then discard any other information about the failure.
</li>
<li class="listitem">
<span class="strong strong"><strong>Simulate first to avoid repeat failures.</strong></span> If you must run a pipeline as part of your remediation process, it is best to simulate the pipeline against the failure first. This will catch any unforeseen issues that may fail the document a second time. Remember, ingest pipeline failures will capture the document before an ingest pipeline is applied to it, which can further complicate remediation when a failure document becomes nested inside a new failure. The easiest way to simulate these changes is via the <a href="/docs/api/doc/elasticsearch/operation/operation-ingest-simulate" class="ulink" target="_top">pipeline simulate API</a> or the <a href="/docs/api/doc/elasticsearch/operation/operation-simulate-ingest" class="ulink" target="_top">simulate ingest API</a>.
</li>
</ul>
</div>
<div class="section">
<div class="titlepage"><div><div>
<div class="position-relative"><h4 class="title"><a id="failure-store-examples-remediation-ingest"></a>Remediating ingest node failures</h4><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.19/docs/reference/data-streams/failure-store-recipes.asciidoc">edit</a></div>
</div></div></div>
<p>Failures that occurred during ingest processing will be stored as they were before any pipelines were run. To replay the document into the data stream, you will need to re-run any applicable pipelines for the document.</p>
<div class="section">
<div class="titlepage"><div><div>
<div class="position-relative"><h5 class="title"><a id="_step_1_separate_out_which_failures_to_replay"></a>Step 1: Separate out which failures to replay</h5><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.19/docs/reference/data-streams/failure-store-recipes.asciidoc">edit</a></div>
</div></div></div>
<p>Start off by constructing a query that can be used to consistently identify which failures will be remediated.</p>
<a id="b3fa4c3b93edae3d43f9ae792047b2f6"></a>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">POST my-datastream-ingest-example::failures/_search
{
  "query": {
    "bool": {
      "must": [
        {
          "exists": { <a id="CO271-1"></a><i class="conum" data-value="1"></i>
            "field": "error.pipeline"
          }
        },
        {
          "match": { <a id="CO271-2"></a><i class="conum" data-value="2"></i>
            "document.index": "my-datastream-ingest-example"
          }
        },
        {
          "match": { <a id="CO271-3"></a><i class="conum" data-value="3"></i>
            "error.type": "illegal_argument_exception"
          }
        },
        {
          "range": { <a id="CO271-4"></a><i class="conum" data-value="4"></i>
            "@timestamp": {
              "gt": "2025-05-01T00:00:00Z",
              "lte": "2025-05-02T00:00:00Z"
            }
          }
        }
      ]
    }
  }
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/823.console"></div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO271-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>Require the <code class="literal">error.pipeline</code> field to exist. This filters to ingest pipeline failures only.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO271-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p>Filter on the data stream name to remediate documents headed for a specific index.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO271-3"><i class="conum" data-value="3"></i></a></p>
</td>
<td align="left" valign="top">
<p>Further narrow which kind of failure you are attempting to remediate. In this example we are targeting a specific type of error.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO271-4"><i class="conum" data-value="4"></i></a></p>
</td>
<td align="left" valign="top">
<p>Filter on timestamp to only retrieve failures before a certain point in time. This provides a stable set of documents.</p>
</td>
</tr>
</table>
</div>
<p>Take note of the documents that are returned. We can use these to simulate that our remediation logic makes sense.</p>
<a id="e615bf3a92daf8c2bd2fc7db3000fefa"></a>
<div class="pre_wrapper lang-console-result">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console-result">{
  "took": 14,
  "timed_out": false,
  "_shards": {
    "total": 2,
    "successful": 2,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 1,
      "relation": "eq"
    },
    "max_score": 2.575364,
    "hits": [
      {
        "_index": ".fs-my-datastream-ingest-example-2025.05.16-000001",
        "_id": "cOnR2ZYByIwDXH-g6GpR",
        "_score": 2.575364,
        "_source": {
          "@timestamp": "2025-05-01T15:58:53.522Z", <a id="CO272-1"></a><i class="conum" data-value="1"></i>
          "document": {
            "index": "my-datastream-ingest-example",
            "source": {
              "@timestamp": "2025-05-01T00:00:00Z",
              "data": {
                "counter": 42 <a id="CO272-2"></a><i class="conum" data-value="2"></i>
              }
            }
          },
          "error": {
            "type": "illegal_argument_exception",
            "message": "field [id] not present as part of path [data.id]", <a id="CO272-3"></a><i class="conum" data-value="3"></i>
            "stack_trace": """j.l.IllegalArgumentException: field [id] not present as part of path [data.id] at o.e.i.IngestDocument.getFieldValue(IngestDocument.java:202) at o.e.i.c.SetProcessor.execute(SetProcessor.java:86) ... 14 more
""",
            "pipeline_trace": [
              "my-datastream-default-pipeline"
            ],
            "pipeline": "my-datastream-default-pipeline", <a id="CO272-4"></a><i class="conum" data-value="4"></i>
            "processor_type": "set"
          }
        }
      }
    ]
  }
}</pre>
</div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO272-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>This document is what we&#8217;ll use for our simulations.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO272-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p>It had a counter value.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO272-3"><i class="conum" data-value="3"></i></a></p>
</td>
<td align="left" valign="top">
<p>The document was missing a required field.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO272-4"><i class="conum" data-value="4"></i></a></p>
</td>
<td align="left" valign="top">
<p>The document failed in the <code class="literal">my-data-stream-default-pipeline</code>.</p>
</td>
</tr>
</table>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<div class="position-relative"><h5 class="title"><a id="_step_2_fix_the_original_problem"></a>Step 2: Fix the original problem</h5><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.19/docs/reference/data-streams/failure-store-recipes.asciidoc">edit</a></div>
</div></div></div>
<p>Because ingest pipeline failures need to be reprocessed by their original pipelines, any problems with those pipelines should be fixed before remediating failures. Investigating the pipeline mentioned in the example above shows that there is a processor that expects a field to be present that is not always present.</p>
<a id="4e605aac71f94c3a436c60bc1313935f"></a>
<div class="pre_wrapper lang-console-result">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console-result">{
  "my-datastream-default-pipeline": {
    "processors": [
      {
        "set": { <a id="CO273-1"></a><i class="conum" data-value="1"></i>
          "field": "identifier",
          "copy_from": "data.id"
        }
      }
    ]
  }
}</pre>
</div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO273-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>The <code class="literal">data.id</code> field is expected to be present. If it isn&#8217;t present this pipeline will fail.</p>
</td>
</tr>
</table>
</div>
<p>Fixing a failure&#8217;s root cause is often a bespoke process. In this example, instead of discarding the data, we will make this identifier field optional.</p>
<a id="ad9c0cd9d90cf57071dfc58d780294cd"></a>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">PUT _ingest/pipeline/my-datastream-default-pipeline
{
  "processors": [
    {
      "set": {
        "field": "identifier",
        "copy_from": "data.id",
        "if": "ctx.data?.id != null" <a id="CO274-1"></a><i class="conum" data-value="1"></i>
      }
    }
  ]
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/824.console"></div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO274-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>Conditionally run the processor only if the field exists.</p>
</td>
</tr>
</table>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<div class="position-relative"><h5 class="title"><a id="_step_3_create_a_pipeline_to_convert_failure_documents"></a>Step 3: Create a pipeline to convert failure documents</h5><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.19/docs/reference/data-streams/failure-store-recipes.asciidoc">edit</a></div>
</div></div></div>
<p>We must convert our failure documents back into their original forms and send them off to be reprocessed. We will create a pipeline to do this:</p>
<a id="7bf552a1c18120f15ea0311fc601dddd"></a>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">PUT _ingest/pipeline/my-datastream-remediation-pipeline
{
  "processors": [
    {
      "script": {
        "lang": "painless",
        "source": """
          ctx._index = ctx.document.index; <a id="CO275-1"></a><i class="conum" data-value="1"></i>
          ctx._routing = ctx.document.routing;
          def s = ctx.document.source; <a id="CO275-2"></a><i class="conum" data-value="2"></i>
          ctx.remove("error"); <a id="CO275-3"></a><i class="conum" data-value="3"></i>
          ctx.remove("document"); <a id="CO275-4"></a><i class="conum" data-value="4"></i>
          for (e in s.entrySet()) { <a id="CO275-5"></a><i class="conum" data-value="5"></i>
            ctx[e.key] = e.value;
          }"""
      }
    },
    {
      "reroute": { <a id="CO275-6"></a><i class="conum" data-value="6"></i>
        "destination": "my-datastream-ingest-example"
      }
    }
  ]
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/825.console"></div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO275-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>Copy the original index name from the failure document over into the document&#8217;s metadata. If you use custom document routing, copy that over too.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO275-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p>Capture the source of the original document.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO275-3"><i class="conum" data-value="3"></i></a></p>
</td>
<td align="left" valign="top">
<p>Discard the <code class="literal">error</code> field since it won&#8217;t be needed for the remediation.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO275-4"><i class="conum" data-value="4"></i></a></p>
</td>
<td align="left" valign="top">
<p>Also discard the <code class="literal">document</code> field.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO275-5"><i class="conum" data-value="5"></i></a></p>
</td>
<td align="left" valign="top">
<p>We extract all the fields from the original document&#8217;s source back to the root of the document.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO275-6"><i class="conum" data-value="6"></i></a></p>
</td>
<td align="left" valign="top">
<p>Since the pipeline that failed was the default pipeline on <code class="literal">my-datastream-ingest-example</code>, we will use the <code class="literal">reroute</code> processor to send any remediated documents to that data stream&#8217;s default pipeline again to be reprocessed.</p>
</td>
</tr>
</table>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<div class="position-relative"><h5 class="title"><a id="_step_4_test_your_pipelines"></a>Step 4: Test your pipelines</h5><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.19/docs/reference/data-streams/failure-store-recipes.asciidoc">edit</a></div>
</div></div></div>
<p>Before sending data off to be reindexed, be sure to test the pipelines in question with an example document to make sure they work. First, test to make sure the resulting document from the remediation pipeline is shaped how you expect. We can use the <a href="/docs/api/doc/elasticsearch/operation/operation-ingest-simulate" class="ulink" target="_top">simulate pipeline API</a> for this.</p>
<a id="3fd5e3adee1e90a3145af55e2c53e1ee"></a>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">POST _ingest/pipeline/_simulate
{
  "pipeline": { <a id="CO276-1"></a><i class="conum" data-value="1"></i>
    "processors": [
      {
        "script": {
          "lang": "painless",
          "source": """
            ctx._index = ctx.document.index;
            ctx._routing = ctx.document.routing;
            def s = ctx.document.source;
            ctx.remove("error");
            ctx.remove("document");
            for (e in s.entrySet()) {
              ctx[e.key] = e.value;
            }"""
        }
      },
      {
        "reroute": {
          "destination": "my-datastream-ingest-example"
        }
      }
    ]
  },
  "docs": [ <a id="CO276-2"></a><i class="conum" data-value="2"></i>
    {
      "_index": ".fs-my-datastream-ingest-example-2025.05.16-000001",
      "_id": "cOnR2ZYByIwDXH-g6GpR",
      "_source": {
        "@timestamp": "2025-05-01T15:58:53.522Z",
        "document": {
          "index": "my-datastream-ingest-example",
          "source": {
            "@timestamp": "2025-05-01T00:00:00Z",
            "data": {
              "counter": 42
            }
          }
        },
        "error": {
          "type": "illegal_argument_exception",
          "message": "field [id] not present as part of path [data.id]",
          "stack_trace": """j.l.IllegalArgumentException: field [id] not present as part of path [data.id] at o.e.i.IngestDocument.getFieldValue(IngestDocument.java:202) at o.e.i.c.SetProcessor.execute(SetProcessor.java:86) ... 14 more
""",
          "pipeline_trace": [
            "my-datastream-default-pipeline"
          ],
          "pipeline": "my-datastream-default-pipeline",
          "processor_type": "set"
        }
      }
    }
  ]
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/826.console"></div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO276-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>The contents of the remediation pipeline written in the previous step.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO276-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p>The contents of an example failure document we identified in the previous steps.</p>
</td>
</tr>
</table>
</div>
<a id="5dd5fd4d8cd0fb0afc07bfe019b59075"></a>
<div class="pre_wrapper lang-console-result">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console-result">{
  "docs": [
    {
      "doc": {
        "_index": "my-datastream-ingest-example", <a id="CO277-1"></a><i class="conum" data-value="1"></i>
        "_version": "-3",
        "_id": "cOnR2ZYByIwDXH-g6GpR", <a id="CO277-2"></a><i class="conum" data-value="2"></i>
        "_source": { <a id="CO277-3"></a><i class="conum" data-value="3"></i>
          "data": {
            "counter": 42
          },
          "@timestamp": "2025-05-01T00:00:00Z"
        },
        "_ingest": {
          "timestamp": "2025-05-01T20:58:03.566210529Z"
        }
      }
    }
  ]
}</pre>
</div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO277-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>The index has been updated via the reroute processor.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO277-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p>The document ID has stayed the same.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO277-3"><i class="conum" data-value="3"></i></a></p>
</td>
<td align="left" valign="top">
<p>The source should cleanly match the contents of the original document.</p>
</td>
</tr>
</table>
</div>
<p>Now that the remediation pipeline has been tested, be sure to test the end-to-end ingestion to verify that no further problems will arise. To do this, we will use the <a href="/docs/api/doc/elasticsearch/operation/operation-simulate-ingest" class="ulink" target="_top">simulate ingestion API</a> to test multiple pipeline executions.</p>
<a id="58e33eeb613fd669be324fadfcf4a219"></a>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">POST _ingest/_simulate?pipeline=my-datastream-remediation-pipeline <a id="CO278-1"></a><i class="conum" data-value="1"></i>
{
  "pipeline_substitutions": {
    "my-datastream-remediation-pipeline": { <a id="CO278-2"></a><i class="conum" data-value="2"></i>
      "processors": [
        {
          "script": {
            "lang": "painless",
            "source": """
              ctx._index = ctx.document.index;
              ctx._routing = ctx.document.routing;
              def s = ctx.document.source;
              ctx.remove("error");
              ctx.remove("document");
              for (e in s.entrySet()) {
                ctx[e.key] = e.value;
              }"""
          }
        },
        {
          "reroute": {
            "destination": "my-datastream-ingest-example"
          }
        }
      ]
    }
  },
  "docs": [ <a id="CO278-3"></a><i class="conum" data-value="3"></i>
    {
      "_index": ".fs-my-datastream-ingest-example-2025.05.16-000001",
      "_id": "cOnR2ZYByIwDXH-g6GpR",
      "_source": {
        "@timestamp": "2025-05-01T15:58:53.522Z",
        "document": {
          "index": "my-datastream-ingest-example",
          "source": {
            "@timestamp": "2025-05-01T00:00:00Z",
            "data": {
              "counter": 42
            }
          }
        },
        "error": {
          "type": "illegal_argument_exception",
          "message": "field [id] not present as part of path [data.id]",
          "stack_trace": """j.l.IllegalArgumentException: field [id] not present as part of path [data.id] at o.e.i.IngestDocument.getFieldValue(IngestDocument.java:202) at o.e.i.c.SetProcessor.execute(SetProcessor.java:86) ... 14 more
""",
          "pipeline_trace": [
            "my-datastream-default-pipeline"
          ],
          "pipeline": "my-datastream-default-pipeline",
          "processor_type": "set"
        }
      }
    }
  ]
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/827.console"></div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO278-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>Set the pipeline to be the remediation pipeline name, otherwise the default pipeline for the document&#8217;s index is used.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO278-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p>The contents of the remediation pipeline in previous steps.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO278-3"><i class="conum" data-value="3"></i></a></p>
</td>
<td align="left" valign="top">
<p>The contents of the previously identified example failure document.</p>
</td>
</tr>
</table>
</div>
<a id="4609acf6c0c4b0173094d792e34799fd"></a>
<div class="pre_wrapper lang-console-result">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console-result">{
  "docs": [
    {
      "doc": {
        "_id": "cOnR2ZYByIwDXH-g6GpR",
        "_index": "my-datastream-ingest-example", <a id="CO279-1"></a><i class="conum" data-value="1"></i>
        "_version": -3,
        "_source": { <a id="CO279-2"></a><i class="conum" data-value="2"></i>
          "@timestamp": "2025-05-01T00:00:00Z",
          "data": {
            "counter": 42
          }
        },
        "executed_pipelines": [ <a id="CO279-3"></a><i class="conum" data-value="3"></i>
          "my-datastream-remediation-pipeline",
          "my-datastream-default-pipeline"
        ]
      }
    }
  ]
}</pre>
</div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO279-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>The index name has been updated.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO279-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p>The source is as expected after the default pipeline has run.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO279-3"><i class="conum" data-value="3"></i></a></p>
</td>
<td align="left" valign="top">
<p>Ensure that both the new remediation pipeline and the original default pipeline have successfully run.</p>
</td>
</tr>
</table>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<div class="position-relative"><h5 class="title"><a id="_step_5_reindex_the_failure_documents"></a>Step 5: Reindex the failure documents</h5><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.19/docs/reference/data-streams/failure-store-recipes.asciidoc">edit</a></div>
</div></div></div>
<p>Combine the remediation pipeline with the failure store query together in a <a href="/docs/api/doc/elasticsearch/operation/operation-reindex" class="ulink" target="_top">reindex operation</a> to replay the failures.</p>
<a id="c321e4f46297291b78aafd627d70ee39"></a>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">POST _reindex
{
  "source": {
    "index": "my-datastream-ingest-example::failures", <a id="CO280-1"></a><i class="conum" data-value="1"></i>
    "query": {
      "bool": { <a id="CO280-2"></a><i class="conum" data-value="2"></i>
        "must": [
          {
            "exists": {
              "field": "error.pipeline"
            }
          },
          {
            "match": {
              "document.index": "my-datastream-ingest-example"
            }
          },
          {
            "match": {
              "error.type": "illegal_argument_exception"
            }
          },
          {
            "range": {
              "@timestamp": {
                "gt": "2025-05-01T00:00:00Z",
                "lte": "2025-05-17T00:00:00Z"
              }
            }
          }
        ]
      }
    }
  },
  "dest": {
    "index": "my-datastream-ingest-example", <a id="CO280-3"></a><i class="conum" data-value="3"></i>
    "op_type": "create",
    "pipeline": "my-datastream-remediation-pipeline" <a id="CO280-4"></a><i class="conum" data-value="4"></i>
  }
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/828.console"></div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO280-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>Read from the failure store.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO280-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p>Only reindex failure documents that match the ones we are replaying.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO280-3"><i class="conum" data-value="3"></i></a></p>
</td>
<td align="left" valign="top">
<p>Set the destination to the data stream the failures originally were sent to.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO280-4"><i class="conum" data-value="4"></i></a></p>
</td>
<td align="left" valign="top">
<p>Replace the pipeline with the remediation pipeline.</p>
</td>
</tr>
</table>
</div>
<a id="708549ecc714c8e8d954a4ab830873ea"></a>
<div class="pre_wrapper lang-console-result">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console-result">{
  "took": 469,
  "timed_out": false,
  "total": 1,
  "updated": 0,
  "created": 1, <a id="CO281-1"></a><i class="conum" data-value="1"></i>
  "deleted": 0,
  "batches": 1,
  "version_conflicts": 0,
  "noops": 0,
  "retries": {
    "bulk": 0,
    "search": 0
  },
  "throttled_millis": 0,
  "requests_per_second": -1,
  "throttled_until_millis": 0,
  "failures": []
}</pre>
</div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO281-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>The failures have been remediated.</p>
</td>
</tr>
</table>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>Since the failure store is enabled on this data stream, it would be wise to check it for any further failures from the reindexing process. Failures that happen at this point in the process may end up as nested failures in the failure store. Remediating nested failures can quickly become a hassle as the original document gets nested multiple levels deep in the failure document. For this reason, it is suggested to remediate data during a quiet period when no other failures are likely to arise. Furthermore, rolling over the failure store before executing the remediation would allow easier discarding of any new nested failures and only operate on the original failure documents.</p>
</div>
</div>
<p>Once any failures have been remediated, you may wish to purge the failures from the failure store to clear up space and to avoid warnings about failed data that has already been replayed. Otherwise, your failures will stay available until the maximum failure store retention should you need to reference them.</p>
</div>

</div>

<div class="section">
<div class="titlepage"><div><div>
<div class="position-relative"><h4 class="title"><a id="failure-store-examples-remediation-mapping"></a>Remediating mapping and shard failures</h4><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.19/docs/reference/data-streams/failure-store-recipes.asciidoc">edit</a></div>
</div></div></div>
<p>As described in the previous <a class="xref" href="failure-store.html#use-failure-store-document-source" title="Failure document source">failure document source</a> section, failures that occur due to a mapping or indexing issue will be stored as they were after any pipelines had executed. This means that to replay the document into the data stream, you will need to make sure to skip any pipelines that have already run.</p>
<div class="tip admon">
<div class="icon"></div>
<div class="admon_content">
<p>You can greatly simplify this remediation process by writing any ingest pipelines to be idempotent. In that case, any document that has already been processed that passes through a pipeline again would be unchanged.</p>
</div>
</div>
<div class="section">
<div class="titlepage"><div><div>
<div class="position-relative"><h5 class="title"><a id="_step_1_separate_out_which_failures_to_replay_2"></a>Step 1: Separate out which failures to replay</h5><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.19/docs/reference/data-streams/failure-store-recipes.asciidoc">edit</a></div>
</div></div></div>
<p>Start by constructing a query that can be used to consistently identify which failures will be remediated.</p>
<a id="e47d1e903b5f7ce07d0aa79127373b7d"></a>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">POST my-datastream-indexing-example::failures/_search
{
  "query": {
    "bool": {
      "must_not": [
        {
          "exists": { <a id="CO282-1"></a><i class="conum" data-value="1"></i>
            "field": "error.pipeline"
          }
        }
      ],
      "must": [
        {
          "match": { <a id="CO282-2"></a><i class="conum" data-value="2"></i>
            "document.index": "my-datastream-indexing-example"
          }
        },
        {
          "match": { <a id="CO282-3"></a><i class="conum" data-value="3"></i>
            "error.type": "document_parsing_exception"
          }
        },
        {
          "range": { <a id="CO282-4"></a><i class="conum" data-value="4"></i>
            "@timestamp": {
              "gt": "2025-05-01T00:00:00Z",
              "lte": "2025-05-02T00:00:00Z"
            }
          }
        }
      ]
    }
  }
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/829.console"></div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO282-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>Require the <code class="literal">error.pipeline</code> field to not exist. This filters out any ingest pipeline failures, and only returns indexing failures.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO282-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p>Filter on the data stream name to remediate documents headed for a specific index.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO282-3"><i class="conum" data-value="3"></i></a></p>
</td>
<td align="left" valign="top">
<p>Further narrow which kind of failure you are attempting to remediate. In this example we are targeting a specific type of error.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO282-4"><i class="conum" data-value="4"></i></a></p>
</td>
<td align="left" valign="top">
<p>Filter on timestamp to only retrieve failures before a certain point in time. This provides a stable set of documents.</p>
</td>
</tr>
</table>
</div>
<p>Take note of the documents that are returned. We can use these to simulate that our remediation logic makes sense.</p>
<a id="a20aab5db4aa6fca01028c702d5ca59e"></a>
<div class="pre_wrapper lang-console-result">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console-result">{
  "took": 1,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 1,
      "relation": "eq"
    },
    "max_score": 1.5753641,
    "hits": [
      {
        "_index": ".fs-my-datastream-indexing-example-2025.05.16-000002",
        "_id": "_lA-GJcBHLe506UUGL0I",
        "_score": 1.5753641,
        "_source": { <a id="CO283-1"></a><i class="conum" data-value="1"></i>
          "@timestamp": "2025-05-02T18:53:31.153Z",
          "document": {
            "id": "_VA-GJcBHLe506UUFL2i",
            "index": "my-datastream-indexing-example",
            "source": {
              "processed": true, <a id="CO283-2"></a><i class="conum" data-value="2"></i>
              "data": {
                "counter": 37
              }
            }
          },
          "error": {
            "type": "document_parsing_exception", <a id="CO283-3"></a><i class="conum" data-value="3"></i>
            "message": "[1:40] failed to parse: data stream timestamp field [@timestamp] is missing",
            "stack_trace": """o.e.i.m.DocumentParsingException: [1:40] failed to parse: data stream timestamp field [@timestamp] is missing at o.e.i.m.DocumentParser.wrapInDocumentParsingException(DocumentParser.java:265) at o.e.i.m.DocumentParser.internalParseDocument(DocumentParser.java:162) ... 19 more
Caused by: j.l.IllegalArgumentException: data stream timestamp field [@timestamp] is missing at o.e.i.m.DataStreamTimestampFieldMapper.extractTimestampValue(DataStreamTimestampFieldMapper.java:210) at o.e.i.m.DataStreamTimestampFieldMapper.postParse(DataStreamTimestampFieldMapper.java:223) ... 20 more
"""
          }
        }
      }
    ]
  }
}</pre>
</div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO283-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>This document is what we&#8217;ll use for our simulations.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO283-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p>The document was missing a required <code class="literal">@timestamp</code> field.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO283-3"><i class="conum" data-value="3"></i></a></p>
</td>
<td align="left" valign="top">
<p>The document failed with a <code class="literal">document_parsing_exception</code> because of the missing timestamp.</p>
</td>
</tr>
</table>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<div class="position-relative"><h5 class="title"><a id="_step_2_fix_the_original_problem_2"></a>Step 2: Fix the original problem</h5><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.19/docs/reference/data-streams/failure-store-recipes.asciidoc">edit</a></div>
</div></div></div>
<p>There are a broad set of possible indexing failures. Most of these problems stem from incorrect values for a particular mapping. Sometimes a large number of new fields are dynamically mapped and the maximum number of mapping fields is reached, so no more can be added. In our example above, the document being indexed is missing a required timestamp.</p>
<p>These problems can occur in a number of places: Data sent from a client may be incomplete, ingest pipelines may not be producing the correct result, or the index mapping may need to be updated to account for changes in data.</p>
<p>Once all clients and pipelines are producing complete and correct documents, and your mappings are correctly configured for your incoming data, proceed with the remediation.</p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<div class="position-relative"><h5 class="title"><a id="_step_3_create_a_pipeline_to_convert_failure_documents_2"></a>Step 3: Create a pipeline to convert failure documents</h5><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.19/docs/reference/data-streams/failure-store-recipes.asciidoc">edit</a></div>
</div></div></div>
<p>We must convert our failure documents back into their original forms and send them off to be reprocessed. We will create a pipeline to do this. Since the example failure was due to not having a timestamp on the document, we will simply use the timestamp at the time of failure for the document since the original timestamp is missing. This solution assumes that the documents we are remediating were created very closely to when the failure occurred. Your remediation process may need adjustments if this is not applicable for you.</p>
<a id="f2227017e46c51940829d64e08474476"></a>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">PUT _ingest/pipeline/my-datastream-remediation-pipeline
{
  "processors": [
    {
      "script": {
      "lang": "painless",
      "source": """
          ctx._index = ctx.document.index; <a id="CO284-1"></a><i class="conum" data-value="1"></i>
          ctx._routing = ctx.document.routing;
          def s = ctx.document.source; <a id="CO284-2"></a><i class="conum" data-value="2"></i>
          ctx.remove("error"); <a id="CO284-3"></a><i class="conum" data-value="3"></i>
          ctx.remove("document"); <a id="CO284-4"></a><i class="conum" data-value="4"></i>
          for (e in s.entrySet()) { <a id="CO284-5"></a><i class="conum" data-value="5"></i>
            ctx[e.key] = e.value;
          }"""
      }
    }
  ]
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/830.console"></div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO284-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>Copy the original index name from the failure document over into the document&#8217;s metadata. If you use custom document routing, copy that over too.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO284-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p>Capture the source of the original document.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO284-3"><i class="conum" data-value="3"></i></a></p>
</td>
<td align="left" valign="top">
<p>Discard the <code class="literal">error</code> field since it won&#8217;t be needed for the remediation.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO284-4"><i class="conum" data-value="4"></i></a></p>
</td>
<td align="left" valign="top">
<p>Also discard the <code class="literal">document</code> field.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO284-5"><i class="conum" data-value="5"></i></a></p>
</td>
<td align="left" valign="top">
<p>We extract all the fields from the original document&#8217;s source back to the root of the document. The <code class="literal">@timestamp</code> field is not overwritten and thus will be present in the final document.</p>
</td>
</tr>
</table>
</div>
<div class="important admon">
<div class="icon"></div>
<div class="admon_content">
<p>Remember that a document that has failed during indexing has already been processed by the ingest processor! It shouldn&#8217;t need to be processed again unless you made changes to your pipeline to fix the original problem. Make sure that any fixes applied to the ingest pipeline are reflected in the pipeline logic here.</p>
</div>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<div class="position-relative"><h5 class="title"><a id="_step_4_test_your_pipeline"></a>Step 4: Test your pipeline</h5><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.19/docs/reference/data-streams/failure-store-recipes.asciidoc">edit</a></div>
</div></div></div>
<p>Before sending data off to be reindexed, be sure to test the remedial pipeline with an example document to make sure it works. Most importantly, make sure the resulting document from the remediation pipeline is shaped how you expect. We can use the <a href="/docs/api/doc/elasticsearch/operation/operation-ingest-simulate" class="ulink" target="_top">simulate pipeline API</a> for this.</p>
<a id="447809c85056383d040c058c48d43c63"></a>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">POST _ingest/pipeline/_simulate
{
  "pipeline": { <a id="CO285-1"></a><i class="conum" data-value="1"></i>
    "processors": [
      {
        "script": {
        "lang": "painless",
        "source": """
            ctx._index = ctx.document.index;
            ctx._routing = ctx.document.routing;
            def s = ctx.document.source;
            ctx.remove("error");
            ctx.remove("document");
            for (e in s.entrySet()) {
              ctx[e.key] = e.value;
            }"""
        }
      }
    ]
  },
  "docs": [ <a id="CO285-2"></a><i class="conum" data-value="2"></i>
    {
        "_index": ".fs-my-datastream-indexing-example-2025.05.16-000002",
        "_id": "_lA-GJcBHLe506UUGL0I",
        "_score": 1.5753641,
        "_source": {
          "@timestamp": "2025-05-02T18:53:31.153Z",
          "document": {
            "id": "_VA-GJcBHLe506UUFL2i",
            "index": "my-datastream-indexing-example",
            "source": {
              "processed": true,
              "data": {
                "counter": 37
              }
            }
          },
          "error": {
            "type": "document_parsing_exception",
            "message": "[1:40] failed to parse: data stream timestamp field [@timestamp] is missing",
            "stack_trace": """o.e.i.m.DocumentParsingException: [1:40] failed to parse: data stream timestamp field [@timestamp] is missing at o.e.i.m.DocumentParser.wrapInDocumentParsingException(DocumentParser.java:265) at o.e.i.m.DocumentParser.internalParseDocument(DocumentParser.java:162) ... 19 more
Caused by: j.l.IllegalArgumentException: data stream timestamp field [@timestamp] is missing at o.e.i.m.DataStreamTimestampFieldMapper.extractTimestampValue(DataStreamTimestampFieldMapper.java:210) at o.e.i.m.DataStreamTimestampFieldMapper.postParse(DataStreamTimestampFieldMapper.java:223) ... 20 more
"""
          }
        }
      }
  ]
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/831.console"></div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO285-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>The contents of the remediation pipeline written in the previous step.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO285-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p>The contents of an example failure document we identified in the previous steps.</p>
</td>
</tr>
</table>
</div>
<a id="95bd390858118e330168d64f32489e30"></a>
<div class="pre_wrapper lang-console-result">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console-result">{
  "docs": [
    {
      "doc": {
        "_index": "my-datastream-indexing-example", <a id="CO286-1"></a><i class="conum" data-value="1"></i>
        "_version": "-3",
        "_id": "_lA-GJcBHLe506UUGL0I",
        "_source": { <a id="CO286-2"></a><i class="conum" data-value="2"></i>
          "processed": true,
          "@timestamp": "2025-05-28T18:53:31.153Z", <a id="CO286-3"></a><i class="conum" data-value="3"></i>
          "data": {
            "counter": 37
          }
        },
        "_ingest": {
          "timestamp": "2025-05-28T19:14:50.457560845Z"
        }
      }
    }
  ]
}</pre>
</div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO286-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>The index has been updated via the script processor.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO286-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p>The source should reflect any fixes and match the expected document shape for the final index.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO286-3"><i class="conum" data-value="3"></i></a></p>
</td>
<td align="left" valign="top">
<p>In this example case, we find that the failure timestamp has stayed in the source.</p>
</td>
</tr>
</table>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<div class="position-relative"><h5 class="title"><a id="_step_5_reindex_the_failure_documents_2"></a>Step 5: Reindex the failure documents</h5><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.19/docs/reference/data-streams/failure-store-recipes.asciidoc">edit</a></div>
</div></div></div>
<p>Combine the remediation pipeline with the failure store query together in a <a href="/docs/api/doc/elasticsearch/operation/operation-reindex" class="ulink" target="_top">reindex operation</a> to replay the failures.</p>
<a id="4d33d8bc26b1568fc36f11b5769ba30b"></a>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">POST _reindex
{
  "source": {
    "index": "my-datastream-indexing-example::failures", <a id="CO287-1"></a><i class="conum" data-value="1"></i>
    "query": {
      "bool": { <a id="CO287-2"></a><i class="conum" data-value="2"></i>
        "must_not": [
          {
            "exists": {
              "field": "error.pipeline"
            }
          }
        ],
        "must": [
          {
            "match": {
              "document.index": "my-datastream-indexing-example"
            }
          },
          {
            "match": {
              "error.type": "document_parsing_exception"
            }
          },
          {
            "range": {
              "@timestamp": {
                "gt": "2025-05-01T00:00:00Z",
                "lte": "2025-05-28T19:00:00Z"
              }
            }
          }
        ]
      }
    }
  },
  "dest": {
    "index": "my-datastream-indexing-example", <a id="CO287-3"></a><i class="conum" data-value="3"></i>
    "op_type": "create",
    "pipeline": "my-datastream-remediation-pipeline" <a id="CO287-4"></a><i class="conum" data-value="4"></i>
  }
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/832.console"></div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO287-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>Read from the failure store.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO287-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p>Only reindex failure documents that match the ones we are replaying.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO287-3"><i class="conum" data-value="3"></i></a></p>
</td>
<td align="left" valign="top">
<p>Set the destination to the data stream the failures originally were sent to. The remediation pipeline in the example updates the index to be the correct one, but a destination is still required.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO287-4"><i class="conum" data-value="4"></i></a></p>
</td>
<td align="left" valign="top">
<p>Replace the original pipeline with the remediation pipeline. This will keep any default pipelines from running.</p>
</td>
</tr>
</table>
</div>
<a id="708549ecc714c8e8d954a4ab830873ea"></a>
<div class="pre_wrapper lang-console-result">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console-result">{
  "took": 469,
  "timed_out": false,
  "total": 1,
  "updated": 0,
  "created": 1, <a id="CO288-1"></a><i class="conum" data-value="1"></i>
  "deleted": 0,
  "batches": 1,
  "version_conflicts": 0,
  "noops": 0,
  "retries": {
    "bulk": 0,
    "search": 0
  },
  "throttled_millis": 0,
  "requests_per_second": -1,
  "throttled_until_millis": 0,
  "failures": []
}</pre>
</div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO288-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>The failures have been remediated.</p>
</td>
</tr>
</table>
</div>
<div class="tip admon">
<div class="icon"></div>
<div class="admon_content">
<p>Since the failure store is enabled on this data stream, it would be wise to check it for any further failures from the reindexing process. Failures that happen at this point in the process may end up as nested failures in the failure store. Remediating nested failures can quickly become a hassle as the original document gets nested multiple levels deep in the failure document. For this reason, it is suggested to remediate data during a quiet period where no other failures will arise. Furthermore, rolling over the failure store before executing the remediation would allow easier discarding of any new nested failures and only operate on the original failure documents.</p>
</div>
</div>
<p>Once any failures have been remediated, you may wish to purge the failures from the failure store to clear up space and to avoid warnings about failed data that has already been replayed. Otherwise, your failures will stay available until the maximum failure store retention should you need to reference them.</p>
</div>

</div>

</div>

</div>
</div>
</div><div class="navfooter">
<span class="prev">
<a href="failure-store.html">« Failure store</a>
</span>
<span class="next">
<a href="ingest.html">Ingest pipelines »</a>
</span>
</div>

                  <!-- end body -->
                </div>

                <div class="col-12 order-3 col-lg-2 order-lg-3 h-almost-full-lg sticky-top-lg" id="right_col">
                  <div id="sticky_content">
                    <!-- The OTP is appended here -->
                    <div class="row">
                      <div class="col-0 col-md-4 col-lg-0" id="bottom_left_col"></div>
                      <div class="col-12 col-md-8 col-lg-12">
                        <div id="rtpcontainer">
                          <div class="mktg-promo" id="most-popular">
                            <p class="aside-heading">Most Popular</p>
                            <div class="pb-2">
                              <p class="media-type">Video</p>
                              <a href="https://www.elastic.co/webinars/getting-started-elasticsearch?page=docs&placement=top-video">
                                <p class="mb-0">Get Started with Elasticsearch</p>
                              </a>
                            </div>
                            <div class="pb-2">
                              <p class="media-type">Video</p>
                              <a href="https://www.elastic.co/webinars/getting-started-kibana?page=docs&placement=top-video">
                                <p class="mb-0">Intro to Kibana</p>
                              </a>
                            </div>
                            <div class="pb-2">
                              <p class="media-type">Video</p>
                              <a href="https://www.elastic.co/webinars/introduction-elk-stack?page=docs&placement=top-video">
                                <p class="mb-0">ELK for Logs & Metrics</p>
                              </a>
                            </div>
                          </div>
                        </div>

                        <!-- Feedback widget -->
                        <div id="feedbackWidgetContainer"></div>
                      </div>
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </section>

        </div>


        <div id='elastic-footer'></div>
        <script src='https://www.elastic.co/elastic-footer.js'></script>
        <!-- Footer Section end-->

      </section>
    </div>

    <!-- Feedback modal -->
    <div id="feedbackModalContainer"></div>

    <script src="/guide/static/jquery.js"></script>
    <script type="text/javascript" src="/guide/static/docs-v1.js"></script>
    <script type="text/javascript">
  window.initial_state = {"alternatives":{"console":{"php":{"hasAny":true},"python":{"hasAny":true},"ruby":{"hasAny":true},"go":{"hasAny":true},"js":{"hasAny":true}}}}</script>
  </body>
</html>
