<!DOCTYPE html>
<html lang="en-us">
  <head>
    
<meta charset="UTF-8">
<meta name="description" content="ELSER is a learned sparse ranking model trained by Elastic.">
<meta name="keywords" content="hot-spotting, hotspot, hot-spot, hot spot, hotspots, hotspotting">
<title>Create trained models API | Elasticsearch Guide [8.8] | Elastic</title>
<meta class="elastic" name="content" content="Create trained models API | Elasticsearch Guide [8.8]">

<link rel="home" href="index.html" title="Elasticsearch Guide [8.8]"/>
<link rel="up" href="ml-df-trained-models-apis.html" title="Machine learning trained model APIs"/>
<link rel="prev" href="put-trained-model-definition-part.html" title="Create trained model definition part API"/>
<link rel="next" href="put-trained-model-vocabulary.html" title="Create trained model vocabulary API"/>
<meta class="elastic" name="product_version" content="8.8"/>
<meta class="elastic" name="product_name" content="Elasticsearch"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/Elasticsearch/Reference/8.8"/>
<meta name="DC.subject" content="Elasticsearch"/>
<meta name="DC.identifier" content="8.8"/>

    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <script src="https://cdn.optimizely.com/js/18132920325.js"></script>
    <link rel="apple-touch-icon" sizes="57x57" href="/apple-icon-57x57.png">
    <link rel="apple-touch-icon" sizes="60x60" href="/apple-icon-60x60.png">
    <link rel="apple-touch-icon" sizes="72x72" href="/apple-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="76x76" href="/apple-icon-76x76.png">
    <link rel="apple-touch-icon" sizes="114x114" href="/apple-icon-114x114.png">
    <link rel="apple-touch-icon" sizes="120x120" href="/apple-icon-120x120.png">
    <link rel="apple-touch-icon" sizes="144x144" href="/apple-icon-144x144.png">
    <link rel="apple-touch-icon" sizes="152x152" href="/apple-icon-152x152.png">
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-icon-180x180.png">
    <link rel="icon" type="image/png" href="/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="/android-chrome-192x192.png" sizes="192x192">
    <link rel="icon" type="image/png" href="/favicon-96x96.png" sizes="96x96">
    <link rel="icon" type="image/png" href="/favicon-16x16.png" sizes="16x16">
    <link rel="manifest" href="/manifest.json">
    <meta name="apple-mobile-web-app-title" content="Elastic">
    <meta name="application-name" content="Elastic">
    <meta name="msapplication-TileColor" content="#ffffff">
    <meta name="msapplication-TileImage" content="/mstile-144x144.png">
    <meta name="theme-color" content="#ffffff">
    <meta name="naver-site-verification" content="936882c1853b701b3cef3721758d80535413dbfd" />
    <meta name="yandex-verification" content="d8a47e95d0972434" />
    <meta name="localized" content="true" />
    <meta name="st:robots" content="follow,index" />
    <meta property="og:image" content="https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/blt280217a63b82a734/6202d3378b1f312528798412/elastic-logo.svg" />
    <meta property="og:image:width" content="500" />
    <meta property="og:image:height" content="172" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <link rel="apple-touch-icon-precomposed" sizes="64x64" href="/favicon_64x64_16bit.png">
    <link rel="apple-touch-icon-precomposed" sizes="32x32" href="/favicon_32x32.png">
    <link rel="apple-touch-icon-precomposed" sizes="16x16" href="/favicon_16x16.png">
    <!-- Give IE8 a fighting chance -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    <link rel="stylesheet" type="text/css" href="/guide/static/styles.css" />
  </head>

  <!--© 2015-2022 Elasticsearch B.V. -->
  <!-- All Elastic documentation is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License. -->
  <!-- http://creativecommons.org/licenses/by-nc-nd/4.0/ -->

  <body>
    <!-- Google Tag Manager -->
    <script>dataLayer = [];</script><noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-58RLH5" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start': new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0], j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src= '//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f); })(window,document,'script','dataLayer','GTM-58RLH5');</script>
    <!-- End Google Tag Manager -->

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-12395217-16"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-12395217-16');
    </script>

    <!-- Google Tag Manager for GA4 -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start': new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0], j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-KNJMG2M');</script>
    <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-KNJMG2M" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    <!-- End Google Tag Manager for GA4-->

    <!--BEGIN QUALTRICS WEBSITE FEEDBACK SNIPPET-->
    <script type='text/javascript'>
      (function(){var g=function(e,h,f,g){
      this.get=function(a){for(var a=a+"=",c=document.cookie.split(";"),b=0,e=c.length;b<e;b++){for(var d=c[b];" "==d.charAt(0);)d=d.substring(1,d.length);if(0==d.indexOf(a))return d.substring(a.length,d.length)}return null};
      this.set=function(a,c){var b="",b=new Date;b.setTime(b.getTime()+6048E5);b="; expires="+b.toGMTString();document.cookie=a+"="+c+b+"; path=/; "};
      this.check=function(){var a=this.get(f);if(a)a=a.split(":");else if(100!=e)"v"==h&&(e=Math.random()>=e/100?0:100),a=[h,e,0],this.set(f,a.join(":"));else return!0;var c=a[1];if(100==c)return!0;switch(a[0]){case "v":return!1;case "r":return c=a[2]%Math.floor(100/c),a[2]++,this.set(f,a.join(":")),!c}return!0};
      this.go=function(){if(this.check()){var a=document.createElement("script");a.type="text/javascript";a.src=g;document.body&&document.body.appendChild(a)}};
      this.start=function(){var a=this;window.addEventListener?window.addEventListener("load",function(){a.go()},!1):window.attachEvent&&window.attachEvent("onload",function(){a.go()})}};
      try{(new g(100,"r","QSI_S_ZN_emkP0oSe9Qrn7kF","https://znemkp0ose9qrn7kf-elastic.siteintercept.qualtrics.com/WRSiteInterceptEngine/?Q_ZID=ZN_emkP0oSe9Qrn7kF")).start()}catch(i){}})();
    </script><div id='ZN_emkP0oSe9Qrn7kF'><!--DO NOT REMOVE-CONTENTS PLACED HERE--></div>
    <!--END WEBSITE FEEDBACK SNIPPET-->

    <div id='elastic-nav' style="display:none;"></div>
    <script src='https://www.elastic.co/elastic-nav.js'></script>

    <div class="main-container">
      <section id="content" >
        <div class="content-wrapper">

          <section id="guide" lang="en">
            <div class="container-fluid">
              <div class="row pb-3">
                <div class="col-12 order-2 col-md-4 order-md-1 col-lg-3 h-almost-full-md sticky-top-md" id="left_col">
                  <!-- The TOC is appended here -->
                </div>

                <div class="col-12 order-1 col-md-8 order-md-2 col-lg-7 order-lg-2 guide-section" id="middle_col">
                  <!-- start body -->
                  <div class="page_header">
You are looking at preliminary documentation for a future release.
Not what you want? See the
<a href="../current/index.html">current release documentation</a>.
</div>
<div id="content">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Elasticsearch Guide [8.8]</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="rest-apis.html">REST APIs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="ml-df-trained-models-apis.html">Machine learning trained model APIs</a></span>
</div>
<div class="navheader">
<span class="prev">
<a href="put-trained-model-definition-part.html">« Create trained model definition part API</a>
</span>
<span class="next">
<a href="put-trained-model-vocabulary.html">Create trained model vocabulary API »</a>
</span>
</div>
<div class="section xpack">
<div class="titlepage"><div><div>
<h2 class="title"><a id="put-trained-models"></a>Create trained models API<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.8/docs/reference/ml/trained-models/apis/put-trained-models.asciidoc">edit</a></h2>
</div></div></div>

<p>Creates a trained model.</p>
<div class="warning admon">
<div class="icon"></div>
<div class="admon_content">
<p>Models created in version 7.8.0 are not backwards compatible
         with older node versions. If in a mixed cluster environment,
         all nodes must be at least 7.8.0 to use a model stored by
         a 7.8.0 node.</p>
</div>
</div>
<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-put-trained-models-request"></a>Request<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.8/docs/reference/ml/trained-models/apis/put-trained-models.asciidoc">edit</a></h3>
</div></div></div>
<p><code class="literal">PUT _ml/trained_models/&lt;model_id&gt;</code></p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-put-trained-models-prereq"></a>Prerequisites<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.8/docs/reference/ml/trained-models/apis/put-trained-models.asciidoc">edit</a></h3>
</div></div></div>
<p>Requires the <code class="literal">manage_ml</code> cluster privilege. This privilege is included in the
<code class="literal">machine_learning_admin</code> built-in role.</p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-put-trained-models-desc"></a>Description<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.8/docs/reference/ml/trained-models/apis/put-trained-models.asciidoc">edit</a></h3>
</div></div></div>
<p>The create trained model API enables you to supply a trained model that is not
created by data frame analytics.</p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-put-trained-models-path-params"></a>Path parameters<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.8/docs/reference/ml/trained-models/apis/put-trained-models.asciidoc">edit</a></h3>
</div></div></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">&lt;model_id&gt;</code>
</span>
</dt>
<dd>
(Required, string)
The unique identifier of the trained model.
</dd>
</dl>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-put-trained-models-query-params"></a>Query parameters<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.8/docs/reference/ml/trained-models/apis/put-trained-models.asciidoc">edit</a></h3>
</div></div></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">defer_definition_decompression</code>
</span>
</dt>
<dd>
(Optional, boolean)
If set to <code class="literal">true</code> and a <code class="literal">compressed_definition</code> is provided, the request defers
definition decompression and skips relevant validations.
This deferral is useful for systems or users that know a good byte size estimate for their
model and know that their model is valid and likely won&#8217;t fail during inference.
</dd>
</dl>
</div>
</div>

<div class="section child_attributes">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-put-trained-models-request-body"></a>Request body<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.8/docs/reference/ml/trained-models/apis/put-trained-models.asciidoc">edit</a></h3>
</div></div></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">compressed_definition</code>
</span>
</dt>
<dd>
(Required, string)
The compressed (GZipped and Base64 encoded) inference definition of the model.
If <code class="literal">compressed_definition</code> is specified, then <code class="literal">definition</code> cannot be specified.
</dd>
</dl>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">definition</code>
</span>
</dt>
<dd>
<p>
(Required, object)
The inference definition for the model. If <code class="literal">definition</code> is specified, then
<code class="literal">compressed_definition</code> cannot be specified.
</p>
<details open>
<summary class="title">Properties of <code class="literal">definition</code></summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">preprocessors</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Collection of preprocessors. See <a class="xref" href="put-trained-models.html#ml-put-trained-models-preprocessor-example" title="Preprocessor examples">Preprocessor examples</a>.
</p>
<details open>
<summary class="title">Properties of <code class="literal">preprocessors</code></summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">frequency_encoding</code>
</span>
</dt>
<dd>
<p>
(Required, object)
Defines a frequency encoding for a field.
</p>
<details open>
<summary class="title">Properties of <code class="literal">frequency_encoding</code></summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">feature_name</code>
</span>
</dt>
<dd>
(Required, string)
The name of the resulting feature.
</dd>
<dt>
<span class="term">
<code class="literal">field</code>
</span>
</dt>
<dd>
(Required, string)
The field name to encode.
</dd>
<dt>
<span class="term">
<code class="literal">frequency_map</code>
</span>
</dt>
<dd>
(Required, object map of string:double)
Object that maps the field value to the frequency encoded value.
</dd>
<dt>
<span class="term">
<code class="literal">custom</code>
</span>
</dt>
<dd>
(Optional, Boolean)
Boolean value indicating if the analytics job created the preprocessor
or if a user provided it. This adjusts the feature importance calculation.
When <code class="literal">true</code>, the feature importance calculation returns importance for the
processed feature. When <code class="literal">false</code>, the total importance of the original field
is returned. Default is <code class="literal">false</code>.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">one_hot_encoding</code>
</span>
</dt>
<dd>
<p>
(Required, object)
Defines a one hot encoding map for a field.
</p>
<details open>
<summary class="title">Properties of <code class="literal">one_hot_encoding</code></summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">field</code>
</span>
</dt>
<dd>
(Required, string)
The field name to encode.
</dd>
<dt>
<span class="term">
<code class="literal">hot_map</code>
</span>
</dt>
<dd>
(Required, object map of strings)
String map of "field_value: one_hot_column_name".
</dd>
<dt>
<span class="term">
<code class="literal">custom</code>
</span>
</dt>
<dd>
(Optional, Boolean)
Boolean value indicating if the analytics job created the preprocessor
or if a user provided it. This adjusts the feature importance calculation.
When <code class="literal">true</code>, the feature importance calculation returns importance for the
processed feature. When <code class="literal">false</code>, the total importance of the original field
is returned. Default is <code class="literal">false</code>.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">target_mean_encoding</code>
</span>
</dt>
<dd>
<p>
(Required, object)
Defines a target mean encoding for a field.
</p>
<details open>
<summary class="title">Properties of <code class="literal">target_mean_encoding</code></summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">default_value</code>
</span>
</dt>
<dd>
(Required, double)
The feature value if the field value is not in the <code class="literal">target_map</code>.
</dd>
<dt>
<span class="term">
<code class="literal">feature_name</code>
</span>
</dt>
<dd>
(Required, string)
The name of the resulting feature.
</dd>
<dt>
<span class="term">
<code class="literal">field</code>
</span>
</dt>
<dd>
(Required, string)
The field name to encode.
</dd>
<dt>
<span class="term">
<code class="literal">target_map</code>
</span>
</dt>
<dd>
<p>
(Required, object map of string:double)
Object that maps the field value to the target mean value.
</p>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">custom</code>
</span>
</dt>
<dd>
(Optional, Boolean)
Boolean value indicating if the analytics job created the preprocessor
or if a user provided it. This adjusts the feature importance calculation.
When <code class="literal">true</code>, the feature importance calculation returns importance for the
processed feature. When <code class="literal">false</code>, the total importance of the original field
is returned. Default is <code class="literal">false</code>.
</dd>
</dl>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">trained_model</code>
</span>
</dt>
<dd>
<p>
(Required, object)
The definition of the trained model.
</p>
<details open>
<summary class="title">Properties of <code class="literal">trained_model</code></summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">tree</code>
</span>
</dt>
<dd>
<p>
(Required, object)
The definition for a binary decision tree.
</p>
<details open>
<summary class="title">Properties of <code class="literal">tree</code></summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">classification_labels</code>
</span>
</dt>
<dd>
(Optional, string) An array of classification labels (used for
<code class="literal">classification</code>).
</dd>
<dt>
<span class="term">
<code class="literal">feature_names</code>
</span>
</dt>
<dd>
(Required, string)
Features expected by the tree, in their expected order.
</dd>
<dt>
<span class="term">
<code class="literal">target_type</code>
</span>
</dt>
<dd>
(Required, string)
String indicating the model target type; <code class="literal">regression</code> or <code class="literal">classification</code>.
</dd>
<dt>
<span class="term">
<code class="literal">tree_structure</code>
</span>
</dt>
<dd>
(Required, object)
An array of <code class="literal">tree_node</code> objects. The nodes must be in ordinal order by their
<code class="literal">tree_node.node_index</code> value.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">tree_node</code>
</span>
</dt>
<dd>
<p>
(Required, object)
The definition of a node in a tree.
</p>
<p>There are two major types of nodes: leaf nodes and not-leaf nodes.</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
Leaf nodes only need <code class="literal">node_index</code> and <code class="literal">leaf_value</code> defined.
</li>
<li class="listitem">
All other nodes need <code class="literal">split_feature</code>, <code class="literal">left_child</code>, <code class="literal">right_child</code>,
<code class="literal">threshold</code>, <code class="literal">decision_type</code>, and <code class="literal">default_left</code> defined.
</li>
</ul>
</div>
<details open>
<summary class="title">Properties of <code class="literal">tree_node</code></summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">decision_type</code>
</span>
</dt>
<dd>
(Optional, string)
Indicates the positive value (in other words, when to choose the left node)
decision type. Supported <code class="literal">lt</code>, <code class="literal">lte</code>, <code class="literal">gt</code>, <code class="literal">gte</code>. Defaults to <code class="literal">lte</code>.
</dd>
<dt>
<span class="term">
<code class="literal">default_left</code>
</span>
</dt>
<dd>
(Optional, Boolean)
Indicates whether to default to the left when the feature is missing. Defaults
to <code class="literal">true</code>.
</dd>
<dt>
<span class="term">
<code class="literal">leaf_value</code>
</span>
</dt>
<dd>
(Optional, double)
The leaf value of the of the node, if the value is a leaf (in other words, no
children).
</dd>
<dt>
<span class="term">
<code class="literal">left_child</code>
</span>
</dt>
<dd>
(Optional, integer)
The index of the left child.
</dd>
<dt>
<span class="term">
<code class="literal">node_index</code>
</span>
</dt>
<dd>
(Integer)
The index of the current node.
</dd>
<dt>
<span class="term">
<code class="literal">right_child</code>
</span>
</dt>
<dd>
(Optional, integer)
The index of the right child.
</dd>
<dt>
<span class="term">
<code class="literal">split_feature</code>
</span>
</dt>
<dd>
(Optional, integer)
The index of the feature value in the feature array.
</dd>
<dt>
<span class="term">
<code class="literal">split_gain</code>
</span>
</dt>
<dd>
(Optional, double) The information gain from the split.
</dd>
<dt>
<span class="term">
<code class="literal">threshold</code>
</span>
</dt>
<dd>
(Optional, double)
The decision threshold with which to compare the feature value.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">ensemble</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
The definition for an ensemble model. See <a class="xref" href="put-trained-models.html#ml-put-trained-models-model-example" title="Model examples">Model examples</a>.
</p>
<details open>
<summary class="title">Properties of <code class="literal">ensemble</code></summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">aggregate_output</code>
</span>
</dt>
<dd>
<p>
(Required, object)
An aggregated output object that defines how to aggregate the outputs of the
<code class="literal">trained_models</code>. Supported objects are <code class="literal">weighted_mode</code>, <code class="literal">weighted_sum</code>, and
<code class="literal">logistic_regression</code>. See <a class="xref" href="put-trained-models.html#ml-put-trained-models-aggregated-output-example" title="Aggregated output example">Aggregated output example</a>.
</p>
<details open>
<summary class="title">Properties of <code class="literal">aggregate_output</code></summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">logistic_regression</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
This <code class="literal">aggregated_output</code> type works with binary classification (classification
for values [0, 1]). It multiplies the outputs (in the case of the <code class="literal">ensemble</code>
model, the inference model values) by the supplied <code class="literal">weights</code>. The resulting
vector is summed and passed to a
<a href="https://en.wikipedia.org/wiki/Sigmoid_function" class="ulink" target="_top"><code class="literal">sigmoid</code> function</a>. The result
of the <code class="literal">sigmoid</code> function is considered the probability of class 1 (<code class="literal">P_1</code>),
consequently, the probability of class 0 is <code class="literal">1 - P_1</code>. The class with the
highest probability (either 0 or 1) is then returned. For more information about
logistic regression, see
<a href="https://en.wikipedia.org/wiki/Logistic_regression" class="ulink" target="_top">this wiki article</a>.
</p>
<details open>
<summary class="title">Properties of <code class="literal">logistic_regression</code></summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">weights</code>
</span>
</dt>
<dd>
(Required, double)
The weights to multiply by the input values (the inference values of the trained
models).
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">weighted_sum</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
This <code class="literal">aggregated_output</code> type works with regression. The weighted sum of the
input values.
</p>
<details open>
<summary class="title">Properties of <code class="literal">weighted_sum</code></summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">weights</code>
</span>
</dt>
<dd>
(Required, double)
The weights to multiply by the input values (the inference values of the trained
models).
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">weighted_mode</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
This <code class="literal">aggregated_output</code> type works with regression or classification. It takes
a weighted vote of the input values. The most common input value (taking the
weights into account) is returned.
</p>
<details open>
<summary class="title">Properties of <code class="literal">weighted_mode</code></summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">weights</code>
</span>
</dt>
<dd>
(Required, double)
The weights to multiply by the input values (the inference values of the trained
models).
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">exponent</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
This <code class="literal">aggregated_output</code> type works with regression. It takes a weighted sum of
the input values and passes the result to an exponent function
(<code class="literal">e^x</code> where <code class="literal">x</code> is the sum of the weighted values).
</p>
<details open>
<summary class="title">Properties of <code class="literal">exponent</code></summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">weights</code>
</span>
</dt>
<dd>
(Required, double)
The weights to multiply by the input values (the inference values of the trained
models).
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">classification_labels</code>
</span>
</dt>
<dd>
(Optional, string)
An array of classification labels.
</dd>
<dt>
<span class="term">
<code class="literal">feature_names</code>
</span>
</dt>
<dd>
(Optional, string)
Features expected by the ensemble, in their expected order.
</dd>
<dt>
<span class="term">
<code class="literal">target_type</code>
</span>
</dt>
<dd>
(Required, string)
String indicating the model target type; <code class="literal">regression</code> or <code class="literal">classification.</code>
</dd>
<dt>
<span class="term">
<code class="literal">trained_models</code>
</span>
</dt>
<dd>
(Required, object)
An array of <code class="literal">trained_model</code> objects. Supported trained models are <code class="literal">tree</code> and
<code class="literal">ensemble</code>.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">description</code>
</span>
</dt>
<dd>
(Optional, string)
A human-readable description of the inference trained model.
</dd>
<dt>
<span class="term">
<code class="literal">estimated_heap_memory_usage_bytes</code>
</span>
</dt>
<dd>
(Optional, integer) <span class="Admonishment Admonishment--change">
[<span class="Admonishment-version u-mono u-strikethrough">7.16.0</span>]
<span class="Admonishment-detail">
Deprecated in 7.16.0. Replaced by <code class="literal">model_size_bytes</code>
</span>
</span>
</dd>
<dt>
<span class="term">
<code class="literal">estimated_operations</code>
</span>
</dt>
<dd>
(Optional, integer)
The estimated number of operations to use the trained model during inference.
This property is supported only if <code class="literal">defer_definition_decompression</code> is <code class="literal">true</code> or
the model definition is not supplied.
</dd>
</dl>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">inference_config</code>
</span>
</dt>
<dd>
<p>
(Required, object)
The default configuration for inference. This can be: <code class="literal">regression</code>,
<code class="literal">classification</code>, <code class="literal">fill_mask</code>, <code class="literal">ner</code>, <code class="literal">question_answering</code>,
<code class="literal">text_classification</code>, <code class="literal">text_embedding</code> or <code class="literal">zero_shot_classification</code>.
If <code class="literal">regression</code> or <code class="literal">classification</code>, it must match the <code class="literal">target_type</code> of the
underlying <code class="literal">definition.trained_model</code>. If <code class="literal">fill_mask</code>, <code class="literal">ner</code>,
<code class="literal">question_answering</code>, <code class="literal">text_classification</code>, or <code class="literal">text_embedding</code>; the
<code class="literal">model_type</code> must be <code class="literal">pytorch</code>.
</p>
<details open>
<summary class="title">Properties of <code class="literal">inference_config</code></summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">classification</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Classification configuration for inference.
</p>
<details open>
<summary class="title">Properties of classification inference</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">num_top_classes</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the number of top class predictions to return. Defaults to 0.
</dd>
<dt>
<span class="term">
<code class="literal">num_top_feature_importance_values</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of
<a href="/guide/en/machine-learning/8.8/ml-feature-importance.html" class="ulink" target="_top">feature importance</a> values per document. Defaults
to 0 which means no feature importance calculation occurs.
</dd>
<dt>
<span class="term">
<code class="literal">prediction_field_type</code>
</span>
</dt>
<dd>
(Optional, string)
Specifies the type of the predicted field to write.
Valid values are: <code class="literal">string</code>, <code class="literal">number</code>, <code class="literal">boolean</code>. When <code class="literal">boolean</code> is provided
<code class="literal">1.0</code> is transformed to <code class="literal">true</code> and <code class="literal">0.0</code> to <code class="literal">false</code>.
</dd>
<dt>
<span class="term">
<code class="literal">results_field</code>
</span>
</dt>
<dd>
(Optional, string)
The field that is added to incoming documents to contain the inference
prediction. Defaults to <code class="literal">predicted_value</code>.
</dd>
<dt>
<span class="term">
<code class="literal">top_classes_results_field</code>
</span>
</dt>
<dd>
(Optional, string)
Specifies the field to which the top classes are written. Defaults to
<code class="literal">top_classes</code>.
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">fill_mask</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Configuration for a fill_mask natural language processing (NLP) task. The
fill_mask task works with models optimized for a fill mask action. For example,
for BERT models, the following text may be provided: "The capital of France is
[MASK].". The response indicates the value most likely to replace <code class="literal">[MASK]</code>. In
this instance, the most probable token is <code class="literal">paris</code>.
</p>
<details open>
<summary class="title">Properties of fill_mask inference</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">num_top_classes</code>
</span>
</dt>
<dd>
(Optional, integer)
Number of top predicted tokens to return for replacing the mask token. Defaults to <code class="literal">0</code>.
</dd>
<dt>
<span class="term">
<code class="literal">results_field</code>
</span>
</dt>
<dd>
(Optional, string)
The field that is added to incoming documents to contain the inference
prediction. Defaults to <code class="literal">predicted_value</code>.
</dd>
<dt>
<span class="term">
<code class="literal">tokenization</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Indicates the tokenization to perform and the desired settings.
The default tokenization configuration is <code class="literal">bert</code>. Valid tokenization
values are
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">bert</code>: Use for BERT-style models
</li>
<li class="listitem">
<code class="literal">mpnet</code>: Use for MPNet-style models
</li>
<li class="listitem">
<code class="literal">roberta</code>: Use for RoBERTa-style and BART-style models
</li>
</ul>
</div>
<details open>
<summary class="title">Properties of tokenization</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">bert</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
BERT-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in BERT-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">[CLS]</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">[SEP]</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
RoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">add_prefix_space</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization should prefix a space to the tokenized input to the model.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in RoBERTa-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">mpnet</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
MPNet-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of mpnet</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in MPNet-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">ner</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Configures a named entity recognition (NER) task. NER is a special case of token
classification. Each token in the sequence is classified according to the
provided classification labels. Currently, the NER task requires the
<code class="literal">classification_labels</code> Inside-Outside-Beginning (IOB) formatted labels. Only
person, organization, location, and miscellaneous are supported.
</p>
<details open>
<summary class="title">Properties of ner inference</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">classification_labels</code>
</span>
</dt>
<dd>
(Optional, string)
An array of classification labels. NER only supports Inside-Outside-Beginning
labels (IOB) and only persons, organizations, locations, and miscellaneous.
Example: ["O", "B-PER", "I-PER", "B-ORG", "I-ORG", "B-LOC", "I-LOC", "B-MISC",
"I-MISC"]
</dd>
<dt>
<span class="term">
<code class="literal">results_field</code>
</span>
</dt>
<dd>
(Optional, string)
The field that is added to incoming documents to contain the inference
prediction. Defaults to <code class="literal">predicted_value</code>.
</dd>
<dt>
<span class="term">
<code class="literal">tokenization</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Indicates the tokenization to perform and the desired settings.
The default tokenization configuration is <code class="literal">bert</code>. Valid tokenization
values are
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">bert</code>: Use for BERT-style models
</li>
<li class="listitem">
<code class="literal">mpnet</code>: Use for MPNet-style models
</li>
<li class="listitem">
<code class="literal">roberta</code>: Use for RoBERTa-style and BART-style models
</li>
</ul>
</div>
<details open>
<summary class="title">Properties of tokenization</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">bert</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
BERT-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in BERT-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">[CLS]</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">[SEP]</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
RoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">add_prefix_space</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization should prefix a space to the tokenized input to the model.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in RoBERTa-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">mpnet</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
MPNet-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of mpnet</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in MPNet-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">pass_through</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Configures a <code class="literal">pass_through</code> task. This task is useful for debugging as no
post-processing is done to the inference output and the raw pooling layer
results are returned to the caller.
</p>
<details open>
<summary class="title">Properties of pass_through inference</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">results_field</code>
</span>
</dt>
<dd>
(Optional, string)
The field that is added to incoming documents to contain the inference
prediction. Defaults to <code class="literal">predicted_value</code>.
</dd>
<dt>
<span class="term">
<code class="literal">tokenization</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Indicates the tokenization to perform and the desired settings.
The default tokenization configuration is <code class="literal">bert</code>. Valid tokenization
values are
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">bert</code>: Use for BERT-style models
</li>
<li class="listitem">
<code class="literal">mpnet</code>: Use for MPNet-style models
</li>
<li class="listitem">
<code class="literal">roberta</code>: Use for RoBERTa-style and BART-style models
</li>
</ul>
</div>
<details open>
<summary class="title">Properties of tokenization</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">bert</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
BERT-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in BERT-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">[CLS]</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">[SEP]</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
RoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">add_prefix_space</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization should prefix a space to the tokenized input to the model.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in RoBERTa-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">mpnet</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
MPNet-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of mpnet</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in MPNet-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">question_answering</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Configures a question answering natural language processing (NLP) task. Question
answering is useful for extracting answers for certain questions from a large
corpus of text.
</p>
<details open>
<summary class="title">Properties of question_answering inference</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">max_answer_length</code>
</span>
</dt>
<dd>
(Optional, integer)
The maximum amount of words in the answer. Defaults to <code class="literal">15</code>.
</dd>
<dt>
<span class="term">
<code class="literal">results_field</code>
</span>
</dt>
<dd>
(Optional, string)
The field that is added to incoming documents to contain the inference
prediction. Defaults to <code class="literal">predicted_value</code>.
</dd>
<dt>
<span class="term">
<code class="literal">tokenization</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Indicates the tokenization to perform and the desired settings.
The default tokenization configuration is <code class="literal">bert</code>. Valid tokenization
values are
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">bert</code>: Use for BERT-style models
</li>
<li class="listitem">
<code class="literal">mpnet</code>: Use for MPNet-style models
</li>
<li class="listitem">
<code class="literal">roberta</code>: Use for RoBERTa-style and BART-style models
</li>
</ul>
</div>
<p>Recommended to set <code class="literal">max_sentence_length</code> to <code class="literal">386</code> with <code class="literal">128</code> of <code class="literal">span</code> and set
<code class="literal">truncate</code> to <code class="literal">none</code>.</p>
<details open>
<summary class="title">Properties of tokenization</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">bert</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
BERT-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in BERT-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">[CLS]</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">[SEP]</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
RoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">add_prefix_space</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization should prefix a space to the tokenized input to the model.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in RoBERTa-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">mpnet</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
MPNet-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of mpnet</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in MPNet-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">regression</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Regression configuration for inference.
</p>
<details open>
<summary class="title">Properties of regression inference</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">num_top_feature_importance_values</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of
<a href="/guide/en/machine-learning/8.8/ml-feature-importance.html" class="ulink" target="_top">feature importance</a> values per document.
By default, it is zero and no feature importance calculation occurs.
</dd>
<dt>
<span class="term">
<code class="literal">results_field</code>
</span>
</dt>
<dd>
(Optional, string)
The field that is added to incoming documents to contain the inference
prediction. Defaults to <code class="literal">predicted_value</code>.
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">text_classification</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
A text classification task. Text classification classifies a provided text
sequence into previously known target classes. A specific example of this is
sentiment analysis, which returns the likely target classes indicating text
sentiment, such as "sad", "happy", or "angry".
</p>
<details open>
<summary class="title">Properties of text_classification inference</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">classification_labels</code>
</span>
</dt>
<dd>
(Optional, string) An array of classification labels.
</dd>
<dt>
<span class="term">
<code class="literal">num_top_classes</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the number of top class predictions to return. Defaults to all classes (-1).
</dd>
<dt>
<span class="term">
<code class="literal">results_field</code>
</span>
</dt>
<dd>
(Optional, string)
The field that is added to incoming documents to contain the inference
prediction. Defaults to <code class="literal">predicted_value</code>.
</dd>
<dt>
<span class="term">
<code class="literal">tokenization</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Indicates the tokenization to perform and the desired settings.
The default tokenization configuration is <code class="literal">bert</code>. Valid tokenization
values are
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">bert</code>: Use for BERT-style models
</li>
<li class="listitem">
<code class="literal">mpnet</code>: Use for MPNet-style models
</li>
<li class="listitem">
<code class="literal">roberta</code>: Use for RoBERTa-style and BART-style models
</li>
</ul>
</div>
<details open>
<summary class="title">Properties of tokenization</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">bert</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
BERT-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in BERT-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">[CLS]</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">[SEP]</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
RoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">add_prefix_space</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization should prefix a space to the tokenized input to the model.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in RoBERTa-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">mpnet</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
MPNet-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of mpnet</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in MPNet-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">text_embedding</code>
</span>
</dt>
<dd>
<p>
(Object, optional)
Text embedding takes an input sequence and transforms it into a vector of
numbers. These embeddings capture not simply tokens, but semantic meanings and
context. These embeddings can be used in a <a class="xref" href="dense-vector.html" title="Dense vector field type">dense vector</a> field
for powerful insights.
</p>
<details open>
<summary class="title">Properties of text_embedding inference</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">embedding_size</code>
</span>
</dt>
<dd>
(Optional, integer)
The number of dimensions in the embedding vector produced by the model.
</dd>
<dt>
<span class="term">
<code class="literal">results_field</code>
</span>
</dt>
<dd>
(Optional, string)
The field that is added to incoming documents to contain the inference
prediction. Defaults to <code class="literal">predicted_value</code>.
</dd>
<dt>
<span class="term">
<code class="literal">tokenization</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Indicates the tokenization to perform and the desired settings.
The default tokenization configuration is <code class="literal">bert</code>. Valid tokenization
values are
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">bert</code>: Use for BERT-style models
</li>
<li class="listitem">
<code class="literal">mpnet</code>: Use for MPNet-style models
</li>
<li class="listitem">
<code class="literal">roberta</code>: Use for RoBERTa-style and BART-style models
</li>
</ul>
</div>
<details open>
<summary class="title">Properties of tokenization</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">bert</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
BERT-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in BERT-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">[CLS]</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">[SEP]</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
RoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">add_prefix_space</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization should prefix a space to the tokenized input to the model.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in RoBERTa-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">mpnet</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
MPNet-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of mpnet</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in MPNet-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">text_similarity</code>
</span>
</dt>
<dd>
(Object, optional)
Text similarity takes an input sequence and compares it with another input sequence. This is commonly referred to
as cross-encoding. This task is useful for ranking document text when comparing it to another provided text input.
</dd>
</dl>
</div>
<details open>
<summary class="title">Properties of text_similarity inference</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">span_score_combination_function</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Identifies how to combine the resulting similarity score when a provided text passage is longer than <code class="literal">max_sequence_length</code> and must be
automatically separated for multiple calls. This only is applicable when <code class="literal">truncate</code> is <code class="literal">none</code> and <code class="literal">span</code> is a non-negative
number. The default value is <code class="literal">max</code>. Available options are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">max</code>: The maximum score from all the spans is returned.
</li>
<li class="listitem">
<code class="literal">mean</code>: The mean score over all the spans is returned.
</li>
</ul>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">tokenization</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Indicates the tokenization to perform and the desired settings.
The default tokenization configuration is <code class="literal">bert</code>. Valid tokenization
values are
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">bert</code>: Use for BERT-style models
</li>
<li class="listitem">
<code class="literal">mpnet</code>: Use for MPNet-style models
</li>
<li class="listitem">
<code class="literal">roberta</code>: Use for RoBERTa-style and BART-style models
</li>
</ul>
</div>
<details open>
<summary class="title">Properties of tokenization</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">bert</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
BERT-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in BERT-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">[CLS]</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">[SEP]</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
RoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">add_prefix_space</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization should prefix a space to the tokenized input to the model.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in RoBERTa-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">mpnet</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
MPNet-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of mpnet</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in MPNet-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">zero_shot_classification</code>
</span>
</dt>
<dd>
<p>
(Object, optional)
Configures a zero-shot classification task. Zero-shot classification allows for
text classification to occur without pre-determined labels. At inference time,
it is possible to adjust the labels to classify. This makes this type of model
and task exceptionally flexible.
</p>
<p>If consistently classifying the same labels, it may be better to use a
fine-tuned text classification model.</p>
<details open>
<summary class="title">Properties of zero_shot_classification inference</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">classification_labels</code>
</span>
</dt>
<dd>
(Required, array)
The classification labels used during the zero-shot classification. Classification
labels must not be empty or null and only set at model creation. They must be all three
of ["entailment", "neutral", "contradiction"].
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>This is NOT the same as <code class="literal">labels</code> which are the values that zero-shot is attempting to
      classify.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">hypothesis_template</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
This is the template used when tokenizing the sequences for classification.
</p>
<p>The labels replace the <code class="literal">{}</code> value in the text. The default value is:
<code class="literal">This example is {}.</code></p>
</dd>
<dt>
<span class="term">
<code class="literal">labels</code>
</span>
</dt>
<dd>
(Optional, array)
The labels to classify. Can be set at creation for default labels, and
then updated during inference.
</dd>
<dt>
<span class="term">
<code class="literal">multi_label</code>
</span>
</dt>
<dd>
(Optional, boolean)
Indicates if more than one <code class="literal">true</code> label is possible given the input.
This is useful when labeling text that could pertain to more than one of the
input labels. Defaults to <code class="literal">false</code>.
</dd>
<dt>
<span class="term">
<code class="literal">results_field</code>
</span>
</dt>
<dd>
(Optional, string)
The field that is added to incoming documents to contain the inference
prediction. Defaults to <code class="literal">predicted_value</code>.
</dd>
<dt>
<span class="term">
<code class="literal">tokenization</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Indicates the tokenization to perform and the desired settings.
The default tokenization configuration is <code class="literal">bert</code>. Valid tokenization
values are
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">bert</code>: Use for BERT-style models
</li>
<li class="listitem">
<code class="literal">mpnet</code>: Use for MPNet-style models
</li>
<li class="listitem">
<code class="literal">roberta</code>: Use for RoBERTa-style and BART-style models
</li>
</ul>
</div>
<details open>
<summary class="title">Properties of tokenization</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">bert</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
BERT-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in BERT-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">[CLS]</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">[SEP]</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
RoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">add_prefix_space</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization should prefix a space to the tokenized input to the model.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in RoBERTa-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">mpnet</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
MPNet-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of mpnet</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in MPNet-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">input</code>
</span>
</dt>
<dd>
<p>
(Required, object)
The input field names for the model definition.
</p>
<details open>
<summary class="title">Properties of <code class="literal">input</code></summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">field_names</code>
</span>
</dt>
<dd>
(Required, string)
An array of input field names for the model.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">location</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
The model definition location. If the <code class="literal">definition</code> or <code class="literal">compressed_definition</code>
are not specified, the <code class="literal">location</code> is required.
</p>
<details open>
<summary class="title">Properties of <code class="literal">location</code></summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">index</code>
</span>
</dt>
<dd>
(Required, object)
Indicates that the model definition is stored in an index. This object must be
empty as the index for storing model definitions is configured automatically.
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">metadata</code>
</span>
</dt>
<dd>
(Optional, object)
An object map that contains metadata about the model.
</dd>
<dt>
<span class="term">
<code class="literal">model_size_bytes</code>
</span>
</dt>
<dd>
(Optional, integer)
The estimated memory usage in bytes to keep the trained model in memory. This
property is supported only if <code class="literal">defer_definition_decompression</code> is <code class="literal">true</code> or the
model definition is not supplied.
</dd>
<dt>
<span class="term">
<code class="literal">model_type</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
The created model type. By default the model type is <code class="literal">tree_ensemble</code>.
Appropriate types are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">tree_ensemble</code>: The model definition is an ensemble model of decision trees.
</li>
<li class="listitem">
<code class="literal">lang_ident</code>: A special type reserved for language identification models.
</li>
<li class="listitem">
<code class="literal">pytorch</code>: The stored definition is a PyTorch (specifically a TorchScript) model. Currently only
NLP models are supported. For more information, refer to <a href="/guide/en/machine-learning/8.8/ml-nlp.html" class="ulink" target="_top">Natural language processing</a>.
</li>
</ul>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">tags</code>
</span>
</dt>
<dd>
(Optional, string)
An array of tags to organize the model.
</dd>
</dl>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-put-trained-models-example"></a>Examples<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.8/docs/reference/ml/trained-models/apis/put-trained-models.asciidoc">edit</a></h3>
</div></div></div>
<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="ml-put-trained-models-preprocessor-example"></a>Preprocessor examples<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.8/docs/reference/ml/trained-models/apis/put-trained-models.asciidoc">edit</a></h4>
</div></div></div>
<p>The example below shows a <code class="literal">frequency_encoding</code> preprocessor object:</p>
<div class="pre_wrapper lang-js">
<pre class="programlisting prettyprint lang-js">{
   "frequency_encoding":{
      "field":"FlightDelayType",
      "feature_name":"FlightDelayType_frequency",
      "frequency_map":{
         "Carrier Delay":0.6007414737092798,
         "NAS Delay":0.6007414737092798,
         "Weather Delay":0.024573576178086153,
         "Security Delay":0.02476631010889467,
         "No Delay":0.6007414737092798,
         "Late Aircraft Delay":0.6007414737092798
      }
   }
}</pre>
</div>
<p>The next example shows a <code class="literal">one_hot_encoding</code> preprocessor object:</p>
<div class="pre_wrapper lang-js">
<pre class="programlisting prettyprint lang-js">{
   "one_hot_encoding":{
      "field":"FlightDelayType",
      "hot_map":{
         "Carrier Delay":"FlightDelayType_Carrier Delay",
         "NAS Delay":"FlightDelayType_NAS Delay",
         "No Delay":"FlightDelayType_No Delay",
         "Late Aircraft Delay":"FlightDelayType_Late Aircraft Delay"
      }
   }
}</pre>
</div>
<p>This example shows a <code class="literal">target_mean_encoding</code> preprocessor object:</p>
<div class="pre_wrapper lang-js">
<pre class="programlisting prettyprint lang-js">{
   "target_mean_encoding":{
      "field":"FlightDelayType",
      "feature_name":"FlightDelayType_targetmean",
      "target_map":{
         "Carrier Delay":39.97465788139886,
         "NAS Delay":39.97465788139886,
         "Security Delay":203.171206225681,
         "Weather Delay":187.64705882352948,
         "No Delay":39.97465788139886,
         "Late Aircraft Delay":39.97465788139886
      },
      "default_value":158.17995752420433
   }
}</pre>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="ml-put-trained-models-model-example"></a>Model examples<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.8/docs/reference/ml/trained-models/apis/put-trained-models.asciidoc">edit</a></h4>
</div></div></div>
<p>The first example shows a <code class="literal">trained_model</code> object:</p>
<div class="pre_wrapper lang-js">
<pre class="programlisting prettyprint lang-js">{
   "tree":{
      "feature_names":[
         "DistanceKilometers",
         "FlightTimeMin",
         "FlightDelayType_NAS Delay",
         "Origin_targetmean",
         "DestRegion_targetmean",
         "DestCityName_targetmean",
         "OriginAirportID_targetmean",
         "OriginCityName_frequency",
         "DistanceMiles",
         "FlightDelayType_Late Aircraft Delay"
      ],
      "tree_structure":[
         {
            "decision_type":"lt",
            "threshold":9069.33437193022,
            "split_feature":0,
            "split_gain":4112.094574306927,
            "node_index":0,
            "default_left":true,
            "left_child":1,
            "right_child":2
         },
         ...
         {
            "node_index":9,
            "leaf_value":-27.68987349695448
         },
         ...
      ],
      "target_type":"regression"
   }
}</pre>
</div>
<p>The following example shows an <code class="literal">ensemble</code> model object:</p>
<div class="pre_wrapper lang-js">
<pre class="programlisting prettyprint lang-js">"ensemble":{
   "feature_names":[
      ...
   ],
   "trained_models":[
      {
         "tree":{
            "feature_names":[],
            "tree_structure":[
               {
                  "decision_type":"lte",
                  "node_index":0,
                  "leaf_value":47.64069875778043,
                  "default_left":false
               }
            ],
            "target_type":"regression"
         }
      },
      ...
   ],
   "aggregate_output":{
      "weighted_sum":{
         "weights":[
            ...
         ]
      }
   },
   "target_type":"regression"
}</pre>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="ml-put-trained-models-aggregated-output-example"></a>Aggregated output example<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.8/docs/reference/ml/trained-models/apis/put-trained-models.asciidoc">edit</a></h4>
</div></div></div>
<p>Example of a <code class="literal">logistic_regression</code> object:</p>
<div class="pre_wrapper lang-js">
<pre class="programlisting prettyprint lang-js">"aggregate_output" : {
  "logistic_regression" : {
    "weights" : [2.0, 1.0, .5, -1.0, 5.0, 1.0, 1.0]
  }
}</pre>
</div>
<p>Example of a <code class="literal">weighted_sum</code> object:</p>
<div class="pre_wrapper lang-js">
<pre class="programlisting prettyprint lang-js">"aggregate_output" : {
  "weighted_sum" : {
    "weights" : [1.0, -1.0, .5, 1.0, 5.0]
  }
}</pre>
</div>
<p>Example of a <code class="literal">weighted_mode</code> object:</p>
<div class="pre_wrapper lang-js">
<pre class="programlisting prettyprint lang-js">"aggregate_output" : {
  "weighted_mode" : {
    "weights" : [1.0, 1.0, 1.0, 1.0, 1.0]
  }
}</pre>
</div>
<p>Example of an <code class="literal">exponent</code> object:</p>
<div class="pre_wrapper lang-js">
<pre class="programlisting prettyprint lang-js">"aggregate_output" : {
  "exponent" : {
    "weights" : [1.0, 1.0, 1.0, 1.0, 1.0]
  }
}</pre>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="ml-put-trained-models-json-schema"></a>Trained models JSON schema<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.8/docs/reference/ml/trained-models/apis/put-trained-models.asciidoc">edit</a></h4>
</div></div></div>
<p>For the full JSON schema of trained models,
<a href="https://github.com/elastic/ml-json-schemas" class="ulink" target="_top">click here</a>.</p>
</div>

</div>

</div>
<div class="navfooter">
<span class="prev">
<a href="put-trained-model-definition-part.html">« Create trained model definition part API</a>
</span>
<span class="next">
<a href="put-trained-model-vocabulary.html">Create trained model vocabulary API »</a>
</span>
</div>
</div>

                  <!-- end body -->
                </div>

                <div class="col-12 order-3 col-lg-2 order-lg-3 h-almost-full-lg sticky-top-lg" id="right_col">
                  <div id="sticky_content">
                    <!-- The OTP is appended here -->
                    <div class="row">
                      <div class="col-0 col-md-4 col-lg-0" id="bottom_left_col"></div>
                      <div class="col-12 col-md-8 col-lg-12">
                        <div id="rtpcontainer">
                          <div class="mktg-promo" id="most-popular">
                            <p class="aside-heading">Most Popular</p>
                            <div class="pb-2">
                              <p class="media-type">Video</p>
                              <a href="https://www.elastic.co/webinars/getting-started-elasticsearch?baymax=default&elektra=docs&storm=top-video">
                                <p class="mb-0">Get Started with Elasticsearch</p>
                              </a>
                            </div>
                            <div class="pb-2">
                              <p class="media-type">Video</p>
                              <a href="https://www.elastic.co/webinars/getting-started-kibana?baymax=default&elektra=docs&storm=top-video">
                                <p class="mb-0">Intro to Kibana</p>
                              </a>
                            </div>
                            <div class="pb-2">
                              <p class="media-type">Video</p>
                              <a href="https://www.elastic.co/webinars/introduction-elk-stack?baymax=default&elektra=docs&storm=top-video">
                                <p class="mb-0">ELK for Logs & Metrics</p>
                              </a>
                            </div>
                          </div>
                        </div>
                      </div>
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </section>

        </div>


<div id='elastic-footer'></div>
<script src='https://www.elastic.co/elastic-footer.js'></script>
<!-- Footer Section end-->

      </section>
    </div>

<script src="/guide/static/jquery.js"></script>
<script type="text/javascript" src="/guide/static/docs.js"></script>
<script type="text/javascript">
  window.initial_state = {"alternatives":{"console":{"php":{"hasAny":true},"python":{"hasAny":true},"ruby":{"hasAny":true},"go":{"hasAny":true},"js":{"hasAny":true}}}}</script>
  </body>
</html>
