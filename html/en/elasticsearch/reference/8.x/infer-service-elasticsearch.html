<!DOCTYPE html>
<html lang="en-us">
  <head>
    
<meta charset="UTF-8">
<title>Elasticsearch inference integration | Elasticsearch Guide [8.x] | Elastic</title>
<meta class="elastic" name="content" content="Elasticsearch inference integration | Elasticsearch Guide [8.x]">

<link rel="home" href="index.html" title="Elasticsearch Guide [8.x]"/>
<link rel="up" href="inference-apis.html" title="Inference APIs"/>
<link rel="prev" href="infer-service-cohere.html" title="Cohere inference integration"/>
<link rel="next" href="infer-service-elser.html" title="ELSER inference integration"/>
<meta class="elastic" name="product_version" content="8.x"/>
<meta class="elastic" name="product_name" content="Elasticsearch"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/Elasticsearch/Reference/8.x"/>
<meta name="DC.subject" content="Elasticsearch"/>
<meta name="DC.identifier" content="8.x"/>
<meta name="robots" content="noindex,nofollow"/>

    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <script src="https://cdn.optimizely.com/js/18132920325.js"></script>
    <link rel="apple-touch-icon" sizes="57x57" href="/apple-icon-57x57.png">
    <link rel="apple-touch-icon" sizes="60x60" href="/apple-icon-60x60.png">
    <link rel="apple-touch-icon" sizes="72x72" href="/apple-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="76x76" href="/apple-icon-76x76.png">
    <link rel="apple-touch-icon" sizes="114x114" href="/apple-icon-114x114.png">
    <link rel="apple-touch-icon" sizes="120x120" href="/apple-icon-120x120.png">
    <link rel="apple-touch-icon" sizes="144x144" href="/apple-icon-144x144.png">
    <link rel="apple-touch-icon" sizes="152x152" href="/apple-icon-152x152.png">
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-icon-180x180.png">
    <link rel="icon" type="image/png" href="/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="/android-chrome-192x192.png" sizes="192x192">
    <link rel="icon" type="image/png" href="/favicon-96x96.png" sizes="96x96">
    <link rel="icon" type="image/png" href="/favicon-16x16.png" sizes="16x16">
    <link rel="manifest" href="/manifest.json">
    <meta name="apple-mobile-web-app-title" content="Elastic">
    <meta name="application-name" content="Elastic">
    <meta name="msapplication-TileColor" content="#ffffff">
    <meta name="msapplication-TileImage" content="/mstile-144x144.png">
    <meta name="theme-color" content="#ffffff">
    <meta name="naver-site-verification" content="936882c1853b701b3cef3721758d80535413dbfd" />
    <meta name="yandex-verification" content="d8a47e95d0972434" />
    <meta name="localized" content="true" />
    <meta name="st:robots" content="follow,index" />
    <meta property="og:image" content="https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/blt280217a63b82a734/6202d3378b1f312528798412/elastic-logo.svg" />
    <meta property="og:image:width" content="500" />
    <meta property="og:image:height" content="172" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <link rel="apple-touch-icon-precomposed" sizes="64x64" href="/favicon_64x64_16bit.png">
    <link rel="apple-touch-icon-precomposed" sizes="32x32" href="/favicon_32x32.png">
    <link rel="apple-touch-icon-precomposed" sizes="16x16" href="/favicon_16x16.png">
    <!-- Give IE8 a fighting chance -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    <link rel="stylesheet" type="text/css" href="/guide/static/styles-v1.css" />
  </head>

  <!--© 2015-2025 Elasticsearch B.V. -->
  <!-- All Elastic documentation is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License. -->
  <!-- http://creativecommons.org/licenses/by-nc-nd/4.0/ -->

  <body>
    <!-- Google Tag Manager -->
    <script>dataLayer = [];</script><noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-58RLH5" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start': new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0], j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src= '//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f); })(window,document,'script','dataLayer','GTM-58RLH5');</script>
    <!-- End Google Tag Manager -->

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-12395217-16"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-12395217-16');
    </script>

    <!-- Google Tag Manager for GA4 -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start': new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0], j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-KNJMG2M');</script>
    <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-KNJMG2M" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    <!-- End Google Tag Manager for GA4-->

    <div id='elastic-nav' style="display:none;"></div>
    <script src='https://www.elastic.co/elastic-nav.js'></script>

    <div class="main-container">
      <section id="content" >
        <div class="content-wrapper">

          <section id="guide" lang="en">
            <div class="container-fluid">
              <div class="row pb-3">
                <div class="col-12 order-2 col-md-4 order-md-1 col-lg-3 h-almost-full-md sticky-top-md" id="left_col">
                  <!-- The TOC is appended here -->
                </div>

                <div class="col-12 order-1 col-md-8 order-md-2 col-lg-7 order-lg-2 guide-section" id="middle_col">
                  <!-- start body -->
                  
<div class="page_header">
This documentation contains work-in-progress information for future Elastic Stack and Cloud releases. Use the version selector to view supported release docs. It also contains some Elastic Cloud serverless information. Check out our <a href="https://www.elastic.co/docs/current/serverless">serverless docs</a> for more details.
</div>
<div class="navheader">
<span class="prev">
<a href="infer-service-cohere.html">« Cohere inference integration</a>
</span>
<span class="next">
<a href="infer-service-elser.html">ELSER inference integration »</a>
</span>
</div>
<div class="book" lang="en">
<div class="titlepage">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Elasticsearch Guide [8.x]</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="rest-apis.html">REST APIs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="inference-apis.html">Inference APIs</a></span>
</div>
<div>
<div><h1 class="title"><a id="id-1"></a>Elasticsearch inference integration</h1><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/8.x/docs/reference/inference/service-elasticsearch.asciidoc">edit</a></div>
</div>
<!--EXTRA-->
</div>
<div id="content">
<div class="section">
<div class="titlepage"><div><div>
<div class="position-relative"><h2 class="title"><a id="infer-service-elasticsearch"></a>Elasticsearch inference integration</h2><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/8.x/docs/reference/inference/service-elasticsearch.asciidoc">edit</a></div>
</div></div></div>
<div class="sidebar">
<div class="titlepage"><div><div>
<p class="title"><strong>New API reference</strong></p>
</div></div></div>
<p>For the most up-to-date API details, refer to <a href="/docs/api/doc/elasticsearch/v8/group/endpoint-inference" class="ulink" target="_top">Inference APIs</a>.</p>
</div>
<p>Creates an inference endpoint to perform an inference task with the <code class="literal">elasticsearch</code> service.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
Your Elasticsearch deployment contains <a class="xref" href="inference-apis.html#default-enpoints" title="Default inference endpoints">preconfigured ELSER and E5 inference endpoints</a>, you only need to create the enpoints using the API if you want to customize the settings.
</li>
<li class="listitem">
If you use the ELSER or the E5 model through the <code class="literal">elasticsearch</code> service, the API request will automatically download and deploy the model if it isn&#8217;t downloaded yet.
</li>
</ul>
</div>
</div>
</div>
<div class="position-relative"><h4><a id="infer-service-elasticsearch-api-request"></a>Request</h4><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/8.x/docs/reference/inference/service-elasticsearch.asciidoc">edit</a></div>
<p><code class="literal">PUT /_inference/&lt;task_type&gt;/&lt;inference_id&gt;</code></p>
<div class="position-relative"><h4><a id="infer-service-elasticsearch-api-path-params"></a>Path parameters</h4><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/8.x/docs/reference/inference/service-elasticsearch.asciidoc">edit</a></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">&lt;inference_id&gt;</code>
</span>
</dt>
<dd>
(Required, string)
The unique identifier of the inference endpoint.
</dd>
<dt>
<span class="term">
<code class="literal">&lt;task_type&gt;</code>
</span>
</dt>
<dd>
<p>
(Required, string)
The type of the inference task that the model will perform.
</p>
<p>Available task types:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">rerank</code>,
</li>
<li class="listitem">
<code class="literal">sparse_embedding</code>,
</li>
<li class="listitem">
<code class="literal">text_embedding</code>.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="position-relative"><h4><a id="infer-service-elasticsearch-api-request-body"></a>Request body</h4><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/8.x/docs/reference/inference/service-elasticsearch.asciidoc">edit</a></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">chunking_settings</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Chunking configuration object.
Refer to <a class="xref" href="inference-apis.html#infer-chunking-config" title="Configuring chunking">Configuring chunking</a> to learn more about chunking.
</p>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">max_chunk_size</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum size of a chunk in words.
Defaults to <code class="literal">250</code>.
This value cannot be higher than <code class="literal">300</code> or lower than <code class="literal">20</code> (for <code class="literal">sentence</code> strategy) or <code class="literal">10</code> (for <code class="literal">word</code> strategy).
</dd>
<dt>
<span class="term">
<code class="literal">overlap</code>
</span>
</dt>
<dd>
(Optional, integer)
Only for <code class="literal">word</code> chunking strategy.
Specifies the number of overlapping words for chunks.
Defaults to <code class="literal">100</code>.
This value cannot be higher than the half of <code class="literal">max_chunk_size</code>.
</dd>
<dt>
<span class="term">
<code class="literal">sentence_overlap</code>
</span>
</dt>
<dd>
(Optional, integer)
Only for <code class="literal">sentence</code> chunking strategy.
Specifies the numnber of overlapping sentences for chunks.
It can be either <code class="literal">1</code> or <code class="literal">0</code>.
Defaults to <code class="literal">1</code>.
</dd>
<dt>
<span class="term">
<code class="literal">strategy</code>
</span>
</dt>
<dd>
(Optional, string)
Specifies the chunking strategy.
It could be either <code class="literal">sentence</code> or <code class="literal">word</code>.
</dd>
</dl>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">service</code>
</span>
</dt>
<dd>
(Required, string)
The type of service supported for the specified task type. In this case,
<code class="literal">elasticsearch</code>.
</dd>
<dt>
<span class="term">
<code class="literal">service_settings</code>
</span>
</dt>
<dd>
<p>
(Required, object)
Settings used to install the inference model.
</p>
<p>These settings are specific to the <code class="literal">elasticsearch</code> service.</p>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">deployment_id</code>
</span>
</dt>
<dd>
(Optional, string)
The <code class="literal">deployment_id</code> of an existing trained model deployment.
When <code class="literal">deployment_id</code> is used the <code class="literal">model_id</code> is optional.
</dd>
<dt>
<span class="term">
<code class="literal">adaptive_allocations</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Adaptive allocations configuration object.
If enabled, the number of allocations of the model is set based on the current load the process gets.
When the load is high, a new model allocation is automatically created (respecting the value of <code class="literal">max_number_of_allocations</code> if it&#8217;s set).
When the load is low, a model allocation is automatically removed (respecting the value of <code class="literal">min_number_of_allocations</code> if it&#8217;s set).
If <code class="literal">adaptive_allocations</code> is enabled, do not set the number of allocations manually.
</p>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">enabled</code>
</span>
</dt>
<dd>
(Optional, Boolean)
If <code class="literal">true</code>, <code class="literal">adaptive_allocations</code> is enabled.
Defaults to <code class="literal">false</code>.
</dd>
<dt>
<span class="term">
<code class="literal">max_number_of_allocations</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of allocations to scale to.
If set, it must be greater than or equal to <code class="literal">min_number_of_allocations</code>.
</dd>
<dt>
<span class="term">
<code class="literal">min_number_of_allocations</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the minimum number of allocations to scale to.
If set, it must be greater than or equal to <code class="literal">0</code>.
If not defined, the deployment scales to <code class="literal">0</code>.
</dd>
</dl>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">model_id</code>
</span>
</dt>
<dd>
(Required, string)
The name of the model to use for the inference task.
It can be the ID of either a built-in model (for example, <code class="literal">.multilingual-e5-small</code> for E5), a text embedding model already
<a href="/guide/en/machine-learning/8.x/ml-nlp-import-model.html#ml-nlp-import-script" class="ulink" target="_top">uploaded through Eland</a>.
</dd>
<dt>
<span class="term">
<code class="literal">num_allocations</code>
</span>
</dt>
<dd>
(Required, integer)
The total number of allocations this model is assigned across machine learning nodes.
Increasing this value generally increases the throughput.
If <code class="literal">adaptive_allocations</code> is enabled, do not set this value, because it&#8217;s automatically set.
</dd>
<dt>
<span class="term">
<code class="literal">num_threads</code>
</span>
</dt>
<dd>
(Required, integer)
Sets the number of threads used by each model allocation during inference. This generally increases the speed per inference request. The inference process is a compute-bound process; <code class="literal">threads_per_allocations</code> must not exceed the number of available allocated processors per node.
Must be a power of 2. Max allowed value is 32.
</dd>
</dl>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">task_settings</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Settings to configure the inference task.
These settings are specific to the <code class="literal">&lt;task_type&gt;</code> you specified.
</p>
<details>
<summary class="title"><code class="literal">task_settings</code> for the <code class="literal">rerank</code> task type</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">return_documents</code>
</span>
</dt>
<dd>
(Optional, Boolean)
Returns the document instead of only the index. Defaults to <code class="literal">true</code>.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
<div class="position-relative"><h4><a id="inference-example-elasticsearch-elser"></a>ELSER via the <code class="literal">elasticsearch</code> service</h4><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/8.x/docs/reference/inference/service-elasticsearch.asciidoc">edit</a></div>
<p>The following example shows how to create an inference endpoint called <code class="literal">my-elser-model</code> to perform a <code class="literal">sparse_embedding</code> task type.</p>
<p>The API request below will automatically download the ELSER model if it isn&#8217;t already downloaded and then deploy the model.</p>
<div class="pre_wrapper lang-python alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-python alternative">resp = client.inference.put(
    task_type="sparse_embedding",
    inference_id="my-elser-model",
    inference_config={
        "service": "elasticsearch",
        "service_settings": {
            "adaptive_allocations": {
                "enabled": True,
                "min_number_of_allocations": 1,
                "max_number_of_allocations": 4
            },
            "num_threads": 1,
            "model_id": ".elser_model_2"
        }
    },
)
print(resp)</pre>
</div>
<div class="pre_wrapper lang-js alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js alternative">const response = await client.inference.put({
  task_type: "sparse_embedding",
  inference_id: "my-elser-model",
  inference_config: {
    service: "elasticsearch",
    service_settings: {
      adaptive_allocations: {
        enabled: true,
        min_number_of_allocations: 1,
        max_number_of_allocations: 4,
      },
      num_threads: 1,
      model_id: ".elser_model_2",
    },
  },
});
console.log(response);</pre>
</div>
<a id="ad9889fd8a4b5930e312a51f3bc996dc"></a>
<div class="pre_wrapper lang-console default has-python has-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console default has-python has-js">PUT _inference/sparse_embedding/my-elser-model
{
  "service": "elasticsearch",
  "service_settings": {
    "adaptive_allocations": { <a id="CO819-1"></a><i class="conum" data-value="1"></i>
      "enabled": true,
      "min_number_of_allocations": 1,
      "max_number_of_allocations": 4
    },
    "num_threads": 1,
    "model_id": ".elser_model_2" <a id="CO819-2"></a><i class="conum" data-value="2"></i>
  }
}</pre>
</div>
<div class="console_widget has-python has-js" data-snippet="snippets/2949.console"></div>
<div class="calloutlist default has-python has-js lang-console">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO819-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>Adaptive allocations will be enabled with the minimum of 1 and the maximum of 10 allocations.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO819-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p>The <code class="literal">model_id</code> must be the ID of one of the built-in ELSER models.
Valid values are <code class="literal">.elser_model_2</code> and <code class="literal">.elser_model_2_linux-x86_64</code>.
For further details, refer to the <a href="/guide/en/machine-learning/8.x/ml-nlp-elser.html" class="ulink" target="_top">ELSER model documentation</a>.</p>
</td>
</tr>
</table>
</div>
<div class="position-relative"><h4><a id="inference-example-elastic-reranker"></a>Elastic Rerank via the <code class="literal">elasticsearch</code> service</h4><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/8.x/docs/reference/inference/service-elasticsearch.asciidoc">edit</a></div>
<p>The following example shows how to create an inference endpoint called <code class="literal">my-elastic-rerank</code> to perform a <code class="literal">rerank</code> task type using the built-in Elastic Rerank cross-encoder model.</p>
<p>The API request below will automatically download the Elastic Rerank model if it isn&#8217;t already downloaded and then deploy the model.
Once deployed, the model can be used for semantic re-ranking with a <a class="xref" href="retriever.html#text-similarity-reranker-retriever-example-elastic-rerank" title="Example: Elastic Rerank"><code class="literal">text_similarity_reranker</code> retriever</a>.</p>
<div class="pre_wrapper lang-python alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-python alternative">resp = client.inference.put(
    task_type="rerank",
    inference_id="my-elastic-rerank",
    inference_config={
        "service": "elasticsearch",
        "service_settings": {
            "model_id": ".rerank-v1",
            "num_threads": 1,
            "adaptive_allocations": {
                "enabled": True,
                "min_number_of_allocations": 1,
                "max_number_of_allocations": 4
            }
        }
    },
)
print(resp)</pre>
</div>
<div class="pre_wrapper lang-js alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js alternative">const response = await client.inference.put({
  task_type: "rerank",
  inference_id: "my-elastic-rerank",
  inference_config: {
    service: "elasticsearch",
    service_settings: {
      model_id: ".rerank-v1",
      num_threads: 1,
      adaptive_allocations: {
        enabled: true,
        min_number_of_allocations: 1,
        max_number_of_allocations: 4,
      },
    },
  },
});
console.log(response);</pre>
</div>
<a id="30d051f534aeb884176eedb2c11dac85"></a>
<div class="pre_wrapper lang-console default has-python has-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console default has-python has-js">PUT _inference/rerank/my-elastic-rerank
{
  "service": "elasticsearch",
  "service_settings": {
    "model_id": ".rerank-v1", <a id="CO820-1"></a><i class="conum" data-value="1"></i>
    "num_threads": 1,
    "adaptive_allocations": { <a id="CO820-2"></a><i class="conum" data-value="2"></i>
      "enabled": true,
      "min_number_of_allocations": 1,
      "max_number_of_allocations": 4
    }
  }
}</pre>
</div>
<div class="console_widget has-python has-js" data-snippet="snippets/2950.console"></div>
<div class="calloutlist default has-python has-js lang-console">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO820-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>The <code class="literal">model_id</code> must be the ID of the built-in Elastic Rerank model: <code class="literal">.rerank-v1</code>.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO820-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p><a href="/guide/en/machine-learning/8.x/ml-nlp-auto-scale.html#nlp-model-adaptive-allocations" class="ulink" target="_top">Adaptive allocations</a> will be enabled with the minimum of 1 and the maximum of 10 allocations.</p>
</td>
</tr>
</table>
</div>
<div class="position-relative"><h4><a id="inference-example-elasticsearch"></a>E5 via the <code class="literal">elasticsearch</code> service</h4><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/8.x/docs/reference/inference/service-elasticsearch.asciidoc">edit</a></div>
<p>The following example shows how to create an inference endpoint called <code class="literal">my-e5-model</code> to perform a <code class="literal">text_embedding</code> task type.</p>
<p>The API request below will automatically download the E5 model if it isn&#8217;t already downloaded and then deploy the model.</p>
<div class="pre_wrapper lang-python alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-python alternative">resp = client.inference.put(
    task_type="text_embedding",
    inference_id="my-e5-model",
    inference_config={
        "service": "elasticsearch",
        "service_settings": {
            "num_allocations": 1,
            "num_threads": 1,
            "model_id": ".multilingual-e5-small"
        }
    },
)
print(resp)</pre>
</div>
<div class="pre_wrapper lang-js alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js alternative">const response = await client.inference.put({
  task_type: "text_embedding",
  inference_id: "my-e5-model",
  inference_config: {
    service: "elasticsearch",
    service_settings: {
      num_allocations: 1,
      num_threads: 1,
      model_id: ".multilingual-e5-small",
    },
  },
});
console.log(response);</pre>
</div>
<a id="00fea15cbca83be9d5f1a024ff2ec708"></a>
<div class="pre_wrapper lang-console default has-python has-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console default has-python has-js">PUT _inference/text_embedding/my-e5-model
{
  "service": "elasticsearch",
  "service_settings": {
    "num_allocations": 1,
    "num_threads": 1,
    "model_id": ".multilingual-e5-small" <a id="CO821-1"></a><i class="conum" data-value="1"></i>
  }
}</pre>
</div>
<div class="console_widget has-python has-js" data-snippet="snippets/2951.console"></div>
<div class="calloutlist default has-python has-js lang-console">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO821-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>The <code class="literal">model_id</code> must be the ID of one of the built-in E5 models.
Valid values are <code class="literal">.multilingual-e5-small</code> and <code class="literal">.multilingual-e5-small_linux-x86_64</code>.
For further details, refer to the <a href="/guide/en/machine-learning/8.x/ml-nlp-e5.html" class="ulink" target="_top">E5 model documentation</a>.</p>
</td>
</tr>
</table>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>You might see a 502 bad gateway error in the response when using the Kibana Console.
This error usually just reflects a timeout, while the model downloads in the background.
You can check the download progress in the Machine Learning UI.
If using the Python client, you can set the <code class="literal">timeout</code> parameter to a higher value.</p>
</div>
</div>
<div class="position-relative"><h4><a id="inference-example-eland"></a>Models uploaded by Eland via the <code class="literal">elasticsearch</code> service</h4><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/8.x/docs/reference/inference/service-elasticsearch.asciidoc">edit</a></div>
<p>The following example shows how to create an inference endpoint called
<code class="literal">my-msmarco-minilm-model</code> to perform a <code class="literal">text_embedding</code> task type.</p>
<div class="pre_wrapper lang-python alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-python alternative">resp = client.inference.put(
    task_type="text_embedding",
    inference_id="my-msmarco-minilm-model",
    inference_config={
        "service": "elasticsearch",
        "service_settings": {
            "num_allocations": 1,
            "num_threads": 1,
            "model_id": "msmarco-MiniLM-L12-cos-v5"
        }
    },
)
print(resp)</pre>
</div>
<div class="pre_wrapper lang-js alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js alternative">const response = await client.inference.put({
  task_type: "text_embedding",
  inference_id: "my-msmarco-minilm-model",
  inference_config: {
    service: "elasticsearch",
    service_settings: {
      num_allocations: 1,
      num_threads: 1,
      model_id: "msmarco-MiniLM-L12-cos-v5",
    },
  },
});
console.log(response);</pre>
</div>
<a id="4c9350ed09b28f00e297ebe73c3b95a2"></a>
<div class="pre_wrapper lang-console default has-python has-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console default has-python has-js">PUT _inference/text_embedding/my-msmarco-minilm-model <a id="CO822-1"></a><i class="conum" data-value="1"></i>
{
  "service": "elasticsearch",
  "service_settings": {
    "num_allocations": 1,
    "num_threads": 1,
    "model_id": "msmarco-MiniLM-L12-cos-v5" <a id="CO822-2"></a><i class="conum" data-value="2"></i>
  }
}</pre>
</div>
<div class="console_widget has-python has-js" data-snippet="snippets/2952.console"></div>
<div class="calloutlist default has-python has-js lang-console">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO822-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>Provide an unique identifier for the inference endpoint. The <code class="literal">inference_id</code> must be unique and must not match the <code class="literal">model_id</code>.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO822-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p>The <code class="literal">model_id</code> must be the ID of a text embedding model which has already been
<a href="/guide/en/machine-learning/8.x/ml-nlp-import-model.html#ml-nlp-import-script" class="ulink" target="_top">uploaded through Eland</a>.</p>
</td>
</tr>
</table>
</div>
<div class="position-relative"><h4><a id="inference-example-adaptive-allocation"></a>Setting adaptive allocation for E5 via the <code class="literal">elasticsearch</code> service</h4><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/8.x/docs/reference/inference/service-elasticsearch.asciidoc">edit</a></div>
<p>The following example shows how to create an inference endpoint called
<code class="literal">my-e5-model</code> to perform a <code class="literal">text_embedding</code> task type and configure adaptive
allocations.</p>
<p>The API request below will automatically download the E5 model if it isn&#8217;t
already downloaded and then deploy the model.</p>
<div class="pre_wrapper lang-python alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-python alternative">resp = client.inference.put(
    task_type="text_embedding",
    inference_id="my-e5-model",
    inference_config={
        "service": "elasticsearch",
        "service_settings": {
            "adaptive_allocations": {
                "enabled": True,
                "min_number_of_allocations": 3,
                "max_number_of_allocations": 10
            },
            "num_threads": 1,
            "model_id": ".multilingual-e5-small"
        }
    },
)
print(resp)</pre>
</div>
<div class="pre_wrapper lang-js alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js alternative">const response = await client.inference.put({
  task_type: "text_embedding",
  inference_id: "my-e5-model",
  inference_config: {
    service: "elasticsearch",
    service_settings: {
      adaptive_allocations: {
        enabled: true,
        min_number_of_allocations: 3,
        max_number_of_allocations: 10,
      },
      num_threads: 1,
      model_id: ".multilingual-e5-small",
    },
  },
});
console.log(response);</pre>
</div>
<a id="083b92e8ea264e49bf9fd40fc6a3094b"></a>
<div class="pre_wrapper lang-console default has-python has-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console default has-python has-js">PUT _inference/text_embedding/my-e5-model
{
  "service": "elasticsearch",
  "service_settings": {
    "adaptive_allocations": {
      "enabled": true,
      "min_number_of_allocations": 3,
      "max_number_of_allocations": 10
    },
    "num_threads": 1,
    "model_id": ".multilingual-e5-small"
  }
}</pre>
</div>
<div class="console_widget has-python has-js" data-snippet="snippets/2953.console"></div>
<div class="position-relative"><h4><a id="inference-example-existing-deployment"></a>Using an existing model deployment with the <code class="literal">elasticsearch</code> service</h4><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/8.x/docs/reference/inference/service-elasticsearch.asciidoc">edit</a></div>
<p>The following example shows how to use an already existing model deployment when creating an inference endpoint.</p>
<div class="pre_wrapper lang-python alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-python alternative">resp = client.inference.put(
    task_type="sparse_embedding",
    inference_id="use_existing_deployment",
    inference_config={
        "service": "elasticsearch",
        "service_settings": {
            "deployment_id": ".elser_model_2"
        }
    },
)
print(resp)</pre>
</div>
<div class="pre_wrapper lang-js alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js alternative">const response = await client.inference.put({
  task_type: "sparse_embedding",
  inference_id: "use_existing_deployment",
  inference_config: {
    service: "elasticsearch",
    service_settings: {
      deployment_id: ".elser_model_2",
    },
  },
});
console.log(response);</pre>
</div>
<a id="85f9fc6f98e8573efed9b034e853d5ae"></a>
<div class="pre_wrapper lang-console default has-python has-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console default has-python has-js">PUT _inference/sparse_embedding/use_existing_deployment
{
  "service": "elasticsearch",
  "service_settings": {
    "deployment_id": ".elser_model_2" <a id="CO823-1"></a><i class="conum" data-value="1"></i>
  }
}</pre>
</div>
<div class="console_widget has-python has-js" data-snippet="snippets/2954.console"></div>
<div class="calloutlist default has-python has-js lang-console">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO823-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>The <code class="literal">deployment_id</code> of the already existing model deployment.</p>
</td>
</tr>
</table>
</div>
<p>The API response contains the <code class="literal">model_id</code>, and the threads and allocations settings from the model deployment:</p>
<a id="8f534b81e42a9793ac819fb9652f650b"></a>
<div class="pre_wrapper lang-console-result">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console-result">{
  "inference_id": "use_existing_deployment",
  "task_type": "sparse_embedding",
  "service": "elasticsearch",
  "service_settings": {
    "num_allocations": 2,
    "num_threads": 1,
    "model_id": ".elser_model_2",
    "deployment_id": ".elser_model_2"
  },
  "chunking_settings": {
    "strategy": "sentence",
    "max_chunk_size": 250,
    "sentence_overlap": 1
  }
}</pre>
</div>
</div>
</div>
</div><div class="navfooter">
<span class="prev">
<a href="infer-service-cohere.html">« Cohere inference integration</a>
</span>
<span class="next">
<a href="infer-service-elser.html">ELSER inference integration »</a>
</span>
</div>

                  <!-- end body -->
                </div>

                <div class="col-12 order-3 col-lg-2 order-lg-3 h-almost-full-lg sticky-top-lg" id="right_col">
                  <div id="sticky_content">
                    <!-- The OTP is appended here -->
                    <div class="row">
                      <div class="col-0 col-md-4 col-lg-0" id="bottom_left_col"></div>
                      <div class="col-12 col-md-8 col-lg-12">
                        <div id="rtpcontainer">
                          <div class="mktg-promo" id="most-popular">
                            <p class="aside-heading">Most Popular</p>
                            <div class="pb-2">
                              <p class="media-type">Video</p>
                              <a href="https://www.elastic.co/webinars/getting-started-elasticsearch?page=docs&placement=top-video">
                                <p class="mb-0">Get Started with Elasticsearch</p>
                              </a>
                            </div>
                            <div class="pb-2">
                              <p class="media-type">Video</p>
                              <a href="https://www.elastic.co/webinars/getting-started-kibana?page=docs&placement=top-video">
                                <p class="mb-0">Intro to Kibana</p>
                              </a>
                            </div>
                            <div class="pb-2">
                              <p class="media-type">Video</p>
                              <a href="https://www.elastic.co/webinars/introduction-elk-stack?page=docs&placement=top-video">
                                <p class="mb-0">ELK for Logs & Metrics</p>
                              </a>
                            </div>
                          </div>
                        </div>

                        <!-- Feedback widget -->
                        <div id="feedbackWidgetContainer"></div>
                      </div>
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </section>

        </div>


        <div id='elastic-footer'></div>
        <script src='https://www.elastic.co/elastic-footer.js'></script>
        <!-- Footer Section end-->

      </section>
    </div>

    <!-- Feedback modal -->
    <div id="feedbackModalContainer"></div>

    <script src="/guide/static/jquery.js"></script>
    <script type="text/javascript" src="/guide/static/docs-v1.js"></script>
    <script type="text/javascript">
  window.initial_state = {"alternatives":{"console":{"php":{"hasAny":true},"python":{"hasAny":true},"ruby":{"hasAny":true},"go":{"hasAny":true},"js":{"hasAny":true}}}}</script>
  </body>
</html>
