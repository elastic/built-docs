<!DOCTYPE html>
<html lang="en-us">
  <head>
    
<meta charset="UTF-8">
<title>Task Manager troubleshooting | Kibana Guide [7.12] | Elastic</title>
<link rel="home" href="index.html" title="Kibana Guide [7.12]"/>
<link rel="up" href="task-manager-production-considerations.html" title="Task Manager"/>
<link rel="prev" href="task-manager-health-monitoring.html" title="Task Manager health monitoring"/>
<link rel="next" href="discover.html" title="Discover"/>
<meta name="DC.type" content="Learn/Docs/Kibana/Reference/7.12"/>
<meta name="DC.subject" content="Kibana"/>
<meta name="DC.identifier" content="7.12"/>

    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <script src="https://cdn.optimizely.com/js/18132920325.js"></script>
    <link rel="apple-touch-icon" sizes="57x57" href="/apple-icon-57x57.png">
    <link rel="apple-touch-icon" sizes="60x60" href="/apple-icon-60x60.png">
    <link rel="apple-touch-icon" sizes="72x72" href="/apple-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="76x76" href="/apple-icon-76x76.png">
    <link rel="apple-touch-icon" sizes="114x114" href="/apple-icon-114x114.png">
    <link rel="apple-touch-icon" sizes="120x120" href="/apple-icon-120x120.png">
    <link rel="apple-touch-icon" sizes="144x144" href="/apple-icon-144x144.png">
    <link rel="apple-touch-icon" sizes="152x152" href="/apple-icon-152x152.png">
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-icon-180x180.png">
    <link rel="icon" type="image/png" href="/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="/android-chrome-192x192.png" sizes="192x192">
    <link rel="icon" type="image/png" href="/favicon-96x96.png" sizes="96x96">
    <link rel="icon" type="image/png" href="/favicon-16x16.png" sizes="16x16">
    <link rel="manifest" href="/manifest.json">
    <meta name="apple-mobile-web-app-title" content="Elastic">
    <meta name="application-name" content="Elastic">
    <meta name="msapplication-TileColor" content="#ffffff">
    <meta name="msapplication-TileImage" content="/mstile-144x144.png">
    <meta name="theme-color" content="#ffffff">
    <meta name="naver-site-verification" content="936882c1853b701b3cef3721758d80535413dbfd" />
    <meta name="yandex-verification" content="d8a47e95d0972434" />
    <meta name="localized" content="true" />
    <meta name="st:robots" content="follow,index" />
    <meta property="og:image" content="https://www.elastic.co/static/images/elastic-logo-200.png" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <link rel="apple-touch-icon-precomposed" sizes="64x64" href="/favicon_64x64_16bit.png">
    <link rel="apple-touch-icon-precomposed" sizes="32x32" href="/favicon_32x32.png">
    <link rel="apple-touch-icon-precomposed" sizes="16x16" href="/favicon_16x16.png">
    <!-- Give IE8 a fighting chance -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    <link rel="stylesheet" type="text/css" href="/guide/static/styles.css" />
  </head>

  <body>
    <!-- Google Tag Manager -->
    <script>dataLayer = [];</script><noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-58RLH5" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start': new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0], j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src= '//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f); })(window,document,'script','dataLayer','GTM-58RLH5');</script>
    <!-- End Google Tag Manager -->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-12395217-16"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-12395217-16');
    </script>

    <!--BEGIN QUALTRICS WEBSITE FEEDBACK SNIPPET-->
    <script type='text/javascript'>
      (function(){var g=function(e,h,f,g){
      this.get=function(a){for(var a=a+"=",c=document.cookie.split(";"),b=0,e=c.length;b<e;b++){for(var d=c[b];" "==d.charAt(0);)d=d.substring(1,d.length);if(0==d.indexOf(a))return d.substring(a.length,d.length)}return null};
      this.set=function(a,c){var b="",b=new Date;b.setTime(b.getTime()+6048E5);b="; expires="+b.toGMTString();document.cookie=a+"="+c+b+"; path=/; "};
      this.check=function(){var a=this.get(f);if(a)a=a.split(":");else if(100!=e)"v"==h&&(e=Math.random()>=e/100?0:100),a=[h,e,0],this.set(f,a.join(":"));else return!0;var c=a[1];if(100==c)return!0;switch(a[0]){case "v":return!1;case "r":return c=a[2]%Math.floor(100/c),a[2]++,this.set(f,a.join(":")),!c}return!0};
      this.go=function(){if(this.check()){var a=document.createElement("script");a.type="text/javascript";a.src=g;document.body&&document.body.appendChild(a)}};
      this.start=function(){var a=this;window.addEventListener?window.addEventListener("load",function(){a.go()},!1):window.attachEvent&&window.attachEvent("onload",function(){a.go()})}};
      try{(new g(100,"r","QSI_S_ZN_emkP0oSe9Qrn7kF","https://znemkp0ose9qrn7kf-elastic.siteintercept.qualtrics.com/WRSiteInterceptEngine/?Q_ZID=ZN_emkP0oSe9Qrn7kF")).start()}catch(i){}})();
    </script><div id='ZN_emkP0oSe9Qrn7kF'><!--DO NOT REMOVE-CONTENTS PLACED HERE--></div>
    <!--END WEBSITE FEEDBACK SNIPPET-->

    <div id='elastic-nav' style="display:none;"></div>
    <script src='https://www.elastic.co/elastic-nav.js'></script>

    <!-- Subnav -->
    <div>
      <div>
        <div class="tertiary-nav d-none d-md-block">
          <div class="container">
            <div class="p-t-b-15 d-flex justify-content-between nav-container">
              <div class="breadcrum-wrapper"><span><a href="/guide/" style="font-size: 14px; font-weight: 600; color: #000;">Docs</a></span></div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="main-container">
      <section id="content" >
        <div class="content-wrapper">

          <section id="guide" lang="en">
            <div class="container">
              <div class="row">
                <div class="col-xs-12 col-sm-8 col-md-8 guide-section">
                  <!-- start body -->
                  <div class="page_header">
You are looking at preliminary documentation for a future release.
Not what you want? See the
<a href="../current/index.html">current release documentation</a>.
</div>
<div id="content">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="index.html">Kibana Guide [7.12]</a></span>
»
<span class="breadcrumb-link"><a href="production.html">Use Kibana in a production environment</a></span>
»
<span class="breadcrumb-link"><a href="task-manager-production-considerations.html">Task Manager</a></span>
»
<span class="breadcrumb-node">Task Manager troubleshooting</span>
</div>
<div class="navheader">
<span class="prev">
<a href="task-manager-health-monitoring.html">« Task Manager health monitoring</a>
</span>
<span class="next">
<a href="discover.html">Discover »</a>
</span>
</div>
<div class="section xpack">
<div class="titlepage"><div><div>
<h2 class="title"><a id="task-manager-troubleshooting"></a>Task Manager troubleshooting<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/kibana/edit/7.12/docs/user/production-considerations/task-manager-troubleshooting.asciidoc">edit</a><a class="xpack_tag" href="/subscriptions"></a></h2>
</div></div></div>

<p>Task Manager is used by a wide range of services in Kibana, such as <a class="xref" href="alerting-production-considerations.html" title="Alerting production considerations">Alerting</a>, Reporting, and Telemetry.
Unexpected behavior in these services might be a downstream issue originating in Task Manager.</p>
<p>This page describes how to resolve common problems you might encounter with Task Manager.
If your problem isn’t described here, please review open issues in the following GitHub repositories:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<a href="https://github.com/elastic/kibana/issues" class="ulink" target="_top">Kibana</a> (<a href="https://github.com/elastic/kibana/issues?q=is%3Aopen+is%3Aissue+label%3A%22Feature%3ATask+Manager%22" class="ulink" target="_top">Task Manager issues</a>)
</li>
</ul>
</div>
<p>Have a question? Contact us in the <a href="https://discuss.elastic.co/" class="ulink" target="_top">discuss forum</a>.</p>
<h4><a id="task-manager-health-scheduled-tasks-small-schedule-interval-run-late"></a>Tasks with small schedule intervals run late<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/kibana/edit/7.12/docs/user/production-considerations/task-manager-troubleshooting.asciidoc">edit</a></h4>
<p><span class="strong strong"><strong>Problem</strong></span>:</p>
<p>Tasks are scheduled to run every 2 seconds, but seem to be running late.</p>
<p><span class="strong strong"><strong>Solution</strong></span>:</p>
<p>Task Manager polls for tasks at the cadence specified by the <a class="xref" href="task-manager-settings-kb.html#task-manager-settings" title="Task Manager settings"><code class="literal">xpack.task_manager.poll_interval</code></a> setting, which is 3 seconds by default. This means that a task could run late if it uses a schedule that is smaller than this setting.</p>
<p>You can adjust the <a class="xref" href="task-manager-settings-kb.html#task-manager-settings" title="Task Manager settings"><code class="literal">xpack.task_manager.poll_interval</code></a> setting.  However, this will add additional load to both Kibana and Elasticsearch instances in the cluster, as they will perform more queries.</p>
<h4><a id="task-manager-health-tasks-run-late"></a>Tasks run late<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/kibana/edit/7.12/docs/user/production-considerations/task-manager-troubleshooting.asciidoc">edit</a></h4>
<p><span class="strong strong"><strong>Problem</strong></span>:</p>
<p>The most common symptom of an underlying problem in Task Manager is that tasks appear to run late.
For instance, recurring tasks might run at an inconsistent cadence, or long after their scheduled time.</p>
<p><span class="strong strong"><strong>Solution</strong></span>:</p>
<p>By default, Kibana polls for tasks at a rate of 10 tasks every 3 seconds.</p>
<p>If many tasks are scheduled to run at the same time, pending tasks will queue in Elasticsearch. Each Kibana instance then polls for pending tasks at a rate of up to 10 tasks at a time, at 3 second intervals. It is possible for pending tasks in the queue to exceed this capacity and run late as a result.</p>
<p>This type of delay is known as <em>drift</em>.The root cause for drift depends on the specific usage, and there are no hard and fast rules for addressing drift.</p>
<p>For example:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
If drift is caused by <span class="strong strong"><strong>an excess of concurrent tasks</strong></span> relative to the available capacity of Kibana instances in the cluster, expand the throughput of the cluster.
</li>
<li class="listitem">
If drift is caused by <span class="strong strong"><strong>long running tasks</strong></span> that overrun their scheduled cadence,  reconfigure the tasks in question.
</li>
</ul>
</div>
<p>Refer to <a class="xref" href="task-manager-troubleshooting.html#task-manager-diagnosing-root-cause" title="Diagnose a root cause for drift">Diagnose a root cause for drift</a> for step-by-step instructions on identifying the correct resolution.</p>
<p><em>Drift</em> is often addressed by adjusting the scaling the deployment to better suit your usage.
For details on scaling Task Manager, see <a class="xref" href="task-manager-production-considerations.html#task-manager-scaling-guidance" title="Scaling guidance">Scaling guidance</a>.</p>
<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="task-manager-diagnosing-root-cause"></a>Diagnose a root cause for drift<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/kibana/edit/7.12/docs/user/production-considerations/task-manager-troubleshooting.asciidoc">edit</a></h3>
</div></div></div>
<p>The following guide helps you identify a root cause for <em>drift</em> by making sense of the output from the <a class="xref" href="task-manager-health-monitoring.html" title="Task Manager health monitoring">Health monitoring</a> endpoint.</p>
<p>By analyzing the different sections of the output, you can evaluate different theories that explain the drift in a deployment.</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<p><a class="xref" href="task-manager-troubleshooting.html#task-manager-health-evaluate-the-configuration" title="Evaluate the Configuration">Evaluate the Configuration</a></p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<a class="xref" href="task-manager-troubleshooting.html#task-manager-theory-reduced-polling-rate">Kibana is configured to poll for tasks at a reduced rate</a>
</li>
</ul>
</div>
</li>
<li class="listitem">
<p><a class="xref" href="task-manager-troubleshooting.html#task-manager-health-evaluate-the-runtime" title="Evaluate the Runtime">Evaluate the Runtime</a></p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<a class="xref" href="task-manager-troubleshooting.html#task-manager-theory-actual-polling-frequently">Kibana is not actually polling as frequently as it should</a>
</li>
<li class="listitem">
<a class="xref" href="task-manager-troubleshooting.html#task-manager-theory-insufficient-throughput">Kibana is polling as frequently as it should, but that isn&#8217;t often enough to keep up with the workload</a>
</li>
<li class="listitem">
<a class="xref" href="task-manager-troubleshooting.html#task-manager-theory-long-running-tasks">Tasks run for too long, overrunning their schedule</a>
</li>
<li class="listitem">
<a class="xref" href="task-manager-troubleshooting.html#task-manager-theory-high-fail-rate">Tasks take multiple attempts to succeed</a>
</li>
</ul>
</div>
</li>
<li class="listitem">
<a class="xref" href="task-manager-troubleshooting.html#task-manager-health-evaluate-the-workload" title="Evaluate the Workload">Evaluate the Workload</a>
</li>
</ul>
</div>
<p>Retrieve the latest monitored health stats of a Kibana instance Task Manager:</p>
<div class="pre_wrapper lang-kibana">
<pre class="programlisting prettyprint lang-kibana">$ curl -X GET api/task_manager/_health</pre>
</div>
<div class="kibana_widget" data-snippet="snippets/3.kibana"></div>
<p>The API returns the following:</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json">{
  "id": "15415ecf-cdb0-4fef-950a-f824bd277fe4",
  "timestamp": "2021-02-16T11:38:10.077Z",
  "status": "OK",
  "last_update": "2021-02-16T11:38:09.934Z",
  "stats": {
    "configuration": {
      "timestamp": "2021-02-16T11:29:05.055Z",
      "value": {
        "request_capacity": 1000,
        "max_poll_inactivity_cycles": 10,
        "monitored_aggregated_stats_refresh_rate": 60000,
        "monitored_stats_running_average_window": 50,
        "monitored_task_execution_thresholds": {
          "default": {
            "error_threshold": 90,
            "warn_threshold": 80
          },
          "custom": {}
        },
        "poll_interval": 3000,
        "max_workers": 10
      },
      "status": "OK"
    },
    "runtime": {
      "timestamp": "2021-02-16T11:38:09.934Z",
      "value": {
        "polling": {
          "last_successful_poll": "2021-02-16T11:38:09.934Z",
          "last_polling_delay": "2021-02-16T11:29:05.053Z",
          "duration": {
            "p50": 13,
            "p90": 128,
            "p95": 143,
            "p99": 168
          },
          "claim_conflicts": {
            "p50": 0,
            "p90": 0,
            "p95": 0,
            "p99": 0
          },
          "claim_mismatches": {
            "p50": 0,
            "p90": 0,
            "p95": 0,
            "p99": 0
          },
          "result_frequency_percent_as_number": {
            "Failed": 0,
            "NoAvailableWorkers": 0,
            "NoTasksClaimed": 80,
            "RanOutOfCapacity": 0,
            "RunningAtCapacity": 0,
            "PoolFilled": 20
          }
        },
        "drift": {
          "p50": 99,
          "p90": 1245,
          "p95": 1845,
          "p99": 2878
        },
        "load": {
          "p50": 0,
          "p90": 0,
          "p95": 10,
          "p99": 20
        },
        "execution": {
          "duration": {
            "alerting:.index-threshold": {
              "p50": 95,
              "p90": 1725,
              "p95": 2761,
              "p99": 2761
            },
            "alerting:xpack.uptime.alerts.monitorStatus": {
              "p50": 149,
              "p90": 1071,
              "p95": 1171,
              "p99": 1171
            },
            "actions:.index": {
              "p50": 166,
              "p90": 166,
              "p95": 166,
              "p99": 166
            }
          },
          "result_frequency_percent_as_number": {
            "alerting:.index-threshold": {
              "Success": 100,
              "RetryScheduled": 0,
              "Failed": 0,
              "status": "OK"
            },
            "alerting:xpack.uptime.alerts.monitorStatus": {
              "Success": 100,
              "RetryScheduled": 0,
              "Failed": 0,
              "status": "OK"
            },
            "actions:.index": {
              "Success": 10,
              "RetryScheduled": 0,
              "Failed": 90,
              "status": "error"
            }
          }
        }
      },
      "status": "OK"
    },
    "workload": {
      "timestamp": "2021-02-16T11:38:05.826Z",
      "value": {
        "count": 26,
        "task_types": {
          "alerting:.index-threshold": {
            "count": 2,
            "status": {
              "idle": 2
            }
          },
          "actions:.index": {
            "count": 14,
            "status": {
              "idle": 2,
              "running": 2,
              "failed": 10
            }
          },
          "alerting:xpack.uptime.alerts.monitorStatus": {
            "count": 10,
            "status": {
              "idle": 10
            }
          },
        },
        "schedule": [
          ["10s", 2],
          ["1m", 2],
          ["60s", 2],
          ["5m", 2],
          ["60m", 4]
        ],
        "overdue": 0,
        "estimated_schedule_density": [0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 3, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0]
      },
      "status": "OK"
    }
  }
}</pre>
</div>
<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="task-manager-health-evaluate-the-configuration"></a>Evaluate the Configuration<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/kibana/edit/7.12/docs/user/production-considerations/task-manager-troubleshooting.asciidoc">edit</a></h4>
</div></div></div>
<p><a id="task-manager-theory-reduced-polling-rate"></a><span class="strong strong"><strong>Theory</strong></span>:
Kibana is configured to poll for tasks at a reduced rate.</p>
<p><span class="strong strong"><strong>Diagnosis</strong></span>:
Evaluating the health stats, you can see the following output under <code class="literal">stats.configuration.value</code>:</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json">{
  "request_capacity": 1000,
  "max_poll_inactivity_cycles": 10,
  "monitored_aggregated_stats_refresh_rate": 60000,
  "monitored_stats_running_average_window": 50,
  "monitored_task_execution_thresholds": {
    "default": {
      "error_threshold": 90,
      "warn_threshold": 80
    },
    "custom": {}
  },
  "poll_interval": 3000, <a id="CO8-1"></a><i class="conum" data-value="1"></i>
  "max_workers": 10 <a id="CO8-2"></a><i class="conum" data-value="2"></i>
}</pre>
</div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO8-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p><code class="literal">poll_interval</code> is set to the default value of 3000 milliseconds</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO8-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p><code class="literal">max_workers</code> is set to the default value of 10 workers</p>
</td>
</tr>
</table>
</div>
<p>You can infer from this output that the Kibana instance polls for work every 3 seconds and can run 10 concurrent tasks.</p>
<p>Now suppose the output under <code class="literal">stats.configuration.value</code> is the following:</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json">{
  "request_capacity": 1000,
  "max_poll_inactivity_cycles": 10,
  "monitored_aggregated_stats_refresh_rate": 60000,
  "monitored_stats_running_average_window": 50,
  "monitored_task_execution_thresholds": {
    "default": {
      "error_threshold": 90,
      "warn_threshold": 80
    },
    "custom": {}
  },
  "poll_interval": 60000, <a id="CO9-1"></a><i class="conum" data-value="1"></i>
  "max_workers": 1 <a id="CO9-2"></a><i class="conum" data-value="2"></i>
}</pre>
</div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO9-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p><code class="literal">poll_interval</code> is set to 60000 milliseconds, far higher than the default</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO9-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p><code class="literal">max_workers</code> is set to 1 worker, far lower than the default</p>
</td>
</tr>
</table>
</div>
<p>You can infer from this output that the Kibana instance only polls for work once a minute and only picks up one task at a time. This throughput is unlikely to support mission critical services, such as Alerting or Reporting, and tasks will usually run late.</p>
<p>There are two possible reasons for such a configuration:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
These settings have been configured manually, which can be resolved by reconfiguring these settings.
For details, see <a class="xref" href="task-manager-settings-kb.html" title="Task Manager settings in Kibana">Task Manager Settings</a>.
</li>
<li class="listitem">
<p>Kibana has reduced its own throughput in reaction to excessive load on the Elasticsearch cluster.</p>
<p>Task Manager is equipped with a reactive self-healing mechanism in response to an increase in load related errors in Elasticsearch. This mechanism will increase the <code class="literal">poll_interval</code> setting (reducing the rate at which it queries Elasticsearch), and decrease the <code class="literal">max_workers</code> (reducing the amount of operations it executes against Elasticsearch). Once the error rate reduces, these settings are incrementally dialed up again, returning them to the configured settings.</p>
<p>This scenario can be identified by searching the Kibana Server Log for messages such as:</p>
<div class="pre_wrapper lang-txt">
<pre class="programlisting prettyprint lang-txt">Max workers configuration is temporarily reduced after Elasticsearch returned 25 "too many request" error(s).</pre>
</div>
<p>Deeper investigation into the high error rate experienced by the Elasticsearch cluster is required.</p>
</li>
</ul>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="task-manager-health-evaluate-the-runtime"></a>Evaluate the Runtime<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/kibana/edit/7.12/docs/user/production-considerations/task-manager-troubleshooting.asciidoc">edit</a></h4>
</div></div></div>
<p><a id="task-manager-theory-actual-polling-frequently"></a><span class="strong strong"><strong>Theory</strong></span>:
Kibana is not polling as frequently as it should</p>
<p><span class="strong strong"><strong>Diagnosis</strong></span>:
Evaluating the health stats, you see the following output under <code class="literal">stats.runtime.value.polling</code>:</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json">{
  "last_successful_poll": "2021-02-16T11:38:09.934Z", <a id="CO10-1"></a><i class="conum" data-value="1"></i>
  "last_polling_delay": "2021-02-14T11:29:05.053Z",
  "duration": { <a id="CO10-2"></a><i class="conum" data-value="2"></i>
    "p50": 13,
    "p90": 128,
    "p95": 143,
    "p99": 168
  },
  "claim_conflicts": { <a id="CO10-3"></a><i class="conum" data-value="3"></i>
    "p50": 0,
    "p90": 0,
    "p95": 0,
    "p99": 2
  },
  "claim_mismatches": {
    "p50": 0,
    "p90": 0,
    "p95": 0,
    "p99": 0
  },
  "result_frequency_percent_as_number": { <a id="CO10-4"></a><i class="conum" data-value="4"></i>
    "Failed": 0,
    "NoAvailableWorkers": 0,
    "NoTasksClaimed": 80,
    "RanOutOfCapacity": 0,
    "RunningAtCapacity": 0,
    "PoolFilled": 20
  }
}</pre>
</div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO10-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>Ensure the last successful polling cycle was completed no more than a couple of multiples of <code class="literal">poll_interval</code> in the past.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO10-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p>Ensure the duration of polling cycles is usually below 100ms. Longer durations are possible, but unexpected.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO10-3"><i class="conum" data-value="3"></i></a></p>
</td>
<td align="left" valign="top">
<p>Ensure Kibana instances in the cluster are not encountering a high rate of version conflicts.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO10-4"><i class="conum" data-value="4"></i></a></p>
</td>
<td align="left" valign="top">
<p>Ensure the majority of polling cycles result in positive outcomes, such as <code class="literal">RunningAtCapacity</code> or <code class="literal">PoolFilled</code>.</p>
</td>
</tr>
</table>
</div>
<p>You can infer from this output that the Kibana instance is polling regularly.
This assessment is based on the following:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
Comparing the <code class="literal">last_successful_poll</code> to the <code class="literal">timestamp</code> (value of <code class="literal">2021-02-16T11:38:10.077Z</code>) at the root, where you can see the last polling cycle took place 1 second before the monitoring stats were exposed by the health monitoring API.
</li>
<li class="listitem">
Comparing the <code class="literal">last_polling_delay</code> to the <code class="literal">timestamp</code> (value of <code class="literal">2021-02-16T11:38:10.077Z</code>) at the root, where you can see the last polling cycle delay took place 2 days ago, suggesting Kibana instances are not conflicting often.
</li>
<li class="listitem">
The <code class="literal">p50</code> of the <code class="literal">duration</code> shows that at least 50% of polling cycles take, at most, 13 millisconds to complete.
</li>
<li class="listitem">
<p>Evaluating the <code class="literal">result_frequency_percent_as_number</code>:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
80% of the polling cycles completed without claiming any tasks (suggesting that there aren&#8217;t any overdue tasks).
</li>
<li class="listitem">
20% completed with Task Manager claiming tasks that were then executed.
</li>
<li class="listitem">
None of the polling cycles ended up occupying all of the available workers, as <code class="literal">RunningAtCapacity</code> has a frequency of 0%, suggesting there is enough capacity in Task Manager to handle the workload.
</li>
</ul>
</div>
</li>
</ul>
</div>
<p>All of these stats are tracked as a running average, which means that they give a snapshot of a period of time (by default Kibana tracks up to 50 cycles), rather than giving a complete history.</p>
<p>Suppose the output under <code class="literal">stats.runtime.value.polling.result_frequency_percent_as_number</code> was the following:</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json">{
  "Failed": 30, <a id="CO11-1"></a><i class="conum" data-value="1"></i>
  "NoAvailableWorkers": 20, <a id="CO11-2"></a><i class="conum" data-value="2"></i>
  "NoTasksClaimed": 10,
  "RanOutOfCapacity": 10, <a id="CO11-3"></a><i class="conum" data-value="3"></i>
  "RunningAtCapacity": 10, <a id="CO11-4"></a><i class="conum" data-value="4"></i>
  "PoolFilled": 20
}</pre>
</div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO11-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>30% of polling cycles failed, which is a high rate.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO11-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p>20% of polling cycles are skipped as Task Manager has no capacity left to run tasks.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO11-3"><i class="conum" data-value="3"></i></a></p>
</td>
<td align="left" valign="top">
<p>10% of polling cycles result in Task Manager claiming more tasks than it has capacity to run.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO11-4"><i class="conum" data-value="4"></i></a></p>
</td>
<td align="left" valign="top">
<p>10% of polling cycles result in Task Manager claiming precisely as many tasks as it has capacity to run.</p>
</td>
</tr>
</table>
</div>
<p>You can infer from this output that Task Manager is not healthy, as the failure rate is high, and Task Manager is fetching tasks it has no capacity to run.
Analyzing the Kibana Server Log should reveal the underlying issue causing the high error rate and capacity issues.</p>
<p>The high <code class="literal">NoAvailableWorkers</code> rate of 20% suggests that there are many tasks running for durations longer than the <code class="literal">poll_interval</code>.
For details on analyzing long task execution durations, see the <a class="xref" href="task-manager-troubleshooting.html#task-manager-theory-long-running-tasks">long running tasks</a> theory.</p>
<p><a id="task-manager-theory-insufficient-throughput"></a><span class="strong strong"><strong>Theory</strong></span>:
Kibana is polling as frequently as it should, but that isn&#8217;t often enough to keep up with the workload</p>
<p><span class="strong strong"><strong>Diagnosis</strong></span>:
Evaluating the health stats, you can see the following output of <code class="literal">drift</code> and <code class="literal">load</code> under <code class="literal">stats.runtime.value</code>:</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json">{
  "drift": { <a id="CO12-1"></a><i class="conum" data-value="1"></i>
    "p50": 99,
    "p90": 1245,
    "p95": 1845,
    "p99": 2878
  },
  "load": { <a id="CO12-2"></a><i class="conum" data-value="2"></i>
    "p50": 0,
    "p90": 0,
    "p95": 10,
    "p99": 20
  },
}</pre>
</div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO12-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p><code class="literal">drift</code> shows us that at least 95% of tasks are running within 2 seconds of their scheduled time.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO12-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p><code class="literal">load</code> shows us that Task Manager is idle at least 90% of the time, and never uses more than 20% of its available workers.</p>
</td>
</tr>
</table>
</div>
<p>You can infer from these stats that this Kibana has plenty of capacity, and any delays you might be experiencing are unlikely to be addressed by expanding the throughput.</p>
<p>Suppose the output of <code class="literal">drift</code> and <code class="literal">load</code> was the following:</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json">{
  "drift": { <a id="CO13-1"></a><i class="conum" data-value="1"></i>
    "p50": 2999,
    "p90": 3845,
    "p95": 3845.75,
    "p99": 4078
  },
  "load": { <a id="CO13-2"></a><i class="conum" data-value="2"></i>
    "p50": 80,
    "p90": 100,
    "p95": 100,
    "p99": 100
  }
}</pre>
</div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO13-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p><code class="literal">drift</code> shows us that all tasks are running 3 to 4 seconds after their scheduled time.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO13-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p><code class="literal">load</code> shows us that at least half of the time Task Manager is running at a load of 80%.</p>
</td>
</tr>
</table>
</div>
<p>You can infer from these stats that this Kibana is using most of its capacity, but seems to keep up with the work most of the time.
This assessment is based on the following:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
The <code class="literal">p90</code> of <code class="literal">load</code> is at 100%, and <code class="literal">p50</code> is also quite high at 80%. This means that there is little to no room for maneuvering, and a spike of work might cause Task Manager to exceed its capacity.
</li>
<li class="listitem">
Tasks run soon after their scheduled time, which is to be expected. A <code class="literal">poll_interval</code> of <code class="literal">3000</code> milliseconds would often experience a consistent drift of somewhere between <code class="literal">0</code> and <code class="literal">3000</code> milliseconds. A <code class="literal">p50 drift</code> of <code class="literal">2999</code> suggests that there is room for improvement, and you could benefit from a higher throughput.
</li>
</ul>
</div>
<p>For details on achieving higher throughput by adjusting your scaling strategy, see <a class="xref" href="task-manager-production-considerations.html#task-manager-scaling-guidance" title="Scaling guidance">Scaling guidance</a>.</p>
<p><a id="task-manager-theory-long-running-tasks"></a><span class="strong strong"><strong>Theory</strong></span>:
Tasks run for too long, overrunning their schedule</p>
<p><span class="strong strong"><strong>Diagnosis</strong></span>:
The <a class="xref" href="task-manager-troubleshooting.html#task-manager-theory-insufficient-throughput">Insufficient throughtput to handle the scheduled workload</a> theory analyzed a hypothetical scenario where both drift and load were unusually high.</p>
<p>Suppose an alternate scenario, where <code class="literal">drift</code> is high, but <code class="literal">load</code> is not, such as the following:</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json">{
    "drift": { <a id="CO14-1"></a><i class="conum" data-value="1"></i>
        "p50": 9799,
        "p90": 83845,
        "p95": 90328,
        "p99": 123845
    },
    "load": { <a id="CO14-2"></a><i class="conum" data-value="2"></i>
        "p50": 40,
        "p90": 75,
        "p95": 80,
        "p99": 100
    }
}</pre>
</div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO14-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p><code class="literal">drift</code> shows that most (if not all) tasks are running at least 32 seconds too late.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO14-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p><code class="literal">load</code> shows that, for the most part, you have capacity to run more concurrent tasks.</p>
</td>
</tr>
</table>
</div>
<p>In the preceding scenario, the  tasks are running far too late, but you have sufficient capacity to run more concurrent tasks.
A high capacity allows Kibana to run multiple different tasks concurrently. If a task is already running when its next schedule run is due, Kibana will avoid running it a second time, and instead wait for the first execution to complete.</p>
<p>If a task takes longer to execute than the cadence of its schedule, then that task will always overrun and experience a high drift. For example, suppose a task is scheduled to execute every 3 seconds, but takes 6 seconds to complete. It will consistently suffer from a drift of, at least, 3 seconds.</p>
<p>Evaluating the health stats in this hypothetical scenario, you see the following output under <code class="literal">stats.runtime.value.execution.duration</code>:</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json">{
  "alerting:.index-threshold": { <a id="CO15-1"></a><i class="conum" data-value="1"></i>
    "p50": 95,
    "p90": 1725,
    "p95": 2761,
    "p99": 2761
  },
  "alerting:.es-query": { <a id="CO15-2"></a><i class="conum" data-value="2"></i>
    "p50": 7149,
    "p90": 40071,
    "p95": 45282,
    "p99": 121845
  },
  "actions:.index": {
    "p50": 166,
    "p90": 166,
    "p95": 166,
    "p99": 166
  }
}</pre>
</div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO15-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>50% of the tasks backing index threshold alerts complete in less than 100 milliseconds.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO15-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p>50% of the tasks backing Elasticsearch query alerts complete in 7 seconds, but at least 10% take longer than 40 seconds.</p>
</td>
</tr>
</table>
</div>
<p>You can infer from these stats that the high drift the Task Manager is experiencing is most likely due to Elasticsearch query alerts that are running for a long time.</p>
<p>Resolving this issue is context dependent and changes from case to case.
In the preceding example above, this would be resolved by modifying the queries in these alerts to make them faster, or improving the Elasticsearch throughput to speed up the exiting query.</p>
<p><a id="task-manager-theory-high-fail-rate"></a><span class="strong strong"><strong>Theory</strong></span>:
Tasks take multiple attempts to succeed</p>
<p><span class="strong strong"><strong>Diagnosis</strong></span>:
A high error rate could cause a task to appear to run late, when in fact it runs on time, but experiences a high failure rate.</p>
<p>Evaluating the preceding health stats, you see the following output under <code class="literal">stats.runtime.value.execution.result_frequency_percent_as_number</code>:</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json">{
  "alerting:.index-threshold": { <a id="CO16-1"></a><i class="conum" data-value="1"></i>
    "Success": 100,
    "RetryScheduled": 0,
    "Failed": 0,
    "status": "OK"
  },
  "alerting:xpack.uptime.alerts.monitorStatus": {
    "Success": 100,
    "RetryScheduled": 0,
    "Failed": 0,
    "status": "OK"
  },
  "actions:.index": { <a id="CO16-2"></a><i class="conum" data-value="2"></i>
    "Success": 8,
    "RetryScheduled": 0,
    "Failed": 92,
    "status": "error" <a id="CO16-3"></a><i class="conum" data-value="3"></i>
  }
}</pre>
</div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO16-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>100% of the tasks backing index threshold alerts successfully complete.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO16-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p>92% of the tasks backing ES index actions fail to complete.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO16-3"><i class="conum" data-value="3"></i></a></p>
</td>
<td align="left" valign="top">
<p>The tasks backing ES index actions have exceeded the default <code class="literal">monitored_task_execution_thresholds</code> <em>error</em> configuration.</p>
</td>
</tr>
</table>
</div>
<p>You can infer from these stats that most <code class="literal">actions:.index</code> tasks, which back the ES Index Kibana action, fail.
Resolving that would require deeper investigation into the Kibana Server Log, where the exact errors are logged, and addressing these specific errors.</p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="task-manager-health-evaluate-the-workload"></a>Evaluate the Workload<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/kibana/edit/7.12/docs/user/production-considerations/task-manager-troubleshooting.asciidoc">edit</a></h4>
</div></div></div>
<p>Predicting the required throughput a deplyment might need to support Task Manager is difficult, as features can schedule an unpredictable number of tasks at a variety of scheduled cadences.</p>
<p><a class="xref" href="task-manager-health-monitoring.html" title="Task Manager health monitoring">Health monitoring</a> provides statistics that make it easier to monitor the adequacy of the existing throughput.
By evaluating the workload, the required throughput can be estimated, which is used when following the Task Manager <a class="xref" href="task-manager-production-considerations.html#task-manager-scaling-guidance" title="Scaling guidance">Scaling guidance</a>.</p>
<p>Evaluating the preceding health stats above, you see the following output under <code class="literal">stats.workload.value</code>:</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json">{
  "count": 26, <a id="CO17-1"></a><i class="conum" data-value="1"></i>
  "task_types": {
    "alerting:.index-threshold": {
      "count": 2, <a id="CO17-2"></a><i class="conum" data-value="2"></i>
      "status": {
        "idle": 2
      }
    },
    "actions:.index": {
      "count": 14,
      "status": {
        "idle": 2,
        "running": 2,
        "failed": 10 <a id="CO17-3"></a><i class="conum" data-value="3"></i>
      }
    },
    "alerting:xpack.uptime.alerts.monitorStatus": {
      "count": 10,
      "status": {
        "idle": 10
      }
    },
  },
  "schedule": [ <a id="CO17-4"></a><i class="conum" data-value="4"></i>
    ["10s", 2],
    ["1m", 2],
    ["90s", 2],
    ["5m", 8]
  ],
  "overdue": 0, <a id="CO17-5"></a><i class="conum" data-value="5"></i>
  "estimated_schedule_density": [  <a id="CO17-6"></a><i class="conum" data-value="6"></i>
    0, 1, 0, 0, 0, 1, 0, 1, 0, 1,
    0, 0, 0, 1, 0, 0, 1, 1, 1, 0,
    0, 3, 0, 0, 0, 1, 0, 1, 0, 1,
    0, 0, 0, 1, 0, 0, 1, 1, 1, 0
  ]
}</pre>
</div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO17-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>There are 26 tasks in the system, including regular tasks, recurring tasks, and failed tasks.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO17-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p>There are 2 <code class="literal">idle</code> index threshold alert tasks, meaning they are scheduled to run at some point in the future.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO17-3"><i class="conum" data-value="3"></i></a></p>
</td>
<td align="left" valign="top">
<p>Of the 14 tasks backing the ES index action, 10 have failed and 2 are running.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO17-4"><i class="conum" data-value="4"></i></a></p>
</td>
<td align="left" valign="top">
<p>A histogram of all scheduled recurring tasks shows that 2 tasks are scheduled to run every 10 seconds, 2  tasks are scheduled to run once a minute, and so on.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO17-5"><i class="conum" data-value="5"></i></a></p>
</td>
<td align="left" valign="top">
<p>There are no tasks overdue, which means that all tasks that <span class="strong strong"><strong>should</strong></span> have run by now <span class="strong strong"><strong>have</strong></span> run.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO17-6"><i class="conum" data-value="6"></i></a></p>
</td>
<td align="left" valign="top">
<p>This histogram shows the tasks scheduled to run throughout the upcoming 20 polling cycles. The histogram represents the entire deployment, rather than just this Kibana instance</p>
</td>
</tr>
</table>
</div>
<p>The <code class="literal">workload</code> section summarizes the work load across the cluster, listing the tasks in the system, their types, schedules, and current status.</p>
<p>You can infer from these stats that a default deployment should suffice.
This assessment is based on the following:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
The estimated schedule density is low.
</li>
<li class="listitem">
There aren&#8217;t many tasks in the system relative to the default capacity.
</li>
</ul>
</div>
<p>Suppose the output of <code class="literal">stats.workload.value</code> looked something like this:</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json">{
  "count": 2191, <a id="CO18-1"></a><i class="conum" data-value="1"></i>
  "task_types": {
    "alerting:.index-threshold": {
      "count": 202,
      "status": {
        "idle": 183,
        "claiming": 2,
        "running": 19
      }
    },
    "alerting:.es-query": {
      "count": 225,
      "status": {
        "idle": 225,
      }
    },
    "actions:.index": {
      "count": 89,
      "status": {
        "idle": 24,
        "running": 2,
        "failed": 63
      }
    },
    "alerting:xpack.uptime.alerts.monitorStatus": {
      "count": 87,
      "status": {
        "idle": 74,
        "running": 13
      }
    },
  },
  "schedule": [ <a id="CO18-2"></a><i class="conum" data-value="2"></i>
    ["10s", 38],
    ["1m", 101],
    ["90s", 55],
    ["5m", 89],
    ["20m", 62],
    ["60m", 106],
    ["1d", 61]
  ],
  "overdue": 0, <a id="CO18-3"></a><i class="conum" data-value="5"></i>
  "estimated_schedule_density": [  <a id="CO18-4"></a><i class="conum" data-value="3"></i>
    10, 1, 0, 10, 0, 20, 0, 1, 0, 1,
    9, 0, 3, 10, 0, 0, 10, 10, 7, 0,
    0, 31, 0, 12, 16, 31, 0, 10, 0, 10,
    3, 22, 0, 10, 0, 2, 10, 10, 1, 0
  ]
}</pre>
</div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO18-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>There are 2,191 tasks in the system.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO18-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p>The scheduled tasks are distributed across a variety of cadences.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO18-4"><i class="conum" data-value="3"></i></a></p>
</td>
<td align="left" valign="top">
<p>The schedule density shows that you expect to exceed the default 10 concurrent tasks.</p>
</td>
</tr>
</table>
</div>
<p>You can infer several important attributes of your workload from this output:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
There are many tasks in your system and ensuring these tasks run on their scheduled cadence will require attention to the Task Manager throughput.
</li>
<li class="listitem">
Assessing the high frequency tasks (tasks that recur at a cadence of a couple of minutes or less), you must support a throughput of approximately 400 tasks per minute (38 every 10 seconds + 101 every minute + 55 every 90 seconds).
</li>
<li class="listitem">
Assessing the medium frequency tasks (tasks that recur at a cadence of an hour or less), you must support an additional throughput of over 2000 tasks per hour (89 every 5 minutes, + 62 every 20 minutes + 106 each hour). You can average the needed throughput for the hour by counting these tasks as an additional 30 to 40 tasks per minute.
</li>
<li class="listitem">
Assessing the estimated schedule density, there are cycles that are due to run upwards of 31 tasks concurrently, and along side these cycles, there are empty cycles. You can expect Task Manager to load balance these tasks throughout the empty cycles, but this won&#8217;t leave much capacity to handle spikes in fresh tasks that might be scheduled in the future.
</li>
</ul>
</div>
<p>These rough calculations give you a lower bound to the required throughput, which is <em>at least</em> 440 tasks per minute to ensure recurring tasks are executed, at their scheduled time. This throughput doesn&#8217;t account for nonrecurring tasks that might have been scheduled, nor does it account for tasks (recurring or otherwise) that might be scheduled in the future.</p>
<p>Given these inferred attributes, it would be safe to assume that a single Kibana instance with default settings <span class="strong strong"><strong>would not</strong></span> provide the required throughput. It is possible that scaling horizontally by adding a couple more Kibana instances will.</p>
<p>For details on scaling Task Manager, see <a class="xref" href="task-manager-production-considerations.html#task-manager-scaling-guidance" title="Scaling guidance">Scaling guidance</a>.</p>
</div>

</div>

</div>
<div class="navfooter">
<span class="prev">
<a href="task-manager-health-monitoring.html">« Task Manager health monitoring</a>
</span>
<span class="next">
<a href="discover.html">Discover »</a>
</span>
</div>
</div>

                  <!-- end body -->
                </div>
                <div class="col-xs-12 col-sm-4 col-md-4" id="right_col">
                  <div id="rtpcontainer" style="display: block;">
                    <div class="mktg-promo">
                      <h3>Most Popular</h3>
                      <ul class="icons">
                        <li class="icon-elasticsearch-white"><a href="https://www.elastic.co/webinars/getting-started-elasticsearch?baymax=default&elektra=docs&storm=top-video">Get Started with Elasticsearch: Video</a></li>
                        <li class="icon-kibana-white"><a href="https://www.elastic.co/webinars/getting-started-kibana?baymax=default&elektra=docs&storm=top-video">Intro to Kibana: Video</a></li>
                        <li class="icon-logstash-white"><a href="https://www.elastic.co/webinars/introduction-elk-stack?baymax=default&elektra=docs&storm=top-video">ELK for Logs & Metrics: Video</a></li>
                      </ul>
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </section>

        </div>


<div id='elastic-footer'></div>
<script src='https://www.elastic.co/elastic-footer.js'></script>
<!-- Footer Section end-->

      </section>
    </div>

<script type="text/javascript">
	var suggestionsUrl = "https://search.elastic.co/suggest";
	var localeUrl = '{"relative_url_prefix":"/","code":"en-us","display_code":"en-us","url":"/guide_template"}';
</script>
<script src="/static/js/swiftype_app_search.umd.min.js"></script>
<script src="/guide/static/jquery.js"></script>
<script type="text/javascript" src="/guide/static/docs.js"></script>
<script type="text/javascript">
  window.initial_state = {}</script>
  </body>
</html>
