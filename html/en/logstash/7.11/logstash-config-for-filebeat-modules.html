<!DOCTYPE html>
<html lang="en-us">
  <head>
    
<meta charset="UTF-8">
<title>Use Logstash pipelines for parsing | Logstash Reference [7.11] | Elastic</title>
<meta class="elastic" name="content" content="Use Logstash pipelines for parsing | Logstash Reference [7.11]">

<link rel="home" href="index.html" title="Logstash Reference [7.11]"/>
<link rel="up" href="filebeat-modules.html" title="Working with Filebeat Modules"/>
<link rel="prev" href="use-ingest-pipelines.html" title="Use ingest pipelines for parsing"/>
<link rel="next" href="use-filebeat-modules-kafka.html" title="Example: Set up Filebeat modules to work with Kafka and Logstash"/>
<meta class="elastic" name="product_version" content="7.11"/>
<meta class="elastic" name="product_name" content="Logstash"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/Logstash/Reference/7.11"/>
<meta name="DC.subject" content="Logstash"/>
<meta name="DC.identifier" content="7.11"/>
<meta name="robots" content="noindex,nofollow"/>

    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <script src="https://cdn.optimizely.com/js/18132920325.js"></script>
    <link rel="apple-touch-icon" sizes="57x57" href="/apple-icon-57x57.png">
    <link rel="apple-touch-icon" sizes="60x60" href="/apple-icon-60x60.png">
    <link rel="apple-touch-icon" sizes="72x72" href="/apple-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="76x76" href="/apple-icon-76x76.png">
    <link rel="apple-touch-icon" sizes="114x114" href="/apple-icon-114x114.png">
    <link rel="apple-touch-icon" sizes="120x120" href="/apple-icon-120x120.png">
    <link rel="apple-touch-icon" sizes="144x144" href="/apple-icon-144x144.png">
    <link rel="apple-touch-icon" sizes="152x152" href="/apple-icon-152x152.png">
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-icon-180x180.png">
    <link rel="icon" type="image/png" href="/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="/android-chrome-192x192.png" sizes="192x192">
    <link rel="icon" type="image/png" href="/favicon-96x96.png" sizes="96x96">
    <link rel="icon" type="image/png" href="/favicon-16x16.png" sizes="16x16">
    <link rel="manifest" href="/manifest.json">
    <meta name="apple-mobile-web-app-title" content="Elastic">
    <meta name="application-name" content="Elastic">
    <meta name="msapplication-TileColor" content="#ffffff">
    <meta name="msapplication-TileImage" content="/mstile-144x144.png">
    <meta name="theme-color" content="#ffffff">
    <meta name="naver-site-verification" content="936882c1853b701b3cef3721758d80535413dbfd" />
    <meta name="yandex-verification" content="d8a47e95d0972434" />
    <meta name="localized" content="true" />
    <meta name="st:robots" content="follow,index" />
    <meta property="og:image" content="https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/blt280217a63b82a734/6202d3378b1f312528798412/elastic-logo.svg" />
    <meta property="og:image:width" content="500" />
    <meta property="og:image:height" content="172" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <link rel="apple-touch-icon-precomposed" sizes="64x64" href="/favicon_64x64_16bit.png">
    <link rel="apple-touch-icon-precomposed" sizes="32x32" href="/favicon_32x32.png">
    <link rel="apple-touch-icon-precomposed" sizes="16x16" href="/favicon_16x16.png">
    <!-- Give IE8 a fighting chance -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    <link rel="stylesheet" type="text/css" href="/guide/static/styles.css" />
  </head>

  <!--© 2015-2022 Elasticsearch B.V. -->
  <!-- All Elastic documentation is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License. -->
  <!-- http://creativecommons.org/licenses/by-nc-nd/4.0/ -->

  <body>
    <!-- Google Tag Manager -->
    <script>dataLayer = [];</script><noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-58RLH5" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start': new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0], j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src= '//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f); })(window,document,'script','dataLayer','GTM-58RLH5');</script>
    <!-- End Google Tag Manager -->

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-12395217-16"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-12395217-16');
    </script>

    <!-- Google Tag Manager for GA4 -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start': new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0], j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-KNJMG2M');</script>
    <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-KNJMG2M" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    <!-- End Google Tag Manager for GA4-->

    <div id='elastic-nav' style="display:none;"></div>
    <script src='https://www.elastic.co/elastic-nav.js'></script>

    <div class="main-container">
      <section id="content" >
        <div class="content-wrapper">

          <section id="guide" lang="en">
            <div class="container-fluid">
              <div class="row pb-3">
                <div class="col-12 order-2 col-md-4 order-md-1 col-lg-3 h-almost-full-md sticky-top-md" id="left_col">
                  <!-- The TOC is appended here -->
                </div>

                <div class="col-12 order-1 col-md-8 order-md-2 col-lg-7 order-lg-2 guide-section" id="middle_col">
                  <!-- start body -->
                  <div class="page_header">
<strong>IMPORTANT</strong>: No additional bug fixes or documentation updates
will be released for this version. For the latest information, see the
<a href="../current/index.html">current release documentation</a>.
</div>
<div id="content">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Logstash Reference [7.11]</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="filebeat-modules.html">Working with Filebeat Modules</a></span>
</div>
<div class="navheader">
<span class="prev">
<a href="use-ingest-pipelines.html">« Use ingest pipelines for parsing</a>
</span>
<span class="next">
<a href="use-filebeat-modules-kafka.html">Example: Set up Filebeat modules to work with Kafka and Logstash »</a>
</span>
</div>
<div class="section">
<div class="titlepage"><div><div>
<h2 class="title"><a id="logstash-config-for-filebeat-modules"></a>Use Logstash pipelines for parsing<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/logstash/edit/7.11/docs/static/filebeat-modules.asciidoc">edit</a></h2>
</div></div></div>
<p>The examples in this section show how to build Logstash pipeline configurations that
replace the ingest pipelines provided with Filebeat modules. The pipelines
take the data collected by Filebeat modules, parse it into fields expected by
the Filebeat index, and send the fields to Elasticsearch so that you can visualize the
data in the pre-built dashboards provided by Filebeat.</p>
<p>This approach is more time consuming than using the existing ingest pipelines to
parse the data, but it gives you more control over how the data is processed.
By writing your own pipeline configurations, you can do additional processing,
such as dropping fields, after the fields are extracted, or you can move your
load from Elasticsearch ingest nodes to Logstash nodes.</p>
<p>Before deciding to replaced the ingest pipelines with Logstash configurations,
read <a class="xref" href="use-ingest-pipelines.html" title="Use ingest pipelines for parsing">Use ingest pipelines for parsing</a>.</p>
<p>Here are some examples that show how to implement Logstash configurations to replace
ingest pipelines:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<a class="xref" href="logstash-config-for-filebeat-modules.html#parsing-apache2" title="Apache 2 Logs">Apache 2 Logs</a>
</li>
<li class="listitem">
<a class="xref" href="logstash-config-for-filebeat-modules.html#parsing-mysql" title="MySQL Logs">MySQL Logs</a>
</li>
<li class="listitem">
<a class="xref" href="logstash-config-for-filebeat-modules.html#parsing-nginx" title="Nginx Logs">Nginx Logs</a>
</li>
<li class="listitem">
<a class="xref" href="logstash-config-for-filebeat-modules.html#parsing-system" title="System Logs">System Logs</a>
</li>
</ul>
</div>
<div class="tip admon">
<div class="icon"></div>
<div class="admon_content">
<p>Logstash provides an <a class="xref" href="ingest-converter.html" title="Converting Ingest Node Pipelines">ingest pipeline conversion tool</a>
to help you migrate ingest pipeline definitions to Logstash configs. The tool does
not currently support all the processors that are available for ingest node, but
it&#8217;s a good starting point.</p>
</div>
</div>
<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="parsing-apache2"></a>Apache 2 Logs<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/logstash/edit/7.11/docs/static/filebeat-modules.asciidoc">edit</a></h3>
</div></div></div>
<p>The Logstash pipeline configuration in this example shows how to ship and parse
access and error logs collected by the
<a href="/guide/en/beats/filebeat/7.11/filebeat-module-apache.html" class="ulink" target="_top"><code class="literal">apache</code> Filebeat module</a>.</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json">input {
  beats {
    port =&gt; 5044
    host =&gt; "0.0.0.0"
  }
}
filter {
  if [fileset][module] == "apache2" {
    if [fileset][name] == "access" {
      grok {
        match =&gt; { "message" =&gt; ["%{IPORHOST:[apache2][access][remote_ip]} - %{DATA:[apache2][access][user_name]} \[%{HTTPDATE:[apache2][access][time]}\] \"%{WORD:[apache2][access][method]} %{DATA:[apache2][access][url]} HTTP/%{NUMBER:[apache2][access][http_version]}\" %{NUMBER:[apache2][access][response_code]} %{NUMBER:[apache2][access][body_sent][bytes]}( \"%{DATA:[apache2][access][referrer]}\")?( \"%{DATA:[apache2][access][agent]}\")?",
          "%{IPORHOST:[apache2][access][remote_ip]} - %{DATA:[apache2][access][user_name]} \\[%{HTTPDATE:[apache2][access][time]}\\] \"-\" %{NUMBER:[apache2][access][response_code]} -" ] }
        remove_field =&gt; "message"
      }
      mutate {
        add_field =&gt; { "read_timestamp" =&gt; "%{@timestamp}" }
      }
      date {
        match =&gt; [ "[apache2][access][time]", "dd/MMM/YYYY:H:m:s Z" ]
        remove_field =&gt; "[apache2][access][time]"
      }
      useragent {
        source =&gt; "[apache2][access][agent]"
        target =&gt; "[apache2][access][user_agent]"
        remove_field =&gt; "[apache2][access][agent]"
      }
      geoip {
        source =&gt; "[apache2][access][remote_ip]"
        target =&gt; "[apache2][access][geoip]"
      }
    }
    else if [fileset][name] == "error" {
      grok {
        match =&gt; { "message" =&gt; ["\[%{APACHE_TIME:[apache2][error][timestamp]}\] \[%{LOGLEVEL:[apache2][error][level]}\]( \[client %{IPORHOST:[apache2][error][client]}\])? %{GREEDYDATA:[apache2][error][message]}",
          "\[%{APACHE_TIME:[apache2][error][timestamp]}\] \[%{DATA:[apache2][error][module]}:%{LOGLEVEL:[apache2][error][level]}\] \[pid %{NUMBER:[apache2][error][pid]}(:tid %{NUMBER:[apache2][error][tid]})?\]( \[client %{IPORHOST:[apache2][error][client]}\])? %{GREEDYDATA:[apache2][error][message1]}" ] }
        pattern_definitions =&gt; {
          "APACHE_TIME" =&gt; "%{DAY} %{MONTH} %{MONTHDAY} %{TIME} %{YEAR}"
        }
        remove_field =&gt; "message"
      }
      mutate {
        rename =&gt; { "[apache2][error][message1]" =&gt; "[apache2][error][message]" }
      }
      date {
        match =&gt; [ "[apache2][error][timestamp]", "EEE MMM dd H:m:s YYYY", "EEE MMM dd H:m:s.SSSSSS YYYY" ]
        remove_field =&gt; "[apache2][error][timestamp]"
      }
    }
  }
}
output {
  elasticsearch {
    hosts =&gt; localhost
    manage_template =&gt; false
    index =&gt; "%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}"
  }
}</pre>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="parsing-mysql"></a>MySQL Logs<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/logstash/edit/7.11/docs/static/filebeat-modules.asciidoc">edit</a></h3>
</div></div></div>
<p>The Logstash pipeline configuration in this example shows how to ship and parse
error and slowlog logs collected by the
<a href="/guide/en/beats/filebeat/7.11/filebeat-module-mysql.html" class="ulink" target="_top"><code class="literal">mysql</code> Filebeat module</a>.</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json">input {
  beats {
    port =&gt; 5044
    host =&gt; "0.0.0.0"
  }
}
filter {
  if [fileset][module] == "mysql" {
    if [fileset][name] == "error" {
      grok {
        match =&gt; { "message" =&gt; ["%{LOCALDATETIME:[mysql][error][timestamp]} (\[%{DATA:[mysql][error][level]}\] )?%{GREEDYDATA:[mysql][error][message]}",
          "%{TIMESTAMP_ISO8601:[mysql][error][timestamp]} %{NUMBER:[mysql][error][thread_id]} \[%{DATA:[mysql][error][level]}\] %{GREEDYDATA:[mysql][error][message1]}",
          "%{GREEDYDATA:[mysql][error][message2]}"] }
        pattern_definitions =&gt; {
          "LOCALDATETIME" =&gt; "[0-9]+ %{TIME}"
        }
        remove_field =&gt; "message"
      }
      mutate {
        rename =&gt; { "[mysql][error][message1]" =&gt; "[mysql][error][message]" }
      }
      mutate {
        rename =&gt; { "[mysql][error][message2]" =&gt; "[mysql][error][message]" }
      }
      date {
        match =&gt; [ "[mysql][error][timestamp]", "ISO8601", "YYMMdd H:m:s" ]
        remove_field =&gt; "[mysql][error][time]"
      }
    }
    else if [fileset][name] == "slowlog" {
      grok {
        match =&gt; { "message" =&gt; ["^# User@Host: %{USER:[mysql][slowlog][user]}(\[[^\]]+\])? @ %{HOSTNAME:[mysql][slowlog][host]} \[(IP:[mysql][slowlog][ip])?\](\s*Id:\s* %{NUMBER:[mysql][slowlog][id]})?\n# Query_time: %{NUMBER:[mysql][slowlog][query_time][sec]}\s* Lock_time: %{NUMBER:[mysql][slowlog][lock_time][sec]}\s* Rows_sent: %{NUMBER:[mysql][slowlog][rows_sent]}\s* Rows_examined: %{NUMBER:[mysql][slowlog][rows_examined]}\n(SET timestamp=%{NUMBER:[mysql][slowlog][timestamp]};\n)?%{GREEDYMULTILINE:[mysql][slowlog][query]}"] }
        pattern_definitions =&gt; {
          "GREEDYMULTILINE" =&gt; "(.|\n)*"
        }
        remove_field =&gt; "message"
      }
      date {
        match =&gt; [ "[mysql][slowlog][timestamp]", "UNIX" ]
      }
      mutate {
        gsub =&gt; ["[mysql][slowlog][query]", "\n# Time: [0-9]+ [0-9][0-9]:[0-9][0-9]:[0-9][0-9](\\.[0-9]+)?$", ""]
      }
    }
  }
}
output {
  elasticsearch {
    hosts =&gt; localhost
    manage_template =&gt; false
    index =&gt; "%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}"
  }
}</pre>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="parsing-nginx"></a>Nginx Logs<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/logstash/edit/7.11/docs/static/filebeat-modules.asciidoc">edit</a></h3>
</div></div></div>
<p>The Logstash pipeline configuration in this example shows how to ship and parse
access and error logs collected by the
<a href="/guide/en/beats/filebeat/7.11/filebeat-module-nginx.html" class="ulink" target="_top"><code class="literal">nginx</code> Filebeat module</a>.</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json">input {
  beats {
    port =&gt; 5044
    host =&gt; "0.0.0.0"
  }
}
filter {
  if [fileset][module] == "nginx" {
    if [fileset][name] == "access" {
      grok {
        match =&gt; { "message" =&gt; ["%{IPORHOST:[nginx][access][remote_ip]} - %{DATA:[nginx][access][user_name]} \[%{HTTPDATE:[nginx][access][time]}\] \"%{WORD:[nginx][access][method]} %{DATA:[nginx][access][url]} HTTP/%{NUMBER:[nginx][access][http_version]}\" %{NUMBER:[nginx][access][response_code]} %{NUMBER:[nginx][access][body_sent][bytes]} \"%{DATA:[nginx][access][referrer]}\" \"%{DATA:[nginx][access][agent]}\""] }
        remove_field =&gt; "message"
      }
      mutate {
        add_field =&gt; { "read_timestamp" =&gt; "%{@timestamp}" }
      }
      date {
        match =&gt; [ "[nginx][access][time]", "dd/MMM/YYYY:H:m:s Z" ]
        remove_field =&gt; "[nginx][access][time]"
      }
      useragent {
        source =&gt; "[nginx][access][agent]"
        target =&gt; "[nginx][access][user_agent]"
        remove_field =&gt; "[nginx][access][agent]"
      }
      geoip {
        source =&gt; "[nginx][access][remote_ip]"
        target =&gt; "[nginx][access][geoip]"
      }
    }
    else if [fileset][name] == "error" {
      grok {
        match =&gt; { "message" =&gt; ["%{DATA:[nginx][error][time]} \[%{DATA:[nginx][error][level]}\] %{NUMBER:[nginx][error][pid]}#%{NUMBER:[nginx][error][tid]}: (\*%{NUMBER:[nginx][error][connection_id]} )?%{GREEDYDATA:[nginx][error][message]}"] }
        remove_field =&gt; "message"
      }
      mutate {
        rename =&gt; { "@timestamp" =&gt; "read_timestamp" }
      }
      date {
        match =&gt; [ "[nginx][error][time]", "YYYY/MM/dd H:m:s" ]
        remove_field =&gt; "[nginx][error][time]"
      }
    }
  }
}
output {
  elasticsearch {
    hosts =&gt; localhost
    manage_template =&gt; false
    index =&gt; "%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}"
  }
}</pre>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="parsing-system"></a>System Logs<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/logstash/edit/7.11/docs/static/filebeat-modules.asciidoc">edit</a></h3>
</div></div></div>
<p>The Logstash pipeline configuration in this example shows how to ship and parse
system logs collected by the
<a href="/guide/en/beats/filebeat/7.11/filebeat-module-system.html" class="ulink" target="_top"><code class="literal">system</code> Filebeat module</a>.</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json">input {
  beats {
    port =&gt; 5044
    host =&gt; "0.0.0.0"
  }
}
filter {
  if [fileset][module] == "system" {
    if [fileset][name] == "auth" {
      grok {
        match =&gt; { "message" =&gt; ["%{SYSLOGTIMESTAMP:[system][auth][timestamp]} %{SYSLOGHOST:[system][auth][hostname]} sshd(?:\[%{POSINT:[system][auth][pid]}\])?: %{DATA:[system][auth][ssh][event]} %{DATA:[system][auth][ssh][method]} for (invalid user )?%{DATA:[system][auth][user]} from %{IPORHOST:[system][auth][ssh][ip]} port %{NUMBER:[system][auth][ssh][port]} ssh2(: %{GREEDYDATA:[system][auth][ssh][signature]})?",
                  "%{SYSLOGTIMESTAMP:[system][auth][timestamp]} %{SYSLOGHOST:[system][auth][hostname]} sshd(?:\[%{POSINT:[system][auth][pid]}\])?: %{DATA:[system][auth][ssh][event]} user %{DATA:[system][auth][user]} from %{IPORHOST:[system][auth][ssh][ip]}",
                  "%{SYSLOGTIMESTAMP:[system][auth][timestamp]} %{SYSLOGHOST:[system][auth][hostname]} sshd(?:\[%{POSINT:[system][auth][pid]}\])?: Did not receive identification string from %{IPORHOST:[system][auth][ssh][dropped_ip]}",
                  "%{SYSLOGTIMESTAMP:[system][auth][timestamp]} %{SYSLOGHOST:[system][auth][hostname]} sudo(?:\[%{POSINT:[system][auth][pid]}\])?: \s*%{DATA:[system][auth][user]} :( %{DATA:[system][auth][sudo][error]} ;)? TTY=%{DATA:[system][auth][sudo][tty]} ; PWD=%{DATA:[system][auth][sudo][pwd]} ; USER=%{DATA:[system][auth][sudo][user]} ; COMMAND=%{GREEDYDATA:[system][auth][sudo][command]}",
                  "%{SYSLOGTIMESTAMP:[system][auth][timestamp]} %{SYSLOGHOST:[system][auth][hostname]} groupadd(?:\[%{POSINT:[system][auth][pid]}\])?: new group: name=%{DATA:system.auth.groupadd.name}, GID=%{NUMBER:system.auth.groupadd.gid}",
                  "%{SYSLOGTIMESTAMP:[system][auth][timestamp]} %{SYSLOGHOST:[system][auth][hostname]} useradd(?:\[%{POSINT:[system][auth][pid]}\])?: new user: name=%{DATA:[system][auth][useradd][name]}, UID=%{NUMBER:[system][auth][useradd][uid]}, GID=%{NUMBER:[system][auth][useradd][gid]}, home=%{DATA:[system][auth][useradd][home]}, shell=%{DATA:[system][auth][useradd][shell]}$",
                  "%{SYSLOGTIMESTAMP:[system][auth][timestamp]} %{SYSLOGHOST:[system][auth][hostname]} %{DATA:[system][auth][program]}(?:\[%{POSINT:[system][auth][pid]}\])?: %{GREEDYMULTILINE:[system][auth][message]}"] }
        pattern_definitions =&gt; {
          "GREEDYMULTILINE"=&gt; "(.|\n)*"
        }
        remove_field =&gt; "message"
      }
      date {
        match =&gt; [ "[system][auth][timestamp]", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss" ]
      }
      geoip {
        source =&gt; "[system][auth][ssh][ip]"
        target =&gt; "[system][auth][ssh][geoip]"
      }
    }
    else if [fileset][name] == "syslog" {
      grok {
        match =&gt; { "message" =&gt; ["%{SYSLOGTIMESTAMP:[system][syslog][timestamp]} %{SYSLOGHOST:[system][syslog][hostname]} %{DATA:[system][syslog][program]}(?:\[%{POSINT:[system][syslog][pid]}\])?: %{GREEDYMULTILINE:[system][syslog][message]}"] }
        pattern_definitions =&gt; { "GREEDYMULTILINE" =&gt; "(.|\n)*" }
        remove_field =&gt; "message"
      }
      date {
        match =&gt; [ "[system][syslog][timestamp]", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss" ]
      }
    }
  }
}
output {
  elasticsearch {
    hosts =&gt; localhost
    manage_template =&gt; false
    index =&gt; "%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}"
  }
}</pre>
</div>
</div>

</div>
<div class="navfooter">
<span class="prev">
<a href="use-ingest-pipelines.html">« Use ingest pipelines for parsing</a>
</span>
<span class="next">
<a href="use-filebeat-modules-kafka.html">Example: Set up Filebeat modules to work with Kafka and Logstash »</a>
</span>
</div>
</div>

                  <!-- end body -->
                </div>

                <div class="col-12 order-3 col-lg-2 order-lg-3 h-almost-full-lg sticky-top-lg" id="right_col">
                  <div id="sticky_content">
                    <!-- The OTP is appended here -->
                    <div class="row">
                      <div class="col-0 col-md-4 col-lg-0" id="bottom_left_col"></div>
                      <div class="col-12 col-md-8 col-lg-12">
                        <div id="rtpcontainer">
                          <div class="mktg-promo" id="most-popular">
                            <p class="aside-heading">Most Popular</p>
                            <div class="pb-2">
                              <p class="media-type">Video</p>
                              <a href="https://www.elastic.co/webinars/getting-started-elasticsearch?baymax=default&elektra=docs&storm=top-video">
                                <p class="mb-0">Get Started with Elasticsearch</p>
                              </a>
                            </div>
                            <div class="pb-2">
                              <p class="media-type">Video</p>
                              <a href="https://www.elastic.co/webinars/getting-started-kibana?baymax=default&elektra=docs&storm=top-video">
                                <p class="mb-0">Intro to Kibana</p>
                              </a>
                            </div>
                            <div class="pb-2">
                              <p class="media-type">Video</p>
                              <a href="https://www.elastic.co/webinars/introduction-elk-stack?baymax=default&elektra=docs&storm=top-video">
                                <p class="mb-0">ELK for Logs & Metrics</p>
                              </a>
                            </div>
                          </div>
                        </div>
                      </div>
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </section>

        </div>


<div id='elastic-footer'></div>
<script src='https://www.elastic.co/elastic-footer.js'></script>
<!-- Footer Section end-->

      </section>
    </div>

<script src="/guide/static/jquery.js"></script>
<script type="text/javascript" src="/guide/static/docs.js"></script>
<script type="text/javascript">
  window.initial_state = {}</script>
  </body>
</html>
