<!DOCTYPE html>
<html lang="en-us">
  <head>
    
<meta charset="UTF-8">
<meta name="description" content="The list of compatible third party NLP models.">
<meta name="keywords" content="ML, Elastic Stack, natural language processing">
<title>Compatible third party NLP models | Machine Learning in the Elastic Stack [8.5] | Elastic</title>
<link rel="home" href="index.html" title="Machine Learning in the Elastic Stack [8.5]"/>
<link rel="up" href="ml-nlp.html" title="Natural language processing"/>
<link rel="prev" href="ml-nlp-apis.html" title="API quick reference"/>
<link rel="next" href="ml-nlp-examples.html" title="Examples"/>
<meta name="DC.type" content="Learn/Docs/Elastic Stack/Machine Learning/8.5"/>
<meta name="DC.subject" content="Machine Learning"/>
<meta name="DC.identifier" content="8.5"/>

    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <script src="https://cdn.optimizely.com/js/18132920325.js"></script>
    <link rel="apple-touch-icon" sizes="57x57" href="/apple-icon-57x57.png">
    <link rel="apple-touch-icon" sizes="60x60" href="/apple-icon-60x60.png">
    <link rel="apple-touch-icon" sizes="72x72" href="/apple-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="76x76" href="/apple-icon-76x76.png">
    <link rel="apple-touch-icon" sizes="114x114" href="/apple-icon-114x114.png">
    <link rel="apple-touch-icon" sizes="120x120" href="/apple-icon-120x120.png">
    <link rel="apple-touch-icon" sizes="144x144" href="/apple-icon-144x144.png">
    <link rel="apple-touch-icon" sizes="152x152" href="/apple-icon-152x152.png">
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-icon-180x180.png">
    <link rel="icon" type="image/png" href="/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="/android-chrome-192x192.png" sizes="192x192">
    <link rel="icon" type="image/png" href="/favicon-96x96.png" sizes="96x96">
    <link rel="icon" type="image/png" href="/favicon-16x16.png" sizes="16x16">
    <link rel="manifest" href="/manifest.json">
    <meta name="apple-mobile-web-app-title" content="Elastic">
    <meta name="application-name" content="Elastic">
    <meta name="msapplication-TileColor" content="#ffffff">
    <meta name="msapplication-TileImage" content="/mstile-144x144.png">
    <meta name="theme-color" content="#ffffff">
    <meta name="naver-site-verification" content="936882c1853b701b3cef3721758d80535413dbfd" />
    <meta name="yandex-verification" content="d8a47e95d0972434" />
    <meta name="localized" content="true" />
    <meta name="st:robots" content="follow,index" />
    <meta property="og:image" content="https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/blt280217a63b82a734/6202d3378b1f312528798412/elastic-logo.svg" />
    <meta property="og:image:width" content="500" />
    <meta property="og:image:height" content="172" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <link rel="apple-touch-icon-precomposed" sizes="64x64" href="/favicon_64x64_16bit.png">
    <link rel="apple-touch-icon-precomposed" sizes="32x32" href="/favicon_32x32.png">
    <link rel="apple-touch-icon-precomposed" sizes="16x16" href="/favicon_16x16.png">
    <!-- Give IE8 a fighting chance -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    <link rel="stylesheet" type="text/css" href="/guide/static/styles.css" />
  </head>

  <!--© 2015-2022 Elasticsearch B.V. -->
  <!-- All Elastic documentation is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License. -->
  <!-- http://creativecommons.org/licenses/by-nc-nd/4.0/ -->

  <body>
    <!-- Google Tag Manager -->
    <script>dataLayer = [];</script><noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-58RLH5" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start': new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0], j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src= '//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f); })(window,document,'script','dataLayer','GTM-58RLH5');</script>
    <!-- End Google Tag Manager -->

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-12395217-16"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-12395217-16');
    </script>

    <!-- Google Tag Manager for GA4 -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start': new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0], j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-KNJMG2M');</script>
    <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-KNJMG2M" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    <!-- End Google Tag Manager for GA4-->

    <!--BEGIN QUALTRICS WEBSITE FEEDBACK SNIPPET-->
    <script type='text/javascript'>
      (function(){var g=function(e,h,f,g){
      this.get=function(a){for(var a=a+"=",c=document.cookie.split(";"),b=0,e=c.length;b<e;b++){for(var d=c[b];" "==d.charAt(0);)d=d.substring(1,d.length);if(0==d.indexOf(a))return d.substring(a.length,d.length)}return null};
      this.set=function(a,c){var b="",b=new Date;b.setTime(b.getTime()+6048E5);b="; expires="+b.toGMTString();document.cookie=a+"="+c+b+"; path=/; "};
      this.check=function(){var a=this.get(f);if(a)a=a.split(":");else if(100!=e)"v"==h&&(e=Math.random()>=e/100?0:100),a=[h,e,0],this.set(f,a.join(":"));else return!0;var c=a[1];if(100==c)return!0;switch(a[0]){case "v":return!1;case "r":return c=a[2]%Math.floor(100/c),a[2]++,this.set(f,a.join(":")),!c}return!0};
      this.go=function(){if(this.check()){var a=document.createElement("script");a.type="text/javascript";a.src=g;document.body&&document.body.appendChild(a)}};
      this.start=function(){var a=this;window.addEventListener?window.addEventListener("load",function(){a.go()},!1):window.attachEvent&&window.attachEvent("onload",function(){a.go()})}};
      try{(new g(100,"r","QSI_S_ZN_emkP0oSe9Qrn7kF","https://znemkp0ose9qrn7kf-elastic.siteintercept.qualtrics.com/WRSiteInterceptEngine/?Q_ZID=ZN_emkP0oSe9Qrn7kF")).start()}catch(i){}})();
    </script><div id='ZN_emkP0oSe9Qrn7kF'><!--DO NOT REMOVE-CONTENTS PLACED HERE--></div>
    <!--END WEBSITE FEEDBACK SNIPPET-->

    <div id='elastic-nav' style="display:none;"></div>
    <script src='https://www.elastic.co/elastic-nav.js'></script>

    <div class="main-container">
      <section id="content" >
        <div class="content-wrapper">

          <section id="guide" lang="en">
            <div class="container-fluid">
              <div class="row pb-3">
                <div class="col-12 order-2 col-md-4 order-md-1 col-lg-3 h-almost-full-md sticky-top-md" id="left_col">
                  <!-- The TOC is appended here -->
                </div>

                <div class="col-12 order-1 col-md-8 order-md-2 col-lg-7 order-lg-2 guide-section" id="middle_col">
                  <!-- start body -->
                  
<div id="content">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span><span class="chevron-right">›</span>
<span class="breadcrumb-link"><a href="index.html">Machine Learning in the Elastic Stack [8.5]</a></span><span class="chevron-right">›</span>
<span class="breadcrumb-link"><a href="ml-nlp.html">Natural language processing</a></span>
</div>
<div class="navheader">
<span class="prev">
<a href="ml-nlp-apis.html">« API quick reference</a>
</span>
<span class="next">
<a href="ml-nlp-examples.html">Examples »</a>
</span>
</div>
<div class="chapter">
<div class="titlepage"><div><div>
<h2 class="title"><a id="ml-nlp-model-ref"></a>Compatible third party NLP models<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/8.5/docs/en/stack/ml/nlp/ml-nlp-model-ref.asciidoc">edit</a></h2>
</div></div></div>

<p>The Elastic Stack machine learning features support transformer models that conform to the standard
BERT model interface and use the WordPiece tokenization algorithm.</p>
<p>The current list of supported architectures is:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
BERT
</li>
<li class="listitem">
BART
</li>
<li class="listitem">
DPR bi-encoders
</li>
<li class="listitem">
DistilBERT
</li>
<li class="listitem">
ELECTRA
</li>
<li class="listitem">
MobileBERT
</li>
<li class="listitem">
RoBERTa
</li>
<li class="listitem">
RetriBERT
</li>
<li class="listitem">
MPNet
</li>
<li class="listitem">
SentenceTransformers bi-encoders with the above transformer architectures
</li>
</ul>
</div>
<p>In general, any trained model that has a supported architecture is deployable in
Elasticsearch by using eland. However, it is not possible to test every third party
model. The following lists are therefore provided for informational purposes
only and may not be current. Elastic makes no warranty or assurance that the
machine learning features will continue to interoperate with these third party models in the
way described, or at all.</p>
<p>These models are listed by NLP task; for more information about those tasks,
refer to <a class="xref" href="ml-nlp-overview.html" title="Overview"><em>Overview</em></a>.</p>
<h3><a id="ml-nlp-model-ref-mask"></a>Third party fill-mask models<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/8.5/docs/en/stack/ml/nlp/ml-nlp-model-ref.asciidoc">edit</a></h3>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<a href="https://huggingface.co/bert-base-uncased" class="ulink" target="_top">BERT base model</a>
</li>
<li class="listitem">
<a href="https://huggingface.co/distilroberta-base" class="ulink" target="_top">DistilRoBERTa base model</a>
</li>
<li class="listitem">
<a href="https://huggingface.co/microsoft/mpnet-base" class="ulink" target="_top">MPNet base model</a>
</li>
<li class="listitem">
<a href="https://huggingface.co/roberta-large" class="ulink" target="_top">RoBERTa large model</a>
</li>
</ul>
</div>
<h3><a id="ml-nlp-model-ref-ner"></a>Third party named entity recognition models<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/8.5/docs/en/stack/ml/nlp/ml-nlp-model-ref.asciidoc">edit</a></h3>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<a href="https://huggingface.co/dslim/bert-base-NER" class="ulink" target="_top">BERT base NER</a>
</li>
<li class="listitem">
<a href="https://huggingface.co/elastic/distilbert-base-cased-finetuned-conll03-english" class="ulink" target="_top">DistilBERT base cased finetuned conll03 English</a>
</li>
<li class="listitem">
<a href="https://huggingface.co/philschmid/distilroberta-base-ner-conll2003" class="ulink" target="_top">DistilRoBERTa base NER conll2003</a>
</li>
<li class="listitem">
<a href="https://huggingface.co/elastic/distilbert-base-uncased-finetuned-conll03-english" class="ulink" target="_top">DistilBERT base uncased finetuned conll03 English</a>
</li>
<li class="listitem">
<a href="https://huggingface.co/HooshvareLab/distilbert-fa-zwnj-base-ner" class="ulink" target="_top">DistilBERT fa zwnj base NER</a>
</li>
</ul>
</div>
<h3><a id="ml-nlp-model-ref-question-answering"></a>Third party question answering models<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/8.5/docs/en/stack/ml/nlp/ml-nlp-model-ref.asciidoc">edit</a></h3>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<a href="https://huggingface.co/bert-large-uncased-whole-word-masking-finetuned-squad" class="ulink" target="_top">BERT large model (uncased) whole word masking finetuned on SQuAD</a>
</li>
<li class="listitem">
<a href="https://huggingface.co/distilbert-base-cased-distilled-squad" class="ulink" target="_top">DistilBERT base cased distilled SQuAD</a>
</li>
<li class="listitem">
<a href="https://huggingface.co/deepset/electra-base-squad2" class="ulink" target="_top">Electra base squad2</a>
</li>
<li class="listitem">
<a href="https://huggingface.co/deepset/tinyroberta-squad2" class="ulink" target="_top">TinyRoBERTa squad2</a>
</li>
</ul>
</div>
<h3><a id="ml-nlp-model-ref-text-embedding"></a>Third party text embedding models<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/8.5/docs/en/stack/ml/nlp/ml-nlp-model-ref.asciidoc">edit</a></h3>
<p>Text Embedding models are designed to work with specific scoring functions
for calculating the similarity between the embeddings they produce.
Examples of typical scoring functions are: <code class="literal">cosine</code>, <code class="literal">dot product</code> and
<code class="literal">euclidean distance</code> (also known as <code class="literal">l2_norm</code>).</p>
<p>The embeddings produced by these models should be indexed in Elasticsearch using the
<a href="/guide/en/elasticsearch/reference/8.5/dense-vector.html" class="ulink" target="_top">dense vector field type</a>
with an appropriate <a href="/guide/en/elasticsearch/reference/8.5/dense-vector.html#dense-vector-params" class="ulink" target="_top">similarity function</a>
chosen for the model.</p>
<p>To find similar embeddings in Elasticsearch use the efficient
<a href="/guide/en/elasticsearch/reference/8.5/knn-search.html#approximate-knn" class="ulink" target="_top">Approximate k-nearest neighbor (kNN)</a>
search API with a text embedding as the query vector. Approximate
kNN search uses the similarity function defined in
the dense vector field mapping is used to calculate the relevance.
For the best results the function must be one of
the suitable similarity functions for the model.</p>
<p>Using <code class="literal">SentenceTransformerWrapper</code>:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<a href="https://huggingface.co/sentence-transformers/all-distilroberta-v1" class="ulink" target="_top">All DistilRoBERTa v1</a>
Suitable similarity functions:	<code class="literal">dot_product</code>, <code class="literal">cosine</code>, <code class="literal">l2_norm</code>
</li>
<li class="listitem">
<a href="https://huggingface.co/sentence-transformers/all-MiniLM-L12-v2" class="ulink" target="_top">All MiniLM L12 v2</a>
Suitable similarity functions:	<code class="literal">dot_product</code>, <code class="literal">cosine</code>, <code class="literal">l2_norm</code>
</li>
<li class="listitem">
<a href="https://huggingface.co/sentence-transformers/all-mpnet-base-v2" class="ulink" target="_top">All MPNet base v2</a>
Suitable similarity functions:	<code class="literal">dot_product</code>, <code class="literal">cosine</code>, <code class="literal">l2_norm</code>
</li>
<li class="listitem">
<a href="https://huggingface.co/sentence-transformers/facebook-dpr-ctx_encoder-multiset-base" class="ulink" target="_top">Facebook dpr-ctx_encoder multiset base</a>
Suitable similarity functions:	<code class="literal">dot_product</code>
</li>
<li class="listitem">
<a href="https://huggingface.co/sentence-transformers/facebook-dpr-question_encoder-single-nq-base" class="ulink" target="_top">Facebook dpr-question_encoder single nq base</a>
Suitable similarity functions:	<code class="literal">dot_product</code>
</li>
<li class="listitem">
<a href="https://huggingface.co/sentence-transformers/LaBSE" class="ulink" target="_top">LaBSE</a>
Suitable similarity functions:	<code class="literal">cosine</code>
</li>
<li class="listitem">
<a href="https://huggingface.co/sentence-transformers/msmarco-distilbert-base-tas-b" class="ulink" target="_top">msmarco DistilBERT base tas b</a>
Suitable similarity functions:	<code class="literal">dot_product</code>
</li>
<li class="listitem">
<a href="https://huggingface.co/sentence-transformers/msmarco-MiniLM-L12-cos-v5" class="ulink" target="_top">msmarco MiniLM L12 v5</a>
Suitable similarity functions:	<code class="literal">dot_product</code>, <code class="literal">cosine</code>, <code class="literal">l2_norm</code>
</li>
<li class="listitem">
<a href="https://huggingface.co/sentence-transformers/paraphrase-mpnet-base-v2" class="ulink" target="_top">paraphrase mpnet base v2</a>
Suitable similarity functions:	<code class="literal">cosine</code>
</li>
</ul>
</div>
<p>Using <code class="literal">DPREncoderWrapper</code>:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<a href="https://huggingface.co/castorini/ance-dpr-context-multi" class="ulink" target="_top">ance dpr-context multi</a>
</li>
<li class="listitem">
<a href="https://huggingface.co/castorini/ance-dpr-question-multi" class="ulink" target="_top">ance dpr-question multi</a>
</li>
<li class="listitem">
<a href="https://huggingface.co/castorini/bpr-nq-ctx-encoder" class="ulink" target="_top">bpr nq-ctx-encoder</a>
</li>
<li class="listitem">
<a href="https://huggingface.co/castorini/bpr-nq-question-encoder" class="ulink" target="_top">bpr nq-question-encoder</a>
</li>
<li class="listitem">
<a href="https://huggingface.co/facebook/dpr-ctx_encoder-single-nq-base" class="ulink" target="_top">dpr-ctx_encoder single nq base</a>
</li>
<li class="listitem">
<a href="https://huggingface.co/facebook/dpr-ctx_encoder-multiset-base" class="ulink" target="_top">dpr-ctx_encoder multiset base</a>
</li>
<li class="listitem">
<a href="https://huggingface.co/facebook/dpr-question_encoder-single-nq-base" class="ulink" target="_top">dpr-question_encoder single nq base</a>
</li>
<li class="listitem">
<a href="https://huggingface.co/facebook/dpr-question_encoder-multiset-base" class="ulink" target="_top">dpr-question_encoder multiset base</a>
</li>
</ul>
</div>
<h4><a id="ml-nlp-model-ref-text-classification"></a>Third party text classification models<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/8.5/docs/en/stack/ml/nlp/ml-nlp-model-ref.asciidoc">edit</a></h4>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<a href="https://huggingface.co/nateraw/bert-base-uncased-emotion" class="ulink" target="_top">BERT base uncased emotion</a>
</li>
<li class="listitem">
<a href="https://huggingface.co/Hate-speech-CNERG/dehatebert-mono-english" class="ulink" target="_top">DehateBERT mono english</a>
</li>
<li class="listitem">
<a href="https://huggingface.co/bhadresh-savani/distilbert-base-uncased-emotion" class="ulink" target="_top">DistilBERT base uncased emotion</a>
</li>
<li class="listitem">
<a href="https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english" class="ulink" target="_top">DistilBERT base uncased finetuned SST-2</a>
</li>
<li class="listitem">
<a href="https://huggingface.co/ProsusAI/finbert" class="ulink" target="_top">FinBERT</a>
</li>
<li class="listitem">
<a href="https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment" class="ulink" target="_top">Twitter roBERTa base for Sentiment Analysis</a>
</li>
</ul>
</div>
<h3><a id="ml-nlp-model-ref-zero-shot"></a>Third party zero-shot text classification models<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/8.5/docs/en/stack/ml/nlp/ml-nlp-model-ref.asciidoc">edit</a></h3>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<a href="https://huggingface.co/facebook/bart-large-mnli" class="ulink" target="_top">BART large mnli</a>
</li>
<li class="listitem">
<a href="https://huggingface.co/typeform/distilbert-base-uncased-mnli" class="ulink" target="_top">DistilBERT base model (uncased)</a>
</li>
<li class="listitem">
<a href="https://huggingface.co/valhalla/distilbart-mnli-12-6" class="ulink" target="_top">DistilBart MNLI</a>
</li>
<li class="listitem">
<a href="https://huggingface.co/typeform/mobilebert-uncased-mnli" class="ulink" target="_top">MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices</a>
</li>
<li class="listitem">
<a href="https://huggingface.co/cross-encoder/nli-distilroberta-base" class="ulink" target="_top">NLI DistilRoBERTa base</a>
</li>
<li class="listitem">
<a href="https://huggingface.co/cross-encoder/nli-roberta-base" class="ulink" target="_top">NLI RoBERTa base</a>
</li>
<li class="listitem">
<a href="https://huggingface.co/typeform/squeezebert-mnli" class="ulink" target="_top">SqueezeBERT</a>
</li>
</ul>
</div>
<h3><a id="_expected_model_output"></a>Expected model output<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/8.5/docs/en/stack/ml/nlp/ml-nlp-model-ref.asciidoc">edit</a></h3>
<p>Models used for each NLP task type must output tensors of a specific format to
be used in the Elasticsearch NLP pipelines.</p>
<p>Here are the expected outputs for each task type.</p>
<h4><a id="_fill_mask_expected_model_output"></a>Fill mask expected model output<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/8.5/docs/en/stack/ml/nlp/ml-nlp-model-ref.asciidoc">edit</a></h4>
<p>Fill mask is a specific kind of token classification; it is the base training
task of many transformer models.</p>
<p>For the Elastic stack&#8217;s fill mask NLP task to understand the model output, it
must have a specific format. It needs to
be a float tensor with
<code class="literal">shape(&lt;number of sequences&gt;, &lt;number of tokens&gt;, &lt;vocab size&gt;)</code>.</p>
<p>Here is an example with a single sequence <code class="literal">"The capital of [MASK] is Paris"</code> and
with vocabulary <code class="literal">["The", "capital", "of", "is", "Paris", "France", "[MASK]"]</code>.</p>
<p>Should output:</p>
<pre class="screen"> [
   [
     [ 0, 0, 0, 0, 0, 0, 0 ], // The
     [ 0, 0, 0, 0, 0, 0, 0 ], // capital
     [ 0, 0, 0, 0, 0, 0, 0 ], // of
     [ 0.01, 0.01, 0.3, 0.01, 0.2, 1.2, 0.1 ], // [MASK]
     [ 0, 0, 0, 0, 0, 0, 0 ], // is
     [ 0, 0, 0, 0, 0, 0, 0 ] // Paris
   ]
]</pre>
<p>The predicted value here for <code class="literal">[MASK]</code> is <code class="literal">"France"</code> with a score of 1.2.</p>
<h4><a id="_named_entity_recognition_expected_model_output"></a>Named entity recognition expected model output<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/8.5/docs/en/stack/ml/nlp/ml-nlp-model-ref.asciidoc">edit</a></h4>
<p>Named entity recognition is a specific token classification task. Each token in
the sequence is scored related to a specific set of classification labels. For
the Elastic Stack, we use Inside-Outside-Beginning (IOB) tagging. Additionally,
only the following classification labels are supported: "O", "B_MISC", "I_MISC",
"B_PER", "I_PER", "B_ORG", "I_ORG", "B_LOC", "I_LOC".</p>
<p>The <code class="literal">"O"</code> entity label indicates that the current token is outside any entity.
<code class="literal">"I"</code> indicates that the token is inside an entity.
<code class="literal">"B"</code> indicates the beginning of an entity.
<code class="literal">"MISC"</code> is a miscellaneous entity.
<code class="literal">"LOC"</code> is a location.
<code class="literal">"PER"</code> is a person.
<code class="literal">"ORG"</code> is an organization.</p>
<p>The response format must be a float tensor with
<code class="literal">shape(&lt;number of sequences&gt;, &lt;number of tokens&gt;, &lt;number of classification labels&gt;)</code>.</p>
<p>Here is an example with a single sequence <code class="literal">"Waldo is in Paris"</code>:</p>
<pre class="screen"> [
   [
//    "O", "B_MISC", "I_MISC", "B_PER", "I_PER", "B_ORG", "I_ORG", "B_LOC", "I_LOC"
     [ 0,  0,         0,       0.4,     0.5,     0,       0.1,     0,       0 ], // Waldo
     [ 1,  0,         0,       0,       0,       0,       0,       0,       0 ], // is
     [ 1,  0,         0,       0,       0,       0,       0,       0,       0 ], // in
     [ 0,  0,         0,       0,       0,       0,       0,       0,       1.0 ] // Paris
   ]
]</pre>
<h4><a id="_text_embedding_expected_model_output"></a>Text embedding expected model output<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/8.5/docs/en/stack/ml/nlp/ml-nlp-model-ref.asciidoc">edit</a></h4>
<p>Text embedding allows for semantic embedding of text for dense information
retrieval.</p>
<p>The output of the model must be the specific embedding directly without any
additional pooling.</p>
<p>Eland does this wrapping for the aforementioned models. But if supplying your
own, the model must output the embedding for each inferred sequence.</p>
<h4><a id="_text_classification_expected_model_output"></a>Text classification expected model output<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/8.5/docs/en/stack/ml/nlp/ml-nlp-model-ref.asciidoc">edit</a></h4>
<p>With text classification (for example, in tasks like sentiment analysis), the
entire sequence is classified. The output of the model must be a float tensor
with <code class="literal">shape(&lt;number of sequences&gt;, &lt;number of classification labels&gt;)</code>.</p>
<p>Here is an example with two sequences for a binary classification model of
"happy" and "sad":</p>
<pre class="screen"> [
   [
//     happy, sad
     [ 0,     1], // first sequence
     [ 1,     0] // second sequence
   ]
]</pre>
<h4><a id="_zero_shot_text_classification_expected_model_output"></a>Zero-shot text classification expected model output<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/8.5/docs/en/stack/ml/nlp/ml-nlp-model-ref.asciidoc">edit</a></h4>
<p>Zero-shot text classification allows text to be classified for arbitrary labels
not necessarily part of the original training. Each sequence is combined with
the label given some hypothesis template. The model then scores each of these
combinations according to <code class="literal">[entailment, neutral, contradiction]</code>. The output of
the model must be a float tensor with
<code class="literal">shape(&lt;number of sequences&gt;, &lt;number of labels&gt;, 3)</code>.</p>
<p>Here is an example with a single sequence classified against 4 labels:</p>
<pre class="screen"> [
   [
//     entailment, neutral, contradiction
     [ 0.5,        0.1,     0.4], // first label
     [ 0,          0,       1], // second label
     [ 1,          0,       0], // third label
     [ 0.7,        0.2,     0.1] // fourth label
   ]
]</pre>
</div>
<div class="navfooter">
<span class="prev">
<a href="ml-nlp-apis.html">« API quick reference</a>
</span>
<span class="next">
<a href="ml-nlp-examples.html">Examples »</a>
</span>
</div>
</div>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  messageStyle: "none",
  tex2jax: {
    inlineMath: [["\\(", "\\)"]],
    displayMath: [["\\[", "\\]"]],
    ignoreClass: "nostem|nolatexmath"
  },
  asciimath2jax: {
    delimiters: [["\\$", "\\$"]],
    ignoreClass: "nostem|noasciimath"
  },
  TeX: { equationNumbers: { autoNumber: "none" } }
})
MathJax.Hub.Register.StartupHook("AsciiMath Jax Ready", function () {
  MathJax.InputJax.AsciiMath.postfilterHooks.Add(function (data, node) {
    if ((node = data.script.parentNode) && (node = node.parentNode) && node.classList.contains('stemblock')) {
      data.math.root.display = "block"
    }
    return data
  })
})
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_HTMLorMML"></script>

                  <!-- end body -->
                </div>

                <div class="col-12 order-3 col-lg-2 order-lg-3 h-almost-full-lg sticky-top-lg" id="right_col">
                  <div id="sticky_content">
                    <!-- The OTP is appended here -->
                    <div class="row">
                      <div class="col-0 col-md-4 col-lg-0" id="bottom_left_col"></div>
                      <div class="col-12 col-md-8 col-lg-12">
                        <div id="rtpcontainer">
                          <div class="mktg-promo" id="most-popular">
                            <p class="aside-heading">Most Popular</p>
                            <div class="pb-2">
                              <p class="media-type">Video</p>
                              <a href="https://www.elastic.co/webinars/getting-started-elasticsearch?baymax=default&elektra=docs&storm=top-video">
                                <p class="mb-0">Get Started with Elasticsearch</p>
                              </a>
                            </div>
                            <div class="pb-2">
                              <p class="media-type">Video</p>
                              <a href="https://www.elastic.co/webinars/getting-started-kibana?baymax=default&elektra=docs&storm=top-video">
                                <p class="mb-0">Intro to Kibana</p>
                              </a>
                            </div>
                            <div class="pb-2">
                              <p class="media-type">Video</p>
                              <a href="https://www.elastic.co/webinars/introduction-elk-stack?baymax=default&elektra=docs&storm=top-video">
                                <p class="mb-0">ELK for Logs & Metrics</p>
                              </a>
                            </div>
                          </div>
                        </div>
                      </div>
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </section>

        </div>


<div id='elastic-footer'></div>
<script src='https://www.elastic.co/elastic-footer.js'></script>
<!-- Footer Section end-->

      </section>
    </div>

<script src="/guide/static/jquery.js"></script>
<script type="text/javascript" src="/guide/static/docs.js"></script>
<script type="text/javascript">
  window.initial_state = {}</script>
  </body>
</html>
