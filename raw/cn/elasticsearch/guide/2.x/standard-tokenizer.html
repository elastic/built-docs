<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>标准分词器 | Elasticsearch: 权威指南 | Elastic</title>
<meta class="elastic" name="content" content="标准分词器 | Elasticsearch: 权威指南">

<link rel="home" href="index.html" title="Elasticsearch: 权威指南"/>
<link rel="up" href="identifying-words.html" title="词汇识别"/>
<link rel="prev" href="standard-analyzer.html" title="标准分析器"/>
<link rel="next" href="icu-plugin.html" title="安装 ICU 插件"/>
<meta class="elastic" name="product_version" content="2.x"/>
<meta class="elastic" name="product_name" content="Elasticsearch"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/Elasticsearch/Definitive Guide"/>
<meta name="DC.subject" content="Elasticsearch"/>
<meta name="DC.identifier" content="2.x"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body>
<div class="page_header">
<b>请注意:</b><br/>本书基于 Elasticsearch 2.x 版本，有些内容可能已经过时。
</div>
<div class="navheader">
<span class="prev">
<a href="standard-analyzer.html">« 标准分析器</a>
</span>
<span class="next">
<a href="icu-plugin.html">安装 ICU 插件 »</a>
</span>
</div>
<div class="book" lang="zh_cn">
<div class="titlepage">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Elasticsearch: 权威指南</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="languages.html">处理人类语言</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="identifying-words.html">词汇识别</a></span>
</div>
<div>
<div><h1 class="title"><a id="id-1"></a>标准分词器</h1><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elasticsearch-cn/elasticsearch-definitive-guide/edit/cn/210_Identifying_words/20_Standard_tokenizer.asciidoc">edit</a></div>
</div>
<!--EXTRA-->
</div>
<div id="content">
<div id="url-to-v3" class="version-warning">
    <strong>IMPORTANT</strong>: This documentation is no longer updated. Refer to <a href="https://www.elastic.co/support/eol">Elastic's version policy</a> and the <a href="https://www.elastic.co/docs">latest documentation</a>.
</div>
<div class="section">
<div class="titlepage"><div><div>
<div class="position-relative"><h2 class="title"><a id="standard-tokenizer"></a>标准分词器</h2><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elasticsearch-cn/elasticsearch-definitive-guide/edit/cn/210_Identifying_words/20_Standard_tokenizer.asciidoc">edit</a></div>
</div></div></div>
<p><em>分词器</em> 接受一个字符串作为输入，将这个字符串拆分成独立的词或 <em>语汇单元（token）</em>
（可能会丢弃一些标点符号等字符），然后输出一个 <em>语汇单元流（token stream）</em> 。</p>
<p>有趣的是用于词汇 <em>识别</em> 的算法。 <code class="literal">whitespace</code> （空白字符）分词器按空白字符 —— 空格、tabs、换行符等等进行简单拆分 —— 然后假定连续的非空格字符组成了一个语汇单元。例如：</p>
<div class="pre_wrapper lang-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js">GET /_analyze?tokenizer=whitespace
You're the 1st runner home!</pre>
</div>
<p>这个请求会返回如下词项（terms）：
<code class="literal">You're</code> 、 <code class="literal">the</code> 、 <code class="literal">1st</code> 、 <code class="literal">runner</code> 、 <code class="literal">home!</code></p>
<p><code class="literal">letter</code> 分词器 ，采用另外一种策略，按照任何非字符进行拆分，
这样将会返回如下单词： <code class="literal">You</code> 、 <code class="literal">re</code> 、 <code class="literal">the</code> 、 <code class="literal">st</code> 、 <code class="literal">runner</code> 、 <code class="literal">home</code> 。</p>
<p><code class="literal">standard</code> 分词器使用 Unicode 文本分割算法
（定义来源于 <a href="http://unicode.org/reports/tr29/" class="ulink" target="_top">Unicode Standard Annex #29</a>）来寻找单词 <em>之间</em> 的界限，并且输出所有界限之间的内容。
Unicode 内含的知识使其可以成功的对包含混合语言的文本进行分词。</p>
<p>标点符号可能是单词的一部分，也可能不是，这取决于它出现的位置：</p>
<div class="pre_wrapper lang-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js">GET /_analyze?tokenizer=standard
You're my 'favorite'.</pre>
</div>
<p>在这个例子中，<code class="literal">You're</code> 中的撇号被视为单词的一部分，然而 <code class="literal">'favorite'</code> 中的单引号则不会被视为单词的一部分，
所以分词结果如下： <code class="literal">You're</code> 、 <code class="literal">my</code> 、 <code class="literal">favorite</code> 。</p>
<div class="tip admon">
<div class="icon"></div>
<div class="admon_content">
<p><code class="literal">uax_url_email</code> 分词器和 <code class="literal">standard</code> 分词器工作方式极其相同。
区别只在于它能识别 email 地址和 URLs 并输出为单个语汇单元。
<code class="literal">standard</code> 分词器则不一样，会将 email 地址和 URLs 拆分成独立的单词。
例如，email 地址 <code class="literal">joe-bloggs@foo-bar.com</code> 的分词结果为 <code class="literal">joe</code> 、 <code class="literal">bloggs</code> 、 <code class="literal">foo</code> 、 <code class="literal">bar.com</code> 。</p>
</div>
</div>
<p><code class="literal">standard</code> 分词器是大多数语言分词的一个合理的起点，特别是西方语言。
事实上，它构成了大多数特定语言分析器的基础，如 <code class="literal">english</code> 、<code class="literal">french</code> 和 <code class="literal">spanish</code> 分析器。
它也支持亚洲语言，只是有些缺陷，你可以考虑通过 ICU 插件的方式使用 <code class="literal">icu_tokenizer</code> 进行替换。</p>
</div>
</div>
</div><div class="navfooter">
<span class="prev">
<a href="standard-analyzer.html">« 标准分析器</a>
</span>
<span class="next">
<a href="icu-plugin.html">安装 ICU 插件 »</a>
</span>
</div>
</body>
</html>
