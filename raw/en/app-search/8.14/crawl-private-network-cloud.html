<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Crawl a private network using a web crawler on Elastic Cloud | App Search documentation [8.14] | Elastic</title>
<meta class="elastic" name="content" content="Crawl a private network using a web crawler on Elastic Cloud | App Search documentation [8.14]">

<link rel="home" href="index.html" title="App Search documentation [8.14]"/>
<link rel="up" href="guides.html" title="Guides"/>
<link rel="prev" href="crawl-web-content.html" title="Crawl web content"/>
<link rel="next" href="crawl-custom-fields-proxy.html" title="Extract custom fields using web crawler and proxy"/>
<meta class="elastic" name="product_version" content="8.14"/>
<meta class="elastic" name="product_name" content="App Search"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/App Search/Guide/8.14"/>
<meta name="DC.subject" content="App Search"/>
<meta name="DC.identifier" content="8.14"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body>
<div class="page_header">
<strong>IMPORTANT</strong>: No additional bug fixes or documentation updates
will be released for this version. For the latest information, see the
<a href="../current/index.html">current release documentation</a>.
</div>
<div class="navheader">
<span class="prev">
<a href="crawl-web-content.html">« Crawl web content</a>
</span>
<span class="next">
<a href="crawl-custom-fields-proxy.html">Extract custom fields using web crawler and proxy »</a>
</span>
</div>
<div class="book" lang="en">
<div class="titlepage">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link">
<div id="related-products" class="dropdown">
<div class="related-products-title"></div>
<div class="dropdown-anchor" tabindex="0">App Search<span class="dropdown-icon"></span></div>
<div class="dropdown-content">
<ul>
<li class="dropdown-category">Enterprise Search guides</li>
<ul>
<li><a href="/guide/en/enterprise-search/current/index.html" target="_blank">Enterprise Search</a></li>
<li><a href="/guide/en/app-search/current/index.html" target="_blank">App Search</a></li>
<li><a href="/guide/en/workplace-search/current/index.html" target="_blank">Workplace Search</a></li>
</ul>
<li class="dropdown-category">Programming language clients</li>
<ul>
<li><a href="https://www.elastic.co/guide/en/enterprise-search-clients/enterprise-search-node/current/index.html" target="_blank">Node.js client</a></li>
<li><a href="https://www.elastic.co/guide/en/enterprise-search-clients/php/current/index.html" target="_blank">PHP client</a></li>
<li><a href="https://www.elastic.co/guide/en/enterprise-search-clients/python/current/index.html" target="_blank">Python client</a></li>
<li><a href="https://www.elastic.co/guide/en/enterprise-search-clients/ruby/current/index.html" target="_blank">Ruby client</a></li>
</ul>
</ul>
</div>
</div>
</span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="guides.html">Guides</a></span>
</div>
<div>
<div><h1 class="title"><a id="id-1"></a>Crawl a private network using a web crawler on Elastic Cloud</h1><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/8.14/app-search-docs/guides/crawl-private-network-cloud.asciidoc">edit</a></div>
</div>
<!--EXTRA-->
</div>
<div id="content">
<div class="section">
<div class="titlepage"><div><div>
<h2 class="title"><a id="crawl-private-network-cloud"></a>Crawl a private network using a web crawler on Elastic Cloud<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/8.14/app-search-docs/guides/crawl-private-network-cloud.asciidoc">edit</a></h2>
</div></div></div>
<p>Since version 7.16.1, the App Search web crawler can crawl content on a private network if the content is accessible through an HTTP proxy.</p>
<p>This document explains how to configure the web crawler to crawl a private network by walking through a detailed example.</p>
<p>The <a href="/guide/en/app-search/8.14/web-crawler.html" class="ulink" target="_top">App Search web crawler</a> is hosted on Elastic Cloud, but has access to protected resources in private networks and other non-public environments.</p>
<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="crawl-private-network-cloud-overview"></a>Infrastructure overview<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/8.14/app-search-docs/guides/crawl-private-network-cloud.asciidoc">edit</a></h3>
</div></div></div>
<p>To demonstrate the authenticated proxy server functionality for App Search web crawler, we will use the infrastructure outlined in this schematic diagram:</p>
<div class="imageblock">
<div class="content">
<img src="images/app-search/crawler-proxy-schematic.png" alt="crawler proxy schematic">
</div>
</div>
<p>This example has all the components needed to understand the use case:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
A VPC (virtual private network) deployed within Google Cloud
</li>
<li class="listitem">
<p>The VPC contains two cloud instances: <code class="literal">web-server</code> and <code class="literal">proxy</code>:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
The web-server hosts a private website, that is only accessible from within the VPC, using a private domain name: <a href="http://marlin-docs.internal" class="ulink" target="_top">http://marlin-docs.internal</a>.
</li>
<li class="listitem">
The proxy server has basic HTTP authentication set up with the <span class="strong strong"><strong>username</strong></span> <code class="literal">proxyuser</code> and <span class="strong strong"><strong>password</strong></span> <code class="literal">proxypass</code>.
It is accessible from the public internet using the <span class="strong strong"><strong>host name</strong></span> <code class="literal">proxy.example.com</code> and the <span class="strong strong"><strong>port number</strong></span> <code class="literal">3128</code>.
</li>
</ul>
</div>
</li>
<li class="listitem">
<p>An Enterprise Search deployment running outside of the VPC, in Elastic Cloud.</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
This deployment has no access to the private network hosting our content.
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>App Search web crawler supports both HTTP and HTTPS.
However, we recommend configuring TLS to protect your content and proxy server credentials.</p>
<p>Refer to your proxy server software documentation for more details on how to set this up.</p>
</div>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="crawl-private-network-cloud-test-proxy"></a>Testing proxy connections<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/8.14/app-search-docs/guides/crawl-private-network-cloud.asciidoc">edit</a></h3>
</div></div></div>
<p>Before changing your Enterprise Search deployment configuration to use the HTTP proxy described above,
first make sure the proxy works and allows access to the private website.</p>
<p>You can configure your web browser to use the proxy and then try to access the private website.
Alternatively, use the following command to fetch the home page from the site using a given proxy:</p>
<div class="pre_wrapper lang-bash">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-bash">curl --head --proxy https://proxyuser:proxypass@proxy.example.com http://marlin-docs.internal</pre>
</div>
<p>This request makes a <code class="literal">HEAD</code> request to the website, using the proxy.
The response should be an <code class="literal">HTTP 200</code> with a set of additional headers.
Here is an example response:</p>
<div class="pre_wrapper lang-bash">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-bash">HTTP/1.1 200 OK
Content-Type: text/html
Content-Length: 42337
Accept-Ranges: bytes
Server: nginx/1.14.2
Date: Tue, 30 Nov 2021 19:19:14 GMT
Last-Modified: Tue, 30 Nov 2021 17:57:39 GMT
ETag: "61a66613-a561"
Age: 4
X-Cache: HIT from test-proxy
X-Cache-Lookup: HIT from test-proxy:3128
Via: 1.1 test-proxy (squid/4.6)
Connection: keep-alive</pre>
</div>
<p>We have confirmed that our proxy credentials and connection parameters are correct, and can now change the Enterprise Search configuration.</p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="crawl-private-network-cloud-configure-ent-search"></a>Configuring Enterprise Search<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/8.14/app-search-docs/guides/crawl-private-network-cloud.asciidoc">edit</a></h3>
</div></div></div>
<p>To prepare our Enterprise Search deployment to use the HTTP proxy for all {crawler }operations, we need to add the following <a href="/guide/en/cloud/current/ec-manage-enterprise-search-settings.html" class="ulink" target="_top">user settings</a>:</p>
<div class="pre_wrapper lang-yaml">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-yaml">crawler.http.proxy.host: proxy.example.com
crawler.http.proxy.port: 3128
crawler.http.proxy.protocol: https
crawler.http.proxy.username: proxyuser
crawler.http.proxy.password: proxypass</pre>
</div>
<p>When this configuration is added, the deployment will perform a graceful restart.
You can find detailed instructions on how to work with custom configurations in our <a href="/guide/en/cloud/current/ec-manage-enterprise-search-settings.html" class="ulink" target="_top">official Elastic Cloud documentation</a>.</p>
<div class="important admon">
<div class="icon"></div>
<div class="admon_content">
<p>HTTP proxy with basic authentication requires an appropriate Elastic subscription level.
Refer to the Elastic subscriptions pages for <a href="/subscriptions/cloud" class="ulink" target="_blank" rel="noopener">Elastic Cloud</a> and <a href="/subscriptions" class="ulink" target="_top">self-managed</a> deployments.</p>
</div>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="crawl-private-network-cloud-test-solution"></a>Testing the solution<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/8.14/app-search-docs/guides/crawl-private-network-cloud.asciidoc">edit</a></h3>
</div></div></div>
<p>With the configuration complete, we can now test the solution.
Create an App Search engine and use the Web Crawler feature to ingest content into the engine:</p>
<div class="imageblock">
<div class="content">
<img src="images/app-search/crawler-proxy-validation.png" alt="crawler proxy validation">
</div>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>The validation process for adding a domain to the App Search web crawler configuration will skip a number of networking-related checks, since these do not work through a proxy.
If you do not see the warning in the above image, check your deployment configuration to ensure you have configured the proxy correctly.</p>
</div>
</div>
<p>Our private domain is now added to the configuration.
We can start the crawl, and the content should be ingested into the deployment.
If there are failures, check your <a href="/guide/en/app-search/8.14/" class="ulink" target="_top">crawler logs</a> and proxy server&#8217;s logs for clues about what might be going wrong.</p>
<p>If you are using a Squid proxy server, the logs should look like this:</p>
<div class="pre_wrapper lang-bash">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-bash">1638298043.202      1 99.250.74.78 TCP_MISS/200 65694 GET http://marlin-docs.internal/docs/gcode/M951.html proxyuser HIER_DIRECT/10.188.0.2 text/html
1638298045.286      1 99.250.74.78 TCP_MISS/200 64730 GET http://marlin-docs.internal/docs/gcode/M997.html proxyuser HIER_DIRECT/10.188.0.2 text/html
1638298045.373      1 99.250.74.78 TCP_MISS/200 63609 GET http://marlin-docs.internal/docs/gcode/M999.html proxyuser HIER_DIRECT/10.188.0.2 text/html</pre>
</div>
</div>

</div>
</div>
</div><div class="navfooter">
<span class="prev">
<a href="crawl-web-content.html">« Crawl web content</a>
</span>
<span class="next">
<a href="crawl-custom-fields-proxy.html">Extract custom fields using web crawler and proxy »</a>
</span>
</div>
</body>
</html>
