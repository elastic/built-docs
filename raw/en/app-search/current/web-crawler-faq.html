<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Web crawler (beta) FAQ | Elastic App Search Documentation [7.11] | Elastic</title>
<link rel="home" href="index.html" title="Elastic App Search Documentation [7.11]"/>
<link rel="up" href="guides.html" title="Guides"/>
<link rel="prev" href="web-crawler.html" title="Web crawler (beta)"/>
<link rel="next" href="web-crawler-reference.html" title="Web crawler (beta) reference"/>
<meta name="DC.type" content="Learn/Docs/App Search/Guide/7.11"/>
<meta name="DC.subject" content="App Search"/>
<meta name="DC.identifier" content="7.11"/>
</head>
<body>
<div id="content">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="index.html">Elastic App Search Documentation [7.11]</a></span>
»
<span class="breadcrumb-link"><a href="guides.html">Guides</a></span>
»
<span class="breadcrumb-node">Web crawler (beta) FAQ</span>
</div>
<div class="navheader">
<span class="prev">
<a href="web-crawler.html">« Web crawler (beta)</a>
</span>
<span class="next">
<a href="web-crawler-reference.html">Web crawler (beta) reference »</a>
</span>
</div>
<div class="section">
<div class="titlepage"><div><div>
<h2 class="title"><a id="web-crawler-faq"></a>Web crawler (beta) FAQ<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/7.11/app-search-docs/guides/web-crawler-faq.asciidoc">edit</a></h2>
</div></div></div>
<div class="caution admon">
<div class="icon"></div>
<div class="admon_content">
<p>The Elastic Enterprise Search web crawler is a <span class="strong strong"><strong>beta</strong></span> feature.
Beta features are subject to change and are not covered by the support SLA of general release (GA) features.
Elastic plans to promote this feature to GA in a future release.</p>
</div>
</div>
<p>View frequently asked questions about the Enterprise Search web crawler:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<a class="xref" href="web-crawler-faq.html#web-crawler-faq-what-functionality-is-supported" title="What functionality is supported?">What functionality is supported?</a>
</li>
<li class="listitem">
<a class="xref" href="web-crawler-faq.html#web-crawler-faq-what-functionality-is-not-supported" title="What functionality is not supported?">What functionality is not supported?</a>
</li>
</ul>
</div>
<p>See <a class="xref" href="web-crawler-reference.html" title="Web crawler (beta) reference">Web crawler (beta) reference</a> for detailed technical information about the web crawler.</p>
<p>We also welcome <a class="xref" href="web-crawler.html#web-crawler-feedback" title="Web crawler feedback">your feedback</a>.</p>
<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="web-crawler-faq-what-functionality-is-supported"></a>What functionality is supported?<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/7.11/app-search-docs/guides/web-crawler-faq.asciidoc">edit</a></h3>
</div></div></div>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<span class="strong strong"><strong>Crawling publicly-accessible HTTP/HTTPS websites</strong></span>
</li>
<li class="listitem">
<span class="strong strong"><strong>Support for crawling multiple domains per-Engine</strong></span>
</li>
<li class="listitem">
<span class="strong strong"><strong>Robots meta tag support</strong></span>
</li>
<li class="listitem">
<p><span class="strong strong"><strong>Robots "nofollow" support</strong></span></p>
<p>Includes robots meta tags set to "nofollow" and links with rel="nofollow" attributes</p>
</li>
<li class="listitem">
<p><span class="strong strong"><strong>Basic content extraction</strong></span></p>
<p>The web crawler will extract content for a predefined, unconfigurable set of fields from each page it visits.</p>
</li>
<li class="listitem">
<p><span class="strong strong"><strong>"Entry points"</strong></span></p>
<p>Entry points allow customers to specify where the web crawler begins crawling each domain.</p>
</li>
<li class="listitem">
<p><span class="strong strong"><strong>"Crawl rules"</strong></span></p>
<p>Crawl rules allow customers to control whether each URL the web crawler encounters will be visited and indexed.</p>
</li>
<li class="listitem">
<p><span class="strong strong"><strong>Logging of each crawl</strong></span></p>
<p>Logs are representative of an entire crawl, which encompasses all domains in an engine.</p>
</li>
<li class="listitem">
<span class="strong strong"><strong>User interfaces for managing domains, entry points, and crawl rules</strong></span>
</li>
</ul>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="web-crawler-faq-what-functionality-is-not-supported"></a>What functionality is not supported?<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/7.11/app-search-docs/guides/web-crawler-faq.asciidoc">edit</a></h3>
</div></div></div>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<p><span class="strong strong"><strong>Automatic or scheduled crawling</strong></span></p>
<p>Start crawls manually from the UI or use the crawler API to schedule a crawl on-demand.</p>
</li>
<li class="listitem">
<p><span class="strong strong"><strong>Single-page app (SPA) support</strong></span></p>
<p>The crawler cannot currently crawl pages that are pure JavaScript single-page apps.</p>
</li>
<li class="listitem">
<p><span class="strong strong"><strong>Configurable content extraction</strong></span></p>
<p>Content extraction is currently limited to an unconfigurable, predefined set of fields.</p>
</li>
<li class="listitem">
<span class="strong strong"><strong>Crawling private websites or websites behind authentication</strong></span>
</li>
<li class="listitem">
<p><span class="strong strong"><strong>Sitemap support</strong></span></p>
<p>The web crawler currently has no knowledge of sitemaps and cannot utilize them to identify pages to visit.</p>
</li>
<li class="listitem">
<p><span class="strong strong"><strong>robots.txt support</strong></span></p>
<p>The web crawler does not currently adhere to <code class="literal">robots.txt</code> rules. The crawler only honors robots meta tags set to <code class="literal">nofollow</code> and links with <code class="literal">rel="nofollow"</code> attributes.</p>
</li>
<li class="listitem">
<p><span class="strong strong"><strong>Crawl persistence</strong></span></p>
<p>If a crawl is unexpectedly stopped before it finishes, it will not be able to restart where it left off. You can restart a crawl again from the beginning. The crawler will not duplicate documents that it already indexed.</p>
</li>
<li class="listitem">
<p><span class="strong strong"><strong>Extracting content from files</strong></span></p>
<p>Currently, the web crawler will only extract content from HTML content.</p>
</li>
</ul>
</div>
</div>

</div>
<div class="navfooter">
<span class="prev">
<a href="web-crawler.html">« Web crawler (beta)</a>
</span>
<span class="next">
<a href="web-crawler-reference.html">Web crawler (beta) reference »</a>
</span>
</div>
</div>
</body>
</html>
