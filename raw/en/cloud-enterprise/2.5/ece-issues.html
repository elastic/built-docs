<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Common issues | Elastic Cloud Enterprise Reference [2.5] | Elastic</title>
<link rel="home" href="index.html" title="Elastic Cloud Enterprise Reference [2.5]"/>
<link rel="up" href="ece-troubleshooting.html" title="Troubleshooting"/>
<link rel="prev" href="ece-troubleshooting.html" title="Troubleshooting"/>
<link rel="next" href="ece-troubleshooting-emergency.html" title="Using the emergency roles token"/>
<meta name="DC.type" content="Learn/Docs/CloudEnterprise/Reference/2.5"/>
<meta name="DC.subject" content="ECE"/>
<meta name="DC.identifier" content="2.5"/>
</head>
<body><div class="page_header">
A newer version is available. For the latest information, see the
<a href="../current/index.html">current release documentation</a>.
</div>
<div id="content">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="index.html">Elastic Cloud Enterprise Reference [2.5]</a></span>
»
<span class="breadcrumb-link"><a href="ece-troubleshooting.html">Troubleshooting</a></span>
»
<span class="breadcrumb-node">Common issues</span>
</div>
<div class="navheader">
<span class="prev">
<a href="ece-troubleshooting.html">« Troubleshooting</a>
</span>
<span class="next">
<a href="ece-troubleshooting-emergency.html">Using the emergency roles token »</a>
</span>
</div>
<div class="chapter">
<div class="titlepage"><div><div>
<h2 class="title"><a id="ece-issues"></a>Common issues<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/cloud/edit/2.5/docs/cloud-enterprise/ce-troubleshooting.asciidoc">edit</a></h2>
</div></div></div>
<h3><a id="ece_installation_failures_with_firewalld_enabled_on_centos_and_rhel"></a>Installation failures with firewalld enabled on CentOS and RHEL<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/cloud/edit/2.5/docs/cloud-enterprise/ce-troubleshooting.asciidoc">edit</a></h3>
<p><span class="strong strong"><strong>Symptom:</strong></span> On CentOS and RHEL the installation of Elastic Cloud Enterprise fails, possibly indicating an issue that affects communication between Docker containers on the host.</p>
<p><span class="strong strong"><strong>Resolution:</strong></span> The issue might be caused by the firewalld service. The service is not compatible with Docker and interferes with the installation of ECE. You must disable firewalld with <code class="literal">sudo systemctl disable firewalld</code> and reboot before installing or reinstalling ECE.</p>
<p>To learn more, see the the configuration steps for <a class="xref" href="ece-configure-hosts-rhel-centos.html" title="Red Hat Enterprise Linux (RHEL) 7 and CentOS 7">Red Hat Enterprise Linux (RHEL) 7 and CentOS 7</a>.</p>
<h3><a id="ece_allocator_failures"></a>Allocator failures<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/cloud/edit/2.5/docs/cloud-enterprise/ce-troubleshooting.asciidoc">edit</a></h3>
<p>Allocator failures result in alerts in the Cloud UI. You cannot repair an allocator in the Cloud UI, so you should first <a class="xref" href="ece-move-nodes.html" title="Move nodes or instances from allocators">move all nodes to a new allocator</a>.  Vacate options for a selected allocator can help fine tune the removal of nodes. After the allocator is vacated, you should investigate the cause of the failure separately, which could be due to a host machine failure, and replace any lost capacity.</p>
<h3><a id="ece-issues-allocator-usage"></a>Allocators not being used<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/cloud/edit/2.5/docs/cloud-enterprise/ce-troubleshooting.asciidoc">edit</a></h3>
<p><span class="strong strong"><strong>Symptoms:</strong></span> You installed Elastic Cloud Enterprise on a new host and assigned it the allocator role from the command line with the <code class="literal">--roles "allocator"</code> parameter during installation, but new clusters are not being created on the allocator.</p>
<p><span class="strong strong"><strong>Resolution:</strong></span> The issue is caused by a token specified with the <code class="literal">--roles-token 'TOKEN'</code> parameter that does not have sufficient privileges to assign the role correctly. To resolve this issue, you might need to refresh the roles for the allocator.</p>
<div class="olist orderedlist">
<ol class="orderedlist">
<li class="listitem">
Follow the steps for <a class="xref" href="ece-change-roles.html" title="Assign roles to runners">assigning roles to runners</a>, but do not change any of the assigned roles. Click <span class="strong strong"><strong>Update roles</strong></span>.
</li>
<li class="listitem">
Verify that the allocator is now being used when creating new Elasticsearch clusters or moving nodes off other allocators.
</li>
</ol>
</div>
<p>To avoid this issue on future allocators you create, <a class="xref" href="ece-generate-roles-token.html" title="Generate roles tokens">generate a roles token</a> that has the right permissions for this to work, in this case the permission to assign the allocator role; the token generated during the installation on the first host will not suffice.</p>
<h3><a id="ece_cloud_ui_login_failures"></a>Cloud UI login failures<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/cloud/edit/2.5/docs/cloud-enterprise/ce-troubleshooting.asciidoc">edit</a></h3>
<p><span class="strong strong"><strong>Symptoms:</strong></span> When you attempt to log into the Cloud UI, the login process appears to hang and then fails.</p>
<p><span class="strong strong"><strong>Resolution:</strong></span> The <a class="xref" href="ece-glossary.html#admin-console">administration console</a> that supports the Cloud UI might be running out of Java heap space, causing login failures. This issue is expected to be fixed in a future release. As a workaround, you can manually increase the heap size.</p>
<p>In the current release, there is no direct way to change the Java heap size in the UI, so you need to increase the heap size as follows:</p>
<div class="olist orderedlist">
<ol class="orderedlist">
<li class="listitem">
For convenience, you can store the IP address of the host machine where the Cloud UI is running in the <code class="literal">ADMIN_IP</code> environment variable. Alternatively, replace <code class="literal">$ADMIN_IP</code> in the commands shown with the IP address.
</li>
<li class="listitem">
<p>Create a file with your current configuration, here <code class="literal">containerdata.json</code> (requires that you have <a href="https://stedolan.github.io/jq/download/" class="ulink" target="_top">jq</a> installed):</p>
<div class="pre_wrapper lang-sh">
<pre class="programlisting prettyprint lang-sh">curl -u admin http://$ADMIN_IP:12400/api/v0/regions/ece-region/container-sets/admin-consoles &gt; containerdata.json</pre>
</div>
<p>When prompted, enter the password you use to log into the Cloud UI.</p>
</li>
<li class="listitem">
<p>Filter the output file to a format that you can modify and push back into the system. If this step fails, do not push the file back into the system as this can prevent the admin console container from starting up.</p>
<div class="pre_wrapper lang-sh">
<pre class="programlisting prettyprint lang-sh">jq '.containers | ."admin-console" | .data' containerdata.json &gt; containerdata_new.json</pre>
</div>
</li>
<li class="listitem">
<p>Open the <code class="literal">containerdata_new.json</code> file in your favorite editor and locate this line:</p>
<div class="pre_wrapper lang-sh">
<pre class="programlisting prettyprint lang-sh">"ADMINCONSOLE_JAVA_OPTIONS=-Djute.maxbuffer=33554432 -Xmx256M -Xms256M",</pre>
</div>
</li>
<li class="listitem">
Increase the Java heap size by changing the values for <code class="literal">Xmx</code> and <code class="literal">Xms</code> to 1024 or 4096, depending on the size of your host machine. For example: Change the values to <code class="literal">-Xmx1024M -Xms1024M</code>.
</li>
<li class="listitem">
Save the configuration and exit the editor.
</li>
<li class="listitem">
<p>Apply the new configuration:</p>
<div class="pre_wrapper lang-sh">
<pre class="programlisting prettyprint lang-sh">curl -XPOST -u admin http://$ADMIN_IP:12400/api/v0/regions/ece-region/container-sets/admin-consoles/containers/admin-console -d @containerdata_new.json</pre>
</div>
</li>
<li class="listitem">
<p>On the host machine where the Cloud UI administration console is running, recreate the Cloud UI:</p>
<div class="pre_wrapper lang-sh">
<pre class="programlisting prettyprint lang-sh">docker stop frc-admin-consoles-admin-console &amp;&amp; docker rm -f frc-admin-consoles-admin-console</pre>
</div>
<p>If you prefer, you can use the HTTPS protocol on port 12443, but it currently supports only a self-signed certificate. Alternatively, you can perform the step from localhost.</p>
</li>
<li class="listitem">
Log into the Cloud UI administration console to confirm that the issue is resolved.
</li>
</ol>
</div>
<h3><a id="ece-aws-private-ip"></a>Cloud UI, Elasticsearch, and Kibana endpoint URLs inaccessible on AWS<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/cloud/edit/2.5/docs/cloud-enterprise/ce-troubleshooting.asciidoc">edit</a></h3>
<p><span class="strong strong"><strong>Symptoms:</strong></span> When you attempt to log into the Cloud UI or when you attempt to connect to an Elasticsearch or Kibana endpoint URL, the connection eventually times out with an error. The error indicates that the host cannot be reached.</p>
<p><span class="strong strong"><strong>Resolution:</strong></span> On AWS, the default URLs provided might point to a private host IP address, which is not accessible externally. To resolve this issue, use a URL for the Cloud UI that is externally accessible and <a class="xref" href="ece-administering-endpoints.html" title="Change endpoint URLs">update your cluster endpoint</a> to use a public IP address for Elasticsearch and Kibana.</p>
<p>This issue applies only to hosts running on AWS, where both public and private IP addresses are provided.</p>
<p>To check if you are affected and to resolve this issue:</p>
<div class="olist orderedlist">
<ol class="orderedlist">
<li class="listitem">
<p>Compare the URL you are trying to reach to the host IP address information in the AWS EC2 Dashboard.</p>
<p>For example, on a Elastic Cloud Enterprise installation, the following URLs might be provided by default:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
Cloud UI: <code class="literal">http://192.168.40.73:12400</code>
</li>
<li class="listitem">
Elasticsearch: <code class="literal">https://e025c4xxxxxxxxxxxxx.192.168.40.73.ip.es.io:9243/</code>
</li>
<li class="listitem">
Kibana: <code class="literal">https://1e2b57xxxxxxxxxxxxx.192.168.40.73.ip.es.io:9243/</code>
</li>
</ul>
</div>
<p>A quick check in the AWS EC2 Dashboard confirms that <code class="literal">192.168.40.73</code> is a private IP address, which is not accessible externally:</p>
<div class="imageblock">
<div class="content">
<img src="images/ece-aws-private-ip.png" alt="Private IP address information in AWS EC2 Dashboard">
</div>
</div>
</li>
<li class="listitem">
<p>To resolve this issue:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
For the Cloud UI, use the public host name or public IP. In this example, the Cloud UI is accessible externally at <code class="literal">ec2-54-162-168-86.compute-1.amazonaws.com:12400</code>.
</li>
<li class="listitem">
<p>For Elasticsearch and Kibana, <a class="xref" href="ece-administering-endpoints.html" title="Change endpoint URLs">update your cluster endpoint</a> to use the public IP address. In this example, you can use <code class="literal">54.162.168.86</code>:</p>
<div class="imageblock">
<div class="content">
<img src="images/ece-aws-public-ip.png" alt="Public IP address is used for cluster endpoints in the Cloud UI">
</div>
</div>
</li>
</ul>
</div>
</li>
</ol>
</div>
<h3><a id="ece-troubleshooting-upgrade"></a>Upgrade failures<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/cloud/edit/2.5/docs/cloud-enterprise/ce-troubleshooting.asciidoc">edit</a></h3>
<p><span class="strong strong"><strong>Symptoms:</strong></span> When upgrading Elastic Cloud Enterprise, the upgrade process indicates that a container upgrade has failed, followed by a rollback of all container upgrades and an error message that the upgrade process has failed. The information you see is similar to this output:</p>
<pre class="literallayout">...
- Runner [192.168.44.10]: container [proxies-proxy] status changed: [upgrade failed] at [2017-08-23T20:27:02.114Z]
- Runner [192.168.44.10]: container [proxies-proxy] status changed: [rollback started] at [2017-08-23T20:27:07.134Z]
...
- The upgrade of the {n} installation has failed, but we successfully rolled back changes.
- Check that all services are running and that they are at the same version level with the docker ps command. Try the upgrade again.
- The log files on each host might provide additional information about the cause of the failures. (path: HOST_STORAGE_PATH/logs/upgrader-logs).
- You can find a backup of ZooKeeper's transaction log that was created before the upgrade in [/mnt/data/elastic/192.168.44.10/services/zookeeper/data/backup/20170823-202249/version-2].
- Exiting upgrader
- Removing upgrade container</pre>

<p><span class="strong strong"><strong>Resolution:</strong></span> The Elastic Cloud Enterprise upgrade process is designed to be safe. If there is an issue with any part of the upgrade, the entire process is rolled back. In most cases, the rollback is automatic and the upgrade process can be reattempted after you fix the issue that caused the rollback.</p>
<p>The upgrade process can fail for several reasons, including:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
If a host fails during the upgrade process, causing the <code class="literal">frc-upgraders-monitor</code> container to time out while it monitors the upgrade process.
</li>
<li class="listitem">
If there is an issue with the ZooKeeper ensemble establishing a quorum after the upgrade or if the <code class="literal">frc-upgraders-upgrader</code> containers performing the upgrade on each host continue to wait for a ZooKeeper connection indefinitely to report their upgrade status.
</li>
<li class="listitem">
If an upgraded container does not keep running and the upgrade process determines that it is not viable.
</li>
</ul>
</div>
<p>To determine the root cause of an upgrade failure, the following logs are available where <code class="literal">HOST_STORAGE_PATH</code> and <code class="literal">RUNNER_ID</code> are specific to your installation:</p>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">HOST_STORAGE_PATH/logs/upgrader-logs/monitor.log</code>
</span>
</dt>
<dd>
Available on the host where you initiated the upgrade process. This log file can help you pinpoint the host where an upgrade issue occurred or where in the overall upgrade process a failure happened.
</dd>
<dt>
<span class="term">
<code class="literal">HOST_STORAGE_PATH/logs/upgrader-logs/upgrader.log</code>
</span>
</dt>
<dd>
Available on every host that attempted the upgrade. This log file can tell you about the specific issues that caused the upgrade to fail on a host.
</dd>
</dl>
</div>
<p>In rare cases, a manual rollback of the upgrade might be required. To have someone walk you through the process, see <a class="xref" href="ece-getting-help.html" title="Getting help">Getting help</a>.</p>
</div>
<div class="navfooter">
<span class="prev">
<a href="ece-troubleshooting.html">« Troubleshooting</a>
</span>
<span class="next">
<a href="ece-troubleshooting-emergency.html">Using the emergency roles token »</a>
</span>
</div>
</div>
</body>
</html>
