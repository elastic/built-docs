<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Storage recommendations | Elastic Cloud on Kubernetes [2.14] | Elastic</title>
<meta class="elastic" name="content" content="Storage recommendations | Elastic Cloud on Kubernetes [2.14]">

<link rel="home" href="index.html" title="Elastic Cloud on Kubernetes [2.14]"/>
<link rel="up" href="k8s-elasticsearch-specification.html" title="Run Elasticsearch on ECK"/>
<link rel="prev" href="k8s-volume-claim-templates.html" title="Volume claim templates"/>
<link rel="next" href="k8s-transport-settings.html" title="Transport settings"/>
<meta class="elastic" name="product_version" content="2.14"/>
<meta class="elastic" name="product_name" content="ECK"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/Kubernetes/Reference/2.14"/>
<meta name="DC.subject" content="ECK"/>
<meta name="DC.identifier" content="2.14"/>
</head>
<body>
<div class="page_header">
This documentation contains work-in-progress information for future Elastic Stack and Cloud releases. Use the version selector to view supported release docs. It also contains some Elastic Cloud serverless information. Check out our <a href="https://www.elastic.co/docs/current/serverless">serverless docs</a> for more details.
</div>
<div class="navheader">
<span class="prev">
<a href="k8s-volume-claim-templates.html">« Volume claim templates</a>
</span>
<span class="next">
<a href="k8s-transport-settings.html">Transport settings »</a>
</span>
</div>
<div class="book" lang="en">
<div class="titlepage">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Elastic Cloud on Kubernetes [2.14]</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="k8s-orchestrating-elastic-stack-applications.html">Orchestrating Elastic Stack applications</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="k8s-elasticsearch-specification.html">Run Elasticsearch on ECK</a></span>
</div>
<div>
<div><h1 class="title"><a id="id-1"></a>Storage recommendations</h1><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/cloud-on-k8s/edit/2.14/docs/orchestrating-elastic-stack-applications/elasticsearch/storage-recommendations.asciidoc">edit</a></div>
</div>
<!--EXTRA-->
</div>
<div id="content">
<div class="section">
<div class="titlepage"><div><div>
<h2 class="title"><a id="k8s-storage-recommendations"></a>Storage recommendations<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/cloud-on-k8s/edit/2.14/docs/orchestrating-elastic-stack-applications/elasticsearch/storage-recommendations.asciidoc">edit</a></h2>
</div></div></div>
<p>ECK does not come with its own storage mechanism for Elasticsearch data. It is compatible with any Kubernetes storage option. It is recommended to use PersistentVolumes, by configuring the <a class="xref" href="k8s-volume-claim-templates.html" title="Volume claim templates">VolumeClaimTemplates</a> section of the Elasticsearch resource.</p>
<p>Multiple PersistentVolume storage classes are available, depending on your Kubernetes setup. Their specifications impact Elasticsearch performance and operations. Evaluate the trade-offs among the various options and choose the solution that best fits your needs.</p>
<h4><a id="k8s_network_attached_or_local_persistentvolumes"></a>Network-attached or Local PersistentVolumes<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/cloud-on-k8s/edit/2.14/docs/orchestrating-elastic-stack-applications/elasticsearch/storage-recommendations.asciidoc">edit</a></h4>
<p>PersistentVolumes can be of two types: <span class="strong strong"><strong>Network-attached</strong></span> or <span class="strong strong"><strong>Local</strong></span>. ECK handles them in the same way, but they have different performance, price and operational characteristics.</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<span class="strong strong"><strong>Network-attached PersistentVolumes</strong></span> can generally be attached to a Pod regardless of the host they are scheduled on.
They provide a major operational benefit: if the host goes down, or needs to be replaced, the Pod can simply be deleted. Kubernetes reschedules it automatically on a different host, generally in the same region, and reattaches the same volume. This can take only a few seconds, and does not require any human intervention.
</li>
<li class="listitem">
<span class="strong strong"><strong>Local PersistentVolumes</strong></span> are bound to a particular host, and map a directory on the filesystem. They provide a major operational overhead: once bound to a Local PersistentVolume, a Pod can only be scheduled on the same host. If that host goes down, or needs to be replaced, the Pod cannot be scheduled on a different host. It remains in a <code class="literal">Pending</code> state until the host is available, or until the PersistentVolumeClaim is manually deleted. For that reason, Local PersistentVolumes bring more operational overhead.
</li>
</ul>
</div>
<p>In both cases, the performance depends on the underlying hardware and implementation. In general, local SSDs give the best performance. The fastest network-attached volumes from major Cloud providers can also provide acceptable performance, depending on your Elasticsearch use cases. To better evaluate your performance requirements, you can <a href="https://github.com/elastic/rally" class="ulink" target="_top">benchmark</a> your storage options against the expected Elasticsearch usage.</p>
<h4><a id="k8s_local_persistentvolumes_operations"></a>Local PersistentVolumes operations<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/cloud-on-k8s/edit/2.14/docs/orchestrating-elastic-stack-applications/elasticsearch/storage-recommendations.asciidoc">edit</a></h4>
<h5><a id="k8s_host_maintenance"></a>Host maintenance<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/cloud-on-k8s/edit/2.14/docs/orchestrating-elastic-stack-applications/elasticsearch/storage-recommendations.asciidoc">edit</a></h5>
<p>To take a host out of the Kubernetes cluster temporarily, it is common to cordon, then drain it. Kubernetes deletes Elasticsearch Pods scheduled on that host automatically, as long as the <a class="xref" href="k8s-pod-disruption-budget.html" title="Pod disruption budget">PodDisruptionBudget</a> allows it. By default, ECK manages a PodDisruptionBudget that allows one Pod to be taken down, as long as the cluster has a green health. Once deleted, that Pod cannot be scheduled again on the cordoned host: the Pod stays <code class="literal">Pending</code>, waiting for that host to come back online. The next Pod can be automatically deleted when the Elasticsearch cluster health becomes green again.</p>
<p>Some hosted Kubernetes offerings only respect the PodDisruptionBudget for a certain amount of time, before killing all Pods on the node. For example, <a href="https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-upgrades" class="ulink" target="_top">GKE automated version upgrade</a> rotates all nodes without preserving local volumes, and respects the PodDisruptionBudget for a maximum of one hour. In such cases it is preferable to <a href="https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-upgrades#upgrading_manually" class="ulink" target="_top">manually handle the cluster version upgrade</a>.</p>
<h5><a id="k8s_host_removal"></a>Host removal<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/cloud-on-k8s/edit/2.14/docs/orchestrating-elastic-stack-applications/elasticsearch/storage-recommendations.asciidoc">edit</a></h5>
<p>If a host has a failure, or is permanently removed, its local data is likely lost. The corresponding Pod stays <code class="literal">Pending</code> because it can no longer attach the PersistentVolume. To schedule the Pod on a different host with a new empty volume, you have to manually remove both the PersistenteVolumeClaim and the Pod. A new Pod is automatically created with a new PersistentVolumeClaim, which is then matched with a PersistentVolume. Then, Elasticsearch shard replication makes sure that data is recovered on the new instance.</p>
<h4><a id="k8s_local_persistentvolume_provisioners"></a>Local PersistentVolume provisioners<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/cloud-on-k8s/edit/2.14/docs/orchestrating-elastic-stack-applications/elasticsearch/storage-recommendations.asciidoc">edit</a></h4>
<p>You can provision Local PersistentVolumes in one of the following ways:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<span class="strong strong"><strong>Manual provisioning</strong></span>: Manually <a href="https://kubernetes.io/blog/2018/04/13/local-persistent-volumes-beta/#creating-a-local-persistent-volume" class="ulink" target="_top">create PersistentVolume resources</a>, matching a local path to a specific host. Data must be manually removed once the PersistentVolumes are released.
</li>
<li class="listitem">
<span class="strong strong"><strong>Static provisioning</strong></span>: Run a program that automatically discovers the existing partitions on each host, and creates the corresponding PersistentVolume resources. The <a href="https://github.com/kubernetes-sigs/sig-storage-local-static-provisioner" class="ulink" target="_top">Local PersistentVolume Static Provisioner</a> is a great way to get started.
</li>
<li class="listitem">
<span class="strong strong"><strong>Dynamic provisioning</strong></span>: <a href="https://openebs.io" class="ulink" target="_top">OpenEBS</a> and <a href="https://github.com/topolvm/topolvm" class="ulink" target="_top">TopoLVM</a> are examples of components you can install into your Kubernetes cluster to manage the provisioning of persistent volumes from local disks attached to the nodes. These tools leverage technologies like LVM and ZFS to dynamically allocate persistent volumes from storage pools made out of local disks. Depending on the technology used, bonus features like dynamic volume resizing, thin-provisioning and, snapshots are also available with some of these offerings. Installation of these components might require initial setup work on your Kubernetes cluster like installing filesystem utilities on all nodes, creating RAID configurations for the disks or even installing API extensions like custom schedulers. Some managed Kubernetes offerings might have restrictions that make it difficult to perform some of those setup steps. Check the documentation of the Kubernetes provider and the storage provisioner to ensure that they are compatible with each other.
</li>
</ul>
</div>
<h4><a id="k8s_storage_class_settings"></a>Storage class settings<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/cloud-on-k8s/edit/2.14/docs/orchestrating-elastic-stack-applications/elasticsearch/storage-recommendations.asciidoc">edit</a></h4>
<h5><a id="k8s_volumebindingmode_waitforfirstconsumer"></a>volumeBindingMode: WaitForFirstConsumer<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/cloud-on-k8s/edit/2.14/docs/orchestrating-elastic-stack-applications/elasticsearch/storage-recommendations.asciidoc">edit</a></h5>
<p>In the PersistentVolume StorageClass, it is important to set <a href="https://kubernetes.io/docs/concepts/storage/storage-classes/#volume-binding-mode" class="ulink" target="_top"><code class="literal">volumeBindingMode: WaitForFirstConsumer</code></a>, otherwise a Pod might be scheduled on a host that cannot access the existing PersistentVolume. This setting isn&#8217;t always applied by default on Cloud providers StorageClasses, but in most cases it is possible to create (or patch) StorageClasses to add the setting.</p>
<h5><a id="k8s_reclaim_policy"></a>Reclaim policy<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/cloud-on-k8s/edit/2.14/docs/orchestrating-elastic-stack-applications/elasticsearch/storage-recommendations.asciidoc">edit</a></h5>
<p>The reclaim policy of a StorageClass specifies whether a PersistentVolume should be automatically deleted once its corresponding PersistentVolumeClaim is deleted. It can be set to <code class="literal">Delete</code> or <code class="literal">Retain</code>.</p>
<p>ECK automatically deletes PersistentVolumeClaims when they are no longer needed, following a cluster downscale or deletion. However, ECK does not delete PersistentVolumes. The system cannot reuse a PersistentVolume with existing data from a different cluster. In this case Elasticsearch does not start, as it detects data that belongs to a different cluster. For this reason, it is recommended to use the <code class="literal">Delete</code> reclaim policy.</p>
</div>
</div>
</div><div class="navfooter">
<span class="prev">
<a href="k8s-volume-claim-templates.html">« Volume claim templates</a>
</span>
<span class="next">
<a href="k8s-transport-settings.html">Transport settings »</a>
</span>
</div>
</body>
</html>
