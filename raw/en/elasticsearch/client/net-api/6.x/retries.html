<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Retries | Elasticsearch.Net and NEST: the .NET clients [6.x] | Elastic</title>
<link rel="home" href="index.html" title="Elasticsearch.Net and NEST: the .NET clients [6.x]"/>
<link rel="up" href="retries-and-failover.html" title="Retries and failover"/>
<link rel="prev" href="fail-over.html" title="Fail over"/>
<link rel="next" href="request-overrides.html" title="Request overrides"/>
<meta name="DC.type" content="Learn/Docs/Clients/.Net/6.x"/>
<meta name="DC.subject" content="Clients"/>
<meta name="DC.identifier" content="6.x"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body><div class="page_header">
<p>
  <strong>NOTE</strong>: You are looking at documentation for an older release. 
  For the latest information, see the 
  <a href="../current/index.html">current release documentation</a>. 
</p>
</div>
<div id="content">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="index.html">Elasticsearch.Net and NEST:  the .NET clients [6.x]</a></span>
»
<span class="breadcrumb-link"><a href="api-conventions.html">API Conventions</a></span>
»
<span class="breadcrumb-link"><a href="retries-and-failover.html">Retries and failover</a></span>
»
<span class="breadcrumb-node">Retries</span>
</div>
<div class="navheader">
<span class="prev">
<a href="fail-over.html">« Fail over</a>
</span>
<span class="next">
<a href="request-overrides.html">Request overrides »</a>
</span>
</div>
<div class="section">
<div class="titlepage"><div><div>
<h2 class="title"><a id="retries"></a>Retries<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-net/edit/6.x/docs/client-concepts/connection-pooling/max-retries/respects-max-retry.asciidoc">edit</a></h2>
</div></div></div>
<p>By default, NEST will retry a request as many times as there are nodes in the cluster, that the client knows about.</p>
<p>Retries still respects the request timeout however, meaning if you have a 100 node cluster
and a request timeout of 20 seconds, the client will retry as many times as it can before
giving up at the request timeout of 20 seconds.</p>
<p>Retry behaviour can be demonstrated using NEST&#8217;s Virtual cluster test framework. In the following
example, a ten node cluster is defined that always fails on all client calls, except on port 9209</p>
<div class="pre_wrapper lang-csharp">
<pre class="programlisting prettyprint lang-csharp">var audit = new Auditor(() =&gt; Framework.Cluster
    .Nodes(10)
    .ClientCalls(r =&gt; r.FailAlways())
    .ClientCalls(r =&gt; r.OnPort(9209).SucceedAlways())
    .StaticConnectionPool()
    .Settings(s =&gt; s.DisablePing())
);</pre>
</div>
<p>The trace of a client call shows that a bad response is received from nodes 9200 to 9208,
finally returning a healthy response from the node on port 9209</p>
<div class="pre_wrapper lang-csharp">
<pre class="programlisting prettyprint lang-csharp">audit = await audit.TraceCall(
    new ClientCall {
        { BadResponse, 9200 },
        { BadResponse, 9201 },
        { BadResponse, 9202 },
        { BadResponse, 9203 },
        { BadResponse, 9204 },
        { BadResponse, 9205 },
        { BadResponse, 9206 },
        { BadResponse, 9207 },
        { BadResponse, 9208 },
        { HealthyResponse, 9209 }
    }
);</pre>
</div>
<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="_maximum_number_of_retries"></a>Maximum number of retries<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-net/edit/6.x/docs/client-concepts/connection-pooling/max-retries/respects-max-retry.asciidoc">edit</a></h3>
</div></div></div>
<p>When you have a 100 node cluster for example, you might want to ensure that retries occur only
a <em>fixed</em> number of times. This can be done using <code class="literal">MaximumRetries(n)</code> on <code class="literal">ConnectionSettings</code></p>
<div class="important admon">
<div class="icon"></div>
<div class="admon_content">
<p>the actual number of requests is <code class="literal">initial attempt + set number of retries</code></p>
</div>
</div>
<div class="pre_wrapper lang-csharp">
<pre class="programlisting prettyprint lang-csharp">var audit = new Auditor(() =&gt; Framework.Cluster
    .Nodes(10)
    .ClientCalls(r =&gt; r.FailAlways())
    .ClientCalls(r =&gt; r.OnPort(9209).SucceedAlways())
    .StaticConnectionPool()
    .Settings(s =&gt; s.DisablePing().MaximumRetries(3)) <a id="CO25-1"></a><i class="conum" data-value="1"></i>
);

audit = await audit.TraceCall(
    new ClientCall {
        { BadResponse, 9200 },
        { BadResponse, 9201 },
        { BadResponse, 9202 },
        { BadResponse, 9203 },
        { MaxRetriesReached } <a id="CO25-2"></a><i class="conum" data-value="2"></i>
    }
);</pre>
</div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO25-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>Set the maximum number of retries to 3</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO25-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p>The client call trace returns an <code class="literal">MaxRetriesReached</code> audit after the initial attempt and the number of retries allowed</p>
</td>
</tr>
</table>
</div>
<p>In our previous example we simulated very fast failures, but in the real world, a call might take upwards of a second.</p>
<p>In this next example, we simulate a particularly heavy search that takes 10 seconds to fail, and set a request timeout of 20 seconds.
We see that the request is tried twice and gives up before a third call is attempted, since the call takes 10 seconds and thus can be
tried twice (initial call and one retry) <em>before</em> the request timeout.</p>
<div class="pre_wrapper lang-csharp">
<pre class="programlisting prettyprint lang-csharp">var audit = new Auditor(() =&gt; Framework.Cluster
    .Nodes(10)
    .ClientCalls(r =&gt; r.FailAlways().Takes(TimeSpan.FromSeconds(10)))
    .ClientCalls(r =&gt; r.OnPort(9209).SucceedAlways())
    .StaticConnectionPool()
    .Settings(s =&gt; s.DisablePing().RequestTimeout(TimeSpan.FromSeconds(20)))
);

audit = await audit.TraceCall(
    new ClientCall {
        { BadResponse, 9200 },
        { BadResponse, 9201 },
        { MaxTimeoutReached }
    }
);</pre>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="_maximum_retry_timeout"></a>Maximum retry timeout<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-net/edit/6.x/docs/client-concepts/connection-pooling/max-retries/respects-max-retry.asciidoc">edit</a></h3>
</div></div></div>
<p>If you set a smaller request timeout you might not want it to also affect the retry timeout.
In cases like this, you can configure the <code class="literal">MaxRetryTimeout</code> separately.
Here we simulate calls taking 3 seconds, a request timeout of 2 seconds and a max retry timeout of 10 seconds.
We should see 5 attempts to perform this query, testing that our request timeout cuts the query off short and that
our max retry timeout of 10 seconds wins over the configured request timeout</p>
<div class="pre_wrapper lang-csharp">
<pre class="programlisting prettyprint lang-csharp">var audit = new Auditor(() =&gt; Framework.Cluster
    .Nodes(10)
    .ClientCalls(r =&gt; r.FailAlways().Takes(TimeSpan.FromSeconds(3)))
    .ClientCalls(r =&gt; r.OnPort(9209).FailAlways())
    .StaticConnectionPool()
    .Settings(s =&gt; s.DisablePing().RequestTimeout(TimeSpan.FromSeconds(2)).MaxRetryTimeout(TimeSpan.FromSeconds(10)))
);

audit = await audit.TraceCall(
    new ClientCall {
        { BadResponse, 9200 },
        { BadResponse, 9201 },
        { BadResponse, 9202 },
        { BadResponse, 9203 },
        { BadResponse, 9204 },
        { MaxTimeoutReached }
    }
);</pre>
</div>
<p>If your retry policy expands beyond the number of available nodes, the client <span class="strong strong"><strong>won&#8217;t</strong></span> retry the same node twice</p>
<div class="pre_wrapper lang-csharp">
<pre class="programlisting prettyprint lang-csharp">var audit = new Auditor(() =&gt; Framework.Cluster
    .Nodes(2)
    .ClientCalls(r =&gt; r.FailAlways().Takes(TimeSpan.FromSeconds(3)))
    .ClientCalls(r =&gt; r.OnPort(9209).SucceedAlways())
    .StaticConnectionPool()
    .Settings(s =&gt; s.DisablePing().RequestTimeout(TimeSpan.FromSeconds(2)).MaxRetryTimeout(TimeSpan.FromSeconds(10)))
);

audit = await audit.TraceCall(
    new ClientCall {
        { BadResponse, 9200 },
        { BadResponse, 9201 },
        { MaxRetriesReached },
        { FailedOverAllNodes }
    }
);</pre>
</div>
<p>This makes setting any retry setting on a single node connection pool a no-op by design!
Connection pooling and failover is all about trying to fail sanely whilst still utilizing the available resources and
not giving up on the fail fast principle; <span class="strong strong"><strong>It is NOT a mechanism for forcing requests to succeed.</strong></span></p>
<div class="pre_wrapper lang-csharp">
<pre class="programlisting prettyprint lang-csharp">var audit = new Auditor(() =&gt; Framework.Cluster
    .Nodes(10)
    .ClientCalls(r =&gt; r.FailAlways().Takes(TimeSpan.FromSeconds(3)))
    .ClientCalls(r =&gt; r.OnPort(9209).SucceedAlways())
    .SingleNodeConnection()
    .Settings(s =&gt; s.DisablePing().MaximumRetries(10))
);

audit = await audit.TraceCall(
    new ClientCall {
        { BadResponse, 9200 }
    }
);</pre>
</div>
</div>

</div>
<div class="navfooter">
<span class="prev">
<a href="fail-over.html">« Fail over</a>
</span>
<span class="next">
<a href="request-overrides.html">Request overrides »</a>
</span>
</div>
</div>
</body>
</html>
