<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Future Mode | Elasticsearch-PHP [7.x] | Elastic</title>
<link rel="home" href="index.html" title="Elasticsearch-PHP [7.x]"/>
<link rel="up" href="index.html" title="Elasticsearch-PHP [7.x]"/>
<link rel="prev" href="per_request_configuration.html" title="Per-request configuration"/>
<link rel="next" href="php_json_objects.html" title="Dealing with JSON arrays and objects in PHP"/>
<meta name="DC.type" content="Learn/Docs/Clients/PHP/7.x"/>
<meta name="DC.subject" content="Clients"/>
<meta name="DC.identifier" content="7.x"/>
</head>
<body>
<div id="content">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="index.html">Elasticsearch-PHP [7.x]</a></span>
»
<span class="breadcrumb-node">Future Mode</span>
</div>
<div class="navheader">
<span class="prev">
<a href="per_request_configuration.html">« Per-request configuration</a>
</span>
<span class="next">
<a href="php_json_objects.html">Dealing with JSON arrays and objects in PHP »</a>
</span>
</div>
<div class="chapter">
<div class="titlepage"><div><div>
<h1 class="title"><a id="future_mode"></a>Future Mode<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch-php/edit/7.x/docs/futures.asciidoc">edit</a></h1>
</div></div></div>
<p>The client offers a mode called "future" or "async" mode. This allows batch
processing of requests (sent in parallel to the cluster), which can have a
dramatic impact on performance and throughput.</p>
<p>PHP is fundamentally single-threaded, however, libcurl provides a functionality
called the "multi interface". This functionality allows languages like PHP to
gain concurrency by providing a batch of requests to process. The batch is
executed in parallel by the underlying multithreaded libcurl library, and the
batch of responses is then returned to PHP.</p>
<p>In a single-threaded environment, the time to execute <code class="literal">n</code> requests is the sum of
those <code class="literal">n</code> request&#8217;s latencies. With the multi interface, the time to execute <code class="literal">n</code>
requests is the latency of the slowest request (assuming enough handles are
available to execute all requests in parallel).</p>
<p>Furthermore, the multi-interface allows requests to different hosts
simultaneously, which means the Elasticsearch-PHP client can more effectively
utilize your full cluster.</p>
<h3><a id="_using_future_mode"></a>Using Future Mode<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch-php/edit/7.x/docs/futures.asciidoc">edit</a></h3>
<p>Utilizing this feature is straightforward, but it does introduce more
responsibility into your code. To enable future mode, set the <code class="literal">future</code> flag in
the client options to <code class="literal">'lazy'</code>:</p>
<div class="pre_wrapper lang-php">
<pre class="programlisting prettyprint lang-php">$client = ClientBuilder::create()-&gt;build();

$params = [
    'index'  =&gt; 'test',
    'id'     =&gt; 1,
    'client' =&gt; [
        'future' =&gt; 'lazy'
    ]
];

$future = $client-&gt;get($params);</pre>
</div>
<p>This returns a <em>future</em>, rather than the actual response. A future represents a
<em>future computation</em> and acts like a placeholder. You can pass a future around
your code like a regular object. When you need the result values, you can
<em>resolve</em> the future. If the future has already resolved (due to some other
activity), the values are immediately available. If the future has not resolved
yet, the resolution blocks until those values become available (for example,
after the API call completes).</p>
<p>In practice, this means you can queue up a batch of requests by using
<code class="literal">future: lazy</code> and they pend until you resolve the futures, at which time all
requests will be sent in parallel to the cluster and return asynchronously to
curl.</p>
<p>This sounds tricky, but it is actually simple thanks to RingPHP&#8217;s <code class="literal">FutureArray</code>
interface, which makes the future act like a simple associative array. For
example:</p>
<div class="pre_wrapper lang-php">
<pre class="programlisting prettyprint lang-php">$client = ClientBuilder::create()-&gt;build();

$params = [
    'index'  =&gt; 'test',
    'id'     =&gt; 1,
    'client' =&gt; [
        'future' =&gt; 'lazy'
    ]
];

$future = $client-&gt;get($params);

$doc = $future['_source'];    // This call blocks and forces the future to resolve</pre>
</div>
<p>Interacting with the future as an associative array, just like a normal
response, causes the future to resolve that particular value (which in turn
resolves all pending requests and values). This allows patterns such as:</p>
<div class="pre_wrapper lang-php">
<pre class="programlisting prettyprint lang-php">$client = ClientBuilder::create()-&gt;build();
$futures = [];

for ($i = 0; $i &lt; 1000; $i++) {
    $params = [
        'index'  =&gt; 'test',
        'id'     =&gt; $i,
        'client' =&gt; [
            'future' =&gt; 'lazy'
        ]
    ];

    $futures[] = $client-&gt;get($params);     //queue up the request
}


foreach ($futures as $future) {
    // access future's values, causing resolution if necessary
    echo $future['_source'];
}</pre>
</div>
<p>The queued requests will execute in parallel and populate their futures after
execution. Batch size defaults to 100 requests/batch.</p>
<p>If you wish to force future resolution, but don&#8217;t need the values immediately,
you can call <code class="literal">wait()</code> on the future to force resolution, too:</p>
<div class="pre_wrapper lang-php">
<pre class="programlisting prettyprint lang-php">$client = ClientBuilder::create()-&gt;build();
$futures = [];

for ($i = 0; $i &lt; 1000; $i++) {
    $params = [
        'index'  =&gt; 'test',
        'id'     =&gt; $i,
        'client' =&gt; [
            'future' =&gt; 'lazy'
        ]
    ];

    $futures[] = $client-&gt;get($params);     //queue up the request
}

//wait() forces future resolution and will execute the underlying curl batch
$futures[999]-&gt;wait();</pre>
</div>
<h3><a id="_changing_batch_size"></a>Changing batch size<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch-php/edit/7.x/docs/futures.asciidoc">edit</a></h3>
<p>The default batch size is 100, meaning 100 requests queue up before the client
forces futures to begin resolving (for example, initiate a <code class="literal">curl_multi</code> call).
The batch size can be changed depending on your preferences. The batch size can
be set via the <code class="literal">max_handles</code> setting when configuring the handler:</p>
<div class="pre_wrapper lang-php">
<pre class="programlisting prettyprint lang-php">$handlerParams = [
    'max_handles' =&gt; 500
];

$defaultHandler = ClientBuilder::defaultHandler($handlerParams);

$client = ClientBuilder::create()
            -&gt;setHandler($defaultHandler)
            -&gt;build();</pre>
</div>
<p>This changes the behavior to wait on 500 queued requests before sending the
batch. Note, however, that forcing a future to resolve causes the underlying
curl batch to execute, regardless of if the batch is "full" or not. In this
example, only 499 requests are added to the queue, but the final future
resolution forces the batch to flush anyway:</p>
<div class="pre_wrapper lang-php">
<pre class="programlisting prettyprint lang-php">$handlerParams = [
    'max_handles' =&gt; 500
];

$defaultHandler = ClientBuilder::defaultHandler($handlerParams);

$client = ClientBuilder::create()
            -&gt;setHandler($defaultHandler)
            -&gt;build();

$futures = [];

for ($i = 0; $i &lt; 499; $i++) {
    $params = [
        'index'  =&gt; 'test',
        'id'     =&gt; $i,
        'client' =&gt; [
            'future' =&gt; 'lazy'
        ]
    ];

    $futures[] = $client-&gt;get($params);     //queue up the request
}

// resolve the future, and therefore the underlying batch
$body = $future[499]['body'];</pre>
</div>
<h3><a id="_heterogeneous_batches_are_ok"></a>Heterogeneous batches are OK<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch-php/edit/7.x/docs/futures.asciidoc">edit</a></h3>
<p>It is possible to queue up heterogeneous batches of requests. For example, you
can queue up several GETs, indexing requests, and a search:</p>
<div class="pre_wrapper lang-php">
<pre class="programlisting prettyprint lang-php">$client = ClientBuilder::create()-&gt;build();
$futures = [];

$params = [
    'index'  =&gt; 'test',
    'id'     =&gt; 1,
    'client' =&gt; [
        'future' =&gt; 'lazy'
    ]
];

$futures['getRequest'] = $client-&gt;get($params);     // First request

$params = [
    'index' =&gt; 'test',
    'id'    =&gt; 2,
    'body'  =&gt; [
        'field' =&gt; 'value'
    ],
    'client' =&gt; [
        'future' =&gt; 'lazy'
    ]
];

$futures['indexRequest'] = $client-&gt;index($params);       // Second request

$params = [
    'index' =&gt; 'test',
    'body'  =&gt; [
        'query' =&gt; [
            'match' =&gt; [
                'field' =&gt; 'value'
            ]
        ]
    ],
    'client' =&gt; [
        'future' =&gt; 'lazy'
    ]
];

$futures['searchRequest'] = $client-&gt;search($params);      // Third request

// Resolve futures...blocks until network call completes
$searchResults = $futures['searchRequest']['hits'];

// Should return immediately, since the previous future resolved the entire batch
$doc = $futures['getRequest']['_source'];</pre>
</div>
<h3><a id="_caveats_to_future_mode"></a>Caveats to Future mode<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch-php/edit/7.x/docs/futures.asciidoc">edit</a></h3>
<p>There are a few caveats to using future mode. The biggest is also the most
obvious: you need to deal with resolving the future yourself. This is usually
trivial, but can sometimes introduce unexpected complications.</p>
<p>For example, if you resolve manually using <code class="literal">wait()</code>, you may need to call
<code class="literal">wait()</code> several times if there were retries. This is because each retry
introduces another layer of wrapped futures, and each needs to be resolved to
get the final result.</p>
<p>However, this is not needed if you access values via the ArrayInterface (for
example, <code class="literal">$response['hits']['hits']</code>) since FutureArrayInterface automatically
and fully resolves the future to provide values.</p>
<p>Another caveat is that certain APIs will lose their "helper" functionality. For
example, "exists" APIs (<code class="literal">$client-&gt;exists()</code>, <code class="literal">$client-&gt;indices()-&gt;exists</code>,
<code class="literal">$client-&gt;indices-&gt;templateExists()</code>, and so on) typically return a true or
false under normal operation.</p>
<p>When operated in future mode, the unwrapping of the future is left to your
application, which means the client can no longer inspect the response and
return a simple true/false. Instead, you&#8217;ll see the raw response from Elasticsearch and
will have to take action appropriately.</p>
<p>This also applies to <code class="literal">ping()</code>.</p>
</div>
<div class="navfooter">
<span class="prev">
<a href="per_request_configuration.html">« Per-request configuration</a>
</span>
<span class="next">
<a href="php_json_objects.html">Dealing with JSON arrays and objects in PHP »</a>
</span>
</div>
</div>
</body>
</html>
