<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Configuration | Elasticsearch Python Client [8.14] | Elastic</title>
<meta class="elastic" name="content" content="Configuration | Elasticsearch Python Client [8.14]">

<link rel="home" href="index.html" title="Elasticsearch Python Client [8.14]"/>
<link rel="up" href="index.html" title="Elasticsearch Python Client [8.14]"/>
<link rel="prev" href="connecting.html" title="Connecting"/>
<link rel="next" href="migration.html" title="Migrating to 8.0"/>
<meta class="elastic" name="product_version" content="8.14"/>
<meta class="elastic" name="product_name" content="Clients"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/Clients/Python/8.14"/>
<meta name="DC.subject" content="Clients"/>
<meta name="DC.identifier" content="8.14"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body>
<div class="page_header">
<strong>IMPORTANT</strong>: No additional bug fixes or documentation updates
will be released for this version. For the latest information, see the
<a href="../current/index.html">current release documentation</a>.
</div>
<div class="navheader">
<span class="prev">
<a href="connecting.html">« Connecting</a>
</span>
<span class="next">
<a href="migration.html">Migrating to 8.0 »</a>
</span>
</div>
<div class="book" lang="en">
<div class="titlepage">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Elasticsearch Python Client [8.14]</a></span>
</div>
<div>
<div><h1 class="title"><a id="id-1"></a>Configuration</h1><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-py/edit/8.14/docs/guide/configuration.asciidoc">edit</a></div>
</div>
<!--EXTRA-->
</div>
<div id="content">
<div class="chapter">
<div class="titlepage"><div><div>
<h2 class="title"><a id="config"></a>Configuration<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-py/edit/8.14/docs/guide/configuration.asciidoc">edit</a></h2>
</div></div></div>
<p>This page contains information about the most important configuration options of
the Python Elasticsearch client.</p>
<h3><a id="tls-and-ssl"></a>TLS/SSL<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-py/edit/8.14/docs/guide/configuration.asciidoc">edit</a></h3>
<p>The options in this section can only be used when the node is configured for HTTPS. An error will be raised if using these options with an HTTP node.</p>
<h4><a id="_verifying_server_certificates"></a>Verifying server certificates<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-py/edit/8.14/docs/guide/configuration.asciidoc">edit</a></h4>
<p>The typical route to verify a cluster certificate is via a "CA bundle" which can be specified via the <code class="literal">ca_certs</code> parameter. If no options are given and the <a href="https://github.com/certifi/python-certifi" class="ulink" target="_top">certifi package</a> is installed then certifi&#8217;s CA bundle is used by default.</p>
<p>If you have your own CA bundle to use you can configure via the <code class="literal">ca_certs</code> parameter:</p>
<div class="pre_wrapper lang-python">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-python">client = Elasticsearch(
    "https://...",
    ca_certs="/path/to/certs.pem"
)</pre>
</div>
<p>If using a generated certificate or certificate with a known fingerprint you can use the <code class="literal">ssl_assert_fingerprint</code> to specify the fingerprint which tries to match the server&#8217;s leaf certificate during the TLS handshake. If there is any matching certificate the connection is verified, otherwise a <code class="literal">TlsError</code> is raised.</p>
<p>In Python 3.9 and earlier only the leaf certificate will be verified but in Python 3.10+ private APIs are used to verify any certificate in the certificate chain. This helps when using certificates that are generated on a multi-node cluster.</p>
<div class="pre_wrapper lang-python">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-python">client = Elasticsearch(
    "https://...",
    ssl_assert_fingerprint=(
        "315f5bdb76d078c43b8ac0064e4a0164612b1fce77c869345bfc94c75894edd3"
    )
)</pre>
</div>
<p>To disable certificate verification use the <code class="literal">verify_certs=False</code> parameter. This option should be avoided in production, instead use the other options to verify the clusters' certificate.</p>
<div class="pre_wrapper lang-python">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-python">client = Elasticsearch(
    "https://...",
    verify_certs=False
)</pre>
</div>
<h4><a id="_tls_versions"></a>TLS versions<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-py/edit/8.14/docs/guide/configuration.asciidoc">edit</a></h4>
<p>Configuring the minimum TLS version to connect to is done via the <code class="literal">ssl_version</code> parameter. By default this is set to a minimum value of TLSv1.2. Use the <code class="literal">ssl.TLSVersion</code> enumeration to specify versions.</p>
<div class="pre_wrapper lang-python">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-python">import ssl

client = Elasticsearch(
    ...,
    ssl_version=ssl.TLSVersion.TLSv1_2
)</pre>
</div>
<h4><a id="_client_tls_certificate_authentication"></a>Client TLS certificate authentication<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-py/edit/8.14/docs/guide/configuration.asciidoc">edit</a></h4>
<p>Elasticsearch can be configured to authenticate clients via TLS client certificates. Client certificate and keys can be configured via the <code class="literal">client_cert</code> and <code class="literal">client_key</code> parameters:</p>
<div class="pre_wrapper lang-python">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-python">client = Elasticsearch(
    ...,
    client_cert="/path/to/cert.pem",
    client_key="/path/to/key.pem",
)</pre>
</div>
<h4><a id="_using_an_sslcontext"></a>Using an SSLContext<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-py/edit/8.14/docs/guide/configuration.asciidoc">edit</a></h4>
<p>For advanced users an <code class="literal">ssl.SSLContext</code> object can be used for configuring TLS via the <code class="literal">ssl_context</code> parameter. The <code class="literal">ssl_context</code> parameter can&#8217;t be combined with any other TLS options except for the <code class="literal">ssl_assert_fingerprint</code> parameter.</p>
<div class="pre_wrapper lang-python">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-python">import ssl

# Create and configure an SSLContext
ctx = ssl.create_default_context()
ctx.load_verify_locations(...)

client = Elasticsearch(
    ...,
    ssl_context=ctx
)</pre>
</div>
<h3><a id="compression"></a>HTTP compression<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-py/edit/8.14/docs/guide/configuration.asciidoc">edit</a></h3>
<p>Compression of HTTP request and response bodies can be enabled with the <code class="literal">http_compress</code> parameter.
If enabled then HTTP request bodies will be compressed with <code class="literal">gzip</code> and HTTP responses will include
the <code class="literal">Accept-Encoding: gzip</code> HTTP header. By default compression is disabled.</p>
<div class="pre_wrapper lang-python">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-python">client = Elasticsearch(
    ...,
    http_compress=True  # Enable compression!
)</pre>
</div>
<p>HTTP compression is recommended to be enabled when requests are traversing the network.
Compression is automatically enabled when connecting to Elastic Cloud.</p>
<h3><a id="timeouts"></a>Request timeouts<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-py/edit/8.14/docs/guide/configuration.asciidoc">edit</a></h3>
<p>Requests can be configured to timeout if taking too long to be serviced. The <code class="literal">request_timeout</code> parameter can be passed via the client constructor or the client <code class="literal">.options()</code> method. When the request times out the node will raise a <code class="literal">ConnectionTimeout</code> exception which can trigger retries.</p>
<p>Setting <code class="literal">request_timeout</code> to <code class="literal">None</code> will disable timeouts.</p>
<div class="pre_wrapper lang-python">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-python">client = Elasticsearch(
    ...,
    request_timeout=10  # 10 second timeout
)

# Search request will timeout in 5 seconds
client.options(request_timeout=5).search(...)</pre>
</div>
<h4><a id="_api_and_server_timeouts"></a>API and server timeouts<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-py/edit/8.14/docs/guide/configuration.asciidoc">edit</a></h4>
<p>There are API-level timeouts to take into consideration when making requests which can cause the request to timeout on server-side rather than client-side. You may need to configure both a transport and API level timeout for long running operations.</p>
<p>In the example below there are three different configurable timeouts for the <code class="literal">cluster.health</code> API all with different meanings for the request:</p>
<div class="pre_wrapper lang-python">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-python">client.options(
    # Amount of time to wait for an HTTP response to start.
    request_timeout=30
).cluster.health(
    # Amount of time to wait to collect info on all nodes.
    timeout=30,
    # Amount of time to wait for info from the master node.
    master_timeout=10,
)</pre>
</div>
<h3><a id="retries"></a>Retries<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-py/edit/8.14/docs/guide/configuration.asciidoc">edit</a></h3>
<p>Requests can be retried if they don&#8217;t return with a successful response. This provides a way for requests to be resilient against transient failures or overloaded nodes.</p>
<p>The maximum number of retries per request can be configured via the <code class="literal">max_retries</code> parameter. Setting this parameter to 0 disables retries. This parameter can be set in the client constructor or per-request via the client <code class="literal">.options()</code> method:</p>
<div class="pre_wrapper lang-python">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-python">client = Elasticsearch(
    ...,
    max_retries=5
)

# For this API request we disable retries with 'max_retries=0'
client.options(max_retries=0).index(
    index="blogs",
    document={
        "title": "..."
    }
)</pre>
</div>
<h4><a id="_retrying_on_connection_errors_and_timeouts"></a>Retrying on connection errors and timeouts<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-py/edit/8.14/docs/guide/configuration.asciidoc">edit</a></h4>
<p>Connection errors are automatically retried if retries are enabled. Retrying requests on connection timeouts can be enabled or disabled via the <code class="literal">retry_on_timeout</code> parameter. This parameter can be set on the client constructor or via the client <code class="literal">.options()</code> method:</p>
<div class="pre_wrapper lang-python">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-python">client = Elasticsearch(
    ...,
    retry_on_timeout=True
)
client.options(retry_on_timeout=False).info()</pre>
</div>
<h4><a id="_retrying_status_codes"></a>Retrying status codes<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-py/edit/8.14/docs/guide/configuration.asciidoc">edit</a></h4>
<p>By default if retries are enabled <code class="literal">retry_on_status</code> is set to <code class="literal">(429, 502, 503, 504)</code>. This parameter can be set on the client constructor or via the client <code class="literal">.options()</code> method. Setting this value to <code class="literal">()</code> will disable the default behavior.</p>
<div class="pre_wrapper lang-python">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-python">client = Elasticsearch(
    ...,
    retry_on_status=()
)

# Retry this API on '500 Internal Error' statuses
client.options(retry_on_status=[500]).index(
    index="blogs",
    document={
        "title": "..."
    }
)</pre>
</div>
<h4><a id="_ignoring_status_codes"></a>Ignoring status codes<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-py/edit/8.14/docs/guide/configuration.asciidoc">edit</a></h4>
<p>By default an <code class="literal">ApiError</code> exception will be raised for any non-2XX HTTP requests that exhaust retries, if any. If you&#8217;re expecting an HTTP error from the API but aren&#8217;t interested in raising an exception you can use the <code class="literal">ignore_status</code> parameter via the client <code class="literal">.options()</code> method.</p>
<p>A good example where this is useful is setting up or cleaning up resources in a cluster in a robust way:</p>
<div class="pre_wrapper lang-python">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-python">client = Elasticsearch(...)

# API request is robust against the index not existing:
resp = client.options(ignore_status=404).indices.delete(index="delete-this")
resp.meta.status  # Can be either '2XX' or '404'

# API request is robust against the index already existing:
resp = client.options(ignore_status=[400]).indices.create(
    index="create-this",
    mapping={
        "properties": {"field": {"type": "integer"}}
    }
)
resp.meta.status  # Can be either '2XX' or '400'</pre>
</div>
<p>When using the <code class="literal">ignore_status</code> parameter the error response will be returned serialized just like a non-error response. In these cases it can be useful to inspect the HTTP status of the response. To do this you can inspect the <code class="literal">resp.meta.status</code>.</p>
<h3><a id="sniffing"></a>Sniffing for new nodes<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-py/edit/8.14/docs/guide/configuration.asciidoc">edit</a></h3>
<p>Additional nodes can be discovered by a process called "sniffing" where the client will query the cluster for more nodes that can handle requests.</p>
<p>Sniffing can happen at three different times: on client instantiation, before requests, and on a node failure. These three behaviors can be enabled and disabled with the <code class="literal">sniff_on_start</code>, <code class="literal">sniff_before_requests</code>, and <code class="literal">sniff_on_node_failure</code> parameters.</p>
<div class="important admon">
<div class="icon"></div>
<div class="admon_content">
<p>When using an HTTP load balancer or proxy you cannot use sniffing functionality as the cluster would supply the client with IP addresses to directly connect to the cluster, circumventing the load balancer. Depending on your configuration this might be something you don&#8217;t want or break completely.</p>
</div>
</div>
<h4><a id="_waiting_between_sniffing_attempts"></a>Waiting between sniffing attempts<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-py/edit/8.14/docs/guide/configuration.asciidoc">edit</a></h4>
<p>To avoid needlessly sniffing too often there is a delay between attempts to discover new nodes. This value can be controlled via the <code class="literal">min_delay_between_sniffing</code> parameter.</p>
<h4><a id="_filtering_nodes_which_are_sniffed"></a>Filtering nodes which are sniffed<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-py/edit/8.14/docs/guide/configuration.asciidoc">edit</a></h4>
<p>By default nodes which are marked with only a <code class="literal">master</code> role will not be used. To change the behavior the parameter <code class="literal">sniffed_node_callback</code> can be used. To mark a sniffed node not to be added to the node pool
return <code class="literal">None</code> from the <code class="literal">sniffed_node_callback</code>, otherwise return a <code class="literal">NodeConfig</code> instance.</p>
<div class="pre_wrapper lang-python">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-python">from typing import Optional, Dict, Any
from elastic_transport import NodeConfig
from elasticsearch import Elasticsearch

def filter_master_eligible_nodes(
    node_info: Dict[str, Any],
    node_config: NodeConfig
) -&gt; Optional[NodeConfig]:
    # This callback ignores all nodes that are master eligible
    # instead of master-only nodes (default behavior)
    if "master" in node_info.get("roles", ()):
        return None
    return node_config

client = Elasticsearch(
    "https://localhost:9200",
    sniffed_node_callback=filter_master_eligible_nodes
)</pre>
</div>
<p>The <code class="literal">node_info</code> parameter is part of the response from the <code class="literal">nodes.info()</code> API, below is an example
of what that object looks like:</p>
<div class="pre_wrapper lang-json">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-json">{
  "name": "SRZpKFZ",
  "transport_address": "127.0.0.1:9300",
  "host": "127.0.0.1",
  "ip": "127.0.0.1",
  "version": "5.0.0",
  "build_hash": "253032b",
  "roles": ["master", "data", "ingest"],
  "http": {
    "bound_address": ["[fe80::1]:9200", "[::1]:9200", "127.0.0.1:9200"],
    "publish_address": "1.1.1.1:123",
    "max_content_length_in_bytes": 104857600
  }
}</pre>
</div>
<h3><a id="node-pool"></a>Node Pool<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-py/edit/8.14/docs/guide/configuration.asciidoc">edit</a></h3>
<h4><a id="_selecting_a_node_from_the_pool"></a>Selecting a node from the pool<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-py/edit/8.14/docs/guide/configuration.asciidoc">edit</a></h4>
<p>You can specify a node selector pattern via the <code class="literal">node_selector_class</code> parameter. The supported values are <code class="literal">round_robin</code> and <code class="literal">random</code>. Default is <code class="literal">round_robin</code>.</p>
<div class="pre_wrapper lang-python">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-python">client = Elasticsearch(
    ...,
    node_selector_class="round_robin"
)</pre>
</div>
<p>Custom selectors are also supported:</p>
<div class="pre_wrapper lang-python">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-python">from elastic_transport import NodeSelector

class CustomSelector(NodeSelector):
    def select(nodes): ...

client = Elasticsearch(
    ...,
    node_selector_class=CustomSelector
)</pre>
</div>
<h4><a id="_marking_nodes_dead_and_alive"></a>Marking nodes dead and alive<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-py/edit/8.14/docs/guide/configuration.asciidoc">edit</a></h4>
<p>Individual nodes of Elasticsearch may have transient connectivity or load issues which may make them unable to service requests. To combat this the pool of nodes will detect when a node isn&#8217;t able to service requests due to transport or API errors.</p>
<p>After a node has been timed out it will be moved back to the set of "alive" nodes but only after the node returns a successful response will the node be marked as "alive" in terms of consecutive errors.</p>
<p>The <code class="literal">dead_node_backoff_factor</code> and <code class="literal">max_dead_node_backoff</code> parameters can be used to configure how long the node pool will put the node into timeout with each consecutive failure. Both parameters use a unit of seconds.</p>
<p>The calculation is equal to <code class="literal">min(dead_node_backoff_factor * (2 ** (consecutive_failures - 1)), max_dead_node_backoff)</code>.</p>
<h3><a id="serializer"></a>Serializers<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-py/edit/8.14/docs/guide/configuration.asciidoc">edit</a></h3>
<p>Serializers transform bytes on the wire into native Python objects and vice-versa. By default the client ships with serializers for <code class="literal">application/json</code>, <code class="literal">application/x-ndjson</code>, <code class="literal">text/*</code>, and <code class="literal">application/mapbox-vector-tile</code>.</p>
<p>You can define custom serializers via the <code class="literal">serializers</code> parameter:</p>
<div class="pre_wrapper lang-python">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-python">from elasticsearch import Elasticsearch, JsonSerializer

class JsonSetSerializer(JsonSerializer):
    """Custom JSON serializer that handles Python sets"""
    def default(self, data: Any) -&gt; Any:
        if isinstance(data, set):
            return list(data)
        return super().default(data)

client = Elasticsearch(
    ...,
    # Serializers are a mapping of 'mimetype' to Serializer class.
    serializers={"application/json": JsonSetSerializer()}
)</pre>
</div>
<p>If the <code class="literal">orjson</code> package is installed, you can use the faster ``OrjsonSerializer`` for the default mimetype (``application/json``):</p>
<div class="pre_wrapper lang-python">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-python">from elasticsearch import Elasticsearch, OrjsonSerializer

es = Elasticsearch(
    ...,
    serializer=OrjsonSerializer()
)</pre>
</div>
<p>orjson is particularly fast when serializing vectors as it has native numpy support. This will be the default in a future release. Note that you can install orjson with the <code class="literal">orjson</code> extra:</p>
<div class="pre_wrapper lang-sh">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-sh">$ python -m pip install elasticsearch[orjson]</pre>
</div>
<h3><a id="nodes"></a>Nodes<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-py/edit/8.14/docs/guide/configuration.asciidoc">edit</a></h3>
<h4><a id="_node_implementations"></a>Node implementations<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-py/edit/8.14/docs/guide/configuration.asciidoc">edit</a></h4>
<p>The default node class for synchronous I/O is <code class="literal">urllib3</code> and the default node class for asynchronous I/O is <code class="literal">aiohttp</code>.</p>
<p>For all of the built-in HTTP node implementations like <code class="literal">urllib3</code>, <code class="literal">requests</code>, and <code class="literal">aiohttp</code> you can specify with a simple string to the <code class="literal">node_class</code> parameter:</p>
<div class="pre_wrapper lang-python">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-python">from elasticsearch import Elasticsearch

client = Elasticsearch(
    ...,
    node_class="requests"
)</pre>
</div>
<p>You can also specify a custom node implementation via the <code class="literal">node_class</code> parameter:</p>
<div class="pre_wrapper lang-python">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-python">from elasticsearch import Elasticsearch
from elastic_transport import Urllib3HttpNode

class CustomHttpNode(Urllib3HttpNode):
    ...

client = Elasticsearch(
    ...
    node_class=CustomHttpNode
)</pre>
</div>
<h4><a id="_http_connections_per_node"></a>HTTP connections per node<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-py/edit/8.14/docs/guide/configuration.asciidoc">edit</a></h4>
<p>Each node contains its own pool of HTTP connections to allow for concurrent requests. This value is configurable via the <code class="literal">connections_per_node</code> parameter:</p>
<div class="pre_wrapper lang-python">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-python">client = Elasticsearch(
    ...,
    connections_per_node=5
)</pre>
</div>
</div>
</div>
</div><div class="navfooter">
<span class="prev">
<a href="connecting.html">« Connecting</a>
</span>
<span class="next">
<a href="migration.html">Migrating to 8.0 »</a>
</span>
</div>
</body>
</html>
