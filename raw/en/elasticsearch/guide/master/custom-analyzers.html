<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Custom Analyzers | Elasticsearch: The Definitive Guide [master] | Elastic</title>
<link rel="home" href="index.html" title="Elasticsearch: The Definitive Guide [master]"/>
<link rel="up" href="index-management.html" title="Index Management"/>
<link rel="prev" href="configuring-analyzers.html" title="Configuring Analyzers"/>
<link rel="next" href="mapping.html" title="Types and Mappings"/>
<meta name="DC.type" content="Learn/Docs/Legacy/Elasticsearch/Definitive Guide/master"/>
<meta name="DC.subject" content="Elasticsearch"/>
<meta name="DC.identifier" content="master"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body><div class="page_header">
This information may not apply to the latest version of Elasticsearch.
For the most up to date information, see the current version of the
<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html">
Elasticsearch Reference</a>.
</div>
<div id="content">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="index.html">Elasticsearch: The Definitive Guide [master]</a></span>
»
<span class="breadcrumb-link"><a href="getting-started.html">Getting Started</a></span>
»
<span class="breadcrumb-link"><a href="index-management.html">Index Management</a></span>
»
<span class="breadcrumb-node">Custom Analyzers</span>
</div>
<div class="navheader">
<span class="prev">
<a href="configuring-analyzers.html">« Configuring Analyzers</a>
</span>
<span class="next">
<a href="mapping.html">Types and Mappings »</a>
</span>
</div>
<div class="section">
<div class="titlepage"><div><div>
<h2 class="title"><a id="custom-analyzers"></a>Custom Analyzers<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-definitive-guide/edit/master/070_Index_Mgmt/20_Custom_Analyzers.asciidoc">edit</a></h2>
</div></div></div>
<p>While Elasticsearch comes with a number of analyzers available out of the box,
the real power comes from the ability to create your own custom analyzers
by combining character filters, tokenizers, and token filters in a
configuration that suits your particular data.</p>
<p>In <a class="xref" href="analysis-intro.html" title="Analysis and Analyzers">Analysis and Analyzers</a>, we said that an <em>analyzer</em> is a wrapper that combines
three functions into a single package, which are executed in sequence:</p>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
Character filters
</span>
</dt>
<dd>
<p>Character filters are used to &#8220;tidy up&#8221; a string before it is tokenized.
For instance, if our text is in HTML format, it will contain HTML tags like
<code class="literal">&lt;p&gt;</code> or <code class="literal">&lt;div&gt;</code> that we don&#8217;t want to be indexed. We can use the
<a href="/guide/en/elasticsearch/reference/2.4/analysis-htmlstrip-charfilter.html" class="ulink" target="_top"><code class="literal">html_strip</code> character filter</a>
to remove all HTML tags and to convert HTML entities like <code class="literal">&amp;Aacute;</code> into the
corresponding Unicode character <code class="literal">Á</code>.</p>
<p>An analyzer may have zero or more character filters.</p>
</dd>
<dt>
<span class="term">
Tokenizers
</span>
</dt>
<dd>
<p>An analyzer <em>must</em> have a single tokenizer.  The tokenizer breaks up the
string into individual terms or tokens. The
<a href="/guide/en/elasticsearch/reference/2.4/analysis-standard-tokenizer.html" class="ulink" target="_top"><code class="literal">standard</code> tokenizer</a>,
which is used in the <code class="literal">standard</code> analyzer, breaks up a string into
individual terms on word boundaries, and removes most punctuation, but
other tokenizers exist that have different behavior.</p>
<p>For instance, the
<a href="/guide/en/elasticsearch/reference/2.4/analysis-keyword-tokenizer.html" class="ulink" target="_top"><code class="literal">keyword</code> tokenizer</a>
outputs exactly the same string as it received, without any tokenization. The
<a href="/guide/en/elasticsearch/reference/2.4/analysis-whitespace-tokenizer.html" class="ulink" target="_top"><code class="literal">whitespace</code> tokenizer</a>
splits text on whitespace only. The
<a href="/guide/en/elasticsearch/reference/2.4/analysis-pattern-tokenizer.html" class="ulink" target="_top"><code class="literal">pattern</code> tokenizer</a> can
be used to split text on a matching regular expression.</p>
</dd>
<dt>
<span class="term">
Token filters
</span>
</dt>
<dd>
<p>After tokenization, the resulting <em>token stream</em> is passed through any
specified token filters, in the order in which they are specified.</p>
<p>Token filters may change, add, or remove tokens.  We have already mentioned the
<a href="/guide/en/elasticsearch/reference/2.4/analysis-lowercase-tokenizer.html" class="ulink" target="_top"><code class="literal">lowercase</code></a> and
<a href="/guide/en/elasticsearch/reference/2.4/analysis-stop-tokenfilter.html" class="ulink" target="_top"><code class="literal">stop</code> token filters</a>,
but there are many more available in Elasticsearch.
<a href="/guide/en/elasticsearch/reference/2.4/analysis-stemmer-tokenfilter.html" class="ulink" target="_top">Stemming token filters</a>
&#8220;stem&#8221; words to their root form. The
<a href="/guide/en/elasticsearch/reference/2.4/analysis-asciifolding-tokenfilter.html" class="ulink" target="_top"><code class="literal">ascii_folding</code> filter</a>
removes diacritics, converting a term like <code class="literal">"très"</code> into <code class="literal">"tres"</code>. The
<a href="/guide/en/elasticsearch/reference/2.4/analysis-ngram-tokenfilter.html" class="ulink" target="_top"><code class="literal">ngram</code></a> and
<a href="/guide/en/elasticsearch/reference/2.4/analysis-edgengram-tokenfilter.html" class="ulink" target="_top"><code class="literal">edge_ngram</code> token filters</a> can produce
tokens suitable for partial matching or autocomplete.</p>
</dd>
</dl>
</div>
<p>In <a class="xref" href="search-in-depth.html" title="Search in Depth">Search in Depth</a>, we discuss examples of where and how to use these
tokenizers and filters.  But first, we need to explain how to create a custom
analyzer.</p>
<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="_creating_a_custom_analyzer"></a>Creating a Custom Analyzer<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-definitive-guide/edit/master/070_Index_Mgmt/20_Custom_Analyzers.asciidoc">edit</a></h3>
</div></div></div>
<p>In the same way as we configured the <code class="literal">es_std</code> analyzer previously, we can configure
character filters, tokenizers, and token filters in their respective sections
under <code class="literal">analysis</code>:</p>
<div class="pre_wrapper lang-js">
<pre class="programlisting prettyprint lang-js">PUT /my_index
{
    "settings": {
        "analysis": {
            "char_filter": { ... custom character filters ... },
            "tokenizer":   { ...    custom tokenizers     ... },
            "filter":      { ...   custom token filters   ... },
            "analyzer":    { ...    custom analyzers      ... }
        }
    }
}</pre>
</div>
<p>As an example, let&#8217;s set up a custom analyzer that will do the following:</p>
<div class="olist orderedlist">
<ol class="orderedlist">
<li class="listitem">
Strip out HTML by using the <code class="literal">html_strip</code> character filter.
</li>
<li class="listitem">
<p>Replace <code class="literal">&amp;</code> characters with <code class="literal">" and "</code>, using a custom <code class="literal">mapping</code>
character filter:</p>
<div class="pre_wrapper lang-js">
<pre class="programlisting prettyprint lang-js">"char_filter": {
    "&amp;_to_and": {
        "type":       "mapping",
        "mappings": [ "&amp;=&gt; and "]
    }
}</pre>
</div>
</li>
<li class="listitem">
Tokenize words, using the <code class="literal">standard</code> tokenizer.
</li>
<li class="listitem">
Lowercase terms, using the <code class="literal">lowercase</code> token filter.
</li>
<li class="listitem">
<p>Remove a custom list of stopwords, using a custom <code class="literal">stop</code> token filter:</p>
<div class="pre_wrapper lang-js">
<pre class="programlisting prettyprint lang-js">"filter": {
    "my_stopwords": {
        "type":        "stop",
        "stopwords": [ "the", "a" ]
    }
}</pre>
</div>
</li>
</ol>
</div>
<p>Our analyzer definition combines the predefined tokenizer and filters with the
custom filters that we have configured previously:</p>
<div class="pre_wrapper lang-js">
<pre class="programlisting prettyprint lang-js">"analyzer": {
    "my_analyzer": {
        "type":           "custom",
        "char_filter":  [ "html_strip", "&amp;_to_and" ],
        "tokenizer":      "standard",
        "filter":       [ "lowercase", "my_stopwords" ]
    }
}</pre>
</div>
<p>To put it all together, the whole <code class="literal">create-index</code> request looks like this:</p>
<div class="pre_wrapper lang-sense">
<pre class="programlisting prettyprint lang-sense">PUT /my_index
{
    "settings": {
        "analysis": {
            "char_filter": {
                "&amp;_to_and": {
                    "type":       "mapping",
                    "mappings": [ "&amp;=&gt; and "]
            }},
            "filter": {
                "my_stopwords": {
                    "type":       "stop",
                    "stopwords": [ "the", "a" ]
            }},
            "analyzer": {
                "my_analyzer": {
                    "type":         "custom",
                    "char_filter":  [ "html_strip", "&amp;_to_and" ],
                    "tokenizer":    "standard",
                    "filter":       [ "lowercase", "my_stopwords" ]
            }}
}}}</pre>
</div>
<div class="sense_widget" data-snippet="snippets/070_Index_Mgmt/20_Custom_analyzer.json"></div>
<p>After creating the index, use the <code class="literal">analyze</code> API to test the new analyzer:</p>
<div class="pre_wrapper lang-sense">
<pre class="programlisting prettyprint lang-sense">GET /my_index/_analyze
{
    "text": "The quick &amp; brown fox",
    "analyzer": "my_analyzer"
}</pre>
</div>
<div class="sense_widget" data-snippet="snippets/070_Index_Mgmt/20_Custom_analyzer.json"></div>
<p>The following abbreviated results show that our analyzer is working correctly:</p>
<div class="pre_wrapper lang-js">
<pre class="programlisting prettyprint lang-js">{
  "tokens" : [
      { "token" :   "quick",    "position" : 2 },
      { "token" :   "and",      "position" : 3 },
      { "token" :   "brown",    "position" : 4 },
      { "token" :   "fox",      "position" : 5 }
    ]
}</pre>
</div>
<p>The analyzer is not much use unless we tell Elasticsearch where to use it. We
can apply it to a <code class="literal">string</code> field with a mapping such as the following:</p>
<div class="pre_wrapper lang-sense">
<pre class="programlisting prettyprint lang-sense">PUT /my_index/_mapping/my_type
{
    "properties": {
        "title": {
            "type":      "string",
            "analyzer":  "my_analyzer"
        }
    }
}</pre>
</div>
<div class="sense_widget" data-snippet="snippets/070_Index_Mgmt/20_Custom_analyzer.json"></div>
</div>

</div>
<div class="navfooter">
<span class="prev">
<a href="configuring-analyzers.html">« Configuring Analyzers</a>
</span>
<span class="next">
<a href="mapping.html">Types and Mappings »</a>
</span>
</div>
</div>
</body>
</html>
