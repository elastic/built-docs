<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="description" content="Reference documentation of elasticsearch-hadoop">
<title>Apache Storm support | Elasticsearch for Apache Hadoop [5.0] | Elastic</title>
<meta class="elastic" name="content" content="Apache Storm support | Elasticsearch for Apache Hadoop [5.0]">

<link rel="home" href="index.html" title="Elasticsearch for Apache Hadoop [5.0]"/>
<link rel="up" href="reference.html" title="Elasticsearch for Apache Hadoop"/>
<link rel="prev" href="spark.html" title="Apache Spark support"/>
<link rel="next" href="mapping.html" title="Mapping and Types"/>
<meta class="elastic" name="product_version" content="5.0"/>
<meta class="elastic" name="product_name" content="Elasticsearch"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/Elasticsearch/Apache Hadoop/5.0"/>
<meta name="DC.subject" content="Elasticsearch"/>
<meta name="DC.identifier" content="5.0"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body>
<div class="page_header">
<p>
  <strong>WARNING</strong>: Version 5.0 has passed its 
  <a href="https://www.elastic.co/support/eol">EOL date</a>. 
</p>  
<p>
  This documentation is no longer being maintained and may be removed. 
  If you are running this version, we strongly advise you to upgrade. 
  For the latest information, see the 
  <a href="../current/index.html">current release documentation</a>. 
</p>
</div>
<div class="navheader">
<span class="prev">
<a href="spark.html">« Apache Spark support</a>
</span>
<span class="next">
<a href="mapping.html">Mapping and Types »</a>
</span>
</div>
<div class="book" lang="en">
<div class="titlepage">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Elasticsearch for Apache Hadoop [5.0]</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="reference.html">Elasticsearch for Apache Hadoop</a></span>
</div>
<div>
<div><h1 class="title"><a id="id-1"></a>Apache Storm support</h1><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-hadoop/edit/5.0/docs/src/reference/asciidoc/core/storm.adoc">edit</a></div>
</div>
<!--EXTRA-->
</div>
<div id="content">
<div class="chapter">
<div class="titlepage"><div><div>
<div class="position-relative"><h2 class="title"><a id="storm"></a>Apache Storm support</h2><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-hadoop/edit/5.0/docs/src/reference/asciidoc/core/storm.adoc">edit</a></div>
</div></div></div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>Added in 2.1.</p>
</div>
</div>
<div class="blockquote">
<table border="0" class="blockquote" summary="Block quote">
<tr>
<td valign="top" width="10%"></td>
<td valign="top" width="80%">
<p><a href="http://storm.apache.org" class="ulink" target="_top">Apache Storm</a> is a free and open source distributed realtime computation system. Storm makes it easy to reliably process unbounded streams of data, doing for realtime processing what Hadoop did for batch processing.</p>
</td>
<td valign="top" width="10%"></td>
</tr>
<tr>
<td valign="top" width="10%"></td>
<td align="right" colspan="2" valign="top">
-- <span class="attribution">Storm website</span>
</td>
</tr>
</table>
</div>
<p>With Storm, one can compute, transform and filter data typically in a streaming scenario. As opposed to the rest of the libraries mentioned in this documentation, Apache Storm is a computational framework that is not tied to Map/Reduce itself however it does integrate with Hadoop, mainly through HDFS.</p>
<div class="important admon">
<div class="icon"></div>
<div class="admon_content">
<p>Since elasticsearch-hadoop 5.0, Storm 1.0 or higher (older versions cannot be used unfortunately as Storm 1.x broke backwards compatibility though package renaming).</p>
</div>
</div>
<div class="position-relative"><h3><a id="storm-installation"></a>Installation</h3><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-hadoop/edit/5.0/docs/src/reference/asciidoc/core/storm.adoc">edit</a></div>
<p>In order to use elasticsearch-hadoop, its jar needs to be available in Storm&#8217;s classpath. The Storm <a href="https://storm.apache.org/documentation/Documentation.html" class="ulink" target="_top">documentation</a> covers this in detail but in short, one can either have the jar available on all Storm nodes or have elasticsearch-hadoop part of the jar being deployed (which we recommend). The latter approach allows isolation between the jobs and since the jar is self-contained, can be easily be moved across environments without additional setup making it much more robust.</p>
<div class="position-relative"><h3><a id="storm-configuration"></a>Configuration</h3><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-hadoop/edit/5.0/docs/src/reference/asciidoc/core/storm.adoc">edit</a></div>
<p>The Storm integration supports the configuration options described in the <a class="xref" href="configuration.html" title="Configuration"><em>Configuration</em></a> chapter plus a few more that are specific to Storm, namely:</p>
<div class="position-relative"><h4><a id="storm-cfg-spout"></a>Spout specific</h4><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-hadoop/edit/5.0/docs/src/reference/asciidoc/core/storm.adoc">edit</a></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">es.storm.spout.reliable</code> (default false)
</span>
</dt>
<dd>
Indicates whether the dedicated <code class="literal">EsSpout</code> is <em>reliable</em>, that is replays the documents in case of failure or not. By default it is set to <code class="literal">false</code> since replaying requires the documents to be kept in memory until are being acknowledged.
</dd>
<dt>
<span class="term">
<code class="literal">es.storm.spout.fields</code> (default "")
</span>
</dt>
<dd>
Specify what fields <code class="literal">EsSpout</code> will declare in its topology and extract from the returned documents. By default is unset meaning the documents are returned as <code class="literal">Map</code>s under the default field <code class="literal">doc</code>.
</dd>
<dt>
<span class="term">
<code class="literal">es.storm.spout.reliable.queue.size</code> (default 0)
</span>
</dt>
<dd>
Applicable only if <code class="literal">es.storm.spout.reliable</code> is <code class="literal">true</code>. Sets the size of the queue which holds documents in memory to be replayed until they are acknowledged. By default, the queue is <em>unbounded</em> (<code class="literal">0</code>) however in a production environment
it is indicated to limit the queue to limit the consumption of memory. If the queue is full, the <code class="literal">Bolt</code> drops any incoming <code class="literal">Tuple</code>s and throws an exception.
</dd>
<dt>
<span class="term">
<code class="literal">es.storm.spout.reliable.retries.per.tuple</code> (default 5)
</span>
</dt>
<dd>
Applicable only if <code class="literal">es.storm.spout.reliable</code> is <code class="literal">true</code>. Set the number of retries (replays) of a failed tuple before giving up. Setting it to a negative value will cause the tuple to be replayed until acknowledged.
</dd>
<dt>
<span class="term">
<code class="literal">es.storm.spout.reliable.handle.tuple.failure</code> (default abort)
</span>
</dt>
<dd>
<p>
Applicable only if <code class="literal">es.storm.spout.reliable</code> is <code class="literal">true</code>. Indicates how to handle failing tuples after the number of retries is depleted. Possible values are :
</p>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">ignore</code>
</span>
</dt>
<dd>
the tuple is discarded
</dd>
<dt>
<span class="term">
<code class="literal">warn</code>
</span>
</dt>
<dd>
a warning message is logged and the tuple is discarded
</dd>
<dt>
<span class="term">
<code class="literal">strict</code>
</span>
</dt>
<dd>
an exception is thrown, aborting the current job
</dd>
</dl>
</div>
</dd>
</dl>
</div>
<div class="position-relative"><h4><a id="storm-cfg-bolt"></a>Bolt specific</h4><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-hadoop/edit/5.0/docs/src/reference/asciidoc/core/storm.adoc">edit</a></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">es.storm.bolt.write.ack</code> (default false)
</span>
</dt>
<dd>
Indicates whether the dedicated <code class="literal">EsBolt</code> is <em>reliable</em>, that is acknowledges the <code class="literal">Tuple</code> <em>after</em> it is written to Elasticsearch instead of when it receives it. By default it is <code class="literal">false</code>. Note that turning this on increases the memory requirements of the <code class="literal">Bolt</code> since it has to keep the data in memory until it is fully written.
</dd>
<dt>
<span class="term">
<code class="literal">es.storm.bolt.flush.entries.size</code> (default 1000)
</span>
</dt>
<dd>
The number of entries that trigger a <em>micro-batch</em> write to Elasticsearch. By default, it uses the same value as <code class="literal">es.batch.size.entries</code> which, by default is <code class="literal">1000</code>.
</dd>
<dt>
<span class="term">
<code class="literal">es.storm.bolt.tick.tuple.flush</code> (default true)
</span>
</dt>
<dd>
Whether or not to flush the existing data if the <code class="literal">Bolt</code> receives a <a href="https://storm.incubator.apache.org/apidocs/" class="ulink" target="_top">Tick</a> tuple. This <em>heart-beat</em>-like mechanism goes hand in hand with the flush limit above to create both a time and size trigger.
When using Storm&#8217;s internal ticks, remember to set the tick interval:
</dd>
</dl>
</div>
<div class="pre_wrapper lang-java">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-java">// tick every 2 seconds
builder.setBolt(...).addConfiguration(Config.TOPOLOGY_TICK_TUPLE_FREQ_SECS, 2)</pre>
</div>
<div class="position-relative"><h4><a id="storm-cfg-set"></a>Setting the configuration</h4><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-hadoop/edit/5.0/docs/src/reference/asciidoc/core/storm.adoc">edit</a></div>
<p>The configuration can be set through Storm&#8217;s <a href="https://storm.incubator.apache.org/apidocs/index.html?backtype/storm/Config.html" class="ulink" target="_top">Config</a> class, in which case they are available <em>globally</em> or, individually for each <code class="literal">EsSpout</code> and <code class="literal">EsBolt</code> instance. In general, it is recommended to set globally <em>only</em> the properties that apply to all the components and are unlikely to change:</p>
<div class="pre_wrapper lang-java">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-java">Config conf = new Config();
conf.put("es.index.auto.create", "true");
StormSubmitter.submitTopology("myTopology", conf, topology);</pre>
</div>
<p>For this reason, typically, one should use the <em>per-component</em> configuration model since it allows different configurations to be used within the same Storm topology:</p>
<div class="pre_wrapper lang-java">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-java">Map conf = new HashMap();
conf.put("es.index.auto.create", "true");
TopologyBuilder builder = new TopologyBuilder();
builder.setSpout("esSpout", new EsSpout("index/type", conf));</pre>
</div>
<div class="position-relative"><h3><a id="storm-write"></a>Writing data to Elasticsearch</h3><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-hadoop/edit/5.0/docs/src/reference/asciidoc/core/storm.adoc">edit</a></div>
<p>Through elasticsearch-hadoop, Elasticsearch is exposed to Storm through a native <code class="literal">Bolt</code>, namely <code class="literal">org.elasticsearch.storm.EsBolt</code> that writes the Storm <code class="literal">Tuple</code>s to Elasticsearch:</p>
<div class="pre_wrapper lang-java">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-java">import org.elasticsearch.storm.EsBolt; <a id="CO94-1"></a><i class="conum" data-value="1"></i>

TopologyBuilder builder = new TopologyBuilder();
builder.setSpout("spout", new RandomSentenceSpout(), 10);
builder.setBolt(
    "es-bolt",
    new EsBolt(<a id="CO94-2"></a><i class="conum" data-value="2"></i>
        "storm/docs"<a id="CO94-3"></a><i class="conum" data-value="3"></i>
    ),
    5)<a id="CO94-4"></a><i class="conum" data-value="4"></i>
    .shuffleGrouping("spout");</pre>
</div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO94-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>elasticsearch-hadoop <code class="literal">EsBolt</code> package import</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO94-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p><code class="literal">EsBolt</code> declaration</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO94-3"><i class="conum" data-value="3"></i></a></p>
</td>
<td align="left" valign="top">
<p>Various constructors are available for <code class="literal">EsBolt</code> - at least the Elasticsearch resource under which the data is indexed, is required</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO94-4"><i class="conum" data-value="4"></i></a></p>
</td>
<td align="left" valign="top">
<p>The number of <code class="literal">EsBolt</code> instances for this topology</p>
</td>
</tr>
</table>
</div>
<div class="important admon">
<div class="icon"></div>
<div class="admon_content">
<p>The number of bolt instances depends highly on your topology and environment. In general a good rule of thumb is to take into account the number of the target index shards as well as the number of spouts sending data to it - a good formula is to take the minimum between the source spouts and the index shards; in this example 5. A high number of <code class="literal">Bolt</code>s does not translate to a bigger through-put - make sure the <code class="literal">Bolt</code>s are the bottleneck since increasing the number simply translates otherwise to wasted cycles.</p>
</div>
</div>
<p>For cases where the id (or other metadata fields like <code class="literal">ttl</code> or <code class="literal">timestamp</code>) of the document needs to be specified, one can do so by setting the appropriate <a class="xref" href="configuration.html#cfg-mapping" title="Mapping (when writing to Elasticsearch)">mapping</a>, namely <code class="literal">es.mapping.id</code>. Thus assuming the documents contain a field called <code class="literal">sentenceId</code> which is unique and is suitable for an identifier, one can update the job configuration as follows:</p>
<div class="pre_wrapper lang-java">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-java">Map conf = new HashMap();
conf.put("es.mapping.id", "sentenceId");
TopologyBuilder builder = new TopologyBuilder();
builder.setSpout("esSpout", new EsSpout("index/type", conf));</pre>
</div>
<div class="position-relative"><h4><a id="storm-write-json"></a>Writing existing JSON to Elasticsearch</h4><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-hadoop/edit/5.0/docs/src/reference/asciidoc/core/storm.adoc">edit</a></div>
<p>If the data passed to Storm is already in JSON format, <code class="literal">EsBolt</code> can pass it directly to Elasticsearch <em>without</em> any transformation; the data is taken as is and sent over the wire. In such cases, one needs to indicate the JSON input by setting the <code class="literal">es.input.json</code> parameter to <code class="literal">true</code>. Furthermore, the <code class="literal">Bolt</code> expects the receiving <code class="literal">Tuple</code> to contain only <em>one</em> value/field representing the JSON document. By default, common <em>textual</em> types are recognized, such as <code class="literal">chararray</code> or <code class="literal">bytearray</code>; otherwise it falls back to calling <code class="literal">toString</code> to get a hold of the JSON content.</p>
<div class="pre_wrapper lang-java">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-java">String json1 = "{\"reason\" : \"business\",\"airport\" : \"SFO\"}";  <a id="CO95-1"></a><i class="conum" data-value="1"></i>
String json2 = "{\"participants\" : 5,\"airport\" : \"OTP\"}";

Map conf = new HashMap();
conf.put("es.input.json", "true"); <a id="CO95-2"></a><i class="conum" data-value="2"></i>

TopologyBuilder builder = new TopologyBuilder();
builder.setSpout("json-spout", new StringSpout(Arrays.asList(json1, json2)); <a id="CO95-3"></a><i class="conum" data-value="3"></i>
builder.setBolt("es-bolt", new EsBolt("storm/json-trips", conf)) <a id="CO95-4"></a><i class="conum" data-value="4"></i>
                                    .shuffleGrouping("json-spout");</pre>
</div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO95-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>JSON document represented as a <code class="literal">String</code></p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO95-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p>Option indicating the input is in JSON format</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO95-3"><i class="conum" data-value="3"></i></a></p>
</td>
<td align="left" valign="top">
<p>Basic <code class="literal">Spout</code> which replays the given <code class="literal">String</code>s as <code class="literal">Tuples</code> with only one value</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO95-4"><i class="conum" data-value="4"></i></a></p>
</td>
<td align="left" valign="top">
<p>Configure <code class="literal">EsBolt</code> to process JSON - the same setting can be passed through the global <code class="literal">Conf</code> object however it is typically convenient to define it <em>locally</em></p>
</td>
</tr>
</table>
</div>
<div class="position-relative"><h4><a id="storm-write-dyn"></a>Writing to dynamic/multi-resources</h4><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-hadoop/edit/5.0/docs/src/reference/asciidoc/core/storm.adoc">edit</a></div>
<p>In cases where the data needs to be indexed based on its content, one can choose the target index based on a <code class="literal">Tuple</code> field.  Reusing the aforementioned <a class="xref" href="configuration.html#cfg-multi-writes" title="Dynamic/multi resource writes">media example</a>, one can <em>partition</em> the documents based on their type. Assuming the document tuple contains fields <code class="literal">media_type</code>, <code class="literal">title</code> and <code class="literal">year</code> one can index them as follows:</p>
<div class="pre_wrapper lang-java">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-java">builder.setBolt("es-bolt",
    new EsBolt("my-collection/{media_type}") <a id="CO96-1"></a><i class="conum" data-value="1"></i>
).shuffleGrouping("spout");</pre>
</div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO96-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>Resource pattern using field <code class="literal">type</code></p>
</td>
</tr>
</table>
</div>
<p>For each tuple about to be written, elasticsearch-hadoop will extract the <code class="literal">type</code> field and use its value to determine the target resource. The functionality is also available when dealing with raw JSON - in this case, the value will be extracted from the JSON document itself.</p>
<p>The functionality is also available when dealing with raw JSON - in this case, the value will be extracted from the JSON document itself. Assuming the JSON source contains documents with the following structure:</p>
<div class="pre_wrapper lang-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js">{
    "media_type":"game",<a id="CO97-1"></a><i class="conum" data-value="1"></i>
    "title":"Final Fantasy VI",
    "year":"1994"
}</pre>
</div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO97-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>field within the JSON document that will be used by the pattern</p>
</td>
</tr>
</table>
</div>
<p>the <code class="literal">EsBolt</code> with the configuration:</p>
<div class="pre_wrapper lang-java">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-java">Map conf = new HashMap();
conf.put("es.input.json", "true"); <a id="CO98-1"></a><i class="conum" data-value="1"></i>

builder.setBolt("es-bolt",
    new EsBolt(
        "my-collection-{year}/{media_type}",<a id="CO98-2"></a><i class="conum" data-value="2"></i>
        conf) <a id="CO98-3"></a><i class="conum" data-value="3"></i>
    ).shuffleGrouping("spout");</pre>
</div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO98-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>Option indicating the input is in JSON format</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO98-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p>Resource pattern - notice how the pattern is used both in the index and the type</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO98-3"><i class="conum" data-value="3"></i></a></p>
</td>
<td align="left" valign="top">
<p>Pass configuration to <code class="literal">EsBolt</code> to indicate the JSON input</p>
</td>
</tr>
</table>
</div>
<div class="position-relative"><h4><a id="storm-read"></a>Reading data from Elasticsearch</h4><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-hadoop/edit/5.0/docs/src/reference/asciidoc/core/storm.adoc">edit</a></div>
<p>As you can expect, for reading data (typically executing queries) elasticsearch-hadoop offers a dedicated <code class="literal">Spout</code> through <code class="literal">org.elasticsearch.storm.EsSpout</code> which executes the query in Elasticsearch and <em>streams</em> the results back to Apache Storm:</p>
<div class="pre_wrapper lang-java">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-java">import org.elasticsearch.storm.EsSpout; <a id="CO99-1"></a><i class="conum" data-value="1"></i>

TopologyBuilder builder = new TopologyBuilder();
builder.setSpout(
    "es-spout",
    new EsSpout(      <a id="CO99-2"></a><i class="conum" data-value="2"></i>
        "storm/docs", <a id="CO99-3"></a><i class="conum" data-value="3"></i>
        "?q=me*),     <a id="CO99-4"></a><i class="conum" data-value="4"></i>
    5);               <a id="CO99-5"></a><i class="conum" data-value="5"></i>
builder.setBolt("bolt", new PrinterBolt()).shuffleGrouping("es-spout");</pre>
</div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO99-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>elasticsearch-hadoop <code class="literal">EsSpout</code> package import</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO99-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p><code class="literal">EsSpout</code> declaration</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO99-3"><i class="conum" data-value="3"></i></a></p>
</td>
<td align="left" valign="top">
<p>The source Elasticsearch resource (index and type) for the data</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO99-4"><i class="conum" data-value="4"></i></a></p>
</td>
<td align="left" valign="top">
<p>The query to execute (optional) - if no query is specified, the entire indexed data is streamed</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO99-5"><i class="conum" data-value="5"></i></a></p>
</td>
<td align="left" valign="top">
<p>The number of <code class="literal">EsSpout</code> instances for this topology. The number should <span class="strong strong"><strong>not</strong></span> be greater than the number of shards available for an index; if it does, it just wastes CPU cycles without improving performance.</p>
</td>
</tr>
</table>
</div>
<div class="important admon">
<div class="icon"></div>
<div class="admon_content">
<p>The number of <code class="literal">Spout</code> instances depends highly on your topology and environment. Typically you should use the number of shards of your target data as an indicator - if you index has 5 shards, create 5 <code class="literal">EsSpout</code>s; however sometimes the shards number might be considerably bigger than the number of <code class="literal">Spout</code>s you can add to your Apache Storm cluster; in that case, it is better to limit the number of <code class="literal">EsSpout</code> instances. Last but not least, adding more <code class="literal">EsSpout</code> instances than the number of shards of the source index does <span class="strong strong"><strong>not</strong></span> improve performance; in fact the extra instances will just waste resources without processing anything.</p>
</div>
</div>
<div class="position-relative"><h5><a id="_customizing_esspout_fields"></a>Customizing <code class="literal">EsSpout</code> fields</h5><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-hadoop/edit/5.0/docs/src/reference/asciidoc/core/storm.adoc">edit</a></div>
<p>Since Storm requires each <code class="literal">Spout</code> to declare its fields when creating a topology, by default <code class="literal">EsSpout</code> declares for its tuples a generic <code class="literal">doc</code> field containing the documents returned (one per tuple) from Elasticsearch. When dealing with structured data (documents sharing the same fields), one can configure the <code class="literal">EsSpout</code> to <em>declare</em> as fields the document properties effectively <em>unwrapping</em> the document as a <code class="literal">Tuple</code>. By setting up <code class="literal">es.storm.spout.fields</code>, <code class="literal">EsSpout</code> will use them indicate to the Storm topology the tuple content and extract them from the returned document.</p>
<p>For example if the Elasticsearch documents contain 3 fields: <code class="literal">name</code>, <code class="literal">age</code> and <code class="literal">gender</code> by setting <code class="literal">es.storm.spout.fields</code> to <code class="literal">name, age, gender</code>, instead of returning a tuple with one field (<code class="literal">doc</code>, containing the document), a tuple containing
the three named fields (<code class="literal">name</code>, <code class="literal">age</code> and <code class="literal">gender</code>) will be returned instead.</p>
</div>
</div>
</div><div class="navfooter">
<span class="prev">
<a href="spark.html">« Apache Spark support</a>
</span>
<span class="next">
<a href="mapping.html">Mapping and Types »</a>
</span>
</div>
</body>
</html>
