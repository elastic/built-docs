<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="description" content="Reference documentation of elasticsearch-hadoop">
<title>Architecture | Elasticsearch for Apache Hadoop [6.7] | Elastic</title>
<link rel="home" href="index.html" title="Elasticsearch for Apache Hadoop [6.7]"/>
<link rel="up" href="reference.html" title="Elasticsearch for Apache Hadoop"/>
<link rel="prev" href="install.html" title="Installation"/>
<link rel="next" href="configuration.html" title="Configuration"/>
<meta name="DC.type" content="Learn/Docs/Elasticsearch/Apache Hadoop/6.7"/>
<meta name="DC.subject" content="Elasticsearch"/>
<meta name="DC.identifier" content="6.7"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body><div class="page_header">
<strong>IMPORTANT</strong>: No additional bug fixes or documentation updates
will be released for this version. For the latest information, see the
<a href="../current/index.html">current release documentation</a>.
</div>
<div id="content">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="index.html">Elasticsearch for Apache Hadoop [6.7]</a></span>
»
<span class="breadcrumb-link"><a href="reference.html">Elasticsearch for Apache Hadoop</a></span>
»
<span class="breadcrumb-node">Architecture</span>
</div>
<div class="navheader">
<span class="prev">
<a href="install.html">« Installation</a>
</span>
<span class="next">
<a href="configuration.html">Configuration »</a>
</span>
</div>
<div class="chapter">
<div class="titlepage"><div><div>
<h2 class="title"><a id="arch"></a>Architecture<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-hadoop/edit/6.7/docs/src/reference/asciidoc/core/arch.adoc">edit</a></h2>
</div></div></div>
<p>At the core, elasticsearch-hadoop integrates two <em>distributed</em> systems: <span class="strong strong"><strong>Hadoop</strong></span>, a distributed computing platform and <span class="strong strong"><strong>Elasticsearch</strong></span>, a real-time search and analytics engine. From a high-level view both provide a computational component: Hadoop through Map/Reduce or recent libraries like Apache Spark on one hand, and Elasticsearch through its search and aggregation on the other.</p>
<p>elasticsearch-hadoop goal is to <em>connect</em> these two entities so that they can transparently benefit from each other.</p>
<h3><a id="arch-shards"></a>Map/Reduce and Shards<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-hadoop/edit/6.7/docs/src/reference/asciidoc/core/arch.adoc">edit</a></h3>
<p>A critical component for scalability is parallelism or splitting a task into multiple, smaller ones that execute at the same time, on different nodes in the cluster. The concept is present in both Hadoop through its <code class="literal">splits</code> (the number of parts in which a source or input can be divided) and Elasticsearch through <a href="http://www.elastic.co/guide/en/elasticsearch/reference/5.0/glossary.html#glossary-shard" class="ulink" target="_top"><code class="literal">shards</code></a> (the number of parts in which a index is divided into).</p>
<p>In short, roughly speaking more input splits means more tasks that can read at the same time, different parts of the source. More shards means more <em>buckets</em> from which to read an index content (at the same time).</p>
<p>As such, elasticsearch-hadoop uses splits and shards as the main drivers behind the number of tasks executed within the Hadoop and Elasticsearch clusters as they have a direct impact on parallelism.</p>
<div class="tip admon">
<div class="icon"></div>
<div class="admon_content">
<p>Hadoop <code class="literal">splits</code> as well as Elasticsearch <code class="literal">shards</code> play an important role regarding a system behavior - we recommend familiarizing with the two concepts to get a better understanding of your system runtime semantics.</p>
</div>
</div>
<h3><a id="arch-spark"></a>Apache Spark and Shards<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-hadoop/edit/6.7/docs/src/reference/asciidoc/core/arch.adoc">edit</a></h3>
<p>While Apache Spark is not built on top of Map/Reduce it shares similar concepts: it features the concept of <code class="literal">partition</code> which is the rough equivalent of Elasticsearch <code class="literal">shard</code> or the Map/Reduce <code class="literal">split</code>. Thus, the analogy above applies here as well - more shards and/or more partitions increase the number of parallelism and thus allows both systems to scale better.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>Due to the similarity in concepts, through-out the docs one can think interchangebly of Hadoop <code class="literal">InputSplit</code> s and Spark <code class="literal">Partition</code> s.</p>
</div>
</div>
<h3><a id="arch-reading"></a>Reading from Elasticsearch<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-hadoop/edit/6.7/docs/src/reference/asciidoc/core/arch.adoc">edit</a></h3>
<p>Shards play a critical role when reading information from Elasticsearch. Since it acts as a source, elasticsearch-hadoop will create one Hadoop <code class="literal">InputSplit</code> per Elasticsearch shard, or in case of Apache Spark one <code class="literal">Partition</code>, that is given a query that works against index <code class="literal">I</code>. elasticsearch-hadoop will dynamically discover the number of shards backing <code class="literal">I</code> and then for each shard will create, in case of Hadoop an input split (which will determine the maximum number of Hadoop tasks to be executed) or in case of Spark a partition which will determine the <code class="literal">RDD</code> maximum parallelism.</p>
<p>With the default settings, Elasticsearch uses <span class="strong strong"><strong>5</strong></span> <a href="http://www.elastic.co/guide/en/elasticsearch/reference/5.0/glossary.html#glossary-primary-shard" class="ulink" target="_top"><code class="literal">primary</code></a> shards per index which will result in the same number of tasks on the Hadoop side for each query.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>elasticsearch-hadoop does not query the same shards - it iterates through all of them (primaries and replicas) using a round-robin approach. To avoid data duplication, only one shard is used from each shard group (primary and replicas).</p>
</div>
</div>
<p>A common concern (read optimization) for improving performance is to increase the number of shards and thus increase the number of tasks on the Hadoop side. Unless such gains are demonstrated through benchmarks, we recommend against such a measure since in most cases, an Elasticsearch shard can <span class="strong strong"><strong>easily</strong></span> handle data streaming to a Hadoop or Spark task.</p>
<h3><a id="arch-writing"></a>Writing to Elasticsearch<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-hadoop/edit/6.7/docs/src/reference/asciidoc/core/arch.adoc">edit</a></h3>
<p>Writing to Elasticsearch is driven by the number of Hadoop input splits (or tasks) or Spark partitions available. elasticsearch-hadoop detects the number of (primary) shards where the write will occur and distributes the writes between these. The more splits/partitions available, the more mappers/reducers can write data in parallel to Elasticsearch.</p>
<h3><a id="arch-colocation"></a>Data co-location<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-hadoop/edit/6.7/docs/src/reference/asciidoc/core/arch.adoc">edit</a></h3>
<p>Whenever possible, elasticsearch-hadoop shares the Elasticsearch cluster information with Hadoop and Spark to facilitate data co-location. In practice, this means whenever data is read from Elasticsearch, the source nodes' IPs are passed on to Hadoop and Spark to optimize task execution. If co-location is desired/possible, hosting the Elasticsearch and Hadoop and Spark clusters within the same rack will provide significant network savings.</p>
</div>
<div class="navfooter">
<span class="prev">
<a href="install.html">« Installation</a>
</span>
<span class="next">
<a href="configuration.html">Configuration »</a>
</span>
</div>
</div>
</body>
</html>
