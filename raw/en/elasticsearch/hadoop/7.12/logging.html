<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="description" content="Reference documentation of elasticsearch-hadoop">
<title>Logging | Elasticsearch for Apache Hadoop [7.12] | Elastic</title>
<link rel="home" href="index.html" title="Elasticsearch for Apache Hadoop [7.12]"/>
<link rel="up" href="reference.html" title="Elasticsearch for Apache Hadoop"/>
<link rel="prev" href="security.html" title="Security"/>
<link rel="next" href="mapreduce.html" title="Map/Reduce integration"/>
<meta name="DC.type" content="Learn/Docs/Elasticsearch/Apache Hadoop/7.12"/>
<meta name="DC.subject" content="Elasticsearch"/>
<meta name="DC.identifier" content="7.12"/>
</head>
<body><div class="page_header">
You are looking at preliminary documentation for a future release.
Not what you want? See the
<a href="../current/index.html">current release documentation</a>.
</div>
<div id="content">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="index.html">Elasticsearch for Apache Hadoop [7.12]</a></span>
»
<span class="breadcrumb-link"><a href="reference.html">Elasticsearch for Apache Hadoop</a></span>
»
<span class="breadcrumb-node">Logging</span>
</div>
<div class="navheader">
<span class="prev">
<a href="security.html">« Security</a>
</span>
<span class="next">
<a href="mapreduce.html">Map/Reduce integration »</a>
</span>
</div>
<div class="chapter">
<div class="titlepage"><div><div>
<h2 class="title"><a id="logging"></a>Logging<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch-hadoop/edit/7.12/docs/src/reference/asciidoc/core/configuration.adoc">edit</a></h2>
</div></div></div>
<p>elasticsearch-hadoop uses <a href="http://commons.apache.org/proper/commons-logging/" class="ulink" target="_top">commons-logging</a> library, same as Hadoop, for its logging infrastructure and thus it shares the same configuration means. Out of the box, no configuration is required - by default, elasticsearch-hadoop logs relevant information about the job progress at <code class="literal">INFO</code> level. Typically, whatever integration you are using (Map/Reduce, Hive, Pig), each job will print in the console at least one message indicating the elasticsearch-hadoop version used:</p>
<div class="pre_wrapper lang-bash">
<pre class="programlisting prettyprint lang-bash">16:13:01,946  INFO main util.Version - Elasticsearch Hadoop v2.0.0.BUILD-SNAPSHOT [f2c5c3e280]</pre>
</div>
<p>Configuring logging for Hadoop (or Hive and Pig) is outside the scope of this documentation, however in short, at runtime, Hadoop relies on <a href="http://logging.apache.org/log4j/1.2/" class="ulink" target="_top">log4j 1.2</a> as an actual logging implementation. In practice, this means adding the package name of interest and its level logging the <code class="literal">log4j.properties</code> file in the job classpath.
elasticsearch-hadoop provides the following important packages:</p>
<div class="informaltable">
<table border="1" cellpadding="4px">
<colgroup>
<col class="col_1"/>
<col class="col_2"/>
</colgroup>
<thead>
<tr>
<th align="center" valign="top">Package</th>
<th align="center" valign="top">Purpose</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" valign="top"><p><code class="literal">org.elasticsearch.hadoop.hive</code></p></td>
<td align="center" valign="top"><p>Apache Hive integration</p></td>
</tr>
<tr>
<td align="center" valign="top"><p><code class="literal">org.elasticsearch.hadoop.mr</code></p></td>
<td align="center" valign="top"><p>Map/Reduce functionality</p></td>
</tr>
<tr>
<td align="center" valign="top"><p><code class="literal">org.elasticsearch.hadoop.pig</code></p></td>
<td align="center" valign="top"><p>Apache Pig integration</p></td>
</tr>
<tr>
<td align="center" valign="top"><p><code class="literal">org.elasticsearch.hadoop.rest</code></p></td>
<td align="center" valign="top"><p>REST/transport infrastructure</p></td>
</tr>
<tr>
<td align="center" valign="top"><p><code class="literal">org.elasticsearch.hadoop.serialization</code></p></td>
<td align="center" valign="top"><p>Serialization package</p></td>
</tr>
<tr>
<td align="center" valign="top"><p><code class="literal">org.elasticsearch.spark</code></p></td>
<td align="center" valign="top"><p>Apache Spark package</p></td>
</tr>
<tr>
<td align="center" valign="top"><p><code class="literal">org.elasticsearch.storm</code></p></td>
<td align="center" valign="top"><p>Apache Storm package</p></td>
</tr>
</tbody>
</table>
</div>
<p>The default logging level (<code class="literal">INFO</code>) is suitable for day-to-day use; if troubleshooting is needed, consider switching to <code class="literal">DEBUG</code> but be selective of the packages included. For low-level details, enable level <code class="literal">TRACE</code> however do remember that it will result in a <span class="strong strong"><strong>significant</strong></span> amount of logging data which <em>will</em> impact your job performance and environment.</p>
<p>To put everything together, if you want to enable <code class="literal">DEBUG</code> logging on the Map/Reduce package make changes to the <code class="literal">log4j.properties</code> (used by your environment):</p>
<div class="pre_wrapper lang-bash">
<pre class="programlisting prettyprint lang-bash">log4j.category.org.elasticsearch.hadoop.mr=DEBUG</pre>
</div>
<div class="tip admon">
<div class="icon"></div>
<div class="admon_content">
<p>See the log4j <a href="https://logging.apache.org/log4j/1.2/apidocs/org/apache/log4j/PropertyConfigurator.html#doConfigure%28java.lang.String,%20org.apache.log4j.spi.LoggerRepository%29" class="ulink" target="_top">javadoc</a> for more information.</p>
</div>
</div>
<div class="section">
<div class="titlepage"><div><div>
<h2 class="title"><a id="_configure_the_executing_jvm_logging_not_the_client"></a>Configure the <em>executing</em> JVM logging not the client<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch-hadoop/edit/7.12/docs/src/reference/asciidoc/core/configuration.adoc">edit</a></h2>
</div></div></div>
<p>One thing to note is that in almost all cases, one needs to configure logging in the <em>executing</em> JVM, where the Map/Reduce tasks actually run and not on the client, where the job is assembled or monitored. Depending on your library, platform and version this can done through some dedicated settings.
In particular Map/Reduce-based libraries like Pig or Hive can be difficult to configure since at runtime, they create Map/Reduce tasks to actually perform the work. Thus, one needs to configure logging and pass the configuration to the Map/Reduce layer for logging to occur.
In both cases, this can be achieved through the <code class="literal">SET</code> command. In particular when using Hadoop 2.6, one can use <code class="literal">mapreduce.job.log4j-properties-file</code> along with an appropriate <a href="https://github.com/apache/hadoop/blob/release-2.6.0/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/resources/container-log4j.properties" class="ulink" target="_top"><code class="literal">container-log4j.properties</code></a> file.
It&#8217;s worth mentioning that Pig allows jobs to be executed locally and logging to be enabled through <code class="literal">pig -x local -4 myLoggingFile someScript.pig</code></p>
</div>

</div>
<div class="navfooter">
<span class="prev">
<a href="security.html">« Security</a>
</span>
<span class="next">
<a href="mapreduce.html">Map/Reduce integration »</a>
</span>
</div>
</div>
</body>
</html>
