<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="description" content="Reference documentation of elasticsearch-hadoop">
<title>Mapping and Types | Elasticsearch for Apache Hadoop [8.14] | Elastic</title>
<meta class="elastic" name="content" content="Mapping and Types | Elasticsearch for Apache Hadoop [8.14]">

<link rel="home" href="index.html" title="Elasticsearch for Apache Hadoop [8.14]"/>
<link rel="up" href="reference.html" title="Elasticsearch for Apache Hadoop"/>
<link rel="prev" href="spark.html" title="Apache Spark support"/>
<link rel="next" href="errorhandlers.html" title="Error Handlers"/>
<meta class="elastic" name="product_version" content="8.14"/>
<meta class="elastic" name="product_name" content="Elasticsearch"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/Elasticsearch/Apache Hadoop/8.14"/>
<meta name="DC.subject" content="Elasticsearch"/>
<meta name="DC.identifier" content="8.14"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body>
<div class="page_header">
<strong>IMPORTANT</strong>: No additional bug fixes or documentation updates
will be released for this version. For the latest information, see the
<a href="../current/index.html">current release documentation</a>.
</div>
<div class="navheader">
<span class="prev">
<a href="spark.html">« Apache Spark support</a>
</span>
<span class="next">
<a href="errorhandlers.html">Error Handlers »</a>
</span>
</div>
<div class="book" lang="en">
<div class="titlepage">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Elasticsearch for Apache Hadoop [8.14]</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="reference.html">Elasticsearch for Apache Hadoop</a></span>
</div>
<div>
<div><h1 class="title"><a id="id-1"></a>Mapping and Types</h1><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-hadoop/edit/8.14/docs/src/reference/asciidoc/core/mapping.adoc">edit</a></div>
</div>
<!--EXTRA-->
</div>
<div id="content">
<div class="chapter">
<div class="titlepage"><div><div>
<h2 class="title"><a id="mapping"></a>Mapping and Types<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-hadoop/edit/8.14/docs/src/reference/asciidoc/core/mapping.adoc">edit</a></h2>
</div></div></div>
<p>As explained in the previous sections, elasticsearch-hadoop integrates closely with the Hadoop ecosystem and performs close introspection of the type information so that the data flow between Elasticsearch and Hadoop is as transparent as possible.
This section takes a closer look at how the type conversion takes place and how data is mapped between the two systems.</p>
<h3><a id="_converting_data_to_elasticsearch"></a>Converting data to Elasticsearch<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-hadoop/edit/8.14/docs/src/reference/asciidoc/core/mapping.adoc">edit</a></h3>
<p>By design, elasticsearch-hadoop provides no data transformation or mapping layer itself simply because there is no need for them: Hadoop is designed to do ETL and some libraries (like Pig and Hive) provide type information themselves. Furthermore, Elasticsearch has rich support for mapping out of the box including automatic detection,  dynamic/schema-less mapping, templates and full manual control.
Need to split strings into token, do data validation or eliminate unneeded data? There are plenty of ways to do that in Hadoop before reading/writing data from/to Elasticsearch. Need control over how data is stored in Elasticsearch? Use Elasticsearch APIs to define the  <a href="/guide/en/elasticsearch/reference/8.14/indices-put-mapping.html" class="ulink" target="_top">mapping</a>, to update <a href="/guide/en/elasticsearch/reference/8.14/indices-update-settings.html" class="ulink" target="_top">settings</a> or add generic <a href="/guide/en/elasticsearch/reference/8.14/mapping-fields.html" class="ulink" target="_top">meta-data</a>.</p>
<h3><a id="mapping-date"></a>Time/Date mapping<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-hadoop/edit/8.14/docs/src/reference/asciidoc/core/mapping.adoc">edit</a></h3>
<p>When it comes to handling dates, Elasticsearch always uses the <a href="http://en.wikipedia.org/wiki/ISO_8601" class="ulink" target="_top">ISO 8601</a> format for date/time. This is the default date format of Elasticsearch - if a custom one is needed, please <span class="strong strong"><strong>add</strong></span> it to the default option rather then just replacing it. See the <a href="/guide/en/elasticsearch/reference/8.14/mapping-date-format.html" class="ulink" target="_top">date format</a> section in Elasticsearch reference documentation for more information.
Note that when reading data, if the date is not in ISO8601 format, by default elasticsearch-hadoop will likely not understand it as it does not replicate the elaborate date parsing in Elasticsearch. In these cases one can simply disable the date conversion
and pass the raw information as a <code class="literal">long</code> or <code class="literal">String</code>, through the <code class="literal">es.mapping.date.rich</code> <a class="xref" href="configuration.html#cfg-field-info" title="Field information (when reading from Elasticsearch)">property</a>.</p>
<p>As a side note, elasticsearch-hadoop tries to detect whether dedicated date parsing libraries (in particular Joda, used also by Elasticsearch) are available at runtime and if so, will use them. If not, it will default to parsing using JDK classes which are not
as rich. Going forward especially with the advent of JDK 8, elasticsearch-hadoop will try to migrate to <code class="literal">javax.time</code> library to have the same behaviour regardless of the classpath available at runtime.</p>
<h3><a id="mapping-arrays"></a>Ordering and Mapping<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-hadoop/edit/8.14/docs/src/reference/asciidoc/core/mapping.adoc">edit</a></h3>
<p>It is important to note that JSON objects (delimited by <code class="literal">{}</code> and typically associated with maps) are <span class="strong strong"><strong>unordered</strong></span>, in other words, they do <span class="strong strong"><strong>not</strong></span> maintain order. JSON
arrays (typically associated with lists or sequences) are <span class="strong strong"><strong>ordered</strong></span>, that is, they <span class="strong strong"><strong>do</strong></span> preserve the initial insertion order. This impacts the way objects are read from Elasticsearch as one might find the insertion structure to be different than the extraction one.
It is however easy to circumvent this problem - as JSON objects (maps) contain fields, use the field names (or keys) instead of their position inside the document to reliably get their values (in Java terms think of a JSON object as a <code class="literal">HashMap</code> as oppose to a <code class="literal">LinkedHashMap</code>).</p>
<h3><a id="mapping-geo"></a>Geo types<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-hadoop/edit/8.14/docs/src/reference/asciidoc/core/mapping.adoc">edit</a></h3>
<p>For geolocation Elasticsearch provides two dedicated types, namely <a href="/guide/en/elasticsearch/reference/2.1/geo-point.html" class="ulink" target="_top"><code class="literal">geo_point</code></a> and <a href="/guide/en/elasticsearch/reference/2.1/geo-shape.html" class="ulink" target="_top"><code class="literal">geo_shape</code></a>
which do not have a direct equivalent in any of the libraries elasticsearch-hadoop integrates with. Further more, Elasticsearch accepts multiple formats for each type (as there are different ways to represent data), in fact there are 4 different representations
for <code class="literal">geo_point</code> and 9 for <code class="literal">geo_shape</code>.
To go around this, the connector breaks down the geo types into primitives depending on the actual format used for their respective types.</p>
<p>For strongly-typed libraries (like SparkSQL <code class="literal">DataFrame</code>s), the format needs to be known before hand and thus, elasticsearch-hadoop will <em>sample</em> the data asking elasticsearch-hadoop for one random document that is representative of the mapping, parse it and based
on the values found, identify the format used and create the necessary schema. This happens automatically at start-up without any user interference. As always, the user data must all be using the <em>same</em> format (a requirement from
SparkSQL) otherwise reading a different format will trigger an exception.</p>
<p>Note that typically handling of these types poses no issues for the user whether reading or writing data.</p>
<h3><a id="mapping-multi-values"></a>Handling array/multi-values fields<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-hadoop/edit/8.14/docs/src/reference/asciidoc/core/mapping.adoc">edit</a></h3>
<p>Elasticsearch treats fields with single or multi-values the same; in fact, the mapping provides no information about this. As a client, it means one cannot tell whether a field is single-valued or not until is actually being read. In most cases this is not an issue and elasticsearch-hadoop automatically creates the necessary list/array on the fly. However in environments with strict schema such as Spark SQL, changing a field actual value from its declared type is not allowed. Worse yet, this information needs to be available even before reading the data. Since the mapping is not conclusive enough, elasticsearch-hadoop allows the user to specify the extra information through <a class="xref" href="configuration.html#cfg-field-info" title="Field information (when reading from Elasticsearch)">field information</a>, specifically <code class="literal">es.read.field.as.array.include</code> and <code class="literal">es.read.field.as.array.exclude</code>.</p>
<h3><a id="_automatic_mapping"></a>Automatic mapping<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-hadoop/edit/8.14/docs/src/reference/asciidoc/core/mapping.adoc">edit</a></h3>
<p>By default, Elasticsearch provides <a href="/guide/en/elasticsearch/reference/8.14/docs-index_.html" class="ulink" target="_top">automatic index and mapping</a> when data is added under an index that has not been created before. In other words, data can be added into Elasticsearch without the index and the mappings being defined a priori. This is quite convenient since Elasticsearch automatically adapts to the data being fed to it - moreover, if certain entries have extra fields, Elasticsearch schema-less nature allows them to be indexed without any issues.</p>
<p><a id="auto-mapping-type-loss"></a>It is important to remember that automatic mapping uses the payload values to identify the <a href="/guide/en/elasticsearch/reference/8.14/mapping-types.html" class="ulink" target="_top">field types</a>, using the <span class="strong strong"><strong>first document</strong></span> that adds each field. elasticsearch-hadoop communicates with Elasticsearch through JSON which does not provide any type information, rather only the field names and their values. One can think of it as <em>type erasure</em> or information loss; for example JSON does not differentiate integer numeric types - <code class="literal">byte</code>, <code class="literal">short</code>, <code class="literal">int</code>, <code class="literal">long</code> are all placed in the same <code class="literal">long</code> <em>bucket</em>. this can have unexpected side-effects since the type information is <em>guessed</em> such as:</p>
<h5><a id="_numbers_mapped_only_as_longdouble"></a>numbers mapped only as <code class="literal">long</code>/<code class="literal">double</code><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-hadoop/edit/8.14/docs/src/reference/asciidoc/core/mapping.adoc">edit</a></h5>
<p>Whenever Elasticsearch encounters a number, it will allocate the largest type for it since it does not know the exact number type of the field. Allocating a small type (such as <code class="literal">byte</code>, <code class="literal">int</code> or <code class="literal">float</code>) can lead to problems if a future document is larger, so Elasticsearch uses a safe default.
For example, the document:</p>
<div class="pre_wrapper lang-json">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-json">{
    "tweet" {
        "user" : "kimchy",
        "message" : "This is a tweet!",
        "postDate" : "2009-11-15T14:12:12",
        "priority" : 4,
        "rank" : 12.3
    }
}</pre>
</div>
<p>triggers the following mapping:</p>
<div class="pre_wrapper lang-json">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-json">{ "test" : {
    "mappings" : {
      "index" : {
        "properties" : {
          "message" : {
            "type" : "string"
          },
          "postDate" : {
            "type" : "date",
            "format" : "dateOptionalTime"      <a id="CO74-1"></a><i class="conum" data-value="1"></i>
          },
          "priority" : {
            "type" : "long"                    <a id="CO74-2"></a><i class="conum" data-value="2"></i>
          },
          "rank" : {
            "type" : "double"                  <a id="CO74-3"></a><i class="conum" data-value="3"></i>
          },
          "user" : {
            "type" : "string"
          }
        }
      }
    }
  }
}</pre>
</div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO74-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>The <em>postDate</em> field was recognized as a date in ISO 8601 format (<code class="literal">dateOptionalTime</code>)</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO74-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p>The <em>integer</em> number (<code class="literal">4</code>) was mapped to the largest available type (<code class="literal">long</code>)</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO74-3"><i class="conum" data-value="3"></i></a></p>
</td>
<td align="left" valign="top">
<p>The <em>fractional</em> number (<code class="literal">12.3</code>) was mapped to the largest available type (<code class="literal">double</code>)</p>
</td>
</tr>
</table>
</div>
<h5><a id="_incorrect_mapping"></a>incorrect mapping<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-hadoop/edit/8.14/docs/src/reference/asciidoc/core/mapping.adoc">edit</a></h5>
<p>This happens when a string field contains numbers (say <code class="literal">1234</code>) - Elasticsearch has no information that the number is actually a string and thus it map the field as a number, causing a parsing exception when a string is encountered.
For example, this document:</p>
<div class="pre_wrapper lang-json">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-json">{ "array":[123, "string"] }</pre>
</div>
<p>causes an exception with automatic mapping:</p>
<div class="pre_wrapper lang-json">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-json">{"error":"MapperParsingException[failed to parse [array]]; nested: NumberFormatException[For input string: \"string\"]; ","status":400}</pre>
</div>
<p>because the field <code class="literal">array</code> is initially detected as a number (because of <code class="literal">123</code>) which causes <code class="literal">"string"</code> to trigger the parsing exception since clearly it is not a number. The same issue tends to occur with strings might be
interpreted as dates.</p>
<p>Hence if the defaults need to be overridden and/or if you experience the problems exposed above, potentially due to a diverse dataset, consider using <a class="xref" href="mapping.html#explicit-mapping" title="Explicit mapping">Explicit mapping</a>.</p>
<h4><a id="_disabling_automatic_mapping"></a>Disabling automatic mapping<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-hadoop/edit/8.14/docs/src/reference/asciidoc/core/mapping.adoc">edit</a></h4>
<p>Elasticsearch allows <em>automatic index creation</em> as well as <em>dynamic mapping</em> (for extra fields present in documents) to be disabled through the <code class="literal">action.auto_create_index</code> and <code class="literal">index.mapper.dynamic</code> settings on the nodes config files. As a safety net, elasticsearch-hadoop provides a dedicated configuration <a class="xref" href="configuration.html#configuration-options-index" title="Index">option</a> <code class="literal">es.index.auto.create</code> which allows elasticsearch-hadoop to either create the index or not without having to modify the Elasticsearch cluster options.</p>
<h3><a id="explicit-mapping"></a>Explicit mapping<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-hadoop/edit/8.14/docs/src/reference/asciidoc/core/mapping.adoc">edit</a></h3>
<p>Explicit or manual mapping should be considered when the defaults need to be overridden, if the data is detected incorrectly (as explained above) or, in most cases, to customize the index analysis.
Refer to Elasticsearch <a href="/guide/en/elasticsearch/reference/8.14/indices-create-index.html" class="ulink" target="_top">create index</a> and <a href="/guide/en/elasticsearch/reference/8.14/indices-put-mapping.html" class="ulink" target="_top">mapping</a> documentation on how to define an index and its types - note that these need to be present <span class="strong strong"><strong>before</strong></span> data is being uploaded to Elasticsearch (otherwise automatic mapping will be used by Elasticsearch, if enabled).</p>
<div class="tip admon">
<div class="icon"></div>
<div class="admon_content">
<p>In most cases, <a href="/guide/en/elasticsearch/reference/8.14/indices-templates.html" class="ulink" target="_top">templates</a> are quite handy as they are automatically applied to new indices created that match the pattern; in other words instead of defining the mapping per index, one can just define the template once and then have it applied to all indices that match its pattern.</p>
</div>
</div>
<h3><a id="limitations"></a>Limitations<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch-hadoop/edit/8.14/docs/src/reference/asciidoc/core/mapping.adoc">edit</a></h3>
<p>Elasticsearch allows field names to contain dots (<em>.</em>). But ES-Hadoop does not support them, and fails when reading or writing fields with dots. Refer to
 Elasticsearch <a href="/guide/en/elasticsearch/reference/8.14/dot-expand-processor.html" class="ulink" target="_top">Dot Expander Processor</a> for tooling to assist replacing dots in field names.</p>
</div>
</div>
</div><div class="navfooter">
<span class="prev">
<a href="spark.html">« Apache Spark support</a>
</span>
<span class="next">
<a href="errorhandlers.html">Error Handlers »</a>
</span>
</div>
</body>
</html>
