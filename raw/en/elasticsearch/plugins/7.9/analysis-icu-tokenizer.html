<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>ICU Tokenizer | Elasticsearch Plugins and Integrations [7.9] | Elastic</title>
<link rel="home" href="index.html" title="Elasticsearch Plugins and Integrations [7.9]"/>
<link rel="up" href="analysis-icu.html" title="ICU Analysis Plugin"/>
<link rel="prev" href="analysis-icu-normalization-charfilter.html" title="ICU Normalization Character Filter"/>
<link rel="next" href="analysis-icu-normalization.html" title="ICU Normalization Token Filter"/>
<meta name="DC.type" content="Learn/Docs/Elasticsearch/Plugins/7.9"/>
<meta name="DC.subject" content="Elasticsearch"/>
<meta name="DC.identifier" content="7.9"/>
</head>
<body><div class="page_header">
A newer version is available. For the latest information, see the
<a href="../current/index.html">current release documentation</a>.
</div>
<div id="content">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="index.html">Elasticsearch Plugins and Integrations [7.9]</a></span>
»
<span class="breadcrumb-link"><a href="analysis.html">Analysis Plugins</a></span>
»
<span class="breadcrumb-link"><a href="analysis-icu.html">ICU Analysis Plugin</a></span>
»
<span class="breadcrumb-node">ICU Tokenizer</span>
</div>
<div class="navheader">
<span class="prev">
<a href="analysis-icu-normalization-charfilter.html">« ICU Normalization Character Filter</a>
</span>
<span class="next">
<a href="analysis-icu-normalization.html">ICU Normalization Token Filter »</a>
</span>
</div>
<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="analysis-icu-tokenizer"></a>ICU Tokenizer<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/7.9/docs/plugins/analysis-icu.asciidoc">edit</a></h3>
</div></div></div>
<p>Tokenizes text into words on word boundaries, as defined in
<a href="https://www.unicode.org/reports/tr29/" class="ulink" target="_top">UAX #29: Unicode Text Segmentation</a>.
It behaves much like the <a href="/guide/en/elasticsearch/reference/7.9/analysis-standard-tokenizer.html" class="ulink" target="_top"><code class="literal">standard</code> tokenizer</a>,
but adds better support for some Asian languages by using a dictionary-based
approach to identify words in Thai, Lao, Chinese, Japanese, and Korean, and
using custom rules to break Myanmar and Khmer text into syllables.</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">PUT icu_sample
{
  "settings": {
    "index": {
      "analysis": {
        "analyzer": {
          "my_icu_analyzer": {
            "tokenizer": "icu_tokenizer"
          }
        }
      }
    }
  }
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/2.console"></div>
<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="_rules_customization"></a>Rules customization<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/7.9/docs/plugins/analysis-icu.asciidoc">edit</a></h4>
</div></div></div>
<div class="warning admon">
<div class="icon"></div>
<div class="admon_content">
<p>This functionality is marked as experimental in Lucene</p>
</div>
</div>
<p>You can customize the <code class="literal">icu-tokenizer</code> behavior by specifying per-script rule files, see the
<a href="http://userguide.icu-project.org/boundaryanalysis#TOC-RBBI-Rules" class="ulink" target="_top">RBBI rules syntax reference</a>
for a more detailed explanation.</p>
<p>To add icu tokenizer rules, set the <code class="literal">rule_files</code> settings, which should contain a comma-separated list of
<code class="literal">code:rulefile</code> pairs in the following format:
<a href="https://unicode.org/iso15924/iso15924-codes.html" class="ulink" target="_top">four-letter ISO 15924 script code</a>,
followed by a colon, then a rule file name. Rule files are placed <code class="literal">ES_HOME/config</code> directory.</p>
<p>As a demonstration of how the rule files can be used, save the following user file to <code class="literal">$ES_HOME/config/KeywordTokenizer.rbbi</code>:</p>
<div class="pre_wrapper lang-text">
<pre class="programlisting prettyprint lang-text">.+ {200};</pre>
</div>
<p>Then create an analyzer to use this rule file as follows:</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">PUT icu_sample
{
  "settings": {
    "index": {
      "analysis": {
        "tokenizer": {
          "icu_user_file": {
            "type": "icu_tokenizer",
            "rule_files": "Latn:KeywordTokenizer.rbbi"
          }
        },
        "analyzer": {
          "my_analyzer": {
            "type": "custom",
            "tokenizer": "icu_user_file"
          }
        }
      }
    }
  }
}

GET icu_sample/_analyze
{
  "analyzer": "my_analyzer",
  "text": "Elasticsearch. Wow!"
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/3.console"></div>
<p>The above <code class="literal">analyze</code> request returns the following:</p>
<div class="pre_wrapper lang-console-result">
<pre class="programlisting prettyprint lang-console-result">{
   "tokens": [
      {
         "token": "Elasticsearch. Wow!",
         "start_offset": 0,
         "end_offset": 19,
         "type": "&lt;ALPHANUM&gt;",
         "position": 0
      }
   ]
}</pre>
</div>
</div>

</div>
<div class="navfooter">
<span class="prev">
<a href="analysis-icu-normalization-charfilter.html">« ICU Normalization Character Filter</a>
</span>
<span class="next">
<a href="analysis-icu-normalization.html">ICU Normalization Token Filter »</a>
</span>
</div>
</div>
</body>
</html>
