<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Index Shard Allocation | Elasticsearch Reference [1.3] | Elastic</title>
<link rel="home" href="index.html" title="Elasticsearch Reference [1.3]"/>
<link rel="up" href="index-modules.html" title="Index Modules"/>
<link rel="prev" href="index-modules-analysis.html" title="Analysis"/>
<link rel="next" href="index-modules-slowlog.html" title="Index Slow Log"/>
<meta name="DC.type" content="Learn/Docs/Elasticsearch/Reference/1.3"/>
<meta name="DC.subject" content="Elasticsearch"/>
<meta name="DC.identifier" content="1.3"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body><div class="page_header">
<p>
  <strong>WARNING</strong>: Version 1.3 of Elasticsearch has passed its 
  <a href="https://www.elastic.co/support/eol">EOL date</a>. 
</p>  
<p>
  This documentation is no longer being maintained and may be removed. 
  If you are running this version, we strongly advise you to upgrade. 
  For the latest information, see the 
  <a href="../current/index.html">current release documentation</a>. 
</p>
</div>
<div id="content">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="index.html">Elasticsearch Reference [1.3]</a></span>
»
<span class="breadcrumb-link"><a href="index-modules.html">Index Modules</a></span>
»
<span class="breadcrumb-node">Index Shard Allocation</span>
</div>
<div class="navheader">
<span class="prev">
<a href="index-modules-analysis.html">« Analysis</a>
</span>
<span class="next">
<a href="index-modules-slowlog.html">Index Slow Log »</a>
</span>
</div>
<div class="chapter">
<div class="titlepage"><div><div>
<h2 class="title"><a id="index-modules-allocation"></a>Index Shard Allocation<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/1.3/docs/reference/index-modules/allocation.asciidoc">edit</a></h2>
</div></div></div>
<h3><a id="shard-allocation-filtering"></a>Shard Allocation Filtering<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/1.3/docs/reference/index-modules/allocation.asciidoc">edit</a></h3>
<p>Allows to control the allocation of indices on nodes based on include/exclude
filters. The filters can be set both on the index level and on the
cluster level. Lets start with an example of setting it on the cluster
level:</p>
<p>Lets say we have 4 nodes, each has specific attribute called <code class="literal">tag</code>
associated with it (the name of the attribute can be any name). Each
node has a specific value associated with <code class="literal">tag</code>. Node 1 has a setting
<code class="literal">node.tag: value1</code>, Node 2 a setting of <code class="literal">node.tag: value2</code>, and so on.</p>
<p>We can create an index that will only deploy on nodes that have <code class="literal">tag</code>
set to <code class="literal">value1</code> and <code class="literal">value2</code> by setting
<code class="literal">index.routing.allocation.include.tag</code> to <code class="literal">value1,value2</code>. For example:</p>
<div class="pre_wrapper lang-js">
<pre class="programlisting prettyprint lang-js">curl -XPUT localhost:9200/test/_settings -d '{
    "index.routing.allocation.include.tag" : "value1,value2"
}'</pre>
</div>
<p>On the other hand, we can create an index that will be deployed on all
nodes except for nodes with a <code class="literal">tag</code> of value <code class="literal">value3</code> by setting
<code class="literal">index.routing.allocation.exclude.tag</code> to <code class="literal">value3</code>. For example:</p>
<div class="pre_wrapper lang-js">
<pre class="programlisting prettyprint lang-js">curl -XPUT localhost:9200/test/_settings -d '{
    "index.routing.allocation.exclude.tag" : "value3"
}'</pre>
</div>
<p><code class="literal">index.routing.allocation.require.*</code> can be used to
specify a number of rules, all of which MUST match in order for a shard
to be allocated to a node. This is in contrast to <code class="literal">include</code> which will
include a node if ANY rule matches.</p>
<p>The <code class="literal">include</code>, <code class="literal">exclude</code> and <code class="literal">require</code> values can have generic simple
matching wildcards, for example, <code class="literal">value1*</code>. Additonally, special attribute
names called <code class="literal">_ip</code>, <code class="literal">_name</code>, <code class="literal">_id</code> and <code class="literal">_host</code> can be used to match by node
ip address, name, id or host name, respectively.</p>
<p>Obviously a node can have several attributes associated with it, and
both the attribute name and value are controlled in the setting. For
example, here is a sample of several node configurations:</p>
<div class="pre_wrapper lang-js">
<pre class="programlisting prettyprint lang-js">node.group1: group1_value1
node.group2: group2_value4</pre>
</div>
<p>In the same manner, <code class="literal">include</code>, <code class="literal">exclude</code> and <code class="literal">require</code> can work against
several attributes, for example:</p>
<div class="pre_wrapper lang-js">
<pre class="programlisting prettyprint lang-js">curl -XPUT localhost:9200/test/_settings -d '{
    "index.routing.allocation.include.group1" : "xxx"
    "index.routing.allocation.include.group2" : "yyy",
    "index.routing.allocation.exclude.group3" : "zzz",
    "index.routing.allocation.require.group4" : "aaa",
}'</pre>
</div>
<p>The provided settings can also be updated in real time using the update
settings API, allowing to "move" indices (shards) around in realtime.</p>
<p>Cluster wide filtering can also be defined, and be updated in real time
using the cluster update settings API. This setting can come in handy
for things like decommissioning nodes (even if the replica count is set
to 0). Here is a sample of how to decommission a node based on <code class="literal">_ip</code>
address:</p>
<div class="pre_wrapper lang-js">
<pre class="programlisting prettyprint lang-js">curl -XPUT localhost:9200/_cluster/settings -d '{
    "transient" : {
        "cluster.routing.allocation.exclude._ip" : "10.0.0.1"
    }
}'</pre>
</div>
<h3><a id="_total_shards_per_node"></a>Total Shards Per Node<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/1.3/docs/reference/index-modules/allocation.asciidoc">edit</a></h3>
<p>The <code class="literal">index.routing.allocation.total_shards_per_node</code> setting allows to
control how many total shards (replicas and primaries) for an index will be allocated per node.
It can be dynamically set on a live index using the update index
settings API.</p>
<h3><a id="disk"></a>Disk-based Shard Allocation<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/1.3/docs/reference/index-modules/allocation.asciidoc">edit</a></h3>
<p><span class="Admonishment Admonishment--change">
[<span class="Admonishment-version u-mono">1.3.0</span>]
<span class="Admonishment-detail">
Added in 1.3.0.
</span>
</span> disk based shard allocation is enabled from version 1.3.0 onward</p>
<p>Elasticsearch can be configured to prevent shard
allocation on nodes depending on disk usage for the node. This
functionality is enabled by default, and can be changed either in the
configuration file, or dynamically using:</p>
<div class="pre_wrapper lang-js">
<pre class="programlisting prettyprint lang-js">curl -XPUT localhost:9200/_cluster/settings -d '{
    "transient" : {
        "cluster.routing.allocation.disk.threshold_enabled" : false
    }
}'</pre>
</div>
<p>Once enabled, Elasticsearch uses two watermarks to decide whether
shards should be allocated or can remain on the node.</p>
<p><code class="literal">cluster.routing.allocation.disk.watermark.low</code> controls the low
watermark for disk usage. It defaults to 85%, meaning ES will not
allocate new shards to nodes once they have more than 85% disk
used. It can also be set to an absolute byte value (like 500mb) to
prevent ES from allocating shards if less than the configured amount
of space is available.</p>
<p><code class="literal">cluster.routing.allocation.disk.watermark.high</code> controls the high
watermark. It defaults to 90%, meaning ES will attempt to relocate
shards to another node if the node disk usage rises above 90%. It can
also be set to an absolute byte value (similar to the low watermark)
to relocate shards once less than the configured amount of space is
available on the node.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>Percentage values refer to used disk space, while byte values refer to
free disk space. This can be confusing, since it flips the meaning of
high and low. For example, it makes sense to set the low watermark to 10gb
and the high watermark to 5gb, but not the other way around.</p>
</div>
</div>
<p>Both watermark settings can be changed dynamically using the cluster
settings API. By default, Elasticsearch will retrieve information
about the disk usage of the nodes every 30 seconds. This can also be
changed by setting the <code class="literal">cluster.info.update.interval</code> setting.</p>
</div>
<div class="navfooter">
<span class="prev">
<a href="index-modules-analysis.html">« Analysis</a>
</span>
<span class="next">
<a href="index-modules-slowlog.html">Index Slow Log »</a>
</span>
</div>
</div>
</body>
</html>
