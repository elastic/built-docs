<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Cluster | Elasticsearch Guide [1.3] | Elastic</title>
<meta class="elastic" name="content" content="Cluster | Elasticsearch Guide [1.3]">

<link rel="home" href="index.html" title="Elasticsearch Guide [1.3]"/>
<link rel="up" href="modules.html" title="Modules"/>
<link rel="prev" href="modules.html" title="Modules"/>
<link rel="next" href="modules-discovery.html" title="Discovery"/>
<meta class="elastic" name="product_version" content="1.3"/>
<meta class="elastic" name="product_name" content="Elasticsearch"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/Elasticsearch/Reference/1.3"/>
<meta name="DC.subject" content="Elasticsearch"/>
<meta name="DC.identifier" content="1.3"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body>
<div class="page_header">
<p>
  <strong>WARNING</strong>: Version 1.3 of Elasticsearch has passed its 
  <a href="https://www.elastic.co/support/eol">EOL date</a>. 
</p>  
<p>
  This documentation is no longer being maintained and may be removed. 
  If you are running this version, we strongly advise you to upgrade. 
  For the latest information, see the 
  <a href="../current/index.html">current release documentation</a>. 
</p>
</div>
<div class="navheader">
<span class="prev">
<a href="modules.html">« Modules</a>
</span>
<span class="next">
<a href="modules-discovery.html">Discovery »</a>
</span>
</div>
<div class="book" lang="en">
<div class="titlepage">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Elasticsearch Guide [1.3]</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="modules.html">Modules</a></span>
</div>
<div>
<div><h1 class="title"><a id="id-1"></a>Cluster</h1><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/1.3/docs/reference/modules/cluster.asciidoc">edit</a></div>
</div>
<!--EXTRA-->
</div>
<div id="content">
<div class="chapter">
<div class="titlepage"><div><div>
<h2 class="title"><a id="modules-cluster"></a>Cluster<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/1.3/docs/reference/modules/cluster.asciidoc">edit</a></h2>
</div></div></div>
<h3><a id="shards-allocation"></a>Shards Allocation<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/1.3/docs/reference/modules/cluster.asciidoc">edit</a></h3>
<p>Shards allocation is the process of allocating shards to nodes. This can
happen during initial recovery, replica allocation, rebalancing, or
handling nodes being added or removed.</p>
<p>The following settings may be used:</p>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">cluster.routing.allocation.allow_rebalance</code>
</span>
</dt>
<dd>
Allow to control when rebalancing will happen based on the total
state of all the indices shards in the cluster. <code class="literal">always</code>,
<code class="literal">indices_primaries_active</code>, and <code class="literal">indices_all_active</code> are allowed,
defaulting to <code class="literal">indices_all_active</code> to reduce chatter during
initial recovery.
</dd>
<dt>
<span class="term">
<code class="literal">cluster.routing.allocation.cluster_concurrent_rebalance</code>
</span>
</dt>
<dd>
Allow to control how many concurrent rebalancing of shards are
allowed cluster wide, and default it to <code class="literal">2</code>.
</dd>
<dt>
<span class="term">
<code class="literal">cluster.routing.allocation.node_initial_primaries_recoveries</code>
</span>
</dt>
<dd>
Allow to control specifically the number of initial recoveries
of primaries that are allowed per node. Since most times local
gateway is used, those should be fast and we can handle more of
those per node without creating load.
</dd>
<dt>
<span class="term">
<code class="literal">cluster.routing.allocation.node_concurrent_recoveries</code>
</span>
</dt>
<dd>
How many concurrent recoveries are allowed to happen on a node.
Defaults to <code class="literal">2</code>.
</dd>
<dt>
<span class="term">
<code class="literal">cluster.routing.allocation.enable</code>
</span>
</dt>
<dd>
<p>
Controls shard allocation for all indices, by allowing specific
kinds of shard to be allocated.
</p>
<p>Can be set to:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">all</code> - (default) Allows shard allocation for all kinds of shards.
</li>
<li class="listitem">
<code class="literal">primaries</code> -  Allows shard allocation only for primary shards.
</li>
<li class="listitem">
<code class="literal">new_primaries</code> - Allows shard allocation only for primary shards for new indices.
</li>
<li class="listitem">
<code class="literal">none</code> - No shard allocations of any kind are allowed for all indices.
</li>
</ul>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">cluster.routing.allocation.disable_new_allocation</code>
</span>
</dt>
<dd>
<span class="Admonishment Admonishment--change">
[<span class="Admonishment-version u-mono u-strikethrough">1.0.0.RC1</span>]
<span class="Admonishment-detail">
Deprecated in 1.0.0.RC1. Replaced by <code class="literal">cluster.routing.allocation.enable</code>
</span>
</span>
</dd>
<dt>
<span class="term">
<code class="literal">cluster.routing.allocation.disable_allocation</code>
</span>
</dt>
<dd>
<span class="Admonishment Admonishment--change">
[<span class="Admonishment-version u-mono u-strikethrough">1.0.0.RC1</span>]
<span class="Admonishment-detail">
Deprecated in 1.0.0.RC1. Replaced by <code class="literal">cluster.routing.allocation.enable</code>
</span>
</span>
</dd>
<dt>
<span class="term">
<code class="literal">cluster.routing.allocation.disable_replica_allocation</code>
</span>
</dt>
<dd>
<span class="Admonishment Admonishment--change">
[<span class="Admonishment-version u-mono u-strikethrough">1.0.0.RC1</span>]
<span class="Admonishment-detail">
Deprecated in 1.0.0.RC1. Replaced by <code class="literal">cluster.routing.allocation.enable</code>
</span>
</span>
</dd>
<dt>
<span class="term">
<code class="literal">cluster.routing.allocation.same_shard.host</code>
</span>
</dt>
<dd>
Allows to perform a check to prevent allocation of multiple instances
of the same shard on a single host, based on host name and host address.
Defaults to <code class="literal">false</code>, meaning that no check is performed by default. This
setting only applies if multiple nodes are started on the same machine.
</dd>
<dt>
<span class="term">
<code class="literal">indices.recovery.concurrent_streams</code>
</span>
</dt>
<dd>
The number of streams to open (on a <span class="strong strong"><strong>node</strong></span> level) to recover a
shard from a peer shard. Defaults to <code class="literal">3</code>.
</dd>
</dl>
</div>
<h3><a id="allocation-awareness"></a>Shard Allocation Awareness<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/1.3/docs/reference/modules/cluster.asciidoc">edit</a></h3>
<p>Cluster allocation awareness allows to configure shard and replicas
allocation across generic attributes associated the nodes. Lets explain
it through an example:</p>
<p>Assume we have several racks. When we start a node, we can configure an
attribute called <code class="literal">rack_id</code> (any attribute name works), for example, here
is a sample config:</p>
<pre class="screen">node.rack_id: rack_one</pre>
<p>The above sets an attribute called <code class="literal">rack_id</code> for the relevant node with
a value of <code class="literal">rack_one</code>. Now, we need to configure the <code class="literal">rack_id</code> attribute
as one of the awareness allocation attributes (set it on <span class="strong strong"><strong>all</strong></span> (master
eligible) nodes config):</p>
<pre class="screen">cluster.routing.allocation.awareness.attributes: rack_id</pre>
<p>The above will mean that the <code class="literal">rack_id</code> attribute will be used to do
awareness based allocation of shard and its replicas. For example, lets
say we start 2 nodes with <code class="literal">node.rack_id</code> set to <code class="literal">rack_one</code>, and deploy a
single index with 5 shards and 1 replica. The index will be fully
deployed on the current nodes (5 shards and 1 replica each, total of 10
shards).</p>
<p>Now, if we start two more nodes, with <code class="literal">node.rack_id</code> set to <code class="literal">rack_two</code>,
shards will relocate to even the number of shards across the nodes, but,
a shard and its replica will not be allocated in the same <code class="literal">rack_id</code>
value.</p>
<p>The awareness attributes can hold several values, for example:</p>
<pre class="screen">cluster.routing.allocation.awareness.attributes: rack_id,zone</pre>
<p><span class="strong strong"><strong>NOTE</strong></span>: When using awareness attributes, shards will not be allocated to
nodes that don&#8217;t have values set for those attributes.</p>
<h3><a id="forced-awareness"></a>Forced Awareness<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/1.3/docs/reference/modules/cluster.asciidoc">edit</a></h3>
<p>Sometimes, we know in advance the number of values an awareness
attribute can have, and more over, we would like never to have more
replicas than needed allocated on a specific group of nodes with the
same awareness attribute value. For that, we can force awareness on
specific attributes.</p>
<p>For example, lets say we have an awareness attribute called <code class="literal">zone</code>, and
we know we are going to have two zones, <code class="literal">zone1</code> and <code class="literal">zone2</code>. Here is how
we can force awareness on a node:</p>
<div class="pre_wrapper lang-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js">cluster.routing.allocation.awareness.force.zone.values: zone1,zone2
cluster.routing.allocation.awareness.attributes: zone</pre>
</div>
<p>Now, lets say we start 2 nodes with <code class="literal">node.zone</code> set to <code class="literal">zone1</code> and
create an index with 5 shards and 1 replica. The index will be created,
but only 5 shards will be allocated (with no replicas). Only when we
start more shards with <code class="literal">node.zone</code> set to <code class="literal">zone2</code> will the replicas be
allocated.</p>
<h4><a id="_automatic_preference_when_searching_geting"></a>Automatic Preference When Searching / GETing<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/1.3/docs/reference/modules/cluster.asciidoc">edit</a></h4>
<p>When executing a search, or doing a get, the node receiving the request
will prefer to execute the request on shards that exists on nodes that
have the same attribute values as the executing node.</p>
<h4><a id="_realtime_settings_update"></a>Realtime Settings Update<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/1.3/docs/reference/modules/cluster.asciidoc">edit</a></h4>
<p>The settings can be updated using the <a class="xref" href="cluster-update-settings.html" title="Cluster Update Settings">cluster update settings API</a> on a live cluster.</p>
<h3><a id="allocation-filtering"></a>Shard Allocation Filtering<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/1.3/docs/reference/modules/cluster.asciidoc">edit</a></h3>
<p>Allow to control allocation of indices on nodes based on include/exclude
filters. The filters can be set both on the index level and on the
cluster level. Lets start with an example of setting it on the cluster
level:</p>
<p>Lets say we have 4 nodes, each has specific attribute called <code class="literal">tag</code>
associated with it (the name of the attribute can be any name). Each
node has a specific value associated with <code class="literal">tag</code>. Node 1 has a setting
<code class="literal">node.tag: value1</code>, Node 2 a setting of <code class="literal">node.tag: value2</code>, and so on.</p>
<p>We can create an index that will only deploy on nodes that have <code class="literal">tag</code>
set to <code class="literal">value1</code> and <code class="literal">value2</code> by setting
<code class="literal">index.routing.allocation.include.tag</code> to <code class="literal">value1,value2</code>. For example:</p>
<div class="pre_wrapper lang-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js">curl -XPUT localhost:9200/test/_settings -d '{
      "index.routing.allocation.include.tag" : "value1,value2"
}'</pre>
</div>
<p>On the other hand, we can create an index that will be deployed on all
nodes except for nodes with a <code class="literal">tag</code> of value <code class="literal">value3</code> by setting
<code class="literal">index.routing.allocation.exclude.tag</code> to <code class="literal">value3</code>. For example:</p>
<div class="pre_wrapper lang-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js">curl -XPUT localhost:9200/test/_settings -d '{
      "index.routing.allocation.exclude.tag" : "value3"
}'</pre>
</div>
<p><code class="literal">index.routing.allocation.require.*</code> can be used to
specify a number of rules, all of which MUST match in order for a shard
to be  allocated to a node. This is in contrast to <code class="literal">include</code> which will
include a node if ANY rule matches.</p>
<p>The <code class="literal">include</code>, <code class="literal">exclude</code> and <code class="literal">require</code> values can have generic simple
matching wildcards, for example, <code class="literal">value1*</code>. A special attribute name
called <code class="literal">_ip</code> can be used to match on node ip values. In addition <code class="literal">_host</code>
attribute can be used to match on either the node&#8217;s hostname or its ip
address. Similarly <code class="literal">_name</code> and <code class="literal">_id</code> attributes can be used to match on
node name and node id accordingly.</p>
<p>Obviously a node can have several attributes associated with it, and
both the attribute name and value are controlled in the setting. For
example, here is a sample of several node configurations:</p>
<div class="pre_wrapper lang-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js">node.group1: group1_value1
node.group2: group2_value4</pre>
</div>
<p>In the same manner, <code class="literal">include</code>, <code class="literal">exclude</code> and <code class="literal">require</code> can work against
several attributes, for example:</p>
<div class="pre_wrapper lang-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js">curl -XPUT localhost:9200/test/_settings -d '{
    "index.routing.allocation.include.group1" : "xxx"
    "index.routing.allocation.include.group2" : "yyy",
    "index.routing.allocation.exclude.group3" : "zzz",
    "index.routing.allocation.require.group4" : "aaa"
}'</pre>
</div>
<p>The provided settings can also be updated in real time using the update
settings API, allowing to "move" indices (shards) around in realtime.</p>
<p>Cluster wide filtering can also be defined, and be updated in real time
using the cluster update settings API. This setting can come in handy
for things like decommissioning nodes (even if the replica count is set
to 0). Here is a sample of how to decommission a node based on <code class="literal">_ip</code>
address:</p>
<div class="pre_wrapper lang-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js">curl -XPUT localhost:9200/_cluster/settings -d '{
    "transient" : {
        "cluster.routing.allocation.exclude._ip" : "10.0.0.1"
    }
}'</pre>
</div>
</div>
</div>
</div><div class="navfooter">
<span class="prev">
<a href="modules.html">« Modules</a>
</span>
<span class="next">
<a href="modules-discovery.html">Discovery »</a>
</span>
</div>
</body>
</html>
