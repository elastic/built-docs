<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Percentiles Aggregation | Elasticsearch Guide [1.4] | Elastic</title>
<meta class="elastic" name="content" content="Percentiles Aggregation | Elasticsearch Guide [1.4]">

<link rel="home" href="index.html" title="Elasticsearch Guide [1.4]"/>
<link rel="up" href="search-aggregations.html" title="Aggregations"/>
<link rel="prev" href="search-aggregations-metrics-valuecount-aggregation.html" title="Value Count Aggregation"/>
<link rel="next" href="search-aggregations-metrics-percentile-rank-aggregation.html" title="Percentile Ranks Aggregation"/>
<meta class="elastic" name="product_version" content="1.4"/>
<meta class="elastic" name="product_name" content="Elasticsearch"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/Elasticsearch/Reference/1.4"/>
<meta name="DC.subject" content="Elasticsearch"/>
<meta name="DC.identifier" content="1.4"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body>
<div class="page_header">
<p>
  <strong>WARNING</strong>: Version 1.4 of Elasticsearch has passed its 
  <a href="https://www.elastic.co/support/eol">EOL date</a>. 
</p>  
<p>
  This documentation is no longer being maintained and may be removed. 
  If you are running this version, we strongly advise you to upgrade. 
  For the latest information, see the 
  <a href="../current/index.html">current release documentation</a>. 
</p>
</div>
<div class="navheader">
<span class="prev">
<a href="search-aggregations-metrics-valuecount-aggregation.html">« Value Count Aggregation</a>
</span>
<span class="next">
<a href="search-aggregations-metrics-percentile-rank-aggregation.html">Percentile Ranks Aggregation »</a>
</span>
</div>
<div class="book" lang="en">
<div class="titlepage">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Elasticsearch Guide [1.4]</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="search.html">Search APIs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="search-aggregations.html">Aggregations</a></span>
</div>
<div>
<div><h1 class="title"><a id="id-1"></a>Percentiles Aggregation</h1><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/1.4/docs/reference/search/aggregations/metrics/percentile-aggregation.asciidoc">edit</a></div>
</div>
<!--EXTRA-->
</div>
<div id="content">
<div class="section">
<div class="titlepage"><div><div>
<h2 class="title"><a id="search-aggregations-metrics-percentile-aggregation"></a>Percentiles Aggregation<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/1.4/docs/reference/search/aggregations/metrics/percentile-aggregation.asciidoc">edit</a></h2>
</div></div></div>
<p>A <code class="literal">multi-value</code> metrics aggregation that calculates one or more percentiles
over numeric values extracted from the aggregated documents.  These values
can be extracted either from specific numeric fields in the documents, or
be generated by a provided script.</p>
<div class="important admon">
<div class="icon"></div>
<div class="admon_content">
<h3>Experimental!</h3>
<p>This feature is marked as experimental, and may be subject to change in the
future.  If you use this feature, please let us know your experience with it!</p>
</div>
</div>
<p>Percentiles show the point at which a certain percentage of observed values
occur.  For example, the 95th percentile is the value which is greater than 95%
of the observed values.</p>
<p>Percentiles are often used to find outliers.  In normal distributions, the
0.13th and 99.87th percentiles represents three standard deviations from the
mean.  Any data which falls outside three standard deviations is often considered
an anomaly.</p>
<p>When a range of percentiles are retrieved, they can be used to estimate the
data distribution and determine if the data is skewed, bimodal, etc.</p>
<p>Assume your data consists of website load times.  The average and median
load times are not overly useful to an administrator.  The max may be interesting,
but it can be easily skewed by a single slow response.</p>
<p>Let&#8217;s look at a range of percentiles representing load time:</p>
<div class="pre_wrapper lang-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js">{
    "aggs" : {
        "load_time_outlier" : {
            "percentiles" : {
                "field" : "load_time" <a id="CO12-1"></a><i class="conum" data-value="1"></i>
            }
        }
    }
}</pre>
</div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO12-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>The field <code class="literal">load_time</code> must be a numeric field</p>
</td>
</tr>
</table>
</div>
<p>By default, the <code class="literal">percentile</code> metric will generate a range of
percentiles: <code class="literal">[ 1, 5, 25, 50, 75, 95, 99 ]</code>.  The response will look like this:</p>
<div class="pre_wrapper lang-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js">{
    ...

   "aggregations": {
      "load_time_outlier": {
         "values" : {
            "1.0": 15,
            "5.0": 20,
            "25.0": 23,
            "50.0": 25,
            "75.0": 29,
            "95.0": 60,
            "99.0": 150
         }
      }
   }
}</pre>
</div>
<p>As you can see, the aggregation will return a calculated value for each percentile
in the default range.  If we assume response times are in milliseconds, it is
immediately obvious that the webpage normally loads in 15-30ms, but occasionally
spikes to 60-150ms.</p>
<p>Often, administrators are only interested in outliers&#8201;&#8212;&#8201;the extreme percentiles.
We can specify just the percents we are interested in (requested percentiles
must be a value between 0-100 inclusive):</p>
<div class="pre_wrapper lang-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js">{
    "aggs" : {
        "load_time_outlier" : {
            "percentiles" : {
                "field" : "load_time",
                "percents" : [95, 99, 99.9] <a id="CO13-1"></a><i class="conum" data-value="1"></i>
            }
        }
    }
}</pre>
</div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO13-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>Use the <code class="literal">percents</code> parameter to specify particular percentiles to calculate</p>
</td>
</tr>
</table>
</div>
<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="_script_8"></a>Script<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/1.4/docs/reference/search/aggregations/metrics/percentile-aggregation.asciidoc">edit</a></h3>
</div></div></div>
<p>The percentile metric supports scripting.  For example, if our load times
are in milliseconds but we want percentiles calculated in seconds, we could use
a script to convert them on-the-fly:</p>
<div class="pre_wrapper lang-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js">{
    "aggs" : {
        "load_time_outlier" : {
            "percentiles" : {
                "script" : "doc['load_time'].value / timeUnit", <a id="CO14-1"></a><i class="conum" data-value="1"></i>
                "params" : {
                    "timeUnit" : 1000   <a id="CO14-2"></a><i class="conum" data-value="2"></i>
                }
            }
        }
    }
}</pre>
</div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO14-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>The <code class="literal">field</code> parameter is replaced with a <code class="literal">script</code> parameter, which uses the
script to generate values which percentiles are calculated on</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO14-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p>Scripting supports parameterized input just like any other script</p>
</td>
</tr>
</table>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="search-aggregations-metrics-percentile-aggregation-approximation"></a>Percentiles are (usually) approximate<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/1.4/docs/reference/search/aggregations/metrics/percentile-aggregation.asciidoc">edit</a></h3>
</div></div></div>
<p>There are many different algorithms to calculate percentiles.  The naive
implementation simply stores all the values in a sorted array.  To find the 50th
percentile, you simply find the value that is at <code class="literal">my_array[count(my_array) * 0.5]</code>.</p>
<p>Clearly, the naive implementation does not scale&#8201;&#8212;&#8201;the sorted array grows
linearly with the number of values in your dataset.  To calculate percentiles
across potentially billions of values in an Elasticsearch cluster, <em>approximate</em>
percentiles are calculated.</p>
<p>The algorithm used by the <code class="literal">percentile</code> metric is called TDigest (introduced by
Ted Dunning in
<a href="https://github.com/tdunning/t-digest/blob/master/docs/t-digest-paper/histo.pdf" class="ulink" target="_top">Computing Accurate Quantiles using T-Digests</a>).</p>
<p>When using this metric, there are a few guidelines to keep in mind:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
Accuracy is proportional to <code class="literal">q(1-q)</code>.  This means that extreme percentiles (e.g. 99%)
are more accurate than less extreme percentiles, such as the median
</li>
<li class="listitem">
For small sets of values, percentiles are highly accurate (and potentially
100% accurate if the data is small enough).
</li>
<li class="listitem">
As the quantity of values in a bucket grows, the algorithm begins to approximate
the percentiles.  It is effectively trading accuracy for memory savings.  The
exact level of inaccuracy is difficult to generalize, since it depends on your
data distribution and volume of data being aggregated
</li>
</ul>
</div>
<p>The following chart shows the relative error on a uniform distribution depending
on the number of collected values and the requested percentile:</p>
<p><span class="image"><img src="images/percentiles_error.png" alt="percentiles error"></span></p>
<p>It shows how precision is better for extreme percentiles. The reason why error diminishes
for large number of values is that the law of large numbers makes the distribution of
values more and more uniform and the t-digest tree can do a better job at summarizing
it. It would not be the case on more skewed distributions.</p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="search-aggregations-metrics-percentile-aggregation-compression"></a>Compression<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/1.4/docs/reference/search/aggregations/metrics/percentile-aggregation.asciidoc">edit</a></h3>
</div></div></div>
<p>Approximate algorithms must balance memory utilization with estimation accuracy.
This balance can be controlled using a <code class="literal">compression</code> parameter:</p>
<div class="pre_wrapper lang-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js">{
    "aggs" : {
        "load_time_outlier" : {
            "percentiles" : {
                "field" : "load_time",
                "compression" : 200 <a id="CO15-1"></a><i class="conum" data-value="1"></i>
            }
        }
    }
}</pre>
</div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO15-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>Compression controls memory usage and approximation error</p>
</td>
</tr>
</table>
</div>
<p>The TDigest algorithm uses a number of "nodes" to approximate percentiles&#8201;&#8212;&#8201;the
more nodes available, the higher the accuracy (and large memory footprint) proportional
to the volume of data.  The <code class="literal">compression</code> parameter limits the maximum number of
nodes to <code class="literal">20 * compression</code>.</p>
<p>Therefore, by increasing the compression value, you can increase the accuracy of
your percentiles at the cost of more memory.  Larger compression values also
make the algorithm slower since the underlying tree data structure grows in size,
resulting in more expensive operations.  The default compression value is
<code class="literal">100</code>.</p>
<p>A "node" uses roughly 32 bytes of memory, so under worst-case scenarios (large amount
of data which arrives sorted and in-order) the default settings will produce a
TDigest roughly 64KB in size.  In practice data tends to be more random and
the TDigest will use less memory.</p>
</div>

</div>
</div>
</div><div class="navfooter">
<span class="prev">
<a href="search-aggregations-metrics-valuecount-aggregation.html">« Value Count Aggregation</a>
</span>
<span class="next">
<a href="search-aggregations-metrics-percentile-rank-aggregation.html">Percentile Ranks Aggregation »</a>
</span>
</div>
</body>
</html>
