<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Pattern Capture Token Filter | Elasticsearch Reference [1.5] | Elastic</title>
<link rel="home" href="index.html" title="Elasticsearch Reference [1.5]"/>
<link rel="up" href="analysis-tokenfilters.html" title="Token Filters"/>
<link rel="prev" href="analysis-unique-tokenfilter.html" title="Unique Token Filter"/>
<link rel="next" href="analysis-pattern_replace-tokenfilter.html" title="Pattern Replace Token Filter"/>
<meta name="DC.type" content="Learn/Docs/Elasticsearch/Reference/1.5"/>
<meta name="DC.subject" content="Elasticsearch"/>
<meta name="DC.identifier" content="1.5"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body><div class="page_header">
<p>
  <strong>WARNING</strong>: Version 1.5 of Elasticsearch has passed its 
  <a href="https://www.elastic.co/support/eol">EOL date</a>. 
</p>  
<p>
  This documentation is no longer being maintained and may be removed. 
  If you are running this version, we strongly advise you to upgrade. 
  For the latest information, see the 
  <a href="../current/index.html">current release documentation</a>. 
</p>
</div>
<div id="content">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="index.html">Elasticsearch Reference [1.5]</a></span>
»
<span class="breadcrumb-link"><a href="analysis.html">Analysis</a></span>
»
<span class="breadcrumb-link"><a href="analysis-tokenfilters.html">Token Filters</a></span>
»
<span class="breadcrumb-node">Pattern Capture Token Filter</span>
</div>
<div class="navheader">
<span class="prev">
<a href="analysis-unique-tokenfilter.html">« Unique Token Filter</a>
</span>
<span class="next">
<a href="analysis-pattern_replace-tokenfilter.html">Pattern Replace Token Filter »</a>
</span>
</div>
<div class="section">
<div class="titlepage"><div><div>
<h2 class="title"><a id="analysis-pattern-capture-tokenfilter"></a>Pattern Capture Token Filter<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/1.5/docs/reference/analysis/tokenfilters/pattern-capture-tokenfilter.asciidoc">edit</a></h2>
</div></div></div>
<p>The <code class="literal">pattern_capture</code> token filter, unlike the <code class="literal">pattern</code> tokenizer,
emits a token for every capture group in the regular expression.
Patterns are not anchored to the beginning and end of the string, so
each pattern can match multiple times, and matches are allowed to
overlap.</p>
<p>For instance a pattern like :</p>
<div class="pre_wrapper lang-js">
<pre class="programlisting prettyprint lang-js">"(([a-z]+)(\d*))"</pre>
</div>
<p>when matched against:</p>
<div class="pre_wrapper lang-js">
<pre class="programlisting prettyprint lang-js">"abc123def456"</pre>
</div>
<p>would produce the tokens: [ <code class="literal">abc123</code>, <code class="literal">abc</code>, <code class="literal">123</code>, <code class="literal">def456</code>, <code class="literal">def</code>,
<code class="literal">456</code> ]</p>
<p>If <code class="literal">preserve_original</code> is set to <code class="literal">true</code> (the default) then it would also
emit the original token: <code class="literal">abc123def456</code>.</p>
<p>This is particularly useful for indexing text like camel-case code, eg
<code class="literal">stripHTML</code> where a user may search for <code class="literal">"strip html"</code> or <code class="literal">"striphtml"</code>:</p>
<div class="pre_wrapper lang-js">
<pre class="programlisting prettyprint lang-js">curl -XPUT localhost:9200/test/  -d '
{
   "settings" : {
      "analysis" : {
         "filter" : {
            "code" : {
               "type" : "pattern_capture",
               "preserve_original" : 1,
               "patterns" : [
                  "(\\p{Ll}+|\\p{Lu}\\p{Ll}+|\\p{Lu}+)",
                  "(\\d+)"
               ]
            }
         },
         "analyzer" : {
            "code" : {
               "tokenizer" : "pattern",
               "filter" : [ "code", "lowercase" ]
            }
         }
      }
   }
}
'</pre>
</div>
<p>When used to analyze the text</p>
<div class="pre_wrapper lang-js">
<pre class="programlisting prettyprint lang-js">import static org.apache.commons.lang.StringEscapeUtils.escapeHtml</pre>
</div>
<p>this emits the tokens: [ <code class="literal">import</code>, <code class="literal">static</code>, <code class="literal">org</code>, <code class="literal">apache</code>, <code class="literal">commons</code>,
<code class="literal">lang</code>, <code class="literal">stringescapeutils</code>, <code class="literal">string</code>, <code class="literal">escape</code>, <code class="literal">utils</code>, <code class="literal">escapehtml</code>,
<code class="literal">escape</code>, <code class="literal">html</code> ]</p>
<p>Another example is analyzing email addresses:</p>
<div class="pre_wrapper lang-js">
<pre class="programlisting prettyprint lang-js">curl -XPUT localhost:9200/test/  -d '
{
   "settings" : {
      "analysis" : {
         "filter" : {
            "email" : {
               "type" : "pattern_capture",
               "preserve_original" : 1,
               "patterns" : [
                  "([^@]+)",
                  "(\\p{L}+)",
                  "(\\d+)",
                  "@(.+)"
               ]
            }
         },
         "analyzer" : {
            "email" : {
               "tokenizer" : "uax_url_email",
               "filter" : [ "email", "lowercase",  "unique" ]
            }
         }
      }
   }
}
'</pre>
</div>
<p>When the above analyzer is used on an email address like:</p>
<div class="pre_wrapper lang-js">
<pre class="programlisting prettyprint lang-js">john-smith_123@foo-bar.com</pre>
</div>
<p>it would produce the following tokens:</p>
<pre class="literallayout">john-smith_123@foo-bar.com, john-smith_123,
john, smith, 123, foo-bar.com, foo, bar, com</pre>

<p>Multiple patterns are required to allow overlapping captures, but also
means that patterns are less dense and easier to understand.</p>
<p><span class="strong strong"><strong>Note:</strong></span> All tokens are emitted in the same position, and with the same
character offsets, so when combined with highlighting, the whole
original token will be highlighted, not just the matching subset. For
instance, querying the above email address for <code class="literal">"smith"</code> would
highlight:</p>
<div class="pre_wrapper lang-js">
<pre class="programlisting prettyprint lang-js">  &lt;em&gt;john-smith_123@foo-bar.com&lt;/em&gt;</pre>
</div>
<p>not:</p>
<div class="pre_wrapper lang-js">
<pre class="programlisting prettyprint lang-js">  john-&lt;em&gt;smith&lt;/em&gt;_123@foo-bar.com</pre>
</div>
</div>
<div class="navfooter">
<span class="prev">
<a href="analysis-unique-tokenfilter.html">« Unique Token Filter</a>
</span>
<span class="next">
<a href="analysis-pattern_replace-tokenfilter.html">Pattern Replace Token Filter »</a>
</span>
</div>
</div>
</body>
</html>
