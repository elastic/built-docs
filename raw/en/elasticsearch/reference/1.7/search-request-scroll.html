<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Scroll | Elasticsearch Reference [1.7] | Elastic</title>
<link rel="home" href="index.html" title="Elasticsearch Reference [1.7]"/>
<link rel="up" href="search-request-body.html" title="Request Body Search"/>
<link rel="prev" href="search-request-search-type.html" title="Search Type"/>
<link rel="next" href="search-request-preference.html" title="Preference"/>
<meta name="DC.type" content="Learn/Docs/Elasticsearch/Reference/1.7"/>
<meta name="DC.subject" content="Elasticsearch"/>
<meta name="DC.identifier" content="1.7"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body><div class="page_header">
<p>
  <strong>WARNING</strong>: Version 1.7 of Elasticsearch has passed its 
  <a href="https://www.elastic.co/support/eol">EOL date</a>. 
</p>  
<p>
  This documentation is no longer being maintained and may be removed. 
  If you are running this version, we strongly advise you to upgrade. 
  For the latest information, see the 
  <a href="../current/index.html">current release documentation</a>. 
</p>
</div>
<div id="content">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="index.html">Elasticsearch Reference [1.7]</a></span>
»
<span class="breadcrumb-link"><a href="search.html">Search APIs</a></span>
»
<span class="breadcrumb-link"><a href="search-request-body.html">Request Body Search</a></span>
»
<span class="breadcrumb-node">Scroll</span>
</div>
<div class="navheader">
<span class="prev">
<a href="search-request-search-type.html">« Search Type</a>
</span>
<span class="next">
<a href="search-request-preference.html">Preference »</a>
</span>
</div>
<div class="section">
<div class="titlepage"><div><div>
<h2 class="title"><a id="search-request-scroll"></a>Scroll<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/1.7/docs/reference/search/request/scroll.asciidoc">edit</a></h2>
</div></div></div>
<p>While a <code class="literal">search</code> request returns a single &#8220;page&#8221; of results, the <code class="literal">scroll</code>
API can be used to retrieve large numbers of results (or even all results)
from a single search request, in much the same way as you would use a cursor
on a traditional database.</p>
<p>Scrolling is not intended for real time user requests, but rather for
processing large amounts of data, e.g. in order to reindex the contents of one
index into a new index with a different configuration.</p>
<div class="sidebar">
<div class="titlepage"><div><div>
<p class="title"><strong>Client support for scrolling and reindexing</strong></p>
</div></div></div>
<p>Some of the officially supported clients provide helpers to assist with
scrolled searches and reindexing of documents from one index to another:</p>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
Perl
</span>
</dt>
<dd>
See <a href="https://metacpan.org/pod/Search::Elasticsearch::Bulk" class="ulink" target="_top">Search::Elasticsearch::Bulk</a>
and <a href="https://metacpan.org/pod/Search::Elasticsearch::Scroll" class="ulink" target="_top">Search::Elasticsearch::Scroll</a>
</dd>
<dt>
<span class="term">
Python
</span>
</dt>
<dd>
See <a href="http://elasticsearch-py.readthedocs.org/en/master/helpers.html" class="ulink" target="_top">elasticsearch.helpers.*</a>
</dd>
</dl>
</div>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>The results that are returned from a scroll request reflect the state of
the index at the time that the initial <code class="literal">search</code> request was  made, like a
snapshot in time. Subsequent changes to documents (index, update or delete)
will only affect later search requests.</p>
</div>
</div>
<p>In order to use scrolling, the initial search request should specify the
<code class="literal">scroll</code> parameter in the query string, which tells Elasticsearch how long it
should keep the &#8220;search context&#8221; alive (see <a class="xref" href="search-request-scroll.html#scroll-search-context" title="Keeping the search context alive">Keeping the search context alive</a>), eg <code class="literal">?scroll=1m</code>.</p>
<div class="pre_wrapper lang-js">
<pre class="programlisting prettyprint lang-js">curl -XGET 'localhost:9200/twitter/tweet/_search?scroll=1m' -d '
{
    "query": {
        "match" : {
            "title" : "elasticsearch"
        }
    }
}
'</pre>
</div>
<p>The result from the above request includes a <code class="literal">_scroll_id</code>, which should
be passed to the <code class="literal">scroll</code> API in order to retrieve the next batch of
results.</p>
<div class="pre_wrapper lang-js">
<pre class="programlisting prettyprint lang-js">curl -XGET 'localhost:9200/_search/scroll?scroll=1m' \ <a id="CO4-1"></a><i class="conum" data-value="1"></i>
     -d    'c2Nhbjs2OzM0NDg1ODpzRlBLc0FXNlNyNm5JWUc1'  <a id="CO4-2"></a><i class="conum" data-value="2"></i></pre>
</div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO4-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p><code class="literal">GET</code> or <code class="literal">POST</code> can be used and the URL should not include the <code class="literal">index</code>
or <code class="literal">type</code> name&#8201;&#8212;&#8201;this is specified in the original <code class="literal">search</code> request instead.
The <code class="literal">scroll</code> parameter tells Elasticsearch to keep the search context open
for another <code class="literal">1m</code>.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO4-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p>The returned <code class="literal">_scroll_id</code> attribute can be passed in the request body or in
the query string as <code class="literal">?scroll_id=....</code></p>
</td>
</tr>
</table>
</div>
<p>Each call to the <code class="literal">scroll</code> API returns the next batch of results until there
are no more results left to return, ie the <code class="literal">hits</code> array is empty.</p>
<div class="important admon">
<div class="icon"></div>
<div class="admon_content">
<p>The initial search request and each subsequent scroll request
returns a new <code class="literal">_scroll_id</code>&#8201;&#8212;&#8201;only the most recent <code class="literal">_scroll_id</code> should be
used.</p>
</div>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>If the request specifies aggregations, only the initial search response
will contain the aggregations results.</p>
</div>
</div>
<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="scroll-scan"></a>Efficient scrolling with Scroll-Scan<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/1.7/docs/reference/search/request/scroll.asciidoc">edit</a></h3>
</div></div></div>
<p>Deep pagination with <a class="xref" href="search-request-from-size.html" title="From / Size"><code class="literal">from</code> and <code class="literal">size</code></a>&#8201;&#8212;&#8201;e.g.
<code class="literal">?size=10&amp;from=10000</code>&#8201;&#8212;&#8201;is very inefficient as (in this example) 100,000
sorted results have to be retrieved from each shard and resorted in order to
return just 10 results.  This process has to be repeated for every page
requested.</p>
<p>The <code class="literal">scroll</code> API keeps track of which results have already been returned and
so is able to return sorted results more efficiently than with deep
pagination.  However, sorting results (which happens by default) still has a
cost.</p>
<p>Normally, you just want to retrieve all results and the order doesn&#8217;t matter.
Scrolling can be combined with the <a class="xref" href="search-request-search-type.html#scan" title="Scan"><code class="literal">scan</code></a> search type to disable
any scoring or sorting and to return results in the most efficient way
possible.  All that is needed is to add <code class="literal">search_type=scan</code> to the query string
of the initial search request:</p>
<div class="pre_wrapper lang-js">
<pre class="programlisting prettyprint lang-js">curl 'localhost:9200/twitter/tweet/_search?scroll=1m&amp;search_type=scan' -d ' <a id="CO5-1"></a><i class="conum" data-value="1"></i>
{
    "query": {
        "match" : {
            "title" : "elasticsearch"
        }
    }
}
'</pre>
</div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO5-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>Setting <code class="literal">search_type</code> to <code class="literal">scan</code> disables sorting and makes scrolling
very efficient.</p>
</td>
</tr>
</table>
</div>
<p>A scanning scroll request differs from a standard scroll request in four
ways:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
No score is calculated and sorting is disabled. Results are returned in
the order they appear in the index.
</li>
<li class="listitem">
Aggregations are not supported.
</li>
<li class="listitem">
The response of the initial <code class="literal">search</code> request will not contain any results in
the <code class="literal">hits</code> array. The first results will be returned by the first <code class="literal">scroll</code>
request.
</li>
<li class="listitem">
The <a class="xref" href="search-request-from-size.html" title="From / Size"><code class="literal">size</code> parameter</a> controls the number of
results <span class="strong strong"><strong>per shard</strong></span>, not per request, so a <code class="literal">size</code> of <code class="literal">10</code> which hits 5
shards will return a maximum of 50 results per <code class="literal">scroll</code> request.
</li>
</ul>
</div>
<p>If you want the scoring to happen, even without sorting on it, set the
<code class="literal">track_scores</code> parameter to <code class="literal">true</code>.</p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="scroll-search-context"></a>Keeping the search context alive<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/1.7/docs/reference/search/request/scroll.asciidoc">edit</a></h3>
</div></div></div>
<p>The <code class="literal">scroll</code> parameter (passed to the <code class="literal">search</code> request and to every <code class="literal">scroll</code>
request) tells Elasticsearch how long it should keep the search context alive.
Its value (e.g. <code class="literal">1m</code>, see <a class="xref" href="common-options.html#time-units" title="Time units">Time units</a>) does not need to be long enough to
process all data&#8201;&#8212;&#8201;it just needs to be long enough to process the previous
batch of results. Each <code class="literal">scroll</code> request (with the <code class="literal">scroll</code> parameter) sets a
new  expiry time.</p>
<p>Normally, the <a class="xref" href="index-modules-merge.html" title="Merge">background merge process</a> optimizes the
index by merging together smaller segments to create new bigger segments, at
which time the smaller segments are deleted. This process continues during
scrolling, but an open search context prevents the old segments from being
deleted while they are still in use.  This is how Elasticsearch is able to
return the results of the initial search request, regardless of subsequent
changes to documents.</p>
<div class="tip admon">
<div class="icon"></div>
<div class="admon_content">
<p>Keeping older segments alive means that more file handles are needed.
Ensure that you have configured your nodes to have ample free file handles.
See <a class="xref" href="setup-configuration.html#file-descriptors" title="File Descriptors">File Descriptors</a>.</p>
</div>
</div>
<p>You can check how many search contexts are open with the
<a class="xref" href="cluster-nodes-stats.html" title="Nodes Stats">nodes stats API</a>:</p>
<div class="pre_wrapper lang-js">
<pre class="programlisting prettyprint lang-js">curl -XGET localhost:9200/_nodes/stats/indices/search?pretty</pre>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="_clear_scroll_api"></a>Clear scroll API<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/1.7/docs/reference/search/request/scroll.asciidoc">edit</a></h3>
</div></div></div>
<p>Search contexts are removed automatically either when all results have been
retrieved or when the <code class="literal">scroll</code> timeout has been exceeded.  However, you can
clear a search context manually with the <code class="literal">clear-scroll</code> API:</p>
<div class="pre_wrapper lang-js">
<pre class="programlisting prettyprint lang-js">curl -XDELETE localhost:9200/_search/scroll \
     -d 'c2Nhbjs2OzM0NDg1ODpzRlBLc0FXNlNyNm5JWUc1' <a id="CO6-1"></a><i class="conum" data-value="1"></i></pre>
</div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO6-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>The <code class="literal">scroll_id</code> can be passed in the request body or in the query string.</p>
</td>
</tr>
</table>
</div>
<p>Multiple scroll IDs can be passed as comma separated values:</p>
<div class="pre_wrapper lang-js">
<pre class="programlisting prettyprint lang-js">curl -XDELETE localhost:9200/_search/scroll \
     -d 'c2Nhbjs2OzM0NDg1ODpzRlBLc0FXNlNyNm5JWUc1,aGVuRmV0Y2g7NTsxOnkxaDZ' <a id="CO7-1"></a><i class="conum" data-value="1"></i></pre>
</div>
<p>All search contexts can be cleared with the <code class="literal">_all</code> parameter:</p>
<div class="pre_wrapper lang-js">
<pre class="programlisting prettyprint lang-js">curl -XDELETE localhost:9200/_search/scroll/_all</pre>
</div>
</div>

</div>
<div class="navfooter">
<span class="prev">
<a href="search-request-search-type.html">« Search Type</a>
</span>
<span class="next">
<a href="search-request-preference.html">Preference »</a>
</span>
</div>
</div>
</body>
</html>
