<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>NGram Tokenizer | Elasticsearch Reference [2.4] | Elastic</title>
<link rel="home" href="index.html" title="Elasticsearch Reference [2.4]"/>
<link rel="up" href="analysis-tokenizers.html" title="Tokenizers"/>
<link rel="prev" href="analysis-lowercase-tokenizer.html" title="Lowercase Tokenizer"/>
<link rel="next" href="analysis-whitespace-tokenizer.html" title="Whitespace Tokenizer"/>
<meta name="DC.type" content="Learn/Docs/Elasticsearch/Reference/2.4"/>
<meta name="DC.subject" content="Elasticsearch"/>
<meta name="DC.identifier" content="2.4"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body><div class="page_header">
<p>
  <strong>WARNING</strong>: Version 2.4 of Elasticsearch has passed its 
  <a href="https://www.elastic.co/support/eol">EOL date</a>. 
</p>  
<p>
  This documentation is no longer being maintained and may be removed. 
  If you are running this version, we strongly advise you to upgrade. 
  For the latest information, see the 
  <a href="../current/index.html">current release documentation</a>. 
</p>
</div>
<div id="content">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="index.html">Elasticsearch Reference [2.4]</a></span>
»
<span class="breadcrumb-link"><a href="analysis.html">Analysis</a></span>
»
<span class="breadcrumb-link"><a href="analysis-tokenizers.html">Tokenizers</a></span>
»
<span class="breadcrumb-node">NGram Tokenizer</span>
</div>
<div class="navheader">
<span class="prev">
<a href="analysis-lowercase-tokenizer.html">« Lowercase Tokenizer</a>
</span>
<span class="next">
<a href="analysis-whitespace-tokenizer.html">Whitespace Tokenizer »</a>
</span>
</div>
<div class="section">
<div class="titlepage"><div><div>
<h2 class="title"><a id="analysis-ngram-tokenizer"></a>NGram Tokenizer<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/2.4/docs/reference/analysis/tokenizers/ngram-tokenizer.asciidoc">edit</a></h2>
</div></div></div>
<p>A tokenizer of type <code class="literal">nGram</code>.</p>
<p>The following are settings that can be set for a <code class="literal">nGram</code> tokenizer type:</p>
<div class="informaltable">
<table border="1" cellpadding="4px">
<colgroup>
<col class="col_1"/>
<col class="col_2"/>
<col class="col_3"/>
</colgroup>
<thead>
<tr>
<th align="left" valign="top">Setting</th>
<th align="left" valign="top">Description</th>
<th align="left" valign="top">Default value</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" valign="top"><p><code class="literal">min_gram</code></p></td>
<td align="left" valign="top"><p>Minimum size in codepoints of a single n-gram</p></td>
<td align="left" valign="top"><p><code class="literal">1</code>.</p></td>
</tr>
<tr>
<td align="left" valign="top"><p><code class="literal">max_gram</code></p></td>
<td align="left" valign="top"><p>Maximum size in codepoints of a single n-gram</p></td>
<td align="left" valign="top"><p><code class="literal">2</code>.</p></td>
</tr>
<tr>
<td align="left" valign="top"><p><code class="literal">token_chars</code></p></td>
<td align="left" valign="top"><p>Characters classes to keep in the
tokens, Elasticsearch will split on characters that don&#8217;t belong to any
of these classes.</p></td>
<td align="left" valign="top"><p><code class="literal">[]</code> (Keep all characters)</p></td>
</tr>
</tbody>
</table>
</div>
<p><code class="literal">token_chars</code> accepts the following character classes:</p>
<div class="informaltable">
<table border="0" cellpadding="4px">
<colgroup>
<col/>
<col/>
</colgroup>
<tbody valign="top">
<tr>
<td valign="top">
<p>
<code class="literal">letter</code>
</p>
</td>
<td valign="top">
<p>
for example <code class="literal">a</code>, <code class="literal">b</code>, <code class="literal">ï</code> or <code class="literal">京</code>
</p>
</td>
</tr>
<tr>
<td valign="top">
<p>
<code class="literal">digit</code>
</p>
</td>
<td valign="top">
<p>
for example <code class="literal">3</code> or <code class="literal">7</code>
</p>
</td>
</tr>
<tr>
<td valign="top">
<p>
<code class="literal">whitespace</code>
</p>
</td>
<td valign="top">
<p>
for example <code class="literal">" "</code> or <code class="literal">"\n"</code>
</p>
</td>
</tr>
<tr>
<td valign="top">
<p>
<code class="literal">punctuation</code>
</p>
</td>
<td valign="top">
<p>
for example <code class="literal">!</code> or <code class="literal">"</code>
</p>
</td>
</tr>
<tr>
<td valign="top">
<p>
<code class="literal">symbol</code>
</p>
</td>
<td valign="top">
<p>
for example <code class="literal">$</code> or <code class="literal">√</code>
</p>
</td>
</tr>
</tbody>
</table>
</div>
<h4><a id="_example_6"></a>Example<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/2.4/docs/reference/analysis/tokenizers/ngram-tokenizer.asciidoc">edit</a></h4>
<div class="pre_wrapper lang-js">
<pre class="programlisting prettyprint lang-js">    curl -XPUT 'localhost:9200/test' -d '
    {
        "settings" : {
            "analysis" : {
                "analyzer" : {
                    "my_ngram_analyzer" : {
                        "tokenizer" : "my_ngram_tokenizer"
                    }
                },
                "tokenizer" : {
                    "my_ngram_tokenizer" : {
                        "type" : "nGram",
                        "min_gram" : "2",
                        "max_gram" : "3",
                        "token_chars": [ "letter", "digit" ]
                    }
                }
            }
        }
    }'

    curl 'localhost:9200/test/_analyze?pretty=1&amp;analyzer=my_ngram_analyzer' -d 'FC Schalke 04'
    # FC, Sc, Sch, ch, cha, ha, hal, al, alk, lk, lke, ke, 04</pre>
</div>
</div>
<div class="navfooter">
<span class="prev">
<a href="analysis-lowercase-tokenizer.html">« Lowercase Tokenizer</a>
</span>
<span class="next">
<a href="analysis-whitespace-tokenizer.html">Whitespace Tokenizer »</a>
</span>
</div>
</div>
</body>
</html>
