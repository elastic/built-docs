<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Letter Tokenizer | Elasticsearch Reference [5.1] | Elastic</title>
<link rel="home" href="index.html" title="Elasticsearch Reference [5.1]"/>
<link rel="up" href="analysis-tokenizers.html" title="Tokenizers"/>
<link rel="prev" href="analysis-standard-tokenizer.html" title="Standard Tokenizer"/>
<link rel="next" href="analysis-lowercase-tokenizer.html" title="Lowercase Tokenizer"/>
<meta name="DC.type" content="Learn/Docs/Elasticsearch/Reference/5.1"/>
<meta name="DC.subject" content="Elasticsearch"/>
<meta name="DC.identifier" content="5.1"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body><div class="page_header">
<p>
  <strong>WARNING</strong>: Version 5.1 of Elasticsearch has passed its 
  <a href="https://www.elastic.co/support/eol">EOL date</a>. 
</p>  
<p>
  This documentation is no longer being maintained and may be removed. 
  If you are running this version, we strongly advise you to upgrade. 
  For the latest information, see the 
  <a href="../current/index.html">current release documentation</a>. 
</p>
</div>
<div id="content">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="index.html">Elasticsearch Reference [5.1]</a></span>
»
<span class="breadcrumb-link"><a href="analysis.html">Analysis</a></span>
»
<span class="breadcrumb-link"><a href="analysis-tokenizers.html">Tokenizers</a></span>
»
<span class="breadcrumb-node">Letter Tokenizer</span>
</div>
<div class="navheader">
<span class="prev">
<a href="analysis-standard-tokenizer.html">« Standard Tokenizer</a>
</span>
<span class="next">
<a href="analysis-lowercase-tokenizer.html">Lowercase Tokenizer »</a>
</span>
</div>
<div class="section">
<div class="titlepage"><div><div>
<h2 class="title"><a id="analysis-letter-tokenizer"></a>Letter Tokenizer<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/5.1/docs/reference/analysis/tokenizers/letter-tokenizer.asciidoc">edit</a></h2>
</div></div></div>
<p>The <code class="literal">letter</code> tokenizer breaks text into terms whenever it encounters a
character which is not a letter. It does a reasonable job for most European
languages, but does a terrible job for some Asian languages, where words are
not separated by spaces.</p>
<h3><a id="_example_output_9"></a>Example output<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/5.1/docs/reference/analysis/tokenizers/letter-tokenizer.asciidoc">edit</a></h3>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">POST _analyze
{
  "tokenizer": "letter",
  "text": "The 2 QUICK Brown-Foxes jumped over the lazy dog's bone."
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/701.console"></div>
<p>The above sentence would produce the following terms:</p>
<div class="pre_wrapper lang-text">
<pre class="programlisting prettyprint lang-text">[ The, QUICK, Brown, Foxes, jumped, over, the, lazy, dog, s, bone ]</pre>
</div>
<h3><a id="_configuration_10"></a>Configuration<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/5.1/docs/reference/analysis/tokenizers/letter-tokenizer.asciidoc">edit</a></h3>
<p>The <code class="literal">letter</code> tokenizer is not configurable.</p>
</div>
<div class="navfooter">
<span class="prev">
<a href="analysis-standard-tokenizer.html">« Standard Tokenizer</a>
</span>
<span class="next">
<a href="analysis-lowercase-tokenizer.html">Lowercase Tokenizer »</a>
</span>
</div>
</div>
</body>
</html>
