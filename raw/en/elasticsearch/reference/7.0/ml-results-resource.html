<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Results resources | Elasticsearch Reference [7.0] | Elastic</title>
<link rel="home" href="index.html" title="Elasticsearch Reference [7.0]"/>
<link rel="up" href="api-definitions.html" title="Definitions"/>
<link rel="prev" href="role-mapping-resources.html" title="Role mapping resources"/>
<link rel="next" href="ml-event-resource.html" title="Scheduled event resources"/>
<meta name="DC.type" content="Learn/Docs/Elasticsearch/Reference/7.0"/>
<meta name="DC.subject" content="Elasticsearch"/>
<meta name="DC.identifier" content="7.0"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body><div class="page_header">
<strong>IMPORTANT</strong>: No additional bug fixes or documentation updates
will be released for this version. For the latest information, see the
<a href="../current/index.html">current release documentation</a>.
</div>
<div id="content">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="index.html">Elasticsearch Reference [7.0]</a></span>
»
<span class="breadcrumb-link"><a href="xpack-api.html">X-Pack APIs</a></span>
»
<span class="breadcrumb-link"><a href="api-definitions.html">Definitions</a></span>
»
<span class="breadcrumb-node">Results resources</span>
</div>
<div class="navheader">
<span class="prev">
<a href="role-mapping-resources.html">« Role mapping resources</a>
</span>
<span class="next">
<a href="ml-event-resource.html">Scheduled event resources »</a>
</span>
</div>
<div class="section xpack">
<div class="titlepage"><div><div>
<h2 class="title"><a id="ml-results-resource"></a>Results resources<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/7.0/docs/reference/ml/apis/resultsresource.asciidoc">edit</a><a class="xpack_tag" href="/subscriptions"></a></h2>
</div></div></div>
<p>Several different result types are created for each job. You can query anomaly
results for <em>buckets</em>, <em>influencers</em>, and <em>records</em> by using the results API.
Summarized bucket results over multiple jobs can be queried as well; those
results are called <em>overall buckets</em>.</p>
<p>Results are written for each <code class="literal">bucket_span</code>. The timestamp for the results is the
start of the bucket time interval.</p>
<p>The results include scores, which are calculated for each anomaly result type and
each bucket interval. These scores are aggregated in order to reduce noise, and
normalized in order to identify and rank the most mathematically significant
anomalies.</p>
<p>Bucket results provide the top level, overall view of the job and are ideal for
alerts. For example, the bucket results might indicate that at 16:05 the system
was unusual. This information is a summary of all the anomalies, pinpointing
when they occurred.</p>
<p>Influencer results show which entities were anomalous and when. For example,
the influencer results might indicate that at 16:05 <code class="literal">user_name: Bob</code> was unusual.
This information is a summary of all the anomalies for each entity, so there
can be a lot of these results. Once you have identified a notable bucket time,
you can look to see which entities were significant.</p>
<p>Record results provide details about what the individual anomaly was, when it
occurred and which entity was involved. For example, the record results might
indicate that at 16:05 Bob sent 837262434 bytes, when the typical value was
1067 bytes. Once you have identified a bucket time and perhaps a significant
entity too, you can drill through to the record results in order to investigate
the anomalous behavior.</p>
<p>Categorization results contain the definitions of <em>categories</em> that have been
identified. These are only applicable for jobs that are configured to analyze
unstructured log data using categorization. These results do not contain a
timestamp or any calculated scores. For more information, see
<a href="/guide/en/x-pack/6.2/ml-configuring-categories.html" class="ulink" target="_top">Categorizing Log Messages</a>.</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<a class="xref" href="ml-results-resource.html#ml-results-buckets" title="Buckets">Buckets</a>
</li>
<li class="listitem">
<a class="xref" href="ml-results-resource.html#ml-results-influencers" title="Influencers">Influencers</a>
</li>
<li class="listitem">
<a class="xref" href="ml-results-resource.html#ml-results-records" title="Records">Records</a>
</li>
<li class="listitem">
<a class="xref" href="ml-results-resource.html#ml-results-categories" title="Categories">Categories</a>
</li>
<li class="listitem">
<a class="xref" href="ml-results-resource.html#ml-results-overall-buckets" title="Overall Buckets">Overall Buckets</a>
</li>
</ul>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>All of these resources and properties are informational; you cannot
change their values.</p>
</div>
</div>
<h4><a id="ml-results-buckets"></a>Buckets<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/7.0/docs/reference/ml/apis/resultsresource.asciidoc">edit</a></h4>
<p>Bucket results provide the top level, overall view of the job and are best for
alerting.</p>
<p>Each bucket has an <code class="literal">anomaly_score</code>, which is a statistically aggregated and
normalized view of the combined anomalousness of all the record results within
each bucket.</p>
<p>One bucket result is written for each <code class="literal">bucket_span</code> for each job, even if it is
not considered to be anomalous. If the bucket is not anomalous, it has an
<code class="literal">anomaly_score</code> of zero.</p>
<p>When you identify an anomalous bucket, you can investigate further by expanding
the bucket resource to show the records as nested objects. Alternatively, you
can access the records resource directly and filter by the date range.</p>
<p>A bucket resource has the following properties:</p>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">anomaly_score</code>
</span>
</dt>
<dd>
(number) The maximum anomaly score, between 0-100, for any of the bucket
influencers. This is an overall, rate-limited score for the job. All the
anomaly records in the bucket contribute to this score. This value might be
updated as new data is analyzed.
</dd>
<dt>
<span class="term">
<code class="literal">bucket_influencers</code>
</span>
</dt>
<dd>
(array) An array of bucket influencer objects.
For more information, see <a class="xref" href="ml-results-resource.html#ml-results-bucket-influencers" title="Bucket Influencers">Bucket Influencers</a>.
</dd>
<dt>
<span class="term">
<code class="literal">bucket_span</code>
</span>
</dt>
<dd>
(number) The length of the bucket in seconds.
This value matches the <code class="literal">bucket_span</code> that is specified in the job.
</dd>
<dt>
<span class="term">
<code class="literal">event_count</code>
</span>
</dt>
<dd>
(number) The number of input data records processed in this bucket.
</dd>
<dt>
<span class="term">
<code class="literal">initial_anomaly_score</code>
</span>
</dt>
<dd>
(number) The maximum <code class="literal">anomaly_score</code> for any of the bucket influencers.
This is the initial value that was calculated at the time the bucket was
processed.
</dd>
<dt>
<span class="term">
<code class="literal">is_interim</code>
</span>
</dt>
<dd>
(boolean) If true, this is an interim result. In other words, the bucket
results are calculated based on partial input data.
</dd>
<dt>
<span class="term">
<code class="literal">job_id</code>
</span>
</dt>
<dd>
(string) The unique identifier for the job that these results belong to.
</dd>
<dt>
<span class="term">
<code class="literal">processing_time_ms</code>
</span>
</dt>
<dd>
(number) The amount of time, in milliseconds, that it took to analyze the
bucket contents and calculate results.
</dd>
<dt>
<span class="term">
<code class="literal">result_type</code>
</span>
</dt>
<dd>
(string) Internal. This value is always set to <code class="literal">bucket</code>.
</dd>
<dt>
<span class="term">
<code class="literal">timestamp</code>
</span>
</dt>
<dd>
(date) The start time of the bucket. This timestamp uniquely identifies the
bucket.<br>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>Events that occur exactly at the timestamp of the bucket are included in
the results for the bucket.</p>
</div>
</div>
<h4><a id="ml-results-bucket-influencers"></a>Bucket Influencers<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/7.0/docs/reference/ml/apis/resultsresource.asciidoc">edit</a></h4>
<p>Bucket influencer results are available as nested objects contained within
bucket results. These results are an aggregation for each type of influencer.
For example, if both <code class="literal">client_ip</code> and <code class="literal">user_name</code> were specified as influencers,
then you would be able to determine when the <code class="literal">client_ip</code> or <code class="literal">user_name</code> values
were collectively anomalous.</p>
<p>There is a built-in bucket influencer called <code class="literal">bucket_time</code> which is always
available. This bucket influencer is the aggregation of all records in the
bucket; it is not just limited to a type of influencer.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>A bucket influencer is a type of influencer. For example, <code class="literal">client_ip</code> or
<code class="literal">user_name</code> can be bucket influencers, whereas <code class="literal">192.168.88.2</code> and <code class="literal">Bob</code> are
influencers.</p>
</div>
</div>
<p>An bucket influencer object has the following properties:</p>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">anomaly_score</code>
</span>
</dt>
<dd>
(number) A normalized score between 0-100, which is calculated for each bucket
influencer. This score might be updated as newer data is analyzed.
</dd>
<dt>
<span class="term">
<code class="literal">bucket_span</code>
</span>
</dt>
<dd>
(number) The length of the bucket in seconds. This value matches the <code class="literal">bucket_span</code>
that is specified in the job.
</dd>
<dt>
<span class="term">
<code class="literal">initial_anomaly_score</code>
</span>
</dt>
<dd>
(number) The score between 0-100 for each bucket influencer. This score is
the initial value that was calculated at the time the bucket was processed.
</dd>
<dt>
<span class="term">
<code class="literal">influencer_field_name</code>
</span>
</dt>
<dd>
(string) The field name of the influencer. For example <code class="literal">client_ip</code> or
<code class="literal">user_name</code>.
</dd>
<dt>
<span class="term">
<code class="literal">influencer_field_value</code>
</span>
</dt>
<dd>
(string) The field value of the influencer. For example <code class="literal">192.168.88.2</code> or
<code class="literal">Bob</code>.
</dd>
<dt>
<span class="term">
<code class="literal">is_interim</code>
</span>
</dt>
<dd>
(boolean) If true, this is an interim result. In other words, the bucket
influencer results are calculated based on partial input data.
</dd>
<dt>
<span class="term">
<code class="literal">job_id</code>
</span>
</dt>
<dd>
(string) The unique identifier for the job that these results belong to.
</dd>
<dt>
<span class="term">
<code class="literal">probability</code>
</span>
</dt>
<dd>
(number) The probability that the bucket has this behavior, in the range 0
to 1. For example, 0.0000109783. This value can be held to a high precision
of over 300 decimal places, so the <code class="literal">anomaly_score</code> is provided as a
human-readable and friendly interpretation of this.
</dd>
<dt>
<span class="term">
<code class="literal">raw_anomaly_score</code>
</span>
</dt>
<dd>
(number) Internal.
</dd>
<dt>
<span class="term">
<code class="literal">result_type</code>
</span>
</dt>
<dd>
(string) Internal. This value is always set to <code class="literal">bucket_influencer</code>.
</dd>
<dt>
<span class="term">
<code class="literal">timestamp</code>
</span>
</dt>
<dd>
(date) The start time of the bucket for which these results were calculated.
</dd>
</dl>
</div>
<h4><a id="ml-results-influencers"></a>Influencers<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/7.0/docs/reference/ml/apis/resultsresource.asciidoc">edit</a></h4>
<p>Influencers are the entities that have contributed to, or are to blame for,
the anomalies. Influencer results are available only if an
<code class="literal">influencer_field_name</code> is specified in the job configuration.</p>
<p>Influencers are given an <code class="literal">influencer_score</code>, which is calculated based on the
anomalies that have occurred in each bucket interval. For jobs with more than
one detector, this gives a powerful view of the most anomalous entities.</p>
<p>For example, if you are analyzing unusual bytes sent and unusual domains
visited and you specified <code class="literal">user_name</code> as the influencer, then an
<code class="literal">influencer_score</code> for each anomalous user name is written per bucket. For
example, if <code class="literal">user_name: Bob</code> had an <code class="literal">influencer_score</code> greater than 75, then
<code class="literal">Bob</code> would be considered very anomalous during this time interval in one or
both of those areas (unusual bytes sent or unusual domains visited).</p>
<p>One influencer result is written per bucket for each influencer that is
considered anomalous.</p>
<p>When you identify an influencer with a high score, you can investigate further
by accessing the records resource for that bucket and enumerating the anomaly
records that contain the influencer.</p>
<p>An influencer object has the following properties:</p>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">bucket_span</code>
</span>
</dt>
<dd>
(number) The length of the bucket in seconds. This value matches the <code class="literal">bucket_span</code>
that is specified in the job.
</dd>
<dt>
<span class="term">
<code class="literal">influencer_score</code>
</span>
</dt>
<dd>
(number) A normalized score between 0-100, which is based on the probability
of the influencer in this bucket aggregated across detectors. Unlike
<code class="literal">initial_influencer_score</code>, this value will be updated by a re-normalization
process as new data is analyzed.
</dd>
<dt>
<span class="term">
<code class="literal">initial_influencer_score</code>
</span>
</dt>
<dd>
(number) A normalized score between 0-100, which is based on the probability
of the influencer aggregated across detectors. This is the initial value that
was calculated at the time the bucket was processed.
</dd>
<dt>
<span class="term">
<code class="literal">influencer_field_name</code>
</span>
</dt>
<dd>
(string) The field name of the influencer.
</dd>
<dt>
<span class="term">
<code class="literal">influencer_field_value</code>
</span>
</dt>
<dd>
(string) The entity that influenced, contributed to, or was to blame for the
anomaly.
</dd>
<dt>
<span class="term">
<code class="literal">is_interim</code>
</span>
</dt>
<dd>
(boolean) If true, this is an interim result. In other words, the influencer
results are calculated based on partial input data.
</dd>
<dt>
<span class="term">
<code class="literal">job_id</code>
</span>
</dt>
<dd>
(string) The unique identifier for the job that these results belong to.
</dd>
<dt>
<span class="term">
<code class="literal">probability</code>
</span>
</dt>
<dd>
(number) The probability that the influencer has this behavior, in the range
0 to 1. For example, 0.0000109783. This value can be held to a high precision
of over 300 decimal places, so the <code class="literal">influencer_score</code> is provided as a
human-readable and friendly interpretation of this.
</dd>
<dt>
<span class="term">
<code class="literal">result_type</code>
</span>
</dt>
<dd>
(string) Internal. This value is always set to <code class="literal">influencer</code>.
</dd>
<dt>
<span class="term">
<code class="literal">timestamp</code>
</span>
</dt>
<dd>
(date) The start time of the bucket for which these results were calculated.
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>Additional influencer properties are added, depending on the fields being
analyzed. For example, if it&#8217;s analyzing <code class="literal">user_name</code> as an influencer, then a
field <code class="literal">user_name</code> is added to the result document. This information enables you to
filter the anomaly results more easily.</p>
</div>
</div>
<h4><a id="ml-results-records"></a>Records<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/7.0/docs/reference/ml/apis/resultsresource.asciidoc">edit</a></h4>
<p>Records contain the detailed analytical results. They describe the anomalous
activity that has been identified in the input data based on the detector
configuration.</p>
<p>For example, if you are looking for unusually large data transfers, an anomaly
record can identify the source IP address, the destination, the time window
during which it occurred, the expected and actual size of the transfer, and the
probability of this occurrence.</p>
<p>There can be many anomaly records depending on the characteristics and size of
the input data. In practice, there are often too many to be able to manually
process them. The machine learning features therefore perform a sophisticated
aggregation of the anomaly records into buckets.</p>
<p>The number of record results depends on the number of anomalies found in each
bucket, which relates to the number of time series being modeled and the number of
detectors.</p>
<p>A record object has the following properties:</p>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">actual</code>
</span>
</dt>
<dd>
(array) The actual value for the bucket.
</dd>
<dt>
<span class="term">
<code class="literal">bucket_span</code>
</span>
</dt>
<dd>
(number) The length of the bucket in seconds.
This value matches the <code class="literal">bucket_span</code> that is specified in the job.
</dd>
<dt>
<span class="term">
<code class="literal">by_field_name</code>
</span>
</dt>
<dd>
(string) The name of the analyzed field. This value is present only if
it is specified in the detector. For example, <code class="literal">client_ip</code>.
</dd>
<dt>
<span class="term">
<code class="literal">by_field_value</code>
</span>
</dt>
<dd>
(string) The value of <code class="literal">by_field_name</code>. This value is present only if
it is specified in the detector. For example, <code class="literal">192.168.66.2</code>.
</dd>
<dt>
<span class="term">
<code class="literal">causes</code>
</span>
</dt>
<dd>
(array) For population analysis, an over field must be specified in the
detector. This property contains an array of anomaly records that are the
causes for the anomaly that has been identified for the over field. If no
over fields exist, this field is not present. This sub-resource contains
the most anomalous records for the <code class="literal">over_field_name</code>. For scalability reasons,
a maximum of the 10 most significant causes of the anomaly are returned. As
part of the core analytical modeling, these low-level anomaly records are
aggregated for their parent over field record. The causes resource contains
similar elements to the record resource, namely <code class="literal">actual</code>, <code class="literal">typical</code>,
<code class="literal">*_field_name</code> and <code class="literal">*_field_value</code>. Probability and scores are not applicable
to causes.
</dd>
<dt>
<span class="term">
<code class="literal">detector_index</code>
</span>
</dt>
<dd>
(number) A unique identifier for the detector.
</dd>
<dt>
<span class="term">
<code class="literal">field_name</code>
</span>
</dt>
<dd>
(string) Certain functions require a field to operate on, for example, <code class="literal">sum()</code>.
For those functions, this value is the name of the field to be analyzed.
</dd>
<dt>
<span class="term">
<code class="literal">function</code>
</span>
</dt>
<dd>
(string) The function in which the anomaly occurs, as specified in the
detector configuration. For example, <code class="literal">max</code>.
</dd>
<dt>
<span class="term">
<code class="literal">function_description</code>
</span>
</dt>
<dd>
(string) The description of the function in which the anomaly occurs, as
specified in the detector configuration.
</dd>
<dt>
<span class="term">
<code class="literal">influencers</code>
</span>
</dt>
<dd>
(array) If <code class="literal">influencers</code> was specified in the detector configuration, then
this array contains influencers that contributed to or were to blame for an
anomaly.
</dd>
<dt>
<span class="term">
<code class="literal">initial_record_score</code>
</span>
</dt>
<dd>
(number) A normalized score between 0-100, which is based on the
probability of the anomalousness of this record. This is the initial value
that was calculated at the time the bucket was processed.
</dd>
<dt>
<span class="term">
<code class="literal">is_interim</code>
</span>
</dt>
<dd>
(boolean) If true, this is an interim result. In other words, the anomaly
record is calculated based on partial input data.
</dd>
<dt>
<span class="term">
<code class="literal">job_id</code>
</span>
</dt>
<dd>
(string) The unique identifier for the job that these results belong to.
</dd>
<dt>
<span class="term">
<code class="literal">over_field_name</code>
</span>
</dt>
<dd>
(string) The name of the over field that was used in the analysis. This value
is present only if it was specified in the detector. Over fields are used
in population analysis. For example, <code class="literal">user</code>.
</dd>
<dt>
<span class="term">
<code class="literal">over_field_value</code>
</span>
</dt>
<dd>
(string) The value of <code class="literal">over_field_name</code>. This value is present only if it
was specified in the detector. For example, <code class="literal">Bob</code>.
</dd>
<dt>
<span class="term">
<code class="literal">partition_field_name</code>
</span>
</dt>
<dd>
(string) The name of the partition field that was used in the analysis. This
value is present only if it was specified in the detector. For example,
<code class="literal">region</code>.
</dd>
<dt>
<span class="term">
<code class="literal">partition_field_value</code>
</span>
</dt>
<dd>
(string) The value of <code class="literal">partition_field_name</code>. This value is present only if
it was specified in the detector. For example, <code class="literal">us-east-1</code>.
</dd>
<dt>
<span class="term">
<code class="literal">probability</code>
</span>
</dt>
<dd>
(number) The probability of the individual anomaly occurring, in the range
0 to 1. For example, 0.0000772031. This value can be held to a high precision
of over 300 decimal places, so the <code class="literal">record_score</code> is provided as a
human-readable and friendly interpretation of this.
</dd>
<dt>
<span class="term">
<code class="literal">multi_bucket_impact</code>
</span>
</dt>
<dd>
(number) an indication of how strongly an anomaly is multi bucket or single bucket.
The value is on a scale of -5 to +5 where -5 means the anomaly is purely single
bucket and +5 means the anomaly is purely multi bucket.
</dd>
<dt>
<span class="term">
<code class="literal">record_score</code>
</span>
</dt>
<dd>
(number) A normalized score between 0-100, which is based on the probability
of the anomalousness of this record. Unlike <code class="literal">initial_record_score</code>, this
value will be updated by a re-normalization process as new data is analyzed.
</dd>
<dt>
<span class="term">
<code class="literal">result_type</code>
</span>
</dt>
<dd>
(string) Internal. This is always set to <code class="literal">record</code>.
</dd>
<dt>
<span class="term">
<code class="literal">timestamp</code>
</span>
</dt>
<dd>
(date) The start time of the bucket for which these results were calculated.
</dd>
<dt>
<span class="term">
<code class="literal">typical</code>
</span>
</dt>
<dd>
(array) The typical value for the bucket, according to analytical modeling.
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>Additional record properties are added, depending on the fields being
analyzed. For example, if it&#8217;s analyzing <code class="literal">hostname</code> as a <em>by field</em>, then a field
<code class="literal">hostname</code> is added to the result document. This information enables you to
filter the anomaly results more easily.</p>
</div>
</div>
<h4><a id="ml-results-categories"></a>Categories<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/7.0/docs/reference/ml/apis/resultsresource.asciidoc">edit</a></h4>
<p>When <code class="literal">categorization_field_name</code> is specified in the job configuration, it is
possible to view the definitions of the resulting categories. A category
definition describes the common terms matched and contains examples of matched
values.</p>
<p>The anomaly results from a categorization analysis are available as bucket,
influencer, and record results. For example, the results might indicate that
at 16:45 there was an unusual count of log message category 11. You can then
examine the description and examples of that category.</p>
<p>A category resource has the following properties:</p>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">category_id</code>
</span>
</dt>
<dd>
(unsigned integer) A unique identifier for the category.
</dd>
<dt>
<span class="term">
<code class="literal">examples</code>
</span>
</dt>
<dd>
(array) A list of examples of actual values that matched the category.
</dd>
<dt>
<span class="term">
<code class="literal">grok_pattern</code>
</span>
</dt>
<dd>
<span class="Admonishment Admonishment--experimental">
[<span class="Admonishment-title u-mono">experimental</span>]
<span class="Admonishment-detail">
This functionality is experimental and may be changed or removed completely in a future release. Elastic will take a best effort approach to fix any issues, but experimental features are not subject to the support SLA of official GA features.
</span>
</span> (string) A Grok pattern that could be used in Logstash or an
Ingest Pipeline to extract fields from messages that match the category. This
field is experimental and may be changed or removed in a future release. The
Grok patterns that are found are not optimal, but are often a good starting
point for manual tweaking.
</dd>
<dt>
<span class="term">
<code class="literal">job_id</code>
</span>
</dt>
<dd>
(string) The unique identifier for the job that these results belong to.
</dd>
<dt>
<span class="term">
<code class="literal">max_matching_length</code>
</span>
</dt>
<dd>
(unsigned integer) The maximum length of the fields that matched the category.
The value is increased by 10% to enable matching for similar fields that have
not been analyzed.
</dd>
<dt>
<span class="term">
<code class="literal">regex</code>
</span>
</dt>
<dd>
(string) A regular expression that is used to search for values that match the
category.
</dd>
<dt>
<span class="term">
<code class="literal">terms</code>
</span>
</dt>
<dd>
(string) A space separated list of the common tokens that are matched in
values of the category.
</dd>
</dl>
</div>
<h4><a id="ml-results-overall-buckets"></a>Overall Buckets<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/7.0/docs/reference/ml/apis/resultsresource.asciidoc">edit</a></h4>
<p>Overall buckets provide a summary of bucket results over multiple jobs.
Their <code class="literal">bucket_span</code> equals the longest <code class="literal">bucket_span</code> of the jobs in question.
The <code class="literal">overall_score</code> is the <code class="literal">top_n</code> average of the max <code class="literal">anomaly_score</code> per job
within the overall bucket time interval.
This means that you can fine-tune the <code class="literal">overall_score</code> so that it is more
or less sensitive to the number of jobs that detect an anomaly at the same time.</p>
<p>An overall bucket resource has the following properties:</p>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">timestamp</code>
</span>
</dt>
<dd>
(date) The start time of the overall bucket.
</dd>
<dt>
<span class="term">
<code class="literal">bucket_span</code>
</span>
</dt>
<dd>
(number) The length of the bucket in seconds. Matches the <code class="literal">bucket_span</code>
of the job with the longest one.
</dd>
<dt>
<span class="term">
<code class="literal">overall_score</code>
</span>
</dt>
<dd>
(number) The <code class="literal">top_n</code> average of the max bucket <code class="literal">anomaly_score</code> per job.
</dd>
<dt>
<span class="term">
<code class="literal">jobs</code>
</span>
</dt>
<dd>
(array) An array of objects that contain the <code class="literal">max_anomaly_score</code> per <code class="literal">job_id</code>.
</dd>
<dt>
<span class="term">
<code class="literal">is_interim</code>
</span>
</dt>
<dd>
(boolean) If true, this is an interim result. In other words, the anomaly
record is calculated based on partial input data.
</dd>
<dt>
<span class="term">
<code class="literal">result_type</code>
</span>
</dt>
<dd>
(string) Internal. This is always set to <code class="literal">overall_bucket</code>.
</dd>
</dl>
</div>
</div>
<div class="navfooter">
<span class="prev">
<a href="role-mapping-resources.html">« Role mapping resources</a>
</span>
<span class="next">
<a href="ml-event-resource.html">Scheduled event resources »</a>
</span>
</div>
</div>
</body>
</html>
