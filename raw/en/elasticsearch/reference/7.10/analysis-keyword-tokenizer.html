<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Keyword tokenizer | Elasticsearch Reference [7.10] | Elastic</title>
<link rel="home" href="index.html" title="Elasticsearch Reference [7.10]"/>
<link rel="up" href="analysis-tokenizers.html" title="Tokenizer reference"/>
<link rel="prev" href="analysis-edgengram-tokenizer.html" title="Edge n-gram tokenizer"/>
<link rel="next" href="analysis-letter-tokenizer.html" title="Letter tokenizer"/>
<meta name="DC.type" content="Learn/Docs/Elasticsearch/Reference/7.10"/>
<meta name="DC.subject" content="Elasticsearch"/>
<meta name="DC.identifier" content="7.10"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body><div class="page_header">
<strong>IMPORTANT</strong>: No additional bug fixes or documentation updates
will be released for this version. For the latest information, see the
<a href="../current/index.html">current release documentation</a>.
</div>
<div id="content">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="index.html">Elasticsearch Reference [7.10]</a></span>
»
<span class="breadcrumb-link"><a href="analysis.html">Text analysis</a></span>
»
<span class="breadcrumb-link"><a href="analysis-tokenizers.html">Tokenizer reference</a></span>
»
<span class="breadcrumb-node">Keyword tokenizer</span>
</div>
<div class="navheader">
<span class="prev">
<a href="analysis-edgengram-tokenizer.html">« Edge n-gram tokenizer</a>
</span>
<span class="next">
<a href="analysis-letter-tokenizer.html">Letter tokenizer »</a>
</span>
</div>
<div class="section">
<div class="titlepage"><div><div>
<h2 class="title"><a id="analysis-keyword-tokenizer"></a>Keyword tokenizer<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/7.10/docs/reference/analysis/tokenizers/keyword-tokenizer.asciidoc">edit</a></h2>
</div></div></div>

<p>The <code class="literal">keyword</code> tokenizer  is a &#8220;noop&#8221; tokenizer that accepts whatever text it
is given and outputs the exact same text as a single term.  It can be combined
with token filters to normalise output, e.g. lower-casing email addresses.</p>
<h3><a id="_example_output_10"></a>Example output<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/7.10/docs/reference/analysis/tokenizers/keyword-tokenizer.asciidoc">edit</a></h3>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">POST _analyze
{
  "tokenizer": "keyword",
  "text": "New York"
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/377.console"></div>
<p>The above sentence would produce the following term:</p>
<div class="pre_wrapper lang-text">
<pre class="programlisting prettyprint lang-text">[ New York ]</pre>
</div>
<h3><a id="analysis-keyword-tokenizer-token-filters"></a>Combine with token filters<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/7.10/docs/reference/analysis/tokenizers/keyword-tokenizer.asciidoc">edit</a></h3>
<p>You can combine the <code class="literal">keyword</code> tokenizer with token filters to normalise
structured data, such as product IDs or email addresses.</p>
<p>For example, the following <a class="xref" href="indices-analyze.html" title="Analyze API">analyze API</a> request uses the
<code class="literal">keyword</code> tokenizer and <a class="xref" href="analysis-lowercase-tokenfilter.html" title="Lowercase token filter"><code class="literal">lowercase</code></a> filter to
convert an email address to lowercase.</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">POST _analyze
{
  "tokenizer": "keyword",
  "filter": [ "lowercase" ],
  "text": "john.SMITH@example.COM"
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/378.console"></div>
<p>The request produces the following token:</p>
<div class="pre_wrapper lang-text">
<pre class="programlisting prettyprint lang-text">[ john.smith@example.com ]</pre>
</div>
<h3><a id="_configuration_11"></a>Configuration<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/7.10/docs/reference/analysis/tokenizers/keyword-tokenizer.asciidoc">edit</a></h3>
<p>The <code class="literal">keyword</code> tokenizer accepts the following parameters:</p>
<div class="informaltable">
<table border="0" cellpadding="4px">
<colgroup>
<col/>
<col/>
</colgroup>
<tbody valign="top">
<tr>
<td valign="top">
<p>
<code class="literal">buffer_size</code>
</p>
</td>
<td valign="top">
<p>
The number of characters read into the term buffer in a single pass.
Defaults to <code class="literal">256</code>.  The term buffer will grow by this size until all the
text has been consumed.  It is advisable not to change this setting.
</p>
</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="navfooter">
<span class="prev">
<a href="analysis-edgengram-tokenizer.html">« Edge n-gram tokenizer</a>
</span>
<span class="next">
<a href="analysis-letter-tokenizer.html">Letter tokenizer »</a>
</span>
</div>
</div>
</body>
</html>
