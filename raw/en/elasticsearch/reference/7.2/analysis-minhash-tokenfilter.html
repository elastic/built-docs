<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>MinHash Token Filter | Elasticsearch Guide [7.2] | Elastic</title>
<meta class="elastic" name="content" content="MinHash Token Filter | Elasticsearch Guide [7.2]">

<link rel="home" href="index.html" title="Elasticsearch Guide [7.2]"/>
<link rel="up" href="analysis-tokenfilters.html" title="Token Filters"/>
<link rel="prev" href="analysis-fingerprint-tokenfilter.html" title="Fingerprint Token Filter"/>
<link rel="next" href="analysis-remove-duplicates-tokenfilter.html" title="Remove Duplicates Token Filter"/>
<meta class="elastic" name="product_version" content="7.2"/>
<meta class="elastic" name="product_name" content="Elasticsearch"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/Elasticsearch/Reference/7.2"/>
<meta name="DC.subject" content="Elasticsearch"/>
<meta name="DC.identifier" content="7.2"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body>
<div class="page_header">
<strong>IMPORTANT</strong>: No additional bug fixes or documentation updates
will be released for this version. For the latest information, see the
<a href="../current/index.html">current release documentation</a>.
</div>
<div class="navheader">
<span class="prev">
<a href="analysis-fingerprint-tokenfilter.html">« Fingerprint Token Filter</a>
</span>
<span class="next">
<a href="analysis-remove-duplicates-tokenfilter.html">Remove Duplicates Token Filter »</a>
</span>
</div>
<div class="book" lang="en">
<div class="titlepage">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Elasticsearch Guide [7.2]</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="analysis.html">Analysis</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="analysis-tokenfilters.html">Token Filters</a></span>
</div>
<div>
<div><h1 class="title"><a id="id-1"></a>MinHash Token Filter</h1><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/7.2/docs/reference/analysis/tokenfilters/minhash-tokenfilter.asciidoc">edit</a></div>
</div>
<!--EXTRA-->
</div>
<div id="content">
<div id="url-to-v3" class="version-warning">
    <strong>IMPORTANT</strong>: This documentation is no longer updated. Refer to <a href="https://www.elastic.co/support/eol">Elastic's version policy</a> and the <a href="https://www.elastic.co/docs/reference/text-analysis/analysis-minhash-tokenfilter">latest documentation</a>.
</div>
<div class="section">
<div class="titlepage"><div><div>
<div class="position-relative"><h2 class="title"><a id="analysis-minhash-tokenfilter"></a>MinHash Token Filter</h2><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/7.2/docs/reference/analysis/tokenfilters/minhash-tokenfilter.asciidoc">edit</a></div>
</div></div></div>
<p>The <code class="literal">min_hash</code> token filter hashes each token of the token stream and divides
the resulting hashes into buckets, keeping the lowest-valued hashes per
bucket. It then returns these hashes as tokens.</p>
<p>The following are settings that can be set for a <code class="literal">min_hash</code> token filter.</p>
<div class="informaltable">
<table border="1" cellpadding="4px">
<colgroup>
<col class="col_1"/>
<col class="col_2"/>
</colgroup>
<thead>
<tr>
<th align="left" valign="top">Setting</th>
<th align="left" valign="top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" valign="top"><p><code class="literal">hash_count</code></p></td>
<td align="left" valign="top"><p>The number of hashes to hash the token stream with. Defaults to <code class="literal">1</code>.</p></td>
</tr>
<tr>
<td align="left" valign="top"><p><code class="literal">bucket_count</code></p></td>
<td align="left" valign="top"><p>The number of buckets to divide the minhashes into. Defaults to <code class="literal">512</code>.</p></td>
</tr>
<tr>
<td align="left" valign="top"><p><code class="literal">hash_set_size</code></p></td>
<td align="left" valign="top"><p>The number of minhashes to keep per bucket. Defaults to <code class="literal">1</code>.</p></td>
</tr>
<tr>
<td align="left" valign="top"><p><code class="literal">with_rotation</code></p></td>
<td align="left" valign="top"><p>Whether or not to fill empty buckets with the value of the first non-empty
bucket to its circular right. Only takes effect if hash_set_size is equal to one.
Defaults to <code class="literal">true</code> if bucket_count is greater than one, else <code class="literal">false</code>.</p></td>
</tr>
</tbody>
</table>
</div>
<p>Some points to consider while setting up a <code class="literal">min_hash</code> filter:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">min_hash</code> filter input tokens should typically be k-words shingles produced
from <a class="xref" href="analysis-shingle-tokenfilter.html" title="Shingle Token Filter">shingle token filter</a>.  You should
choose <code class="literal">k</code> large enough so that the probability of any given shingle
occurring in a  document is low. At the same time, as
internally each shingle is hashed into to 128-bit hash, you should choose
<code class="literal">k</code> small enough so that all possible
different k-words shingles can be hashed to 128-bit hash with
minimal collision.
</li>
<li class="listitem">
<p>choosing the right settings for <code class="literal">hash_count</code>, <code class="literal">bucket_count</code> and
<code class="literal">hash_set_size</code> needs some experimentation.</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
to improve the precision, you should increase <code class="literal">bucket_count</code> or
<code class="literal">hash_set_size</code>. Higher values of <code class="literal">bucket_count</code> or <code class="literal">hash_set_size</code>
will provide a higher guarantee that different tokens are
indexed to different buckets.
</li>
<li class="listitem">
to improve the recall,
you should increase <code class="literal">hash_count</code> parameter. For example,
setting <code class="literal">hash_count=2</code>, will make each token to be hashed in
two different ways, thus increasing the number of potential
candidates for search.
</li>
</ul>
</div>
</li>
<li class="listitem">
the default settings makes the  <code class="literal">min_hash</code> filter to produce for
each document 512 <code class="literal">min_hash</code> tokens, each is of size 16 bytes.
Thus, each document&#8217;s size will be increased by around 8Kb.
</li>
<li class="listitem">
<code class="literal">min_hash</code> filter is used to hash for Jaccard similarity. This means
that it doesn&#8217;t matter how many times a document contains a certain token,
only that if it contains it or not.
</li>
</ul>
</div>
<div class="section">
<div class="titlepage"><div><div>
<div class="position-relative"><h3 class="title"><a id="_theory"></a>Theory</h3><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/7.2/docs/reference/analysis/tokenfilters/minhash-tokenfilter.asciidoc">edit</a></div>
</div></div></div>
<p>MinHash token filter allows you to hash documents for similarity search.
Similarity search, or nearest neighbor search is a complex problem.
A naive solution requires an exhaustive pairwise comparison between a query
document and every document in an index. This is a prohibitive operation
if the index is large. A number of approximate nearest neighbor search
solutions have been developed to make similarity search more practical and
computationally feasible. One of these solutions involves hashing of documents.</p>
<p>Documents are hashed in a way that similar documents are more likely
to produce the same hash code and are put into the same hash bucket,
while dissimilar documents are more likely to be hashed into
different hash buckets. This type of hashing is known as
locality sensitive hashing (LSH).</p>
<p>Depending on what constitutes the similarity between documents,
various LSH functions <a href="https://arxiv.org/abs/1408.2927" class="ulink" target="_top">have been proposed</a>.
For <a href="https://en.wikipedia.org/wiki/Jaccard_index" class="ulink" target="_top">Jaccard similarity</a>, a popular
LSH function is <a href="https://en.wikipedia.org/wiki/MinHash" class="ulink" target="_top">MinHash</a>.
A general idea of the way MinHash produces a signature for a document
is by applying a random permutation over the whole index vocabulary (random
numbering for the vocabulary), and recording the minimum value for this permutation
for the document (the minimum number for a vocabulary word that is present
in the document). The permutations are run several times;
combining the minimum values for all of them will constitute a
signature for the document.</p>
<p>In practice, instead of random permutations, a number of hash functions
are chosen. A hash function calculates a hash code for each of a
document&#8217;s tokens and chooses the minimum hash code among them.
The minimum hash codes from all hash functions are combined
to form a signature for the document.</p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<div class="position-relative"><h3 class="title"><a id="_example_of_setting_minhash_token_filter_in_elasticsearch"></a>Example of setting MinHash Token Filter in Elasticsearch</h3><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/7.2/docs/reference/analysis/tokenfilters/minhash-tokenfilter.asciidoc">edit</a></div>
</div></div></div>
<p>Here is an example of setting up a <code class="literal">min_hash</code> filter:</p>
<div class="pre_wrapper lang-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js">POST /index1
{
  "settings": {
    "analysis": {
      "filter": {
        "my_shingle_filter": { <a id="CO351-1"></a><i class="conum" data-value="1"></i>
          "type": "shingle",
          "min_shingle_size": 5,
          "max_shingle_size": 5,
          "output_unigrams": false
        },
        "my_minhash_filter": {
          "type": "min_hash",
          "hash_count": 1,   <a id="CO351-2"></a><i class="conum" data-value="2"></i>
          "bucket_count": 512, <a id="CO351-3"></a><i class="conum" data-value="3"></i>
          "hash_set_size": 1, <a id="CO351-4"></a><i class="conum" data-value="4"></i>
          "with_rotation": true <a id="CO351-5"></a><i class="conum" data-value="5"></i>
        }
      },
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "standard",
          "filter": [
            "my_shingle_filter",
            "my_minhash_filter"
          ]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "fingerprint": {
        "type": "text",
        "analyzer": "my_analyzer"
      }
    }
  }
}</pre>
</div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO351-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>setting a shingle filter with 5-word shingles</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO351-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p>setting min_hash filter to hash with 1 hash</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO351-3"><i class="conum" data-value="3"></i></a></p>
</td>
<td align="left" valign="top">
<p>setting min_hash filter to hash tokens into 512 buckets</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO351-4"><i class="conum" data-value="4"></i></a></p>
</td>
<td align="left" valign="top">
<p>setting min_hash filter to keep only a single smallest hash in each bucket</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO351-5"><i class="conum" data-value="5"></i></a></p>
</td>
<td align="left" valign="top">
<p>setting min_hash filter to fill empty buckets with values from neighboring buckets</p>
</td>
</tr>
</table>
</div>
</div>

</div>
</div>
</div><div class="navfooter">
<span class="prev">
<a href="analysis-fingerprint-tokenfilter.html">« Fingerprint Token Filter</a>
</span>
<span class="next">
<a href="analysis-remove-duplicates-tokenfilter.html">Remove Duplicates Token Filter »</a>
</span>
</div>
</body>
</html>
