<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Anatomy of an analyzer | Elasticsearch Reference [7.2] | Elastic</title>
<link rel="home" href="index.html" title="Elasticsearch Reference [7.2]"/>
<link rel="up" href="analysis.html" title="Analysis"/>
<link rel="prev" href="analysis.html" title="Analysis"/>
<link rel="next" href="_testing_analyzers.html" title="Testing analyzers"/>
<meta name="DC.type" content="Learn/Docs/Elasticsearch/Reference/7.2"/>
<meta name="DC.subject" content="Elasticsearch"/>
<meta name="DC.identifier" content="7.2"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body><div class="page_header">
<strong>IMPORTANT</strong>: No additional bug fixes or documentation updates
will be released for this version. For the latest information, see the
<a href="../current/index.html">current release documentation</a>.
</div>
<div id="content">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="index.html">Elasticsearch Reference [7.2]</a></span>
»
<span class="breadcrumb-link"><a href="analysis.html">Analysis</a></span>
»
<span class="breadcrumb-node">Anatomy of an analyzer</span>
</div>
<div class="navheader">
<span class="prev">
<a href="analysis.html">« Analysis</a>
</span>
<span class="next">
<a href="_testing_analyzers.html">Testing analyzers »</a>
</span>
</div>
<div class="chapter">
<div class="titlepage"><div><div>
<h2 class="title"><a id="analyzer-anatomy"></a>Anatomy of an analyzer<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/7.2/docs/reference/analysis/anatomy.asciidoc">edit</a></h2>
</div></div></div>
<p>An <em>analyzer</em> &#8201;&#8212;&#8201;whether built-in or custom&#8201;&#8212;&#8201;is just a package which
contains three lower-level building blocks: <em>character filters</em>,
<em>tokenizers</em>, and <em>token filters</em>.</p>
<p>The built-in <a class="xref" href="analysis-analyzers.html" title="Analyzers">analyzers</a> pre-package these building
blocks into analyzers suitable for different languages and types of text.
Elasticsearch also exposes the individual building blocks so that they can be
combined to define new <a class="xref" href="analysis-custom-analyzer.html" title="Custom Analyzer"><code class="literal">custom</code></a> analyzers.</p>
<h3><a id="_character_filters"></a>Character filters<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/7.2/docs/reference/analysis/anatomy.asciidoc">edit</a></h3>
<p>A <em>character filter</em> receives the original text as a stream of characters and
can transform the stream by adding, removing, or changing characters.  For
instance, a character filter could be used to convert Hindu-Arabic numerals
(٠‎١٢٣٤٥٦٧٨‎٩‎) into their Arabic-Latin equivalents (0123456789), or to strip HTML
elements like <code class="literal">&lt;b&gt;</code> from the stream.</p>
<p>An analyzer may have <span class="strong strong"><strong>zero or more</strong></span> <a class="xref" href="analysis-charfilters.html" title="Character Filters">character filters</a>,
which are applied in order.</p>
<h3><a id="_tokenizer"></a>Tokenizer<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/7.2/docs/reference/analysis/anatomy.asciidoc">edit</a></h3>
<p>A <em>tokenizer</em>  receives a stream of characters, breaks it up into individual
<em>tokens</em> (usually individual words), and outputs a stream of <em>tokens</em>. For
instance, a <a class="xref" href="analysis-whitespace-tokenizer.html" title="Whitespace Tokenizer"><code class="literal">whitespace</code></a> tokenizer breaks
text into tokens whenever it sees any whitespace.  It would convert the text
<code class="literal">"Quick brown fox!"</code> into the terms <code class="literal">[Quick, brown, fox!]</code>.</p>
<p>The tokenizer is also responsible for recording the order or <em>position</em> of
each term and the start and end <em>character offsets</em> of the original word which
the term represents.</p>
<p>An analyzer must have <span class="strong strong"><strong>exactly one</strong></span> <a class="xref" href="analysis-tokenizers.html" title="Tokenizers">tokenizer</a>.</p>
<h3><a id="_token_filters"></a>Token filters<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/7.2/docs/reference/analysis/anatomy.asciidoc">edit</a></h3>
<p>A <em>token filter</em> receives the token stream and may add, remove, or change
tokens.  For example, a <a class="xref" href="analysis-lowercase-tokenfilter.html" title="Lowercase Token Filter"><code class="literal">lowercase</code></a> token
filter converts all tokens to lowercase, a
<a class="xref" href="analysis-stop-tokenfilter.html" title="Stop Token Filter"><code class="literal">stop</code></a> token filter removes common words
(<em>stop words</em>) like <code class="literal">the</code> from the token stream, and a
<a class="xref" href="analysis-synonym-tokenfilter.html" title="Synonym Token Filter"><code class="literal">synonym</code></a> token filter introduces synonyms
into the token stream.</p>
<p>Token filters are not allowed to change the position or character offsets of
each token.</p>
<p>An analyzer may have <span class="strong strong"><strong>zero or more</strong></span> <a class="xref" href="analysis-tokenfilters.html" title="Token Filters">token filters</a>,
which are applied in order.</p>
</div>
<div class="navfooter">
<span class="prev">
<a href="analysis.html">« Analysis</a>
</span>
<span class="next">
<a href="_testing_analyzers.html">Testing analyzers »</a>
</span>
</div>
</div>
</body>
</html>
