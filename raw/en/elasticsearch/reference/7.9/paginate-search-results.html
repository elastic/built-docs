<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Paginate search results | Elasticsearch Guide [7.9] | Elastic</title>
<meta class="elastic" name="content" content="Paginate search results | Elasticsearch Guide [7.9]">

<link rel="home" href="index.html" title="Elasticsearch Guide [7.9]"/>
<link rel="up" href="search-your-data.html" title="Search your data"/>
<link rel="prev" href="near-real-time.html" title="Near real-time search"/>
<link rel="next" href="inner-hits.html" title="Retrieve inner hits"/>
<meta class="elastic" name="product_version" content="7.9"/>
<meta class="elastic" name="product_name" content="Elasticsearch"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/Elasticsearch/Reference/7.9"/>
<meta name="DC.subject" content="Elasticsearch"/>
<meta name="DC.identifier" content="7.9"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body>
<div class="page_header">
<strong>IMPORTANT</strong>: No additional bug fixes or documentation updates
will be released for this version. For the latest information, see the
<a href="../current/index.html">current release documentation</a>.
</div>
<div class="navheader">
<span class="prev">
<a href="near-real-time.html">« Near real-time search</a>
</span>
<span class="next">
<a href="inner-hits.html">Retrieve inner hits »</a>
</span>
</div>
<div class="book" lang="en">
<div class="titlepage">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Elasticsearch Guide [7.9]</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="search-your-data.html">Search your data</a></span>
</div>
<div>
<div><h1 class="title"><a id="id-1"></a>Paginate search results</h1><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/7.9/docs/reference/search/search-your-data/paginate-search-results.asciidoc">edit</a></div>
</div>
<!--EXTRA-->
</div>
<div id="content">
<div class="chapter">
<div class="titlepage"><div><div>
<h2 class="title"><a id="paginate-search-results"></a>Paginate search results<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/7.9/docs/reference/search/search-your-data/paginate-search-results.asciidoc">edit</a></h2>
</div></div></div>
<p>By default, the <a class="xref" href="search-search.html" title="Search API">search API</a> returns the top 10 matching documents.</p>
<p>To paginate through a larger set of results, you can use the search API&#8217;s <code class="literal">size</code>
and <code class="literal">from</code> parameters. The <code class="literal">size</code> parameter is the number of matching documents
to return. The <code class="literal">from</code> parameter is a zero-indexed offset from the beginning of
the complete result set that indicates the document you want to start with.</p>
<p>The following search API request sets the <code class="literal">from</code> offset to <code class="literal">5</code>, meaning the
request offsets, or skips, the first five matching documents.</p>
<p>The <code class="literal">size</code> parameter is <code class="literal">20</code>, meaning the request can return up to 20 documents,
starting at the offset.</p>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">GET /_search
{
  "from": 5,
  "size": 20,
  "query": {
    "match": {
      "user.id": "kimchy"
    }
  }
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/658.console"></div>
<p>By default, you cannot page through more than 10,000 documents using the <code class="literal">from</code>
and <code class="literal">size</code> parameters. This limit is set using the
<a class="xref" href="index-modules.html#index-max-result-window"><code class="literal">index.max_result_window</code></a> index setting.</p>
<p>Deep paging or requesting many results at once can result in slow searches.
Results are sorted before being returned. Because search requests usually span
multiple shards, each shard must generate its own sorted results. These separate
results must then be combined and sorted to ensure that the overall sort order
is correct.</p>
<p>As an alternative to deep paging, we recommend using
<a class="xref" href="paginate-search-results.html#scroll-search-results" title="Scroll search results">scroll</a> or the
<a class="xref" href="paginate-search-results.html#search-after" title="Search after"><code class="literal">search_after</code></a> parameter.</p>
<div class="warning admon">
<div class="icon"></div>
<div class="admon_content">
<p>Elasticsearch uses Lucene&#8217;s internal doc IDs as tie-breakers. These internal
doc IDs can be completely different across replicas of the same
data. When paginating, you might occasionally see that documents with the same
sort values are not ordered consistently.</p>
</div>
</div>
<h3><a id="scroll-search-results"></a>Scroll search results<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/7.9/docs/reference/search/search-your-data/paginate-search-results.asciidoc">edit</a></h3>
<p>While a <code class="literal">search</code> request returns a single &#8220;page&#8221; of results, the <code class="literal">scroll</code>
API can be used to retrieve large numbers of results (or even all results)
from a single search request, in much the same way as you would use a cursor
on a traditional database.</p>
<p>Scrolling is not intended for real time user requests, but rather for
processing large amounts of data, e.g. in order to reindex the contents of one
data stream or index into a new data stream or index with a different
configuration.</p>
<div class="sidebar">
<div class="titlepage"><div><div>
<p class="title"><strong>Client support for scrolling and reindexing</strong></p>
</div></div></div>
<p>Some of the officially supported clients provide helpers to assist with
scrolled searches and reindexing:</p>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
Perl
</span>
</dt>
<dd>
See <a href="https://metacpan.org/pod/Search::Elasticsearch::Client::5_0::Bulk" class="ulink" target="_top">Search::Elasticsearch::Client::5_0::Bulk</a>
and <a href="https://metacpan.org/pod/Search::Elasticsearch::Client::5_0::Scroll" class="ulink" target="_top">Search::Elasticsearch::Client::5_0::Scroll</a>
</dd>
<dt>
<span class="term">
Python
</span>
</dt>
<dd>
See <a href="https://elasticsearch-py.readthedocs.org/en/master/helpers.html" class="ulink" target="_top">elasticsearch.helpers.*</a>
</dd>
<dt>
<span class="term">
JavaScript
</span>
</dt>
<dd>
See <a href="/guide/en/elasticsearch/client/javascript-api/current/client-helpers.html" class="ulink" target="_top">client.helpers.*</a>
</dd>
</dl>
</div>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>The results that are returned from a scroll request reflect the state of
the data stream or index at the time that the initial <code class="literal">search</code> request was  made, like a
snapshot in time. Subsequent changes to documents (index, update or delete)
will only affect later search requests.</p>
</div>
</div>
<p>In order to use scrolling, the initial search request should specify the
<code class="literal">scroll</code> parameter in the query string, which tells Elasticsearch how long it
should keep the &#8220;search context&#8221; alive (see <a class="xref" href="paginate-search-results.html#scroll-search-context" title="Keeping the search context alive">Keeping the search context alive</a>), eg <code class="literal">?scroll=1m</code>.</p>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">POST /my-index-000001/_search?scroll=1m
{
  "size": 100,
  "query": {
    "match": {
      "message": "foo"
    }
  }
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/659.console"></div>
<p>The result from the above request includes a <code class="literal">_scroll_id</code>, which should
be passed to the <code class="literal">scroll</code> API in order to retrieve the next batch of
results.</p>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">POST /_search/scroll                                                               <a id="CO183-1"></a><i class="conum" data-value="1"></i>
{
  "scroll" : "1m",                                                                 <a id="CO183-2"></a><i class="conum" data-value="2"></i>
  "scroll_id" : "DXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAD4WYm9laVYtZndUQlNsdDcwakFMNjU1QQ==" <a id="CO183-3"></a><i class="conum" data-value="3"></i>
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/660.console"></div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO183-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p><code class="literal">GET</code> or <code class="literal">POST</code> can be used and the URL should not include the <code class="literal">index</code>
name&#8201;&#8212;&#8201;this is specified in the original <code class="literal">search</code> request instead.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO183-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p>The <code class="literal">scroll</code> parameter tells Elasticsearch to keep the search context open
for another <code class="literal">1m</code>.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO183-3"><i class="conum" data-value="3"></i></a></p>
</td>
<td align="left" valign="top">
<p>The <code class="literal">scroll_id</code> parameter</p>
</td>
</tr>
</table>
</div>
<p>The <code class="literal">size</code> parameter allows you to configure the maximum number of hits to be
returned with each batch of results.  Each call to the <code class="literal">scroll</code> API returns the
next batch of results until there are no more results left to return, ie the
<code class="literal">hits</code> array is empty.</p>
<div class="important admon">
<div class="icon"></div>
<div class="admon_content">
<p>The initial search request and each subsequent scroll request each
return a <code class="literal">_scroll_id</code>. While the <code class="literal">_scroll_id</code> may change between requests, it doesn’t
always change — in any case, only the most recently received <code class="literal">_scroll_id</code> should be used.</p>
</div>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>If the request specifies aggregations, only the initial search response
will contain the aggregations results.</p>
</div>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>Scroll requests have optimizations that make them faster when the sort
order is <code class="literal">_doc</code>. If you want to iterate over all documents regardless of the
order, this is the most efficient option:</p>
</div>
</div>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">GET /_search?scroll=1m
{
  "sort": [
    "_doc"
  ]
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/661.console"></div>
<h4><a id="scroll-search-context"></a>Keeping the search context alive<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/7.9/docs/reference/search/search-your-data/paginate-search-results.asciidoc">edit</a></h4>
<p>A scroll returns all the documents which matched the search at the time of the
initial search request. It ignores any subsequent changes to these documents.
The <code class="literal">scroll_id</code> identifies a <em>search context</em> which keeps track of everything
that Elasticsearch needs to return the correct documents. The search context is created
by the initial request and kept alive by subsequent requests.</p>
<p>The <code class="literal">scroll</code> parameter (passed to the <code class="literal">search</code> request and to every <code class="literal">scroll</code>
request) tells Elasticsearch how long it should keep the search context alive.
Its value (e.g. <code class="literal">1m</code>, see <a class="xref" href="common-options.html#time-units" title="Time units">Time units</a>) does not need to be long enough to
process all data&#8201;&#8212;&#8201;it just needs to be long enough to process the previous
batch of results. Each <code class="literal">scroll</code> request (with the <code class="literal">scroll</code> parameter) sets a
new  expiry time. If a <code class="literal">scroll</code> request doesn&#8217;t pass in the <code class="literal">scroll</code>
parameter, then the search context will be freed as part of <em>that</em> <code class="literal">scroll</code>
request.</p>
<p>Normally, the background merge process optimizes the index by merging together
smaller segments to create new, bigger segments. Once the smaller segments are
no longer needed they are deleted. This process continues during scrolling, but
an open search context prevents the old segments from being deleted since they
are still in use.</p>
<div class="tip admon">
<div class="icon"></div>
<div class="admon_content">
<p>Keeping older segments alive means that more disk space and file handles
are needed. Ensure that you have configured your nodes to have ample free file
handles. See <a class="xref" href="file-descriptors.html" title="File Descriptors">File Descriptors</a>.</p>
</div>
</div>
<p>Additionally, if a segment contains deleted or updated documents then the
search context must keep track of whether each document in the segment was live
at the time of the initial search request. Ensure that your nodes have
sufficient heap space if you have many open scrolls on an index that is subject
to ongoing deletes or updates.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>To prevent against issues caused by having too many scrolls open, the
user is not allowed to open scrolls past a certain limit. By default, the
maximum number of open scrolls is 500. This limit can be updated with the
<code class="literal">search.max_open_scroll_context</code> cluster setting.</p>
</div>
</div>
<p>You can check how many search contexts are open with the
<a class="xref" href="cluster-nodes-stats.html" title="Nodes stats API">nodes stats API</a>:</p>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">GET /_nodes/stats/indices/search</pre>
</div>
<div class="console_widget" data-snippet="snippets/662.console"></div>
<h4><a id="clear-scroll"></a>Clear scroll<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/7.9/docs/reference/search/search-your-data/paginate-search-results.asciidoc">edit</a></h4>
<p>Search context are automatically removed when the <code class="literal">scroll</code> timeout has been
exceeded. However keeping scrolls open has a cost, as discussed in the
<a class="xref" href="paginate-search-results.html#scroll-search-context" title="Keeping the search context alive">previous section</a> so scrolls should be explicitly
cleared as soon as the scroll is not being used anymore using the
<code class="literal">clear-scroll</code> API:</p>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">DELETE /_search/scroll
{
  "scroll_id" : "DXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAD4WYm9laVYtZndUQlNsdDcwakFMNjU1QQ=="
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/663.console"></div>
<p>Multiple scroll IDs can be passed as array:</p>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">DELETE /_search/scroll
{
  "scroll_id" : [
    "DXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAD4WYm9laVYtZndUQlNsdDcwakFMNjU1QQ==",
    "DnF1ZXJ5VGhlbkZldGNoBQAAAAAAAAABFmtSWWRRWUJrU2o2ZExpSGJCVmQxYUEAAAAAAAAAAxZrUllkUVlCa1NqNmRMaUhiQlZkMWFBAAAAAAAAAAIWa1JZZFFZQmtTajZkTGlIYkJWZDFhQQAAAAAAAAAFFmtSWWRRWUJrU2o2ZExpSGJCVmQxYUEAAAAAAAAABBZrUllkUVlCa1NqNmRMaUhiQlZkMWFB"
  ]
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/664.console"></div>
<p>All search contexts can be cleared with the <code class="literal">_all</code> parameter:</p>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">DELETE /_search/scroll/_all</pre>
</div>
<div class="console_widget" data-snippet="snippets/665.console"></div>
<p>The <code class="literal">scroll_id</code> can also be passed as a query string parameter or in the request body.
Multiple scroll IDs can be passed as comma separated values:</p>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">DELETE /_search/scroll/DXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAD4WYm9laVYtZndUQlNsdDcwakFMNjU1QQ==,DnF1ZXJ5VGhlbkZldGNoBQAAAAAAAAABFmtSWWRRWUJrU2o2ZExpSGJCVmQxYUEAAAAAAAAAAxZrUllkUVlCa1NqNmRMaUhiQlZkMWFBAAAAAAAAAAIWa1JZZFFZQmtTajZkTGlIYkJWZDFhQQAAAAAAAAAFFmtSWWRRWUJrU2o2ZExpSGJCVmQxYUEAAAAAAAAABBZrUllkUVlCa1NqNmRMaUhiQlZkMWFB</pre>
</div>
<div class="console_widget" data-snippet="snippets/666.console"></div>
<h4><a id="slice-scroll"></a>Sliced scroll<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/7.9/docs/reference/search/search-your-data/paginate-search-results.asciidoc">edit</a></h4>
<p>For scroll queries that return a lot of documents it is possible to split the scroll in multiple slices which
can be consumed independently:</p>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">GET /my-index-000001/_search?scroll=1m
{
  "slice": {
    "id": 0,                      <a id="CO184-1"></a><i class="conum" data-value="1"></i>
    "max": 2                      <a id="CO184-2"></a><i class="conum" data-value="2"></i>
  },
  "query": {
    "match": {
      "message": "foo"
    }
  }
}
GET /my-index-000001/_search?scroll=1m
{
  "slice": {
    "id": 1,
    "max": 2
  },
  "query": {
    "match": {
      "message": "foo"
    }
  }
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/667.console"></div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO184-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>The id of the slice</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO184-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p>The maximum number of slices</p>
</td>
</tr>
</table>
</div>
<p>The result from the first request returned documents that belong to the first slice (id: 0) and the result from the
second request returned documents that belong to the second slice. Since the maximum number of slices is set to 2
 the union of the results of the two requests is equivalent to the results of a scroll query without slicing.
By default the splitting is done on the shards first and then locally on each shard using the _id field
with the following formula:
<code class="literal">slice(doc) = floorMod(hashCode(doc._id), max)</code>
For instance if the number of shards is equal to 2 and the user requested 4 slices then the slices 0 and 2 are assigned
to the first shard and the slices 1 and 3 are assigned to the second shard.</p>
<p>Each scroll is independent and can be processed in parallel like any scroll request.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>If the number of slices is bigger than the number of shards the slice filter is very slow on the first calls, it has a complexity of O(N) and a memory cost equals
to N bits per slice where N is the total number of documents in the shard.
After few calls the filter should be cached and subsequent calls should be faster but you should limit the number of
 sliced query you perform in parallel to avoid the memory explosion.</p>
</div>
</div>
<p>To avoid this cost entirely it is possible to use the <code class="literal">doc_values</code> of another field to do the slicing
but the user must ensure that the field has the following properties:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
The field is numeric.
</li>
<li class="listitem">
<code class="literal">doc_values</code> are enabled on that field
</li>
<li class="listitem">
Every document should contain a single value. If a document has multiple values for the specified field, the first value is used.
</li>
<li class="listitem">
The value for each document should be set once when the document is created and never updated. This ensures that each
slice gets deterministic results.
</li>
<li class="listitem">
The cardinality of the field should be high. This ensures that each slice gets approximately the same amount of documents.
</li>
</ul>
</div>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">GET /my-index-000001/_search?scroll=1m
{
  "slice": {
    "field": "@timestamp",
    "id": 0,
    "max": 10
  },
  "query": {
    "match": {
      "message": "foo"
    }
  }
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/668.console"></div>
<p>For append only time-based indices, the <code class="literal">timestamp</code> field can be used safely.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>By default the maximum number of slices allowed per scroll is limited to 1024.
You can update the <code class="literal">index.max_slices_per_scroll</code> index setting to bypass this limit.</p>
</div>
</div>
<h3><a id="search-after"></a>Search after<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/7.9/docs/reference/search/search-your-data/paginate-search-results.asciidoc">edit</a></h3>
<p>Pagination of results can be done by using the <code class="literal">from</code> and <code class="literal">size</code> but the cost becomes prohibitive when the deep pagination is reached.
The <code class="literal">index.max_result_window</code> which defaults to 10,000 is a safeguard, search requests take heap memory and time proportional to <code class="literal">from + size</code>.
The <a class="xref" href="paginate-search-results.html#scroll-search-results" title="Scroll search results">scroll</a> API is recommended for efficient deep scrolling but scroll contexts are costly and it is not
recommended to use it for real time user requests.
The <code class="literal">search_after</code> parameter circumvents this problem by providing a live cursor.
The idea is to use the results from the previous page to help the retrieval of the next page.</p>
<p>Suppose that the query to retrieve the first page looks like this:</p>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">GET my-index-000001/_search
{
  "size": 10,
  "query": {
    "match" : {
      "message" : "foo"
    }
  },
  "sort": [
    {"@timestamp": "asc"},
    {"tie_breaker_id": "asc"}      <a id="CO185-1"></a><i class="conum" data-value="1"></i>
  ]
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/669.console"></div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO185-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>A copy of the <code class="literal">_id</code> field with <code class="literal">doc_values</code> enabled</p>
</td>
</tr>
</table>
</div>
<div class="important admon">
<div class="icon"></div>
<div class="admon_content">
<p>A field with one unique value per document should be used as the tiebreaker
of the sort specification. Otherwise the sort order for documents that have
the same sort values would be undefined and could lead to missing or duplicate
results. The <a class="xref" href="mapping-id-field.html" title="_id field"><code class="literal">_id</code> field</a> has a unique value per document
but it is not recommended to use it as a tiebreaker directly.
Beware that <code class="literal">search_after</code> looks for the first document which fully or partially
matches tiebreaker&#8217;s provided value. Therefore if a document has a tiebreaker value of
<code class="literal">"654323"</code> and you <code class="literal">search_after</code> for <code class="literal">"654"</code> it would still match that document
and return results found after it.
<a class="xref" href="doc-values.html" title="doc_values">doc value</a> are disabled on this field so sorting on it requires
to load a lot of data in memory. Instead it is advised to duplicate (client side
 or with a <a class="xref" href="ingest-processors.html" title="Processors">set ingest processor</a>) the content
of the <a class="xref" href="mapping-id-field.html" title="_id field"><code class="literal">_id</code> field</a> in another field that has
<a class="xref" href="doc-values.html" title="doc_values">doc value</a> enabled and to use this new field as the tiebreaker
for the sort.</p>
</div>
</div>
<p>The result from the above request includes an array of <code class="literal">sort values</code> for each document.
These <code class="literal">sort values</code> can be used in conjunction with the <code class="literal">search_after</code> parameter to start returning results "after" any
document in the result list.
For instance we can use the <code class="literal">sort values</code> of the last document and pass it to <code class="literal">search_after</code> to retrieve the next page of results:</p>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">GET my-index-000001/_search
{
  "size": 10,
  "query": {
    "match" : {
      "message" : "foo"
    }
  },
  "search_after": [1463538857, "654323"],
  "sort": [
    {"@timestamp": "asc"},
    {"tie_breaker_id": "asc"}
  ]
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/670.console"></div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>The parameter <code class="literal">from</code> must be set to 0 (or -1) when <code class="literal">search_after</code> is used.</p>
</div>
</div>
<p><code class="literal">search_after</code> is not a solution to jump freely to a random page but rather to scroll many queries in parallel.
It is very similar to the <code class="literal">scroll</code> API but unlike it, the <code class="literal">search_after</code> parameter is stateless, it is always resolved against the latest
 version of the searcher. For this reason the sort order may change during a walk depending on the updates and deletes of your index.</p>
</div>
</div>
</div><div class="navfooter">
<span class="prev">
<a href="near-real-time.html">« Near real-time search</a>
</span>
<span class="next">
<a href="inner-hits.html">Retrieve inner hits »</a>
</span>
</div>
</body>
</html>
