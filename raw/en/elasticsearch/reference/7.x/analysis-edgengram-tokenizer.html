<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Edge n-gram tokenizer | Elasticsearch Reference [7.x] | Elastic</title>
<link rel="home" href="index.html" title="Elasticsearch Reference [7.x]"/>
<link rel="up" href="analysis-tokenizers.html" title="Tokenizer reference"/>
<link rel="prev" href="analysis-classic-tokenizer.html" title="Classic tokenizer"/>
<link rel="next" href="analysis-keyword-tokenizer.html" title="Keyword tokenizer"/>
<meta name="DC.type" content="Learn/Docs/Elasticsearch/Reference/7.x"/>
<meta name="DC.subject" content="Elasticsearch"/>
<meta name="DC.identifier" content="7.x"/>
</head>
<body><div class="page_header">
You are looking at preliminary documentation for a future release.
Not what you want? See the
<a href="../current/index.html">current release documentation</a>.
</div>
<div id="content">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="index.html">Elasticsearch Reference [7.x]</a></span>
»
<span class="breadcrumb-link"><a href="analysis.html">Text analysis</a></span>
»
<span class="breadcrumb-link"><a href="analysis-tokenizers.html">Tokenizer reference</a></span>
»
<span class="breadcrumb-node">Edge n-gram tokenizer</span>
</div>
<div class="navheader">
<span class="prev">
<a href="analysis-classic-tokenizer.html">« Classic tokenizer</a>
</span>
<span class="next">
<a href="analysis-keyword-tokenizer.html">Keyword tokenizer »</a>
</span>
</div>
<div class="section">
<div class="titlepage"><div><div>
<h2 class="title"><a id="analysis-edgengram-tokenizer"></a>Edge n-gram tokenizer<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/7.x/docs/reference/analysis/tokenizers/edgengram-tokenizer.asciidoc">edit</a></h2>
</div></div></div>

<p>The <code class="literal">edge_ngram</code> tokenizer first breaks text down into words whenever it
encounters one of a list of specified characters, then it emits
<a href="https://en.wikipedia.org/wiki/N-gram" class="ulink" target="_top">N-grams</a> of each word where the start of
the N-gram is anchored to the beginning of the word.</p>
<p>Edge N-Grams are useful for <em>search-as-you-type</em> queries.</p>
<div class="tip admon">
<div class="icon"></div>
<div class="admon_content">
<p>When you need <em>search-as-you-type</em> for text which has a widely known
order, such as movie or song titles, the
<a class="xref" href="search-suggesters.html#completion-suggester" title="Completion Suggester">completion suggester</a> is a much more efficient
choice than edge N-grams.  Edge N-grams have the advantage when trying to
autocomplete words that can appear in any order.</p>
</div>
</div>
<h3><a id="_example_output_9"></a>Example output<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/7.x/docs/reference/analysis/tokenizers/edgengram-tokenizer.asciidoc">edit</a></h3>
<p>With the default settings, the <code class="literal">edge_ngram</code> tokenizer treats the initial text as a
single token and produces N-grams with minimum length <code class="literal">1</code> and maximum length
<code class="literal">2</code>:</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">POST _analyze
{
  "tokenizer": "edge_ngram",
  "text": "Quick Fox"
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/398.console"></div>
<p>The above sentence would produce the following terms:</p>
<div class="pre_wrapper lang-text">
<pre class="programlisting prettyprint lang-text">[ Q, Qu ]</pre>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>These default gram lengths are almost entirely useless.  You need to
configure the <code class="literal">edge_ngram</code> before using it.</p>
</div>
</div>
<h3><a id="_configuration_10"></a>Configuration<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/7.x/docs/reference/analysis/tokenizers/edgengram-tokenizer.asciidoc">edit</a></h3>
<p>The <code class="literal">edge_ngram</code> tokenizer accepts the following parameters:</p>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">min_gram</code>
</span>
</dt>
<dd>
Minimum length of characters in a gram.  Defaults to <code class="literal">1</code>.
</dd>
<dt>
<span class="term">
<code class="literal">max_gram</code>
</span>
</dt>
<dd>
<p>Maximum length of characters in a gram.  Defaults to <code class="literal">2</code>.</p>
<p>See <a class="xref" href="analysis-edgengram-tokenizer.html#max-gram-limits" title="Limitations of the max_gram parameter">Limitations of the <code class="literal">max_gram</code> parameter</a>.</p>
</dd>
<dt>
<span class="term">
<code class="literal">token_chars</code>
</span>
</dt>
<dd>
<p>
Character classes that should be included in a token.  Elasticsearch
will split on characters that don&#8217;t belong to the classes specified.
Defaults to <code class="literal">[]</code> (keep all characters).
</p>
<p>Character classes may be any of the following:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">letter</code>&#8201;&#8212;&#8201;     for example <code class="literal">a</code>, <code class="literal">b</code>, <code class="literal">ï</code> or <code class="literal">京</code>
</li>
<li class="listitem">
<code class="literal">digit</code>&#8201;&#8212;&#8201;      for example <code class="literal">3</code> or <code class="literal">7</code>
</li>
<li class="listitem">
<code class="literal">whitespace</code>&#8201;&#8212;&#8201; for example <code class="literal">" "</code> or <code class="literal">"\n"</code>
</li>
<li class="listitem">
<code class="literal">punctuation</code>&#8201;&#8212;&#8201;for example <code class="literal">!</code> or <code class="literal">"</code>
</li>
<li class="listitem">
<code class="literal">symbol</code>&#8201;&#8212;&#8201;     for example <code class="literal">$</code> or <code class="literal">√</code>
</li>
<li class="listitem">
<code class="literal">custom</code>&#8201;&#8212;&#8201;     custom characters which need to be set using the
<code class="literal">custom_token_chars</code> setting.
</li>
</ul>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">custom_token_chars</code>
</span>
</dt>
<dd>
Custom characters that should be treated as part of a token. For example,
setting this to <code class="literal">+-_</code> will make the tokenizer treat the plus, minus and
underscore sign  as part of a token.
</dd>
</dl>
</div>
<h3><a id="max-gram-limits"></a>Limitations of the <code class="literal">max_gram</code> parameter<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/7.x/docs/reference/analysis/tokenizers/edgengram-tokenizer.asciidoc">edit</a></h3>
<p>The <code class="literal">edge_ngram</code> tokenizer&#8217;s <code class="literal">max_gram</code> value limits the character length of
tokens. When the <code class="literal">edge_ngram</code> tokenizer is used with an index analyzer, this
means search terms longer than the <code class="literal">max_gram</code> length may not match any indexed
terms.</p>
<p>For example, if the <code class="literal">max_gram</code> is <code class="literal">3</code>, searches for <code class="literal">apple</code> won&#8217;t match the
indexed term <code class="literal">app</code>.</p>
<p>To account for this, you can use the
<a class="xref" href="analysis-truncate-tokenfilter.html" title="Truncate token filter"><code class="literal">truncate</code></a> token filter with a search analyzer
to shorten search terms to the <code class="literal">max_gram</code> character length. However, this could
return irrelevant results.</p>
<p>For example, if the <code class="literal">max_gram</code> is <code class="literal">3</code> and search terms are truncated to three
characters, the search term <code class="literal">apple</code> is shortened to <code class="literal">app</code>. This means searches
for <code class="literal">apple</code> return any indexed terms matching <code class="literal">app</code>, such as <code class="literal">apply</code>, <code class="literal">snapped</code>,
and <code class="literal">apple</code>.</p>
<p>We recommend testing both approaches to see which best fits your
use case and desired search experience.</p>
<h3><a id="_example_configuration_7"></a>Example configuration<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/7.x/docs/reference/analysis/tokenizers/edgengram-tokenizer.asciidoc">edit</a></h3>
<p>In this example, we configure the <code class="literal">edge_ngram</code> tokenizer to treat letters and
digits as tokens, and to produce grams with minimum length <code class="literal">2</code> and maximum
length <code class="literal">10</code>:</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">PUT my-index-00001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "my_tokenizer"
        }
      },
      "tokenizer": {
        "my_tokenizer": {
          "type": "edge_ngram",
          "min_gram": 2,
          "max_gram": 10,
          "token_chars": [
            "letter",
            "digit"
          ]
        }
      }
    }
  }
}

POST my-index-00001/_analyze
{
  "analyzer": "my_analyzer",
  "text": "2 Quick Foxes."
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/399.console"></div>
<p>The above example produces the following terms:</p>
<div class="pre_wrapper lang-text">
<pre class="programlisting prettyprint lang-text">[ Qu, Qui, Quic, Quick, Fo, Fox, Foxe, Foxes ]</pre>
</div>
<p>Usually we recommend using the same <code class="literal">analyzer</code> at index time and at search
time. In the case of the <code class="literal">edge_ngram</code> tokenizer, the advice is different. It
only makes sense to use the <code class="literal">edge_ngram</code> tokenizer at index time, to ensure
that partial words are available for matching in the index. At search time,
just search for the terms the user has typed in, for instance: <code class="literal">Quick Fo</code>.</p>
<p>Below is an example of how to set up a field for <em>search-as-you-type</em>.</p>
<p>Note that the <code class="literal">max_gram</code> value for the index analyzer is <code class="literal">10</code>, which limits
indexed terms to 10 characters. Search terms are not truncated, meaning that
search terms longer than 10 characters may not match any indexed terms.</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">PUT my-index-00001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "autocomplete": {
          "tokenizer": "autocomplete",
          "filter": [
            "lowercase"
          ]
        },
        "autocomplete_search": {
          "tokenizer": "lowercase"
        }
      },
      "tokenizer": {
        "autocomplete": {
          "type": "edge_ngram",
          "min_gram": 2,
          "max_gram": 10,
          "token_chars": [
            "letter"
          ]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "title": {
        "type": "text",
        "analyzer": "autocomplete",
        "search_analyzer": "autocomplete_search"
      }
    }
  }
}

PUT my-index-00001/_doc/1
{
  "title": "Quick Foxes" <a id="CO158-1"></a><i class="conum" data-value="1"></i>
}

POST my-index-00001/_refresh

GET my-index-00001/_search
{
  "query": {
    "match": {
      "title": {
        "query": "Quick Fo", <a id="CO158-2"></a><i class="conum" data-value="2"></i>
        "operator": "and"
      }
    }
  }
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/400.console"></div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO158-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>The <code class="literal">autocomplete</code> analyzer indexes the terms <code class="literal">[qu, qui, quic, quick, fo, fox, foxe, foxes]</code>.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO158-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p>The <code class="literal">autocomplete_search</code> analyzer searches for the terms <code class="literal">[quick, fo]</code>, both of which appear in the index.</p>
</td>
</tr>
</table>
</div>
</div>
<div class="navfooter">
<span class="prev">
<a href="analysis-classic-tokenizer.html">« Classic tokenizer</a>
</span>
<span class="next">
<a href="analysis-keyword-tokenizer.html">Keyword tokenizer »</a>
</span>
</div>
</div>
</body>
</html>
