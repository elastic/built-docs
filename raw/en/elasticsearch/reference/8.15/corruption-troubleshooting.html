<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="keywords" content="hot-spotting, hotspot, hot-spot, hot spot, hotspots, hotspotting">
<title>Troubleshooting corruption | Elasticsearch Guide [8.15] | Elastic</title>
<meta class="elastic" name="content" content="Troubleshooting corruption | Elasticsearch Guide [8.15]">

<link rel="home" href="index.html" title="Elasticsearch Guide [8.15]"/>
<link rel="up" href="troubleshooting.html" title="Troubleshooting"/>
<link rel="prev" href="increase-cluster-shard-limit.html" title="Total number of shards per node has been reached"/>
<link rel="next" href="fix-data-node-out-of-disk.html" title="Fix data nodes out of disk"/>
<meta class="elastic" name="product_version" content="8.15"/>
<meta class="elastic" name="product_name" content="Elasticsearch"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/Elasticsearch/Reference/8.15"/>
<meta name="DC.subject" content="Elasticsearch"/>
<meta name="DC.identifier" content="8.15"/>
</head>
<body>
<div class="navheader">
<span class="prev">
<a href="increase-cluster-shard-limit.html">« Total number of shards per node has been reached</a>
</span>
<span class="next">
<a href="fix-data-node-out-of-disk.html">Fix data nodes out of disk »</a>
</span>
</div>
<div class="book" lang="en">
<div class="titlepage">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Elasticsearch Guide [8.15]</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="troubleshooting.html">Troubleshooting</a></span>
</div>
<div>
<div><h1 class="title"><a id="id-1"></a>Troubleshooting corruption</h1><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.15/docs/reference/troubleshooting/corruption-issues.asciidoc">edit</a></div>
</div>
<!--EXTRA-->
</div>
<div id="content">
<div class="chapter">
<div class="titlepage"><div><div>
<h2 class="title"><a id="corruption-troubleshooting"></a>Troubleshooting corruption<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.15/docs/reference/troubleshooting/corruption-issues.asciidoc">edit</a></h2>
</div></div></div>
<p>Elasticsearch expects that the data it reads from disk is exactly the data it previously
wrote. If it detects that the data on disk is different from what it wrote then
it will report some kind of exception such as:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">org.apache.lucene.index.CorruptIndexException</code>
</li>
<li class="listitem">
<code class="literal">org.elasticsearch.gateway.CorruptStateException</code>
</li>
<li class="listitem">
<code class="literal">org.elasticsearch.index.translog.TranslogCorruptedException</code>
</li>
</ul>
</div>
<p>Typically these exceptions happen due to a checksum mismatch. Most of the data
that Elasticsearch writes to disk is followed by a checksum using a simple algorithm
known as CRC32 which is fast to compute and good at detecting the kinds of
random corruption that may happen when using faulty storage. A CRC32 checksum
mismatch definitely indicates that something is faulty, although of course a
matching checksum doesn&#8217;t prove the absence of corruption.</p>
<p>Verifying a checksum is expensive since it involves reading every byte of the
file which takes significant effort and might evict more useful data from the
filesystem cache, so systems typically don&#8217;t verify the checksum on a file very
often. This is why you tend only to encounter a corruption exception when
something unusual is happening. For instance, corruptions are often detected
during merges, shard movements, and snapshots. This does not mean that these
processes are causing corruption: they are examples of the rare times where
reading a whole file is necessary. Elasticsearch takes the opportunity to verify the
checksum at the same time, and this is when the corruption is detected and
reported. It doesn&#8217;t indicate the cause of the corruption or when it happened.
Corruptions can remain undetected for many months.</p>
<p>The files that make up a Lucene index are written sequentially from start to
end and then never modified or overwritten. This access pattern means the
checksum computation is very simple and can happen on-the-fly as the file is
initially written, and also makes it very unlikely that an incorrect checksum
is due to a userspace bug at the time the file was written. The part of Elasticsearch
that computes the checksum is straightforward, widely used, and very
well-tested, so you can be very confident that a checksum mismatch really does
indicate that the data read from disk is different from the data that Elasticsearch
previously wrote.</p>
<p>If a file header is corrupted then it&#8217;s possible that Elasticsearch might not be able
to work out how to even start reading the file which can lead to an exception
such as:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">org.apache.lucene.index.IndexFormatTooOldException</code>
</li>
<li class="listitem">
<code class="literal">org.apache.lucene.index.IndexFormatTooNewException</code>
</li>
</ul>
</div>
<p>It is also possible that Elasticsearch reports a corruption if a file it needs is
entirely missing, with an exception such as:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">java.io.FileNotFoundException</code>
</li>
<li class="listitem">
<code class="literal">java.nio.file.NoSuchFileException</code>
</li>
</ul>
</div>
<p>The files that make up a Lucene index are written in full before they are used.
If a file is needed to recover an index after a restart then your storage
system previously confirmed to Elasticsearch that this file was durably synced to disk.
On Linux this means that the <code class="literal">fsync()</code> system call returned successfully. Elasticsearch
sometimes reports that an index is corrupt because a file needed for recovery
is missing, or it exists but has been truncated or is missing its footer. This
may indicate that your storage system acknowledges durable writes incorrectly.</p>
<p>There are many possible explanations for Elasticsearch detecting corruption in your
cluster. Databases like Elasticsearch generate a challenging I/O workload that may find
subtle infrastructural problems which other tests may miss. Elasticsearch is known to
expose the following problems as file corruptions:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
Filesystem bugs, especially in newer and nonstandard filesystems which might
  not have seen enough real-world production usage to be confident that they
work correctly.
</li>
<li class="listitem">
<a href="/blog/canonical-elastic-and-google-team-up-to-prevent-data-corruption-in-linux" class="ulink" target="_top">Kernel bugs</a>.
</li>
<li class="listitem">
Bugs in firmware running on the drive or RAID controller.
</li>
<li class="listitem">
Incorrect configuration, for instance configuring <code class="literal">fsync()</code> to report success
before all durable writes have completed.
</li>
<li class="listitem">
Faulty hardware, which may include the drive itself, the RAID controller,
your RAM or CPU.
</li>
<li class="listitem">
Third-party software which modifies the files that Elasticsearch writes.
</li>
</ul>
</div>
<p>Data corruption typically doesn&#8217;t result in other evidence of problems apart
from the checksum mismatch. Do not interpret this as an indication that your
storage subsystem is working correctly and therefore that Elasticsearch itself caused
the corruption. It is rare for faulty storage to show any evidence of problems
apart from the data corruption, but data corruption itself is a very strong
indicator that your storage subsystem is not working correctly.</p>
<p>To rule out Elasticsearch as the source of data corruption, generate an I/O workload
using something other than Elasticsearch and look for data integrity errors. On Linux
the <code class="literal">fio</code> and <code class="literal">stress-ng</code> tools can both generate challenging I/O workloads and
verify the integrity of the data they write. Use version 0.12.01 or newer of
<code class="literal">stress-ng</code> since earlier versions do not have strong enough integrity checks.
Verify that durable writes persist across power outages using a script such as
<a href="https://gist.github.com/bradfitz/3172656" class="ulink" target="_top"><code class="literal">diskchecker.pl</code></a>. Alternatively, use
a tool such as <code class="literal">strace</code> to observe the sequence of syscalls that Elasticsearch makes
when writing data and confirm that this sequence does not explain the reported
corruption.</p>
<p>To narrow down the source of the corruptions, systematically change components
in your cluster&#8217;s environment until the corruptions stop. The details will
depend on the exact configuration of your environment, but may include the
following:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
Try a different filesystem or a different kernel.
</li>
<li class="listitem">
Try changing each hardware component in turn, ideally changing to a different
model or manufacturer.
</li>
<li class="listitem">
Try different firmware versions for each hardware component.
</li>
<li class="listitem">
Remove any third-party software which may modify the contents of the Elasticsearch
data path.
</li>
</ul>
</div>
</div>
</div>
</div><div class="navfooter">
<span class="prev">
<a href="increase-cluster-shard-limit.html">« Total number of shards per node has been reached</a>
</span>
<span class="next">
<a href="fix-data-node-out-of-disk.html">Fix data nodes out of disk »</a>
</span>
</div>
</body>
</html>
