<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Dictionary decompounder token filter | Elasticsearch Guide [8.16] | Elastic</title>
<meta class="elastic" name="content" content="Dictionary decompounder token filter | Elasticsearch Guide [8.16]">

<link rel="home" href="index.html" title="Elasticsearch Guide [8.16]"/>
<link rel="up" href="analysis-tokenfilters.html" title="Token filter reference"/>
<link rel="prev" href="analysis-delimited-payload-tokenfilter.html" title="Delimited payload token filter"/>
<link rel="next" href="analysis-edgengram-tokenfilter.html" title="Edge n-gram token filter"/>
<meta class="elastic" name="product_version" content="8.16"/>
<meta class="elastic" name="product_name" content="Elasticsearch"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/Elasticsearch/Reference/8.16"/>
<meta name="DC.subject" content="Elasticsearch"/>
<meta name="DC.identifier" content="8.16"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body>
<div class="page_header">
This documentation contains work-in-progress information for future Elastic Stack and Cloud releases. Use the version selector to view supported release docs. It also contains some Elastic Cloud serverless information. Check out our <a href="https://www.elastic.co/docs/current/serverless">serverless docs</a> for more details.
</div>
<div class="navheader">
<span class="prev">
<a href="analysis-delimited-payload-tokenfilter.html">« Delimited payload token filter</a>
</span>
<span class="next">
<a href="analysis-edgengram-tokenfilter.html">Edge n-gram token filter »</a>
</span>
</div>
<div class="book" lang="en">
<div class="titlepage">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Elasticsearch Guide [8.16]</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="analysis.html">Text analysis</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="analysis-tokenfilters.html">Token filter reference</a></span>
</div>
<div>
<div><h1 class="title"><a id="id-1"></a>Dictionary decompounder token filter</h1><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/8.16/docs/reference/analysis/tokenfilters/dictionary-decompounder-tokenfilter.asciidoc">edit</a></div>
</div>
<!--EXTRA-->
</div>
<div id="content">
<div class="section">
<div class="titlepage"><div><div>
<div class="position-relative"><h2 class="title"><a id="analysis-dict-decomp-tokenfilter"></a>Dictionary decompounder token filter</h2><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/8.16/docs/reference/analysis/tokenfilters/dictionary-decompounder-tokenfilter.asciidoc">edit</a></div>
</div></div></div>

<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>In most cases, we recommend using the faster
<a class="xref" href="analysis-hyp-decomp-tokenfilter.html" title="Hyphenation decompounder token filter"><code class="literal">hyphenation_decompounder</code></a> token filter
in place of this filter. However, you can use the
<code class="literal">dictionary_decompounder</code> filter to check the quality of a word list before
implementing it in the <code class="literal">hyphenation_decompounder</code> filter.</p>
</div>
</div>
<p>Uses a specified list of words and a brute force approach to find subwords in
compound words. If found, these subwords are included in the token output.</p>
<p>This filter uses Lucene&#8217;s
<a href="https://lucene.apache.org/core/9_12_0/analysis/common/org/apache/lucene/analysis/compound/DictionaryCompoundWordTokenFilter.html" class="ulink" target="_top">DictionaryCompoundWordTokenFilter</a>,
which was built for Germanic languages.</p>
<div class="section">
<div class="titlepage"><div><div>
<div class="position-relative"><h3 class="title"><a id="analysis-dict-decomp-tokenfilter-analyze-ex"></a>Example</h3><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/8.16/docs/reference/analysis/tokenfilters/dictionary-decompounder-tokenfilter.asciidoc">edit</a></div>
</div></div></div>
<p>The following <a class="xref" href="indices-analyze.html" title="Analyze API">analyze API</a> request uses the
<code class="literal">dictionary_decompounder</code> filter to find subwords in <code class="literal">Donaudampfschiff</code>. The
filter then checks these subwords against the specified list of words: <code class="literal">Donau</code>,
<code class="literal">dampf</code>, <code class="literal">meer</code>, and <code class="literal">schiff</code>.</p>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">GET _analyze
{
  "tokenizer": "standard",
  "filter": [
    {
      "type": "dictionary_decompounder",
      "word_list": ["Donau", "dampf", "meer", "schiff"]
    }
  ],
  "text": "Donaudampfschiff"
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/540.console"></div>
<p>The filter produces the following tokens:</p>
<div class="pre_wrapper lang-text">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-text">[ Donaudampfschiff, Donau, dampf, schiff ]</pre>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<div class="position-relative"><h3 class="title"><a id="analysis-dict-decomp-tokenfilter-configure-parms"></a>Configurable parameters</h3><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/8.16/docs/reference/analysis/tokenfilters/dictionary-decompounder-tokenfilter.asciidoc">edit</a></div>
</div></div></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">word_list</code>
</span>
</dt>
<dd>
<p>(Required*, array of strings)
A list of subwords to look for in the token stream. If found, the subword is
included in the token output.</p>
<p>Either this parameter or <code class="literal">word_list_path</code> must be specified.</p>
</dd>
<dt>
<span class="term">
<code class="literal">word_list_path</code>
</span>
</dt>
<dd>
<p>(Required*, string)
Path to a file that contains a list of subwords to find in the token stream. If
found, the subword is included in the token output.</p>
<p>This path must be absolute or relative to the <code class="literal">config</code> location, and the file
must be UTF-8 encoded. Each token in the file must be separated by a line break.</p>
<p>Either this parameter or <code class="literal">word_list</code> must be specified.</p>
</dd>
<dt>
<span class="term">
<code class="literal">max_subword_size</code>
</span>
</dt>
<dd>
(Optional, integer)
Maximum subword character length. Longer subword tokens are excluded from the
output. Defaults to <code class="literal">15</code>.
</dd>
<dt>
<span class="term">
<code class="literal">min_subword_size</code>
</span>
</dt>
<dd>
(Optional, integer)
Minimum subword character length. Shorter subword tokens are excluded from the
output. Defaults to <code class="literal">2</code>.
</dd>
<dt>
<span class="term">
<code class="literal">min_word_size</code>
</span>
</dt>
<dd>
(Optional, integer)
Minimum word character length. Shorter word tokens are excluded from the
output. Defaults to <code class="literal">5</code>.
</dd>
<dt>
<span class="term">
<code class="literal">only_longest_match</code>
</span>
</dt>
<dd>
(Optional, Boolean)
If <code class="literal">true</code>, only include the longest matching subword. Defaults to <code class="literal">false</code>.
</dd>
</dl>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<div class="position-relative"><h3 class="title"><a id="analysis-dict-decomp-tokenfilter-customize"></a>Customize and add to an analyzer</h3><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/8.16/docs/reference/analysis/tokenfilters/dictionary-decompounder-tokenfilter.asciidoc">edit</a></div>
</div></div></div>
<p>To customize the <code class="literal">dictionary_decompounder</code> filter, duplicate it to create the
basis for a new custom token filter. You can modify the filter using its
configurable parameters.</p>
<p>For example, the following <a class="xref" href="indices-create-index.html" title="Create index API">create index API</a> request
uses a custom <code class="literal">dictionary_decompounder</code> filter to configure a new
<a class="xref" href="analysis-custom-analyzer.html" title="Create a custom analyzer">custom analyzer</a>.</p>
<p>The custom <code class="literal">dictionary_decompounder</code> filter find subwords in the
<code class="literal">analysis/example_word_list.txt</code> file. Subwords longer than 22 characters are
excluded from the token output.</p>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">PUT dictionary_decompound_example
{
  "settings": {
    "analysis": {
      "analyzer": {
        "standard_dictionary_decompound": {
          "tokenizer": "standard",
          "filter": [ "22_char_dictionary_decompound" ]
        }
      },
      "filter": {
        "22_char_dictionary_decompound": {
          "type": "dictionary_decompounder",
          "word_list_path": "analysis/example_word_list.txt",
          "max_subword_size": 22
        }
      }
    }
  }
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/541.console"></div>
</div>

</div>
</div>
</div><div class="navfooter">
<span class="prev">
<a href="analysis-delimited-payload-tokenfilter.html">« Delimited payload token filter</a>
</span>
<span class="next">
<a href="analysis-edgengram-tokenfilter.html">Edge n-gram token filter »</a>
</span>
</div>
</body>
</html>
