PUT /_inference/chat_completion/chat-completion-endpoint
{
    "service": "elastic",
    "service_settings": {
        "model_id": "model-1"
    }
}
