<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Troubleshooting corruption | Elasticsearch Guide [8.6] | Elastic</title>
<link rel="home" href="index.html" title="Elasticsearch Guide [8.6]"/>
<link rel="up" href="troubleshooting.html" title="Troubleshooting"/>
<link rel="prev" href="increase-cluster-shard-limit.html" title="Total number of shards per node has been reached"/>
<link rel="next" href="fix-data-node-out-of-disk.html" title="Fix data nodes out of disk"/>
<meta name="DC.type" content="Learn/Docs/Elasticsearch/Reference/8.6"/>
<meta name="DC.subject" content="Elasticsearch"/>
<meta name="DC.identifier" content="8.6"/>
</head>
<body>
<div id="content">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span><span class="chevron-right">›</span>
<span class="breadcrumb-link"><a href="index.html">Elasticsearch Guide [8.6]</a></span><span class="chevron-right">›</span>
<span class="breadcrumb-link"><a href="troubleshooting.html">Troubleshooting</a></span>
</div>
<div class="navheader">
<span class="prev">
<a href="increase-cluster-shard-limit.html">« Total number of shards per node has been reached</a>
</span>
<span class="next">
<a href="fix-data-node-out-of-disk.html">Fix data nodes out of disk »</a>
</span>
</div>
<div class="chapter">
<div class="titlepage"><div><div>
<h2 class="title"><a id="corruption-troubleshooting"></a>Troubleshooting corruption<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.6/docs/reference/troubleshooting/corruption-issues.asciidoc">edit</a></h2>
</div></div></div>
<p>Elasticsearch expects that the data it reads from disk is exactly the data it previously
wrote. If it detects that the data on disk is different from what it wrote then
it will report some kind of exception such as:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">org.apache.lucene.index.CorruptIndexException</code>
</li>
<li class="listitem">
<code class="literal">org.elasticsearch.gateway.CorruptStateException</code>
</li>
<li class="listitem">
<code class="literal">org.elasticsearch.index.translog.TranslogCorruptedException</code>
</li>
</ul>
</div>
<p>Typically these exceptions happen due to a checksum mismatch. Most of the data
that Elasticsearch writes to disk is followed by a checksum using a simple algorithm
known as CRC32 which is fast to compute and good at detecting the kinds of
random corruption that may happen when using faulty storage. A CRC32 checksum
mismatch definitely indicates that something is faulty, although of course a
matching checksum doesn&#8217;t prove the absence of corruption.</p>
<p>Verifying a checksum is expensive since it involves reading every byte of the
file which takes significant effort and might evict more useful data from the
filesystem cache, so systems typically don&#8217;t verify the checksum on a file very
often. This is why you tend only to encounter a corruption exception when
something unusual is happening. For instance, corruptions are often detected
during merges, shard movements, and snapshots. This does not mean that these
processes are causing corruption: they are examples of the rare times where
reading a whole file is necessary. Elasticsearch takes the opportunity to verify the
checksum at the same time, and this is when the corruption is detected and
reported. It doesn&#8217;t indicate the cause of the corruption or when it happened.
Corruptions can remain undetected for many months.</p>
<p>The files that make up a Lucene index are written sequentially from start to
end and then never modified or overwritten. This access pattern means the
checksum computation is very simple and can happen on-the-fly as the file is
initially written, and also makes it very unlikely that an incorrect checksum
is due to a userspace bug at the time the file was written. The routine that
computes the checksum is straightforward, widely used, and very well-tested, so
you can be very confident that a checksum mismatch really does indicate that
the data read from disk is different from the data that Elasticsearch previously wrote.</p>
<p>The files that make up a Lucene index are written in full before they are used.
If a file is needed to recover an index after a restart then your storage
system previously confirmed to Elasticsearch that this file was durably synced to disk.
On Linux this means that the <code class="literal">fsync()</code> system call returned successfully. Elasticsearch
sometimes detects that an index is corrupt because a file needed for recovery
has been truncated or is missing its footer. This indicates that your storage
system acknowledges durable writes incorrectly.</p>
<p>There are many possible explanations for Elasticsearch detecting corruption in your
cluster. Databases like Elasticsearch generate a challenging I/O workload that may find
subtle infrastructural problems which other tests may miss. Elasticsearch is known to
expose the following problems as file corruptions:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
Filesystem bugs, especially in newer and nonstandard filesystems which might
  not have seen enough real-world production usage to be confident that they
work correctly.
</li>
<li class="listitem">
<a href="/blog/canonical-elastic-and-google-team-up-to-prevent-data-corruption-in-linux" class="ulink" target="_top">Kernel bugs</a>.
</li>
<li class="listitem">
Bugs in firmware running on the drive or RAID controller.
</li>
<li class="listitem">
Incorrect configuration, for instance configuring <code class="literal">fsync()</code> to report success
before all durable writes have completed.
</li>
<li class="listitem">
Faulty hardware, which may include the drive itself, the RAID controller,
your RAM or CPU.
</li>
</ul>
</div>
<p>Data corruption typically doesn&#8217;t result in other evidence of problems apart
from the checksum mismatch. Do not interpret this as an indication that your
storage subsystem is working correctly and therefore that Elasticsearch itself caused
the corruption. It is rare for faulty storage to show any evidence of problems
apart from the data corruption, but data corruption itself is a very strong
indicator that your storage subsystem is not working correctly.</p>
<p>To rule out Elasticsearch as the source of data corruption, generate an I/O workload
using something other than Elasticsearch and look for data integrity errors. On Linux
the <code class="literal">fio</code> and <code class="literal">stress-ng</code> tools can both generate challenging I/O workloads and
verify the integrity of the data they write. Use version 0.12.01 or newer of
<code class="literal">stress-ng</code> since earlier versions do not have strong enough integrity checks.
You can check that durable writes persist across power outages using a script
such as <a href="https://gist.github.com/bradfitz/3172656" class="ulink" target="_top"><code class="literal">diskchecker.pl</code></a>.</p>
<p>To narrow down the source of the corruptions, systematically change components
in your cluster&#8217;s environment until the corruptions stop. The details will
depend on the exact configuration of your hardware, but may include the
following:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
Try a different filesystem or a different kernel.
</li>
<li class="listitem">
Try changing each hardware component in turn, ideally changing to a different
model or manufacturer.
</li>
<li class="listitem">
Try different firmware versions for each hardware component.
</li>
</ul>
</div>
</div>
<div class="navfooter">
<span class="prev">
<a href="increase-cluster-shard-limit.html">« Total number of shards per node has been reached</a>
</span>
<span class="next">
<a href="fix-data-node-out-of-disk.html">Fix data nodes out of disk »</a>
</span>
</div>
</div>
</body>
</html>
