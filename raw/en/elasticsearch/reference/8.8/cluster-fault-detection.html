<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Cluster fault detection | Elasticsearch Guide [8.8] | Elastic</title>
<meta class="elastic" name="content" content="Cluster fault detection | Elasticsearch Guide [8.8]">

<link rel="home" href="index.html" title="Elasticsearch Guide [8.8]"/>
<link rel="up" href="modules-discovery.html" title="Discovery and cluster formation"/>
<link rel="prev" href="cluster-state-publishing.html" title="Publishing the cluster state"/>
<link rel="next" href="add-elasticsearch-nodes.html" title="Add and remove nodes in your cluster"/>
<meta class="elastic" name="product_version" content="8.8"/>
<meta class="elastic" name="product_name" content="Elasticsearch"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/Elasticsearch/Reference/8.8"/>
<meta name="DC.subject" content="Elasticsearch"/>
<meta name="DC.identifier" content="8.8"/>
</head>
<body><div class="page_header">
You are looking at preliminary documentation for a future release.
Not what you want? See the
<a href="../current/index.html">current release documentation</a>.
</div>
<div id="content">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Elasticsearch Guide [8.8]</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="setup.html">Set up Elasticsearch</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="modules-discovery.html">Discovery and cluster formation</a></span>
</div>
<div class="navheader">
<span class="prev">
<a href="cluster-state-publishing.html">« Publishing the cluster state</a>
</span>
<span class="next">
<a href="add-elasticsearch-nodes.html">Add and remove nodes in your cluster »</a>
</span>
</div>
<div class="section">
<div class="titlepage"><div><div>
<h2 class="title"><a id="cluster-fault-detection"></a>Cluster fault detection<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.8/docs/reference/modules/discovery/fault-detection.asciidoc">edit</a></h2>
</div></div></div>
<p>The elected master periodically checks each of the nodes in the cluster to
ensure that they are still connected and healthy. Each node in the cluster also
periodically checks the health of the elected master. These checks are known
respectively as <em>follower checks</em> and <em>leader checks</em>.</p>
<p>Elasticsearch allows these checks to occasionally fail or timeout without
taking any action. It considers a node to be faulty only after a number of
consecutive checks have failed. You can control fault detection behavior with
<a class="xref" href="modules-discovery-settings.html" title="Discovery and cluster formation settings"><code class="literal">cluster.fault_detection.*</code> settings</a>.</p>
<p>If the elected master detects that a node has disconnected, however, this
situation is treated as an immediate failure. The master bypasses the timeout
and retry setting values and attempts to remove the node from the cluster.
Similarly, if a node detects that the elected master has disconnected, this
situation is treated as an immediate failure. The node bypasses the timeout and
retry settings and restarts its discovery phase to try and find or elect a new
master.</p>
<p><a id="cluster-fault-detection-filesystem-health"></a>Additionally, each node periodically verifies that its data path is healthy by
writing a small file to disk and then deleting it again. If a node discovers
its data path is unhealthy then it is removed from the cluster until the data
path recovers. You can control this behavior with the
<a class="xref" href="modules-discovery-settings.html" title="Discovery and cluster formation settings"><code class="literal">monitor.fs.health</code> settings</a>.</p>
<p><a id="cluster-fault-detection-cluster-state-publishing"></a> The elected master node
will also remove nodes from the cluster if nodes are unable to apply an updated
cluster state within a reasonable time. The timeout defaults to 2 minutes
starting from the beginning of the cluster state update. Refer to
<a class="xref" href="cluster-state-publishing.html" title="Publishing the cluster state">Publishing the cluster state</a> for a more detailed description.</p>
<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="cluster-fault-detection-troubleshooting"></a>Troubleshooting an unstable cluster<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.8/docs/reference/modules/discovery/fault-detection.asciidoc">edit</a></h3>
</div></div></div>
<p>Normally, a node will only leave a cluster if deliberately shut down. If a node
leaves the cluster unexpectedly, it&#8217;s important to address the cause. A cluster
in which nodes leave unexpectedly is unstable and can create several issues.
For instance:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
The cluster health may be yellow or red.
</li>
<li class="listitem">
Some shards will be initializing and other shards may be failing.
</li>
<li class="listitem">
Search, indexing, and monitoring operations may fail and report exceptions in
logs.
</li>
<li class="listitem">
The <code class="literal">.security</code> index may be unavailable, blocking access to the cluster.
</li>
<li class="listitem">
The master may appear busy due to frequent cluster state updates.
</li>
</ul>
</div>
<p>To troubleshoot a cluster in this state, first ensure the cluster has a
<a class="xref" href="discovery-troubleshooting.html" title="Troubleshooting discovery">stable master</a>. Next, focus on the nodes
unexpectedly leaving the cluster ahead of all other issues. It will not be
possible to solve other issues until the cluster has a stable master node and
stable node membership.</p>
<p>Diagnostics and statistics are usually not useful in an unstable cluster. These
tools only offer a view of the state of the cluster at a single point in time.
Instead, look at the cluster logs to see the pattern of behaviour over time.
Focus particularly on logs from the elected master. When a node leaves the
cluster, logs for the elected master include a message like this (with line
breaks added to make it easier to read):</p>
<div class="pre_wrapper lang-text">
<pre class="programlisting prettyprint lang-text">[2022-03-21T11:02:35,513][INFO ][o.e.c.c.NodeLeftExecutor] [instance-0000000000]
    node-left: [{instance-0000000004}{bfcMDTiDRkietFb9v_di7w}{aNlyORLASam1ammv2DzYXA}{172.27.47.21}{172.27.47.21:19054}{m}]
    with reason [disconnected]</pre>
</div>
<p>This message says that the <code class="literal">NodeLeftExecutor</code> on the elected master
(<code class="literal">instance-0000000000</code>) processed a <code class="literal">node-left</code> task, identifying the node that
was removed and the reason for its removal. When the node joins the cluster
again, logs for the elected master will include a message like this (with line
breaks added to make it easier to read):</p>
<div class="pre_wrapper lang-text">
<pre class="programlisting prettyprint lang-text">[2022-03-21T11:02:59,892][INFO ][o.e.c.c.NodeJoinExecutor] [instance-0000000000]
    node-join: [{instance-0000000004}{bfcMDTiDRkietFb9v_di7w}{UNw_RuazQCSBskWZV8ID_w}{172.27.47.21}{172.27.47.21:19054}{m}]
    with reason [joining after restart, removed [24s] ago with reason [disconnected]]</pre>
</div>
<p>This message says that the <code class="literal">NodeJoinExecutor</code> on the elected master
(<code class="literal">instance-0000000000</code>) processed a <code class="literal">node-join</code> task, identifying the node that
was added to the cluster and the reason for the task.</p>
<p>Other nodes may log similar messages, but report fewer details:</p>
<div class="pre_wrapper lang-text">
<pre class="programlisting prettyprint lang-text">[2020-01-29T11:02:36,985][INFO ][o.e.c.s.ClusterApplierService]
    [instance-0000000001] removed {
        {instance-0000000004}{bfcMDTiDRkietFb9v_di7w}{aNlyORLASam1ammv2DzYXA}{172.27.47.21}{172.27.47.21:19054}{m}
        {tiebreaker-0000000003}{UNw_RuazQCSBskWZV8ID_w}{bltyVOQ-RNu20OQfTHSLtA}{172.27.161.154}{172.27.161.154:19251}{mv}
    }, term: 14, version: 1653415, reason: Publication{term=14, version=1653415}</pre>
</div>
<p>These messages are not especially useful for troubleshooting, so focus on the
ones from the <code class="literal">NodeLeftExecutor</code> and <code class="literal">NodeJoinExecutor</code> which are only emitted
on the elected master and which contain more details. If you don&#8217;t see the
messages from the <code class="literal">NodeLeftExecutor</code> and <code class="literal">NodeJoinExecutor</code>, check that:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
You&#8217;re looking at the logs for the elected master node.
</li>
<li class="listitem">
The logs cover the correct time period.
</li>
<li class="listitem">
Logging is enabled at <code class="literal">INFO</code> level.
</li>
</ul>
</div>
<p>Nodes will also log a message containing <code class="literal">master node changed</code> whenever they
start or stop following the elected master. You can use these messages to
determine each node&#8217;s view of the state of the master over time.</p>
<p>If a node restarts, it will leave the cluster and then join the cluster again.
When it rejoins, the <code class="literal">NodeJoinExecutor</code> will log that it processed a
<code class="literal">node-join</code> task indicating that the node is <code class="literal">joining after restart</code>. If a node
is unexpectedly restarting, look at the node&#8217;s logs to see why it is shutting
down.</p>
<p>If the node did not restart then you should look at the reason for its
departure more closely. Each reason has different troubleshooting steps,
described below. There are three possible reasons:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">disconnected</code>: The connection from the master node to the removed node was
closed.
</li>
<li class="listitem">
<code class="literal">lagging</code>: The master published a cluster state update, but the removed node
did not apply it within the permitted timeout. By default, this timeout is 2
minutes. Refer to <a class="xref" href="modules-discovery-settings.html" title="Discovery and cluster formation settings">Discovery and cluster formation settings</a> for information about the
settings which control this mechanism.
</li>
<li class="listitem">
<code class="literal">followers check retry count exceeded</code>: The master sent a number of
consecutive health checks to the removed node. These checks were rejected or
timed out. By default, each health check times out after 10 seconds and Elasticsearch
removes the node removed after three consecutively failed health checks. Refer
to <a class="xref" href="modules-discovery-settings.html" title="Discovery and cluster formation settings">Discovery and cluster formation settings</a> for information about the settings which
control this mechanism.
</li>
</ul>
</div>
<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="_diagnosing_disconnected_nodes"></a>Diagnosing <code class="literal">disconnected</code> nodes<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.8/docs/reference/modules/discovery/fault-detection.asciidoc">edit</a></h4>
</div></div></div>
<p>Nodes typically leave the cluster with reason <code class="literal">disconnected</code> when they shut
down, but if they rejoin the cluster without restarting then there is some
other problem.</p>
<p>Elasticsearch is designed to run on a fairly reliable network. It opens a number of TCP
connections between nodes and expects these connections to remain open forever.
If a connection is closed then Elasticsearch will try and reconnect, so the occasional
blip should have limited impact on the cluster even if the affected node
briefly leaves the cluster. In contrast, repeatedly-dropped connections will
severely affect its operation.</p>
<p>The connections from the elected master node to every other node in the cluster
are particularly important. The elected master never spontaneously closes its
outbound connections to other nodes. Similarly, once a connection is fully
established, a node never spontaneously close its inbound connections unless
the node is shutting down.</p>
<p>If you see a node unexpectedly leave the cluster with the <code class="literal">disconnected</code>
reason, something other than Elasticsearch likely caused the connection to close. A
common cause is a misconfigured firewall with an improper timeout or another
policy that&#8217;s <a class="xref" href="modules-network.html#long-lived-connections" title="Long-lived idle connections">incompatible with Elasticsearch</a>. It could also
be caused by general connectivity issues, such as packet loss due to faulty
hardware or network congestion. If you&#8217;re an advanced user, you can get more
detailed information about network exceptions by configuring the following
loggers:</p>
<div class="pre_wrapper lang-yaml">
<pre class="programlisting prettyprint lang-yaml">logger.org.elasticsearch.transport.TcpTransport: DEBUG
logger.org.elasticsearch.xpack.core.security.transport.netty4.SecurityNetty4Transport: DEBUG</pre>
</div>
<p>In extreme cases, you may need to take packet captures using <code class="literal">tcpdump</code> to
determine whether messages between nodes are being dropped or rejected by some
other device on the network.</p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="_diagnosing_lagging_nodes"></a>Diagnosing <code class="literal">lagging</code> nodes<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.8/docs/reference/modules/discovery/fault-detection.asciidoc">edit</a></h4>
</div></div></div>
<p>Elasticsearch needs every node to process cluster state updates reasonably quickly. If a
node takes too long to process a cluster state update, it can be harmful to the
cluster. The master will remove these nodes with the <code class="literal">lagging</code> reason. Refer to
<a class="xref" href="modules-discovery-settings.html" title="Discovery and cluster formation settings">Discovery and cluster formation settings</a> for information about the settings which control
this mechanism.</p>
<p>Lagging is typically caused by performance issues on the removed node. However,
a node may also lag due to severe network delays. To rule out network delays,
ensure that <code class="literal">net.ipv4.tcp_retries2</code> is <a class="xref" href="system-config-tcpretries.html" title="TCP retransmission timeout">configured
properly</a>. Log messages that contain <code class="literal">warn threshold</code> may provide more
information about the root cause.</p>
<p>If you&#8217;re an advanced user, you can get more detailed information about what
the node was doing when it was removed by configuring the following logger:</p>
<div class="pre_wrapper lang-yaml">
<pre class="programlisting prettyprint lang-yaml">logger.org.elasticsearch.cluster.coordination.LagDetector: DEBUG</pre>
</div>
<p>When this logger is enabled, Elasticsearch will attempt to run the
<a class="xref" href="cluster-nodes-hot-threads.html" title="Nodes hot threads API">Nodes hot threads</a> API on the faulty node and report the results in
the logs on the elected master. The results are compressed, encoded, and split
into chunks to avoid truncation:</p>
<div class="pre_wrapper lang-text">
<pre class="programlisting prettyprint lang-text">[DEBUG][o.e.c.c.LagDetector      ] [master] hot threads from node [{node}{g3cCUaMDQJmQ2ZLtjr-3dg}{10.0.0.1:9300}] lagging at version [183619] despite commit of cluster state version [183620] [part 1]: H4sIAAAAAAAA/x...
[DEBUG][o.e.c.c.LagDetector      ] [master] hot threads from node [{node}{g3cCUaMDQJmQ2ZLtjr-3dg}{10.0.0.1:9300}] lagging at version [183619] despite commit of cluster state version [183620] [part 2]: p7x3w1hmOQVtuV...
[DEBUG][o.e.c.c.LagDetector      ] [master] hot threads from node [{node}{g3cCUaMDQJmQ2ZLtjr-3dg}{10.0.0.1:9300}] lagging at version [183619] despite commit of cluster state version [183620] [part 3]: v7uTboMGDbyOy+...
[DEBUG][o.e.c.c.LagDetector      ] [master] hot threads from node [{node}{g3cCUaMDQJmQ2ZLtjr-3dg}{10.0.0.1:9300}] lagging at version [183619] despite commit of cluster state version [183620] [part 4]: 4tse0RnPnLeDNN...
[DEBUG][o.e.c.c.LagDetector      ] [master] hot threads from node [{node}{g3cCUaMDQJmQ2ZLtjr-3dg}{10.0.0.1:9300}] lagging at version [183619] despite commit of cluster state version [183620] (gzip compressed, base64-encoded, and split into 4 parts on preceding log lines)</pre>
</div>
<p>To reconstruct the output, base64-decode the data and decompress it using
<code class="literal">gzip</code>. For instance, on Unix-like systems:</p>
<div class="pre_wrapper lang-sh">
<pre class="programlisting prettyprint lang-sh">cat lagdetector.log | sed -e 's/.*://' | base64 --decode | gzip --decompress</pre>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="_diagnosing_follower_check_retry_count_exceeded_nodes"></a>Diagnosing <code class="literal">follower check retry count exceeded</code> nodes<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.8/docs/reference/modules/discovery/fault-detection.asciidoc">edit</a></h4>
</div></div></div>
<p>Nodes sometimes leave the cluster with reason <code class="literal">follower check retry count
exceeded</code> when they shut down, but if they rejoin the cluster without
restarting then there is some other problem.</p>
<p>Elasticsearch needs every node to respond to network messages successfully and
reasonably quickly. If a node rejects requests or does not respond at all then
it can be harmful to the cluster. If enough consecutive checks fail then the
master will remove the node with reason <code class="literal">follower check retry count exceeded</code>
and will indicate in the <code class="literal">node-left</code> message how many of the consecutive
unsuccessful checks failed and how many of them timed out. Refer to
<a class="xref" href="modules-discovery-settings.html" title="Discovery and cluster formation settings">Discovery and cluster formation settings</a> for information about the settings which control
this mechanism.</p>
<p>Timeouts and failures may be due to network delays or performance problems on
the affected nodes. Ensure that <code class="literal">net.ipv4.tcp_retries2</code> is
<a class="xref" href="system-config-tcpretries.html" title="TCP retransmission timeout">configured properly</a> to eliminate network delays as
a possible cause for this kind of instability. Log messages containing
<code class="literal">warn threshold</code> may give further clues about the cause of the instability.</p>
<p>If the last check failed with an exception then the exception is reported, and
typically indicates the problem that needs to be addressed. If any of the
checks timed out, it may be necessary to understand the detailed sequence of
steps involved in a successful check. Here is an example of such a sequence:</p>
<div class="olist orderedlist">
<ol class="orderedlist">
<li class="listitem">
The master&#8217;s <code class="literal">FollowerChecker</code>, running on thread
<code class="literal">elasticsearch[master][scheduler][T#1]</code>, tells the <code class="literal">TransportService</code> to send
the check request message to a follower node.
</li>
<li class="listitem">
The master&#8217;s <code class="literal">TransportService</code> running on thread
<code class="literal">elasticsearch[master][transport_worker][T#2]</code> passes the check request message
onto the operating system.
</li>
<li class="listitem">
The operating system on the master converts the message into one or more
packets and sends them out over the network.
</li>
<li class="listitem">
Miscellaneous routers, firewalls, and other devices between the master node
and the follower node forward the packets, possibly fragmenting or
defragmenting them on the way.
</li>
<li class="listitem">
The operating system on the follower node receives the packets and notifies
Elasticsearch that they&#8217;ve been received.
</li>
<li class="listitem">
The follower&#8217;s <code class="literal">TransportService</code>, running on thread
<code class="literal">elasticsearch[follower][transport_worker][T#3]</code>, reads the incoming packets.
It then reconstructs and processes the check request. Usually, the check
quickly succeeds. If so, the same thread immediately constructs a response and
passes it back to the operating system.
</li>
<li class="listitem">
<p>If the check doesn&#8217;t immediately succeed (for example, an election started
recently) then:</p>
<div class="olist orderedlist">
<ol class="orderedlist">
<li class="listitem">
The follower&#8217;s <code class="literal">FollowerChecker</code>, running on thread
<code class="literal">elasticsearch[follower][cluster_coordination][T#4]</code>, processes the request. It
constructs a response and tells the <code class="literal">TransportService</code> to send the response
back to the master.
</li>
<li class="listitem">
The follower&#8217;s <code class="literal">TransportService</code>, running on thread
<code class="literal">elasticsearch[follower][transport_worker][T#3]</code>, passes the response to the
operating system.
</li>
</ol>
</div>
</li>
<li class="listitem">
The operating system on the follower converts the response into one or more
packets and sends them out over the network.
</li>
<li class="listitem">
Miscellaneous routers, firewalls, and other devices between master and
follower forward the packets, possibly fragmenting or defragmenting them on the
way.
</li>
<li class="listitem">
The operating system on the master receives the packets and notifies Elasticsearch
that they&#8217;ve been received.
</li>
<li class="listitem">
The master&#8217;s <code class="literal">TransportService</code>, running on thread
<code class="literal">elasticsearch[master][transport_worker][T#2]</code>, reads the incoming packets,
reconstructs the check response, and processes it as long as the check didn&#8217;t
already time out.
</li>
</ol>
</div>
<p>There are a lot of different things that can delay the completion of a check
and cause it to time out. Here are some examples for each step:</p>
<div class="olist orderedlist">
<ol class="orderedlist">
<li class="listitem">
There may be a long garbage collection (GC) or virtual machine (VM) pause
after passing the check request to the <code class="literal">TransportService</code>.
</li>
<li class="listitem">
There may be a long wait for the specific <code class="literal">transport_worker</code> thread to become
available, or there may be a long GC or VM pause before passing the check
request onto the operating system.
</li>
<li class="listitem">
A system fault (for example, a broken network card) on the master may delay
sending the message over the network, possibly indefinitely.
</li>
<li class="listitem">
Intermediate devices may delay, drop, or corrupt packets along the way. The
operating system for the master will wait and retransmit any unacknowledged or
corrupted packets up to <code class="literal">net.ipv4.tcp_retries2</code> times. We recommend
<a class="xref" href="system-config-tcpretries.html" title="TCP retransmission timeout">reducing this value</a> since the default represents a
very long delay.
</li>
<li class="listitem">
A system fault (for example, a broken network card) on the follower may delay
receiving the message from the network.
</li>
<li class="listitem">
There may be a long wait for the specific <code class="literal">transport_worker</code> thread to become
available, or there may be a long GC or VM pause during the processing of the
request on the follower.
</li>
<li class="listitem">
There may be a long wait for the <code class="literal">cluster_coordination</code> thread to become
available, or for the specific <code class="literal">transport_worker</code> thread to become available
again. There may also be a long GC or VM pause during the processing of the
request.
</li>
<li class="listitem">
A system fault (for example, a broken network card) on the follower may delay
sending the response from the network.
</li>
<li class="listitem">
Intermediate devices may delay, drop, or corrupt packets along the way again,
causing retransmissions.
</li>
<li class="listitem">
A system fault (for example, a broken network card) on the master may delay
receiving the message from the network.
</li>
<li class="listitem">
There may be a long wait for the specific <code class="literal">transport_worker</code> thread to become
available to process the response, or a long GC or VM pause.
</li>
</ol>
</div>
<p>To determine why follower checks are timing out, we can narrow down the reason
for the delay as follows:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
GC pauses are recorded in the GC logs that Elasticsearch emits by default, and also
usually by the <code class="literal">JvmMonitorService</code> in the main node logs. Use these logs to
confirm whether or not GC is resulting in delays.
</li>
<li class="listitem">
VM pauses also affect other processes on the same host. A VM pause also
typically causes a discontinuity in the system clock, which Elasticsearch will report in
its logs.
</li>
<li class="listitem">
Packet captures will reveal system-level and network-level faults, especially
if you capture the network traffic simultaneously at the elected master and the
faulty node. The connection used for follower checks is not used for any other
traffic so it can be easily identified from the flow pattern alone, even if TLS
is in use: almost exactly every second there will be a few hundred bytes sent
each way, first the request by the master and then the response by the
follower. You should be able to observe any retransmissions, packet loss, or
other delays on such a connection.
</li>
<li class="listitem">
Long waits for particular threads to be available can be identified by taking
stack dumps (for example, using <code class="literal">jstack</code>) or a profiling trace (for example,
using Java Flight Recorder) in the few seconds leading up to a node departure.
The <a class="xref" href="cluster-nodes-hot-threads.html" title="Nodes hot threads API">Nodes hot threads</a> API sometimes yields useful information, but
bear in mind that this API also requires a number of <code class="literal">transport_worker</code> and
<code class="literal">generic</code> threads across all the nodes in the cluster. The API may be affected
by the very problem you&#8217;re trying to diagnose. <code class="literal">jstack</code> is much more reliable
since it doesn&#8217;t require any JVM threads. The threads involved in the follower
checks are <code class="literal">transport_worker</code> and <code class="literal">cluster_coordination</code> threads, for which
there should never be a long wait. There may also be evidence of long waits for
threads in the Elasticsearch logs. Refer to <a class="xref" href="modules-network.html#modules-network-threading-model" title="Networking threading model">Networking threading model</a> for more
information.
</li>
</ul>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="_diagnosing_shardlockobtainfailedexception_failures"></a>Diagnosing <code class="literal">ShardLockObtainFailedException</code> failures<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.8/docs/reference/modules/discovery/fault-detection.asciidoc">edit</a></h4>
</div></div></div>
<p>If a node leaves and rejoins the cluster then Elasticsearch will usually shut down and
re-initialize its shards. If the shards do not shut down quickly enough then
Elasticsearch may fail to re-initialize them due to a <code class="literal">ShardLockObtainFailedException</code>.</p>
<p>To gather more information about the reason for shards shutting down slowly,
configure the following logger:</p>
<div class="pre_wrapper lang-yaml">
<pre class="programlisting prettyprint lang-yaml">logger.org.elasticsearch.env.NodeEnvironment: DEBUG</pre>
</div>
<p>When this logger is enabled, Elasticsearch will attempt to run the
<a class="xref" href="cluster-nodes-hot-threads.html" title="Nodes hot threads API">Nodes hot threads</a> API whenever it encounters a
<code class="literal">ShardLockObtainFailedException</code>. The results are compressed, encoded, and
split into chunks to avoid truncation:</p>
<div class="pre_wrapper lang-text">
<pre class="programlisting prettyprint lang-text">[DEBUG][o.e.e.NodeEnvironment    ] [master] hot threads while failing to obtain shard lock for [index][0] [part 1]: H4sIAAAAAAAA/x...
[DEBUG][o.e.e.NodeEnvironment    ] [master] hot threads while failing to obtain shard lock for [index][0] [part 2]: p7x3w1hmOQVtuV...
[DEBUG][o.e.e.NodeEnvironment    ] [master] hot threads while failing to obtain shard lock for [index][0] [part 3]: v7uTboMGDbyOy+...
[DEBUG][o.e.e.NodeEnvironment    ] [master] hot threads while failing to obtain shard lock for [index][0] [part 4]: 4tse0RnPnLeDNN...
[DEBUG][o.e.e.NodeEnvironment    ] [master] hot threads while failing to obtain shard lock for [index][0] (gzip compressed, base64-encoded, and split into 4 parts on preceding log lines)</pre>
</div>
<p>To reconstruct the output, base64-decode the data and decompress it using
<code class="literal">gzip</code>. For instance, on Unix-like systems:</p>
<div class="pre_wrapper lang-sh">
<pre class="programlisting prettyprint lang-sh">cat shardlock.log | sed -e 's/.*://' | base64 --decode | gzip --decompress</pre>
</div>
</div>

</div>

</div>
<div class="navfooter">
<span class="prev">
<a href="cluster-state-publishing.html">« Publishing the cluster state</a>
</span>
<span class="next">
<a href="add-elasticsearch-nodes.html">Add and remove nodes in your cluster »</a>
</span>
</div>
</div>
</body>
</html>
