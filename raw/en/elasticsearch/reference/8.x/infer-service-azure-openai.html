<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="keywords" content="Elasticsearch diagnostic, diagnostics">
<title>Azure OpenAI inference service | Elasticsearch Guide [8.x] | Elastic</title>
<meta class="elastic" name="content" content="Azure OpenAI inference service | Elasticsearch Guide [8.x]">

<link rel="home" href="index.html" title="Elasticsearch Guide [8.x]"/>
<link rel="up" href="inference-apis.html" title="Inference APIs"/>
<link rel="prev" href="infer-service-azure-ai-studio.html" title="Azure AI studio inference service"/>
<link rel="next" href="infer-service-cohere.html" title="Cohere inference service"/>
<meta class="elastic" name="product_version" content="8.x"/>
<meta class="elastic" name="product_name" content="Elasticsearch"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/Elasticsearch/Reference/8.x"/>
<meta name="DC.subject" content="Elasticsearch"/>
<meta name="DC.identifier" content="8.x"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body>
<div class="page_header">
This documentation contains work-in-progress information for future Elastic Stack and Cloud releases. Use the version selector to view supported release docs. It also contains some Elastic Cloud serverless information. Check out our <a href="https://www.elastic.co/docs/current/serverless">serverless docs</a> for more details.
</div>
<div class="navheader">
<span class="prev">
<a href="infer-service-azure-ai-studio.html">« Azure AI studio inference service</a>
</span>
<span class="next">
<a href="infer-service-cohere.html">Cohere inference service »</a>
</span>
</div>
<div class="book" lang="en">
<div class="titlepage">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Elasticsearch Guide [8.x]</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="rest-apis.html">REST APIs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="inference-apis.html">Inference APIs</a></span>
</div>
<div>
<div><h1 class="title"><a id="id-1"></a>Azure OpenAI inference service</h1><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/8.x/docs/reference/inference/service-azure-openai.asciidoc">edit</a></div>
</div>
<!--EXTRA-->
</div>
<div id="content">
<div class="section">
<div class="titlepage"><div><div>
<div class="position-relative"><h2 class="title"><a id="infer-service-azure-openai"></a>Azure OpenAI inference service</h2><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/8.x/docs/reference/inference/service-azure-openai.asciidoc">edit</a></div>
</div></div></div>
<p>Creates an inference endpoint to perform an inference task with the <code class="literal">azureopenai</code> service.</p>
<div class="position-relative"><h4><a id="infer-service-azure-openai-api-request"></a>Request</h4><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/8.x/docs/reference/inference/service-azure-openai.asciidoc">edit</a></div>
<p><code class="literal">PUT /_inference/&lt;task_type&gt;/&lt;inference_id&gt;</code></p>
<div class="position-relative"><h4><a id="infer-service-azure-openai-api-path-params"></a>Path parameters</h4><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/8.x/docs/reference/inference/service-azure-openai.asciidoc">edit</a></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">&lt;inference_id&gt;</code>
</span>
</dt>
<dd>
(Required, string)
The unique identifier of the inference endpoint.
</dd>
<dt>
<span class="term">
<code class="literal">&lt;task_type&gt;</code>
</span>
</dt>
<dd>
<p>
(Required, string)
The type of the inference task that the model will perform.
</p>
<p>Available task types:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">completion</code>,
</li>
<li class="listitem">
<code class="literal">text_embedding</code>.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="position-relative"><h4><a id="infer-service-azure-openai-api-request-body"></a>Request body</h4><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/8.x/docs/reference/inference/service-azure-openai.asciidoc">edit</a></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">chunking_settings</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Chunking configuration object.
Refer to <a class="xref" href="inference-apis.html#infer-chunking-config" title="Configuring chunking">Configuring chunking</a> to learn more about chunking.
</p>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">max_chunking_size</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum size of a chunk in words.
Defaults to <code class="literal">250</code>.
This value cannot be higher than <code class="literal">300</code> or lower than <code class="literal">20</code> (for <code class="literal">sentence</code> strategy) or <code class="literal">10</code> (for <code class="literal">word</code> strategy).
</dd>
<dt>
<span class="term">
<code class="literal">overlap</code>
</span>
</dt>
<dd>
(Optional, integer)
Only for <code class="literal">word</code> chunking strategy.
Specifies the number of overlapping words for chunks.
Defaults to <code class="literal">100</code>.
This value cannot be higher than the half of <code class="literal">max_chunking_size</code>.
</dd>
<dt>
<span class="term">
<code class="literal">sentence_overlap</code>
</span>
</dt>
<dd>
(Optional, integer)
Only for <code class="literal">sentence</code> chunking strategy.
Specifies the numnber of overlapping sentences for chunks.
It can be either <code class="literal">1</code> or <code class="literal">0</code>.
Defaults to <code class="literal">1</code>.
</dd>
<dt>
<span class="term">
<code class="literal">strategy</code>
</span>
</dt>
<dd>
(Optional, string)
Specifies the chunking strategy.
It could be either <code class="literal">sentence</code> or <code class="literal">word</code>.
</dd>
</dl>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">service</code>
</span>
</dt>
<dd>
(Required, string)
The type of service supported for the specified task type. In this case,
<code class="literal">azureopenai</code>.
</dd>
<dt>
<span class="term">
<code class="literal">service_settings</code>
</span>
</dt>
<dd>
<p>
(Required, object)
Settings used to install the inference model.
</p>
<p>These settings are specific to the <code class="literal">azureopenai</code> service.</p>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">api_key</code> or <code class="literal">entra_id</code>
</span>
</dt>
<dd>
<p>
(Required, string)
You must provide <em>either</em> an API key or an Entra ID.
If you do not provide either, or provide both, you will receive an error when trying to create your model.
See the <a href="https://learn.microsoft.com/en-us/azure/ai-services/openai/reference#authentication" class="ulink" target="_top">Azure OpenAI Authentication documentation</a> for more details on these authentication types.
</p>
<div class="important admon">
<div class="icon"></div>
<div class="admon_content">
<p>You need to provide the API key only once, during the inference model creation.
The <a class="xref" href="get-inference-api.html" title="Get inference API">Get inference API</a> does not retrieve your API key.
After creating the inference model, you cannot change the associated API key.
If you want to use a different API key, delete the inference model and recreate it with the same name and the updated API key.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">resource_name</code>
</span>
</dt>
<dd>
(Required, string)
The name of your Azure OpenAI resource.
You can find this from the <a href="https://portal.azure.com/#view/HubsExtension/BrowseAll" class="ulink" target="_top">list of resources</a> in the Azure Portal for your subscription.
</dd>
<dt>
<span class="term">
<code class="literal">deployment_id</code>
</span>
</dt>
<dd>
(Required, string)
The deployment name of your deployed models.
Your Azure OpenAI deployments can be found though the <a href="https://oai.azure.com/" class="ulink" target="_top">Azure OpenAI Studio</a> portal that is linked to your subscription.
</dd>
<dt>
<span class="term">
<code class="literal">api_version</code>
</span>
</dt>
<dd>
(Required, string)
The Azure API version ID to use.
We recommend using the <a href="https://learn.microsoft.com/en-us/azure/ai-services/openai/reference#embeddings" class="ulink" target="_top">latest supported non-preview version</a>.
</dd>
<dt>
<span class="term">
<code class="literal">rate_limit</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
The <code class="literal">azureopenai</code> service sets a default number of requests allowed per minute depending on the task type.
For <code class="literal">text_embedding</code> it is set to <code class="literal">1440</code>.
For <code class="literal">completion</code> it is set to <code class="literal">120</code>.
This helps to minimize the number of rate limit errors returned from Azure.
To modify this, set the <code class="literal">requests_per_minute</code> setting of this object in your service settings:
</p>
<div class="pre_wrapper lang-text">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-text">"rate_limit": {
    "requests_per_minute": &lt;&lt;number_of_requests&gt;&gt;
}</pre>
</div>
<p>More information about the rate limits for Azure can be found in the <a href="https://learn.microsoft.com/en-us/azure/ai-services/openai/quotas-limits" class="ulink" target="_top">Quota limits docs</a> and <a href="https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/quota?tabs=rest" class="ulink" target="_top">How to change the quotas</a>.</p>
</dd>
</dl>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">task_settings</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Settings to configure the inference task.
These settings are specific to the <code class="literal">&lt;task_type&gt;</code> you specified.
</p>
<details>
<summary class="title"><code class="literal">task_settings</code> for the <code class="literal">completion</code> task type</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">user</code>
</span>
</dt>
<dd>
(optional, string)
Specifies the user issuing the request, which can be used for abuse detection.
</dd>
</dl>
</div>
</div>
</details>
<details>
<summary class="title"><code class="literal">task_settings</code> for the <code class="literal">text_embedding</code> task type</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">user</code>
</span>
</dt>
<dd>
(optional, string)
Specifies the user issuing the request, which can be used for abuse detection.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
<div class="position-relative"><h4><a id="inference-example-azure-openai"></a>Azure OpenAI service example</h4><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/8.x/docs/reference/inference/service-azure-openai.asciidoc">edit</a></div>
<p>The following example shows how to create an inference endpoint called
<code class="literal">azure_openai_embeddings</code> to perform a <code class="literal">text_embedding</code> task type.
Note that we do not specify a model here, as it is defined already via our Azure OpenAI deployment.</p>
<p>The list of embeddings models that you can choose from in your deployment can be found in the <a href="https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models#embeddings" class="ulink" target="_top">Azure models documentation</a>.</p>
<div class="pre_wrapper lang-python alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-python alternative">resp = client.inference.put(
    task_type="text_embedding",
    inference_id="azure_openai_embeddings",
    inference_config={
        "service": "azureopenai",
        "service_settings": {
            "api_key": "&lt;api_key&gt;",
            "resource_name": "&lt;resource_name&gt;",
            "deployment_id": "&lt;deployment_id&gt;",
            "api_version": "2024-02-01"
        }
    },
)
print(resp)</pre>
</div>
<div class="pre_wrapper lang-js alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js alternative">const response = await client.inference.put({
  task_type: "text_embedding",
  inference_id: "azure_openai_embeddings",
  inference_config: {
    service: "azureopenai",
    service_settings: {
      api_key: "&lt;api_key&gt;",
      resource_name: "&lt;resource_name&gt;",
      deployment_id: "&lt;deployment_id&gt;",
      api_version: "2024-02-01",
    },
  },
});
console.log(response);</pre>
</div>
<a id="77b90f6787195767b6da60d8532714b4"></a>
<div class="pre_wrapper lang-console default has-python has-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console default has-python has-js">PUT _inference/text_embedding/azure_openai_embeddings
{
    "service": "azureopenai",
    "service_settings": {
        "api_key": "&lt;api_key&gt;",
        "resource_name": "&lt;resource_name&gt;",
        "deployment_id": "&lt;deployment_id&gt;",
        "api_version": "2024-02-01"
    }
}</pre>
</div>
<div class="console_widget has-python has-js" data-snippet="snippets/3093.console"></div>
<p>The next example shows how to create an inference endpoint called
<code class="literal">azure_openai_completion</code> to perform a <code class="literal">completion</code> task type.</p>
<div class="pre_wrapper lang-python alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-python alternative">resp = client.inference.put(
    task_type="completion",
    inference_id="azure_openai_completion",
    inference_config={
        "service": "azureopenai",
        "service_settings": {
            "api_key": "&lt;api_key&gt;",
            "resource_name": "&lt;resource_name&gt;",
            "deployment_id": "&lt;deployment_id&gt;",
            "api_version": "2024-02-01"
        }
    },
)
print(resp)</pre>
</div>
<div class="pre_wrapper lang-js alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js alternative">const response = await client.inference.put({
  task_type: "completion",
  inference_id: "azure_openai_completion",
  inference_config: {
    service: "azureopenai",
    service_settings: {
      api_key: "&lt;api_key&gt;",
      resource_name: "&lt;resource_name&gt;",
      deployment_id: "&lt;deployment_id&gt;",
      api_version: "2024-02-01",
    },
  },
});
console.log(response);</pre>
</div>
<a id="f57ce7de0946e9416ddb9150e95f4b74"></a>
<div class="pre_wrapper lang-console default has-python has-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console default has-python has-js">PUT _inference/completion/azure_openai_completion
{
    "service": "azureopenai",
    "service_settings": {
        "api_key": "&lt;api_key&gt;",
        "resource_name": "&lt;resource_name&gt;",
        "deployment_id": "&lt;deployment_id&gt;",
        "api_version": "2024-02-01"
    }
}</pre>
</div>
<div class="console_widget has-python has-js" data-snippet="snippets/3094.console"></div>
<p>The list of chat completion models that you can choose from in your Azure OpenAI deployment can be found at the following places:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<a href="https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-models" class="ulink" target="_top">GPT-4 and GPT-4 Turbo models</a>
</li>
<li class="listitem">
<a href="https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models#gpt-35" class="ulink" target="_top">GPT-3.5</a>
</li>
</ul>
</div>
</div>
</div>
</div><div class="navfooter">
<span class="prev">
<a href="infer-service-azure-ai-studio.html">« Azure AI studio inference service</a>
</span>
<span class="next">
<a href="infer-service-cohere.html">Cohere inference service »</a>
</span>
</div>
</body>
</html>
