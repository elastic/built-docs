<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>ELSER inference integration | Elasticsearch Guide [8.x] | Elastic</title>
<meta class="elastic" name="content" content="ELSER inference integration | Elasticsearch Guide [8.x]">

<link rel="home" href="index.html" title="Elasticsearch Guide [8.x]"/>
<link rel="up" href="inference-apis.html" title="Inference APIs"/>
<link rel="prev" href="infer-service-elasticsearch.html" title="Elasticsearch inference integration"/>
<link rel="next" href="infer-service-google-ai-studio.html" title="Google AI Studio inference integration"/>
<meta class="elastic" name="product_version" content="8.x"/>
<meta class="elastic" name="product_name" content="Elasticsearch"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/Elasticsearch/Reference/8.x"/>
<meta name="DC.subject" content="Elasticsearch"/>
<meta name="DC.identifier" content="8.x"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body>
<div class="page_header">
This documentation contains work-in-progress information for future Elastic Stack and Cloud releases. Use the version selector to view supported release docs. It also contains some Elastic Cloud serverless information. Check out our <a href="https://www.elastic.co/docs/current/serverless">serverless docs</a> for more details.
</div>
<div class="navheader">
<span class="prev">
<a href="infer-service-elasticsearch.html">« Elasticsearch inference integration</a>
</span>
<span class="next">
<a href="infer-service-google-ai-studio.html">Google AI Studio inference integration »</a>
</span>
</div>
<div class="book" lang="en">
<div class="titlepage">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Elasticsearch Guide [8.x]</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="rest-apis.html">REST APIs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="inference-apis.html">Inference APIs</a></span>
</div>
<div>
<div><h1 class="title"><a id="id-1"></a>ELSER inference integration</h1><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/8.x/docs/reference/inference/service-elser.asciidoc">edit</a></div>
</div>
<!--EXTRA-->
</div>
<div id="content">
<div id="url-to-v3" class="version-warning">
    <strong>IMPORTANT</strong>: This documentation is no longer updated. Refer to <a href="https://www.elastic.co/support/eol">Elastic's version policy</a> and the <a href="https://www.elastic.co/docs/api/doc/elasticsearch/operation/operation-inference-put">latest documentation</a>.
</div>
<div class="section">
<div class="titlepage"><div><div>
<div class="position-relative"><h2 class="title"><a id="infer-service-elser"></a>ELSER inference integration</h2><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/8.x/docs/reference/inference/service-elser.asciidoc">edit</a></div>
</div></div></div>
<div class="sidebar">
<div class="titlepage"><div><div>
<p class="title"><strong>New API reference</strong></p>
</div></div></div>
<p>For the most up-to-date API details, refer to <a href="/docs/api/doc/elasticsearch/v8/group/endpoint-inference" class="ulink" target="_top">Inference APIs</a>.</p>
</div>
<p>Creates an inference endpoint to perform an inference task with the <code class="literal">elser</code> service.
You can also deploy ELSER by using the <a class="xref" href="infer-service-elasticsearch.html" title="Elasticsearch inference integration">Elasticsearch inference integration</a>.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
Your Elasticsearch deployment contains <a class="xref" href="inference-apis.html#default-enpoints" title="Default inference endpoints">a preconfigured ELSER inference endpoint</a>, you only need to create the enpoint using the API if you want to customize the settings.
</li>
<li class="listitem">
The API request will automatically download and deploy the ELSER model if it isn&#8217;t already downloaded.
</li>
</ul>
</div>
</div>
</div>
<div class="warning admon">
<div class="icon"></div>
<div class="admon_content">
<p class="admon_title">Deprecated in 8.16</p>
<p>The <code class="literal">elser</code> service is deprecated and will be removed in a future release.
Use the <a class="xref" href="infer-service-elasticsearch.html" title="Elasticsearch inference integration">Elasticsearch inference integration</a> instead, with <code class="literal">model_id</code> included in the <code class="literal">service_settings</code>.</p>
</div>
</div>
<div class="position-relative"><h4><a id="infer-service-elser-api-request"></a>Request</h4><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/8.x/docs/reference/inference/service-elser.asciidoc">edit</a></div>
<p><code class="literal">PUT /_inference/&lt;task_type&gt;/&lt;inference_id&gt;</code></p>
<div class="position-relative"><h4><a id="infer-service-elser-api-path-params"></a>Path parameters</h4><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/8.x/docs/reference/inference/service-elser.asciidoc">edit</a></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">&lt;inference_id&gt;</code>
</span>
</dt>
<dd>
(Required, string)
The unique identifier of the inference endpoint.
</dd>
<dt>
<span class="term">
<code class="literal">&lt;task_type&gt;</code>
</span>
</dt>
<dd>
<p>
(Required, string)
The type of the inference task that the model will perform.
</p>
<p>Available task types:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">sparse_embedding</code>.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="position-relative"><h4><a id="infer-service-elser-api-request-body"></a>Request body</h4><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/8.x/docs/reference/inference/service-elser.asciidoc">edit</a></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">chunking_settings</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Chunking configuration object.
Refer to <a class="xref" href="inference-apis.html#infer-chunking-config" title="Configuring chunking">Configuring chunking</a> to learn more about chunking.
</p>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">max_chunk_size</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum size of a chunk in words.
Defaults to <code class="literal">250</code>.
This value cannot be higher than <code class="literal">300</code> or lower than <code class="literal">20</code> (for <code class="literal">sentence</code> strategy) or <code class="literal">10</code> (for <code class="literal">word</code> strategy).
</dd>
<dt>
<span class="term">
<code class="literal">overlap</code>
</span>
</dt>
<dd>
(Optional, integer)
Only for <code class="literal">word</code> chunking strategy.
Specifies the number of overlapping words for chunks.
Defaults to <code class="literal">100</code>.
This value cannot be higher than the half of <code class="literal">max_chunk_size</code>.
</dd>
<dt>
<span class="term">
<code class="literal">sentence_overlap</code>
</span>
</dt>
<dd>
(Optional, integer)
Only for <code class="literal">sentence</code> chunking strategy.
Specifies the numnber of overlapping sentences for chunks.
It can be either <code class="literal">1</code> or <code class="literal">0</code>.
Defaults to <code class="literal">1</code>.
</dd>
<dt>
<span class="term">
<code class="literal">strategy</code>
</span>
</dt>
<dd>
(Optional, string)
Specifies the chunking strategy.
It could be either <code class="literal">sentence</code> or <code class="literal">word</code>.
</dd>
</dl>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">service</code>
</span>
</dt>
<dd>
(Required, string)
The type of service supported for the specified task type. In this case,
<code class="literal">elser</code>.
</dd>
<dt>
<span class="term">
<code class="literal">service_settings</code>
</span>
</dt>
<dd>
<p>
(Required, object)
Settings used to install the inference model.
</p>
<p>These settings are specific to the <code class="literal">elser</code> service.</p>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">adaptive_allocations</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Adaptive allocations configuration object.
If enabled, the number of allocations of the model is set based on the current load the process gets.
When the load is high, a new model allocation is automatically created (respecting the value of <code class="literal">max_number_of_allocations</code> if it&#8217;s set).
When the load is low, a model allocation is automatically removed (respecting the value of <code class="literal">min_number_of_allocations</code> if it&#8217;s set).
If <code class="literal">adaptive_allocations</code> is enabled, do not set the number of allocations manually.
</p>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">enabled</code>
</span>
</dt>
<dd>
(Optional, Boolean)
If <code class="literal">true</code>, <code class="literal">adaptive_allocations</code> is enabled.
Defaults to <code class="literal">false</code>.
</dd>
<dt>
<span class="term">
<code class="literal">max_number_of_allocations</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of allocations to scale to.
If set, it must be greater than or equal to <code class="literal">min_number_of_allocations</code>.
</dd>
<dt>
<span class="term">
<code class="literal">min_number_of_allocations</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the minimum number of allocations to scale to.
If set, it must be greater than or equal to <code class="literal">0</code>.
If not defined, the deployment scales to <code class="literal">0</code>.
</dd>
</dl>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">num_allocations</code>
</span>
</dt>
<dd>
(Required, integer)
The total number of allocations this model is assigned across machine learning nodes.
Increasing this value generally increases the throughput.
If <code class="literal">adaptive_allocations</code> is enabled, do not set this value, because it&#8217;s automatically set.
</dd>
<dt>
<span class="term">
<code class="literal">num_threads</code>
</span>
</dt>
<dd>
(Required, integer)
Sets the number of threads used by each model allocation during inference. This generally increases the speed per inference request. The inference process is a compute-bound process; <code class="literal">threads_per_allocations</code> must not exceed the number of available allocated processors per node.
Must be a power of 2. Max allowed value is 32.
</dd>
</dl>
</div>
</dd>
</dl>
</div>
<div class="position-relative"><h4><a id="inference-example-elser-adaptive-allocation"></a>ELSER service example with adaptive allocations</h4><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/8.x/docs/reference/inference/service-elser.asciidoc">edit</a></div>
<p>When adaptive allocations are enabled, the number of allocations of the model is set automatically based on the current load.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For more information on how to optimize your ELSER endpoints, refer to <a href="/guide/en/machine-learning/8.x/ml-nlp-elser.html#elser-recommendations" class="ulink" target="_top">the ELSER recommendations</a> section in the model documentation.
To learn more about model autoscaling, refer to the <a href="/guide/en/machine-learning/8.x/ml-nlp-auto-scale.html" class="ulink" target="_top">trained model autoscaling</a> page.</p>
</div>
</div>
<p>The following example shows how to create an inference endpoint called <code class="literal">my-elser-model</code> to perform a <code class="literal">sparse_embedding</code> task type and configure adaptive allocations.</p>
<p>The request below will automatically download the ELSER model if it isn&#8217;t already downloaded and then deploy the model.</p>
<div class="pre_wrapper lang-python alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-python alternative">resp = client.inference.put(
    task_type="sparse_embedding",
    inference_id="my-elser-model",
    inference_config={
        "service": "elser",
        "service_settings": {
            "adaptive_allocations": {
                "enabled": True,
                "min_number_of_allocations": 3,
                "max_number_of_allocations": 10
            },
            "num_threads": 1
        }
    },
)
print(resp)</pre>
</div>
<div class="pre_wrapper lang-js alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js alternative">const response = await client.inference.put({
  task_type: "sparse_embedding",
  inference_id: "my-elser-model",
  inference_config: {
    service: "elser",
    service_settings: {
      adaptive_allocations: {
        enabled: true,
        min_number_of_allocations: 3,
        max_number_of_allocations: 10,
      },
      num_threads: 1,
    },
  },
});
console.log(response);</pre>
</div>
<a id="565386eee0951865a684e41fab53b40c"></a>
<div class="pre_wrapper lang-console default has-python has-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console default has-python has-js">PUT _inference/sparse_embedding/my-elser-model
{
  "service": "elser",
  "service_settings": {
    "adaptive_allocations": {
      "enabled": true,
      "min_number_of_allocations": 3,
      "max_number_of_allocations": 10
    },
    "num_threads": 1
  }
}</pre>
</div>
<div class="console_widget has-python has-js" data-snippet="snippets/2968.console"></div>
<div class="position-relative"><h4><a id="inference-example-elser"></a>ELSER service example without adaptive allocations</h4><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/8.x/docs/reference/inference/service-elser.asciidoc">edit</a></div>
<p>The following example shows how to create an inference endpoint called <code class="literal">my-elser-model</code> to perform a <code class="literal">sparse_embedding</code> task type.
Refer to the <a href="/guide/en/machine-learning/8.x/ml-nlp-elser.html" class="ulink" target="_top">ELSER model documentation</a> for more info.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>If you want to optimize your ELSER endpoint for ingest, set the number of threads to <code class="literal">1</code> (<code class="literal">"num_threads": 1</code>).
If you want to optimize your ELSER endpoint for search, set the number of threads to greater than <code class="literal">1</code>.</p>
</div>
</div>
<p>The request below will automatically download the ELSER model if it isn&#8217;t already downloaded and then deploy the model.</p>
<div class="pre_wrapper lang-python alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-python alternative">resp = client.inference.put(
    task_type="sparse_embedding",
    inference_id="my-elser-model",
    inference_config={
        "service": "elser",
        "service_settings": {
            "num_allocations": 1,
            "num_threads": 1
        }
    },
)
print(resp)</pre>
</div>
<div class="pre_wrapper lang-js alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js alternative">const response = await client.inference.put({
  task_type: "sparse_embedding",
  inference_id: "my-elser-model",
  inference_config: {
    service: "elser",
    service_settings: {
      num_allocations: 1,
      num_threads: 1,
    },
  },
});
console.log(response);</pre>
</div>
<a id="cedb56a71cc743d80263ce352bb21720"></a>
<div class="pre_wrapper lang-console default has-python has-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console default has-python has-js">PUT _inference/sparse_embedding/my-elser-model
{
  "service": "elser",
  "service_settings": {
    "num_allocations": 1,
    "num_threads": 1
  }
}</pre>
</div>
<div class="console_widget has-python has-js" data-snippet="snippets/2969.console"></div>
<p>Example response:</p>
<a id="85eb7282ac0193478132d3de11f3ffec"></a>
<div class="pre_wrapper lang-console-result">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console-result">{
  "inference_id": "my-elser-model",
  "task_type": "sparse_embedding",
  "service": "elser",
  "service_settings": {
    "num_allocations": 1,
    "num_threads": 1
  },
  "task_settings": {}
}</pre>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>You might see a 502 bad gateway error in the response when using the Kibana Console.
This error usually just reflects a timeout, while the model downloads in the background.
You can check the download progress in the Machine Learning UI.
If using the Python client, you can set the <code class="literal">timeout</code> parameter to a higher value.</p>
</div>
</div>
</div>
</div>
</div><div class="navfooter">
<span class="prev">
<a href="infer-service-elasticsearch.html">« Elasticsearch inference integration</a>
</span>
<span class="next">
<a href="infer-service-google-ai-studio.html">Google AI Studio inference integration »</a>
</span>
</div>
</body>
</html>
