<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Tune approximate kNN search | Elasticsearch Guide [8.x] | Elastic</title>
<meta class="elastic" name="content" content="Tune approximate kNN search | Elasticsearch Guide [8.x]">

<link rel="home" href="index.html" title="Elasticsearch Guide [8.x]"/>
<link rel="up" href="how-to.html" title="Optimizations"/>
<link rel="prev" href="tune-for-search-speed.html" title="Tune for search speed"/>
<link rel="next" href="tune-for-disk-usage.html" title="Tune for disk usage"/>
<meta class="elastic" name="product_version" content="8.x"/>
<meta class="elastic" name="product_name" content="Elasticsearch"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/Elasticsearch/Reference/8.x"/>
<meta name="DC.subject" content="Elasticsearch"/>
<meta name="DC.identifier" content="8.x"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body>
<div class="page_header">
This documentation contains work-in-progress information for future Elastic Stack and Cloud releases. Use the version selector to view supported release docs. It also contains some Elastic Cloud serverless information. Check out our <a href="https://www.elastic.co/docs/current/serverless">serverless docs</a> for more details.
</div>
<div class="navheader">
<span class="prev">
<a href="tune-for-search-speed.html">« Tune for search speed</a>
</span>
<span class="next">
<a href="tune-for-disk-usage.html">Tune for disk usage »</a>
</span>
</div>
<div class="book" lang="en">
<div class="titlepage">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Elasticsearch Guide [8.x]</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="how-to.html">Optimizations</a></span>
</div>
<div>
<div><h1 class="title"><a id="id-1"></a>Tune approximate kNN search</h1><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/8.x/docs/reference/how-to/knn-search.asciidoc">edit</a></div>
</div>
<!--EXTRA-->
</div>
<div id="content">
<div class="chapter">
<div class="titlepage"><div><div>
<div class="position-relative"><h2 class="title"><a id="tune-knn-search"></a>Tune approximate kNN search</h2><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/8.x/docs/reference/how-to/knn-search.asciidoc">edit</a></div>
</div></div></div>
<p>Elasticsearch supports <a class="xref" href="knn-search.html#approximate-knn" title="Approximate kNN">approximate k-nearest neighbor search</a> for
efficiently finding the <em>k</em> nearest vectors to a query vector. Since
approximate kNN search works differently from other queries, there are special
considerations around its performance.</p>
<p>Many of these recommendations help improve search speed. With approximate kNN,
the indexing algorithm runs searches under the hood to create the vector index
structures. So these same recommendations also help with indexing speed.</p>
<div class="position-relative"><h3><a id="_reduce_vector_memory_foot_print"></a>Reduce vector memory foot-print</h3><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/8.x/docs/reference/how-to/knn-search.asciidoc">edit</a></div>
<p>The default <a class="xref" href="dense-vector.html#dense-vector-element-type"><code class="literal">element_type</code></a> is <code class="literal">float</code>. But this
can be automatically quantized during index time through
<a class="xref" href="dense-vector.html#dense-vector-quantization" title="Automatically quantize vectors for kNN search"><code class="literal">quantization</code></a>. Quantization will reduce the
required memory by 4x, 8x, or as much as 32x, but it will also reduce the precision of the vectors and
increase disk usage for the field (by up to 25%, 12.5%, or 3.125%, respectively). Increased disk usage is a
result of Elasticsearch storing both the quantized and the unquantized vectors.
For example, when int8 quantizing 40GB of floating point vectors an extra 10GB of data will be stored for the quantized vectors.
The total disk usage amounts to 50GB, but the memory usage for fast search will be reduced to 10GB.</p>
<p>For <code class="literal">float</code> vectors with <code class="literal">dim</code> greater than or equal to <code class="literal">384</code>, using a
<a class="xref" href="dense-vector.html#dense-vector-quantization" title="Automatically quantize vectors for kNN search"><code class="literal">quantized</code></a> index is highly recommended.</p>
<div class="position-relative"><h3><a id="_reduce_vector_dimensionality"></a>Reduce vector dimensionality</h3><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/8.x/docs/reference/how-to/knn-search.asciidoc">edit</a></div>
<p>The speed of kNN search scales linearly with the number of vector dimensions,
because each similarity computation considers each element in the two vectors.
Whenever possible, it&#8217;s better to use vectors with a lower dimension. Some
embedding models come in different "sizes", with both lower and higher
dimensional options available. You could also experiment with dimensionality
reduction techniques like PCA. When experimenting with different approaches,
it&#8217;s important to measure the impact on relevance to ensure the search
quality is still acceptable.</p>
<div class="position-relative"><h3><a id="_exclude_vector_fields_from_source"></a>Exclude vector fields from <code class="literal">_source</code></h3><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/8.x/docs/reference/how-to/knn-search.asciidoc">edit</a></div>
<p>Elasticsearch stores the original JSON document that was passed at index time in the
<a class="xref" href="mapping-source-field.html" title="_source field"><code class="literal">_source</code> field</a>. By default, each hit in the search
results contains the full document <code class="literal">_source</code>. When the documents contain
high-dimensional <code class="literal">dense_vector</code> fields, the <code class="literal">_source</code> can be quite large and
expensive to load. This could significantly slow down the speed of kNN search.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p><a class="xref" href="docs-reindex.html" title="Reindex API">reindex</a>, <a class="xref" href="docs-update.html" title="Update API">update</a>,
and <a class="xref" href="docs-update-by-query.html" title="Update By Query API">update by query</a> operations generally
require the <code class="literal">_source</code> field. Disabling <code class="literal">_source</code> for a field might result in
unexpected behavior for these operations. For example, reindex might not actually
contain the <code class="literal">dense_vector</code> field in the new index.</p>
</div>
</div>
<p>You can disable storing <code class="literal">dense_vector</code> fields in the <code class="literal">_source</code> through the
<a class="xref" href="mapping-source-field.html#include-exclude" title="Including / Excluding fields from _source"><code class="literal">excludes</code></a> mapping parameter. This prevents loading and
returning large vectors during search, and also cuts down on the index size.
Vectors that have been omitted from <code class="literal">_source</code> can still be used in kNN search,
since it relies on separate data structures to perform the search. Before
using the <a class="xref" href="mapping-source-field.html#include-exclude" title="Including / Excluding fields from _source"><code class="literal">excludes</code></a> parameter, make sure to review the
downsides of omitting fields from <code class="literal">_source</code>.</p>
<p>Another option is to use  <a class="xref" href="mapping-source-field.html#synthetic-source" title="Synthetic _source">synthetic <code class="literal">_source</code></a>.</p>
<div class="position-relative"><h3><a id="_ensure_data_nodes_have_enough_memory"></a>Ensure data nodes have enough memory</h3><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/8.x/docs/reference/how-to/knn-search.asciidoc">edit</a></div>
<p>Elasticsearch uses the <a href="https://arxiv.org/abs/1603.09320" class="ulink" target="_top">HNSW</a> algorithm for approximate
kNN search. HNSW is a graph-based algorithm which only works efficiently when
most vector data is held in memory. You should ensure that data nodes have at
least enough RAM to hold the vector data and index structures. To check the
size of the vector data, you can use the <a class="xref" href="indices-disk-usage.html" title="Analyze index disk usage API">Analyze index disk usage</a> API.</p>
<p>Here are estimates for different element types and quantization levels:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">element_type: float</code>: <code class="literal">num_vectors * num_dimensions * 4</code>
</li>
<li class="listitem">
<code class="literal">element_type: float</code> with <code class="literal">quantization: int8</code>: <code class="literal">num_vectors * (num_dimensions + 4)</code>
</li>
<li class="listitem">
<code class="literal">element_type: float</code> with <code class="literal">quantization: int4</code>: <code class="literal">num_vectors * (num_dimensions/2 + 4)</code>
</li>
<li class="listitem">
<code class="literal">element_type: float</code> with <code class="literal">quantization: bbq</code>: <code class="literal">num_vectors * (num_dimensions/8 + 12)</code>
</li>
<li class="listitem">
<code class="literal">element_type: byte</code>: <code class="literal">num_vectors * num_dimensions</code>
</li>
<li class="listitem">
<code class="literal">element_type: bit</code>: <code class="literal">num_vectors * (num_dimensions/8)</code>
</li>
</ul>
</div>
<p>If utilizing HNSW, the graph must also be in memory, to estimate the required bytes use <code class="literal">num_vectors * 4 * HNSW.m</code>. The
default value for <code class="literal">HNSW.m</code> is 16, so by default <code class="literal">num_vectors * 4 * 16</code>.</p>
<p>Note that the required RAM is for the filesystem cache, which is separate from the Java heap.</p>
<p>The data nodes should also leave a buffer for other ways that RAM is needed.
For example your index might also include text fields and numerics, which also
benefit from using filesystem cache. It&#8217;s recommended to run benchmarks with
your specific dataset to ensure there&#8217;s a sufficient amount of memory to give
good search performance.
You can find <a href="https://elasticsearch-benchmarks.elastic.co/#tracks/so_vector" class="ulink" target="_top">here</a>
and <a href="https://elasticsearch-benchmarks.elastic.co/#tracks/dense_vector" class="ulink" target="_top">here</a> some examples
of datasets and configurations that we use for our nightly benchmarks.</p>
<div class="position-relative"><h3><a id="dense-vector-preloading"></a>Warm up the filesystem cache</h3><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/8.x/docs/reference/how-to/search-speed.asciidoc">edit</a></div>
<p>If the machine running Elasticsearch is restarted, the filesystem cache will be
empty, so it will take some time before the operating system loads hot regions
of the index into memory so that search operations are fast. You can explicitly
tell the operating system which files should be loaded into memory eagerly
depending on the file extension using the
<a class="xref" href="preload-data-to-file-system-cache.html" title="Preloading data into the file system cache"><code class="literal">index.store.preload</code></a> setting.</p>
<div class="warning admon">
<div class="icon"></div>
<div class="admon_content">
<p>Loading data into the filesystem cache eagerly on too many indices or
too many files will make search <em>slower</em> if the filesystem cache is not large
enough to hold all the data. Use with caution.</p>
</div>
</div>
<p>The following file extensions are used for the approximate kNN search:
Each extension is broken down by the quantization types.</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">vex</code> for the HNSW graph
</li>
<li class="listitem">
<code class="literal">vec</code> for all non-quantized vector values. This includes all element types: <code class="literal">float</code>, <code class="literal">byte</code>, and <code class="literal">bit</code>.
</li>
<li class="listitem">
<code class="literal">veq</code> for quantized vectors indexed with <a class="xref" href="dense-vector.html#dense-vector-quantization" title="Automatically quantize vectors for kNN search"><code class="literal">quantization</code></a>: <code class="literal">int4</code> or <code class="literal">int8</code>
</li>
<li class="listitem">
<code class="literal">veb</code> for binary vectors indexed with <a class="xref" href="dense-vector.html#dense-vector-quantization" title="Automatically quantize vectors for kNN search"><code class="literal">quantization</code></a>: <code class="literal">bbq</code>
</li>
<li class="listitem">
<code class="literal">vem</code>, <code class="literal">vemf</code>, <code class="literal">vemq</code>, and <code class="literal">vemb</code> for metadata, usually small and not a concern for preloading
</li>
</ul>
</div>
<p>Generally, if you are using a quantized index, you should only preload the relevant quantized values and the HNSW graph.
Preloading the raw vectors is not necessary and might be counterproductive.</p>
<div class="position-relative"><h3><a id="_reduce_the_number_of_index_segments"></a>Reduce the number of index segments</h3><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/8.x/docs/reference/how-to/knn-search.asciidoc">edit</a></div>
<p>Elasticsearch shards are composed of segments, which are internal storage elements in
the index. For approximate kNN search, Elasticsearch stores the vector values of
each segment as a separate HNSW graph, so kNN search must check each segment.
The recent parallelization of kNN search made it much faster to search across
multiple segments, but still kNN search can be up to several times
faster if there are fewer segments. By default, Elasticsearch periodically
merges smaller segments into larger ones through a background
<a class="xref" href="index-modules-merge.html" title="Merge">merge process</a>. If this isn&#8217;t sufficient, you can take
explicit steps to reduce the number of index segments.</p>
<div class="position-relative"><h4><a id="_increase_maximum_segment_size"></a>Increase maximum segment size</h4><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/8.x/docs/reference/how-to/knn-search.asciidoc">edit</a></div>
<p>Elasticsearch provides many tunable settings for controlling the merge process. One
important setting is <code class="literal">index.merge.policy.max_merged_segment</code>. This controls
the maximum size of the segments that are created during the merge process.
By increasing the value, you can reduce the number of segments in the index.
The default value is <code class="literal">5GB</code>, but that might be too small for larger dimensional vectors.
Consider increasing this value to <code class="literal">10GB</code> or <code class="literal">20GB</code> can help reduce the number of segments.</p>
<div class="position-relative"><h4><a id="_create_large_segments_during_bulk_indexing"></a>Create large segments during bulk indexing</h4><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/8.x/docs/reference/how-to/knn-search.asciidoc">edit</a></div>
<p>A common pattern is to first perform an initial bulk upload, then make an
index available for searches. Instead of force merging, you can adjust the
index settings to encourage Elasticsearch to create larger initial segments:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
Ensure there are no searches during the bulk upload and disable
<a class="xref" href="index-modules.html#index-refresh-interval-setting"><code class="literal">index.refresh_interval</code></a> by setting it to
<code class="literal">-1</code>. This prevents refresh operations and avoids creating extra segments.
</li>
<li class="listitem">
Give Elasticsearch a large indexing buffer so it can accept more documents before
flushing. By default, the <a class="xref" href="indexing-buffer.html" title="Indexing buffer settings"><code class="literal">indices.memory.index_buffer_size</code></a>
is set to 10% of the heap size. With a substantial heap size like 32GB, this
is often enough. To allow the full indexing buffer to be used, you should also
increase the limit <a class="xref" href="index-modules-translog.html" title="Translog"><code class="literal">index.translog.flush_threshold_size</code></a>.
</li>
</ul>
</div>
<div class="position-relative"><h3><a id="_avoid_heavy_indexing_during_searches"></a>Avoid heavy indexing during searches</h3><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/8.x/docs/reference/how-to/knn-search.asciidoc">edit</a></div>
<p>Actively indexing documents can have a negative impact on approximate kNN
search performance, since indexing threads steal compute resources from
search. When indexing and searching at the same time, Elasticsearch also refreshes
frequently, which creates several small segments. This also hurts search
performance, since approximate kNN search is slower when there are more
segments.</p>
<p>When possible, it&#8217;s best to avoid heavy indexing during approximate kNN
search. If you need to reindex all the data, perhaps because the vector
embedding model changed, then it&#8217;s better to reindex the new documents into a
separate index rather than update them in-place. This helps avoid the slowdown
mentioned above, and prevents expensive merge operations due to frequent
document updates.</p>
<div class="position-relative"><h3><a id="_avoid_page_cache_thrashing_by_using_modest_readahead_values_on_linux_2"></a>Avoid page cache thrashing by using modest readahead values on Linux</h3><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/8.x/docs/reference/how-to/search-speed.asciidoc">edit</a></div>
<p>Search can cause a lot of randomized read I/O. When the underlying block
device has a high readahead value, there may be a lot of unnecessary
read I/O done, especially when files are accessed using memory mapping
(see <a class="xref" href="index-modules-store.html#file-system" title="File system storage types">storage types</a>).</p>
<p>Most Linux distributions use a sensible readahead value of <code class="literal">128KiB</code> for a
single plain device, however, when using software raid, LVM or dm-crypt the
resulting block device (backing Elasticsearch <a class="xref" href="important-settings.html#path-settings" title="Path settings">path.data</a>)
may end up having a very large readahead value (in the range of several MiB).
This usually results in severe page (filesystem) cache thrashing adversely
affecting search (or <a class="xref" href="docs.html" title="Document APIs">update</a>) performance.</p>
<p>You can check the current value in <code class="literal">KiB</code> using
<code class="literal">lsblk -o NAME,RA,MOUNTPOINT,TYPE,SIZE</code>.
Consult the documentation of your distribution on how to alter this value
(for example with a <code class="literal">udev</code> rule to persist across reboots, or via
<a href="https://man7.org/linux/man-pages/man8/blockdev.8.html" class="ulink" target="_top">blockdev --setra</a>
as a transient setting). We recommend a value of <code class="literal">128KiB</code> for readahead.</p>
<div class="warning admon">
<div class="icon"></div>
<div class="admon_content">
<p><code class="literal">blockdev</code> expects values in 512 byte sectors whereas <code class="literal">lsblk</code> reports
values in <code class="literal">KiB</code>. As an example, to temporarily set readahead to <code class="literal">128KiB</code>
for <code class="literal">/dev/nvme0n1</code>, specify <code class="literal">blockdev --setra 256 /dev/nvme0n1</code>.</p>
</div>
</div>
</div>
</div>
</div><div class="navfooter">
<span class="prev">
<a href="tune-for-search-speed.html">« Tune for search speed</a>
</span>
<span class="next">
<a href="tune-for-disk-usage.html">Tune for disk usage »</a>
</span>
</div>
</body>
</html>
