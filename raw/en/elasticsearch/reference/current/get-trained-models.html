<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="keywords" content="Elasticsearch, high watermark, low watermark, full disk">
<title>Get trained models API | Elasticsearch Guide [8.7] | Elastic</title>
<meta class="elastic" name="content" content="Get trained models API | Elasticsearch Guide [8.7]">

<link rel="home" href="index.html" title="Elasticsearch Guide [8.7]"/>
<link rel="up" href="ml-df-trained-models-apis.html" title="Machine learning trained model APIs"/>
<link rel="prev" href="delete-trained-models.html" title="Delete trained models API"/>
<link rel="next" href="get-trained-models-stats.html" title="Get trained models statistics API"/>
<meta class="elastic" name="product_version" content="8.7"/>
<meta class="elastic" name="product_name" content="Elasticsearch"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/Elasticsearch/Reference/8.7"/>
<meta name="DC.subject" content="Elasticsearch"/>
<meta name="DC.identifier" content="8.7"/>
</head>
<body>
<div id="content">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Elasticsearch Guide [8.7]</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="rest-apis.html">REST APIs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="ml-df-trained-models-apis.html">Machine learning trained model APIs</a></span>
</div>
<div class="navheader">
<span class="prev">
<a href="delete-trained-models.html">« Delete trained models API</a>
</span>
<span class="next">
<a href="get-trained-models-stats.html">Get trained models statistics API »</a>
</span>
</div>
<div class="section xpack">
<div class="titlepage"><div><div>
<h2 class="title"><a id="get-trained-models"></a>Get trained models API<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.7/docs/reference/ml/trained-models/apis/get-trained-models.asciidoc">edit</a></h2>
</div></div></div>

<p>Retrieves configuration information for a trained model.</p>
<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-get-trained-models-request"></a>Request<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.7/docs/reference/ml/trained-models/apis/get-trained-models.asciidoc">edit</a></h3>
</div></div></div>
<p><code class="literal">GET _ml/trained_models/</code><br></p>
<p><code class="literal">GET _ml/trained_models/&lt;model_id&gt;</code><br></p>
<p><code class="literal">GET _ml/trained_models/_all</code><br></p>
<p><code class="literal">GET _ml/trained_models/&lt;model_id1&gt;,&lt;model_id2&gt;</code><br></p>
<p><code class="literal">GET _ml/trained_models/&lt;model_id_pattern*&gt;</code></p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-get-trained-models-prereq"></a>Prerequisites<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.7/docs/reference/ml/trained-models/apis/get-trained-models.asciidoc">edit</a></h3>
</div></div></div>
<p>Requires the <code class="literal">monitor_ml</code> cluster privilege. This privilege is included in the
<code class="literal">machine_learning_user</code> built-in role.</p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-get-trained-models-path-params"></a>Path parameters<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.7/docs/reference/ml/trained-models/apis/get-trained-models.asciidoc">edit</a></h3>
</div></div></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">&lt;model_id&gt;</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
The unique identifier of the trained model or a model alias.
</p>
<p>You can get information for multiple trained models in a single API request by
using a comma-separated list of model IDs or a wildcard expression.</p>
</dd>
</dl>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-get-trained-models-query-params"></a>Query parameters<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.7/docs/reference/ml/trained-models/apis/get-trained-models.asciidoc">edit</a></h3>
</div></div></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">allow_no_match</code>
</span>
</dt>
<dd>
<p>
(Optional, Boolean)
Specifies what to do when the request:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
Contains wildcard expressions and there are no models that match.
</li>
<li class="listitem">
Contains the <code class="literal">_all</code> string or no identifiers and there are no matches.
</li>
<li class="listitem">
Contains wildcard expressions and there are only partial matches.
</li>
</ul>
</div>
<p>The default value is <code class="literal">true</code>, which returns an empty array when there are no
matches and the subset of results when there are partial matches. If this
parameter is <code class="literal">false</code>, the request returns a <code class="literal">404</code> status code when there are no
matches or only partial matches.</p>
</dd>
<dt>
<span class="term">
<code class="literal">decompress_definition</code>
</span>
</dt>
<dd>
(Optional, Boolean)
Specifies whether the included model definition should be returned as a JSON map
(<code class="literal">true</code>) or in a custom compressed format (<code class="literal">false</code>). Defaults to <code class="literal">true</code>.
</dd>
<dt>
<span class="term">
<code class="literal">exclude_generated</code>
</span>
</dt>
<dd>
(Optional, Boolean)
Indicates if certain fields should be removed from the configuration on
retrieval. This allows the configuration to be in an acceptable format to be retrieved
and then added to another cluster. Default is false.
</dd>
<dt>
<span class="term">
<code class="literal">from</code>
</span>
</dt>
<dd>
(Optional, integer)
Skips the specified number of models. The default value is <code class="literal">0</code>.
</dd>
<dt>
<span class="term">
<code class="literal">include</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
A comma delimited string of optional fields to include in the response body. The
default value is empty, indicating no optional fields are included. Valid
options are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">definition</code>: Includes the model definition.
</li>
<li class="listitem">
<code class="literal">feature_importance_baseline</code>: Includes the baseline for feature importance values.
</li>
<li class="listitem">
<code class="literal">hyperparameters</code>: Includes the information about hyperparameters used to
train the model. This information consists of the value, the absolute and
relative importance of the hyperparameter as well as an indicator of whether
it was specified by the user or tuned during hyperparameter optimization.
</li>
<li class="listitem">
<code class="literal">total_feature_importance</code>: Includes the total feature importance for the training
   data set.
The baseline and total feature importance values are returned in the <code class="literal">metadata</code> field
in the response body.
</li>
</ul>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">size</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of models to obtain. The default value
is <code class="literal">100</code>.
</dd>
<dt>
<span class="term">
<code class="literal">tags</code>
</span>
</dt>
<dd>
(Optional, string)
A comma delimited string of tags. A trained model can have many tags, or none.
When supplied, only trained models that contain all the supplied tags are
returned.
</dd>
</dl>
</div>
</div>

<div class="section child_attributes">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-get-trained-models-results"></a>Response body<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.7/docs/reference/ml/trained-models/apis/get-trained-models.asciidoc">edit</a></h3>
</div></div></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">trained_model_configs</code>
</span>
</dt>
<dd>
<p>
(array)
An array of trained model resources, which are sorted by the <code class="literal">model_id</code> value in
ascending order.
</p>
<details open>
<summary class="title">Properties of trained model resources</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">created_by</code>
</span>
</dt>
<dd>
(string)
The creator of the trained model.
</dd>
<dt>
<span class="term">
<code class="literal">create_time</code>
</span>
</dt>
<dd>
(<a class="xref" href="api-conventions.html#time-units" title="Time units">time units</a>)
The time when the trained model was created.
</dd>
<dt>
<span class="term">
<code class="literal">default_field_map</code>
</span>
</dt>
<dd>
<p>
(object)
A string object that contains the default field map to use when inferring
against the model. For example, data frame analytics may train the model on a specific
multi-field <code class="literal">foo.keyword</code>. The analytics job would then supply a default field
map entry for <code class="literal">"foo" : "foo.keyword"</code>.
</p>
<p>Any field map described in the inference configuration takes precedence.</p>
</dd>
<dt>
<span class="term">
<code class="literal">description</code>
</span>
</dt>
<dd>
(string)
The free-text description of the trained model.
</dd>
<dt>
<span class="term">
<code class="literal">model_size_bytes</code>
</span>
</dt>
<dd>
(integer)
The estimated model size in bytes to keep the trained model in memory.
</dd>
<dt>
<span class="term">
<code class="literal">estimated_operations</code>
</span>
</dt>
<dd>
(integer)
The estimated number of operations to use the trained model.
</dd>
<dt>
<span class="term">
<code class="literal">inference_config</code>
</span>
</dt>
<dd>
<p>
(object)
The default configuration for inference. This can be either a <code class="literal">regression</code>
or <code class="literal">classification</code> configuration. It must match the <code class="literal">target_type</code> of the
underlying <code class="literal">definition.trained_model</code>.
</p>
<details open>
<summary class="title">Properties of <code class="literal">inference_config</code></summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">classification</code>
</span>
</dt>
<dd>
<p>
(object)
Classification configuration for inference.
</p>
<details open>
<summary class="title">Properties of classification inference</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">num_top_classes</code>
</span>
</dt>
<dd>
(integer)
Specifies the number of top class predictions to return. Defaults to 0.
</dd>
<dt>
<span class="term">
<code class="literal">num_top_feature_importance_values</code>
</span>
</dt>
<dd>
(integer)
Specifies the maximum number of
<a href="/guide/en/machine-learning/8.7/ml-feature-importance.html" class="ulink" target="_top">feature importance</a> values per document. Defaults
to 0 which means no feature importance calculation occurs.
</dd>
<dt>
<span class="term">
<code class="literal">prediction_field_type</code>
</span>
</dt>
<dd>
(string)
Specifies the type of the predicted field to write.
Valid values are: <code class="literal">string</code>, <code class="literal">number</code>, <code class="literal">boolean</code>. When <code class="literal">boolean</code> is provided
<code class="literal">1.0</code> is transformed to <code class="literal">true</code> and <code class="literal">0.0</code> to <code class="literal">false</code>.
</dd>
<dt>
<span class="term">
<code class="literal">results_field</code>
</span>
</dt>
<dd>
(string)
The field that is added to incoming documents to contain the inference
prediction. Defaults to <code class="literal">predicted_value</code>.
</dd>
<dt>
<span class="term">
<code class="literal">top_classes_results_field</code>
</span>
</dt>
<dd>
(string)
Specifies the field to which the top classes are written. Defaults to
<code class="literal">top_classes</code>.
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">fill_mask</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Configuration for a fill_mask natural language processing (NLP) task. The
fill_mask task works with models optimized for a fill mask action. For example,
for BERT models, the following text may be provided: "The capital of France is
[MASK].". The response indicates the value most likely to replace <code class="literal">[MASK]</code>. In
this instance, the most probable token is <code class="literal">paris</code>.
</p>
<details open>
<summary class="title">Properties of fill_mask inference</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">tokenization</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Indicates the tokenization to perform and the desired settings.
The default tokenization configuration is <code class="literal">bert</code>. Valid tokenization
values are
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">bert</code>: Use for BERT-style models
</li>
<li class="listitem">
<code class="literal">mpnet</code>: Use for MPNet-style models
</li>
<li class="listitem">
<code class="literal">roberta</code>: Use for RoBERTa-style and BART-style models
</li>
</ul>
</div>
<details open>
<summary class="title">Properties of tokenization</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">bert</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
BERT-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in BERT-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">[CLS]</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">[SEP]</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
RoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">add_prefix_space</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization should prefix a space to the tokenized input to the model.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in RoBERTa-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">mpnet</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
MPNet-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of mpnet</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in MPNet-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">vocabulary</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
The configuration for retrieving the vocabulary of the model. The vocabulary is
then used at inference time. This information is usually provided automatically
by storing vocabulary in a known, internally managed index.
</p>
<details open>
<summary class="title">Properties of vocabulary</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">index</code>
</span>
</dt>
<dd>
(Required, string)
The index where the vocabulary is stored.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">ner</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Configures a named entity recognition (NER) task. NER is a special case of token
classification. Each token in the sequence is classified according to the
provided classification labels. Currently, the NER task requires the
<code class="literal">classification_labels</code> Inside-Outside-Beginning (IOB) formatted labels. Only
person, organization, location, and miscellaneous are supported.
</p>
<details open>
<summary class="title">Properties of ner inference</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">classification_labels</code>
</span>
</dt>
<dd>
(Optional, string)
An array of classification labels. NER supports only
Inside-Outside-Beginning labels (IOB) and only persons, organizations, locations,
and miscellaneous. For example:
<code class="literal">["O", "B-PER", "I-PER", "B-ORG", "I-ORG", "B-LOC", "I-LOC", "B-MISC", "I-MISC"]</code>.
</dd>
<dt>
<span class="term">
<code class="literal">tokenization</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Indicates the tokenization to perform and the desired settings.
The default tokenization configuration is <code class="literal">bert</code>. Valid tokenization
values are
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">bert</code>: Use for BERT-style models
</li>
<li class="listitem">
<code class="literal">mpnet</code>: Use for MPNet-style models
</li>
<li class="listitem">
<code class="literal">roberta</code>: Use for RoBERTa-style and BART-style models
</li>
</ul>
</div>
<details open>
<summary class="title">Properties of tokenization</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">bert</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
BERT-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in BERT-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">[CLS]</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">[SEP]</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
RoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">add_prefix_space</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization should prefix a space to the tokenized input to the model.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in RoBERTa-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">mpnet</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
MPNet-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of mpnet</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in MPNet-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">vocabulary</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
The configuration for retrieving the vocabulary of the model. The vocabulary is
then used at inference time. This information is usually provided automatically
by storing vocabulary in a known, internally managed index.
</p>
<details open>
<summary class="title">Properties of vocabulary</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">index</code>
</span>
</dt>
<dd>
(Required, string)
The index where the vocabulary is stored
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">pass_through</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Configures a <code class="literal">pass_through</code> task. This task is useful for debugging as no
post-processing is done to the inference output and the raw pooling layer
results are returned to the caller.
</p>
<details open>
<summary class="title">Properties of pass_through inference</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">tokenization</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Indicates the tokenization to perform and the desired settings.
The default tokenization configuration is <code class="literal">bert</code>. Valid tokenization
values are
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">bert</code>: Use for BERT-style models
</li>
<li class="listitem">
<code class="literal">mpnet</code>: Use for MPNet-style models
</li>
<li class="listitem">
<code class="literal">roberta</code>: Use for RoBERTa-style and BART-style models
</li>
</ul>
</div>
<details open>
<summary class="title">Properties of tokenization</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">bert</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
BERT-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in BERT-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">[CLS]</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">[SEP]</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
RoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">add_prefix_space</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization should prefix a space to the tokenized input to the model.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in RoBERTa-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">mpnet</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
MPNet-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of mpnet</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in MPNet-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">vocabulary</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
The configuration for retrieving the vocabulary of the model. The vocabulary is
then used at inference time. This information is usually provided automatically
by storing vocabulary in a known, internally managed index.
</p>
<details open>
<summary class="title">Properties of vocabulary</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">index</code>
</span>
</dt>
<dd>
(Required, string)
The index where the vocabulary is stored.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">regression</code>
</span>
</dt>
<dd>
<p>
(object)
Regression configuration for inference.
</p>
<details open>
<summary class="title">Properties of regression inference</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">num_top_feature_importance_values</code>
</span>
</dt>
<dd>
(integer)
Specifies the maximum number of
<a href="/guide/en/machine-learning/8.7/ml-feature-importance.html" class="ulink" target="_top">feature importance</a> values per document.
By default, it is zero and no feature importance calculation occurs.
</dd>
<dt>
<span class="term">
<code class="literal">results_field</code>
</span>
</dt>
<dd>
(string)
The field that is added to incoming documents to contain the inference
prediction. Defaults to <code class="literal">predicted_value</code>.
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">text_classification</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
A text classification task. Text classification classifies a provided text
sequence into previously known target classes. A specific example of this is
sentiment analysis, which returns the likely target classes indicating text
sentiment, such as "sad", "happy", or "angry".
</p>
<details open>
<summary class="title">Properties of text_classification inference</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">classification_labels</code>
</span>
</dt>
<dd>
(Optional, string)
An array of classification labels.
</dd>
<dt>
<span class="term">
<code class="literal">num_top_classes</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the number of top class predictions to return. Defaults to all classes (-1).
</dd>
<dt>
<span class="term">
<code class="literal">tokenization</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Indicates the tokenization to perform and the desired settings.
The default tokenization configuration is <code class="literal">bert</code>. Valid tokenization
values are
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">bert</code>: Use for BERT-style models
</li>
<li class="listitem">
<code class="literal">mpnet</code>: Use for MPNet-style models
</li>
<li class="listitem">
<code class="literal">roberta</code>: Use for RoBERTa-style and BART-style models
</li>
</ul>
</div>
<details open>
<summary class="title">Properties of tokenization</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">bert</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
BERT-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in BERT-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">[CLS]</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">[SEP]</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
RoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">add_prefix_space</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization should prefix a space to the tokenized input to the model.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in RoBERTa-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">mpnet</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
MPNet-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of mpnet</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in MPNet-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">vocabulary</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
The configuration for retrieving the vocabulary of the model. The vocabulary is
then used at inference time. This information is usually provided automatically
by storing vocabulary in a known, internally managed index.
</p>
<details open>
<summary class="title">Properties of vocabulary</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">index</code>
</span>
</dt>
<dd>
(Required, string)
The index where the vocabulary is stored.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">text_embedding</code>
</span>
</dt>
<dd>
<p>
(Object, optional)
Text embedding takes an input sequence and transforms it into a vector of
numbers. These embeddings capture not simply tokens, but semantic meanings and
context. These embeddings can be used in a <a class="xref" href="dense-vector.html" title="Dense vector field type">dense vector</a> field
for powerful insights.
</p>
<details open>
<summary class="title">Properties of text_embedding inference</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">tokenization</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Indicates the tokenization to perform and the desired settings.
The default tokenization configuration is <code class="literal">bert</code>. Valid tokenization
values are
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">bert</code>: Use for BERT-style models
</li>
<li class="listitem">
<code class="literal">mpnet</code>: Use for MPNet-style models
</li>
<li class="listitem">
<code class="literal">roberta</code>: Use for RoBERTa-style and BART-style models
</li>
</ul>
</div>
<details open>
<summary class="title">Properties of tokenization</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">bert</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
BERT-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in BERT-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">[CLS]</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">[SEP]</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
RoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">add_prefix_space</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization should prefix a space to the tokenized input to the model.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in RoBERTa-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">mpnet</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
MPNet-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of mpnet</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in MPNet-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">vocabulary</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
The configuration for retrieving the vocabulary of the model. The vocabulary is
then used at inference time. This information is usually provided automatically
by storing vocabulary in a known, internally managed index.
</p>
<details open>
<summary class="title">Properties of vocabulary</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">index</code>
</span>
</dt>
<dd>
(Required, string)
The index where the vocabulary is stored.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">text_similarity</code>
</span>
</dt>
<dd>
<p>
(Object, optional)
Text similarity takes an input sequence and compares it with another input sequence. This is commonly referred to
as cross-encoding. This task is useful for ranking document text when comparing it to another provided text input.
</p>
<details open>
<summary class="title">Properties of text_similarity inference</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">span_score_combination_function</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Identifies how to combine the resulting similarity score when a provided text passage is longer than <code class="literal">max_sequence_length</code> and must be
automatically separated for multiple calls. This only is applicable when <code class="literal">truncate</code> is <code class="literal">none</code> and <code class="literal">span</code> is a non-negative
number. The default value is <code class="literal">max</code>. Available options are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">max</code>: The maximum score from all the spans is returned.
</li>
<li class="listitem">
<code class="literal">mean</code>: The mean score over all the spans is returned.
</li>
</ul>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">tokenization</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Indicates the tokenization to perform and the desired settings.
The default tokenization configuration is <code class="literal">bert</code>. Valid tokenization
values are
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">bert</code>: Use for BERT-style models
</li>
<li class="listitem">
<code class="literal">mpnet</code>: Use for MPNet-style models
</li>
<li class="listitem">
<code class="literal">roberta</code>: Use for RoBERTa-style and BART-style models
</li>
</ul>
</div>
<details open>
<summary class="title">Properties of tokenization</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">bert</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
BERT-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in BERT-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">[CLS]</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">[SEP]</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
RoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">add_prefix_space</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization should prefix a space to the tokenized input to the model.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in RoBERTa-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">mpnet</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
MPNet-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of mpnet</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in MPNet-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">vocabulary</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
The configuration for retrieving the vocabulary of the model. The vocabulary is
then used at inference time. This information is usually provided automatically
by storing vocabulary in a known, internally managed index.
</p>
<details open>
<summary class="title">Properties of vocabulary</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">index</code>
</span>
</dt>
<dd>
(Required, string)
The index where the vocabulary is stored.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">zero_shot_classification</code>
</span>
</dt>
<dd>
<p>
(Object, optional)
Configures a zero-shot classification task. Zero-shot classification allows for
text classification to occur without pre-determined labels. At inference time,
it is possible to adjust the labels to classify. This makes this type of model
and task exceptionally flexible.
</p>
<p>If consistently classifying the same labels, it may be better to use a
fine-tuned text classification model.</p>
<details open>
<summary class="title">Properties of zero_shot_classification inference</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">classification_labels</code>
</span>
</dt>
<dd>
(Required, array)
The classification labels used during the zero-shot classification. Classification
labels must not be empty or null and only set at model creation. They must be all three
of ["entailment", "neutral", "contradiction"].
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>This is NOT the same as <code class="literal">labels</code> which are the values that zero-shot is attempting to
      classify.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">hypothesis_template</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
This is the template used when tokenizing the sequences for classification.
</p>
<p>The labels replace the <code class="literal">{}</code> value in the text. The default value is:
<code class="literal">This example is {}.</code></p>
</dd>
<dt>
<span class="term">
<code class="literal">labels</code>
</span>
</dt>
<dd>
(Optional, array)
The labels to classify. Can be set at creation for default labels, and
then updated during inference.
</dd>
<dt>
<span class="term">
<code class="literal">multi_label</code>
</span>
</dt>
<dd>
(Optional, boolean)
Indicates if more than one <code class="literal">true</code> label is possible given the input.
This is useful when labeling text that could pertain to more than one of the
input labels. Defaults to <code class="literal">false</code>.
</dd>
<dt>
<span class="term">
<code class="literal">tokenization</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Indicates the tokenization to perform and the desired settings.
The default tokenization configuration is <code class="literal">bert</code>. Valid tokenization
values are
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">bert</code>: Use for BERT-style models
</li>
<li class="listitem">
<code class="literal">mpnet</code>: Use for MPNet-style models
</li>
<li class="listitem">
<code class="literal">roberta</code>: Use for RoBERTa-style and BART-style models
</li>
</ul>
</div>
<details open>
<summary class="title">Properties of tokenization</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">bert</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
BERT-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in BERT-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">[CLS]</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">[SEP]</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
RoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">add_prefix_space</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization should prefix a space to the tokenized input to the model.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in RoBERTa-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">mpnet</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
MPNet-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of mpnet</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in MPNet-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">vocabulary</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
The configuration for retrieving the vocabulary of the model. The vocabulary is
then used at inference time. This information is usually provided automatically
by storing vocabulary in a known, internally managed index.
</p>
<details open>
<summary class="title">Properties of vocabulary</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">index</code>
</span>
</dt>
<dd>
(Required, string)
The index where the vocabulary is stored.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">input</code>
</span>
</dt>
<dd>
<p>
(object)
The input field names for the model definition.
</p>
<details open>
<summary class="title">Properties of <code class="literal">input</code></summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">field_names</code>
</span>
</dt>
<dd>
(string)
An array of input field names for the model.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">location</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
The model definition location. Must be provided if the <code class="literal">definition</code> or <code class="literal">compressed_definition</code> are not
provided.
</p>
<details open>
<summary class="title">Properties of <code class="literal">location</code></summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">index</code>
</span>
</dt>
<dd>
(Required, object)
Indicates that the model definition is stored in an index. It is required to be empty as
the index for storing model definitions is configured automatically.
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">license_level</code>
</span>
</dt>
<dd>
(string)
The license level of the trained model.
</dd>
<dt>
<span class="term">
<code class="literal">metadata</code>
</span>
</dt>
<dd>
<p>
(object)
An object containing metadata about the trained model. For example, models
created by data frame analytics contain <code class="literal">analysis_config</code> and <code class="literal">input</code> objects.
</p>
<details open>
<summary class="title">Properties of metadata</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">feature_importance_baseline</code>
</span>
</dt>
<dd>
(object)
An object that contains the baseline for feature importance values. For regression analysis,
it is a single value. For classification analysis, there is a value for each class.
</dd>
<dt>
<span class="term">
<code class="literal">hyperparameters</code>
</span>
</dt>
<dd>
<p>
(array)
List of the available hyperparameters optimized during the
<code class="literal">fine_parameter_tuning</code> phase as well as specified by the user.
</p>
<details open>
<summary class="title">Properties of hyperparameters</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">absolute_importance</code>
</span>
</dt>
<dd>
(double)
A positive number showing how much the parameter influences the variation of the
<a href="/guide/en/machine-learning/8.7/dfa-regression-lossfunction.html" class="ulink" target="_top">loss function</a>. For
hyperparameters with values that are not specified by the user but tuned during
hyperparameter optimization.
</dd>
<dt>
<span class="term">
<code class="literal">max_trees</code>
</span>
</dt>
<dd>
(integer)
The maximum number of decision trees in the forest. The maximum value is 2000.
By default, this value is calculated during hyperparameter optimization.
</dd>
<dt>
<span class="term">
<code class="literal">name</code>
</span>
</dt>
<dd>
(string)
Name of the hyperparameter.
</dd>
<dt>
<span class="term">
<code class="literal">relative_importance</code>
</span>
</dt>
<dd>
(double)
A number between 0 and 1 showing the proportion of influence on the variation of
the loss function among all tuned hyperparameters. For hyperparameters with
values that are not specified by the user but tuned during hyperparameter
optimization.
</dd>
<dt>
<span class="term">
<code class="literal">supplied</code>
</span>
</dt>
<dd>
(Boolean)
Indicates if the hyperparameter is specified by the user (<code class="literal">true</code>) or optimized
(<code class="literal">false</code>).
</dd>
<dt>
<span class="term">
<code class="literal">value</code>
</span>
</dt>
<dd>
(double)
The value of the hyperparameter, either optimized or specified by the user.
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">total_feature_importance</code>
</span>
</dt>
<dd>
<p>
(array)
An array of the total feature importance for each feature used from
the training data set. This array of objects is returned if data frame analytics trained
the model and the request includes <code class="literal">total_feature_importance</code> in the <code class="literal">include</code>
request parameter.
</p>
<details open>
<summary class="title">Properties of total feature importance</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">feature_name</code>
</span>
</dt>
<dd>
(string)
The feature for which this importance was calculated.
</dd>
<dt>
<span class="term">
<code class="literal">importance</code>
</span>
</dt>
<dd>
<p>
(object)
A collection of feature importance statistics related to the training data set for this particular feature.
</p>
<details open>
<summary class="title">Properties of feature importance</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">mean_magnitude</code>
</span>
</dt>
<dd>
(double)
The average magnitude of this feature across all the training data.
This value is the average of the absolute values of the importance
for this feature.
</dd>
<dt>
<span class="term">
<code class="literal">max</code>
</span>
</dt>
<dd>
(integer)
The maximum importance value across all the training data for this
feature.
</dd>
<dt>
<span class="term">
<code class="literal">min</code>
</span>
</dt>
<dd>
(integer)
The minimum importance value across all the training data for this
feature.
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">classes</code>
</span>
</dt>
<dd>
<p>
(array)
If the trained model is a classification model, feature importance statistics are gathered
per target class value.
</p>
<details open>
<summary class="title">Properties of class feature importance</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">class_name</code>
</span>
</dt>
<dd>
(string)
The target class value. Could be a string, boolean, or number.
</dd>
<dt>
<span class="term">
<code class="literal">importance</code>
</span>
</dt>
<dd>
<p>
(object)
A collection of feature importance statistics related to the training data set for this particular feature.
</p>
<details open>
<summary class="title">Properties of feature importance</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">mean_magnitude</code>
</span>
</dt>
<dd>
(double)
The average magnitude of this feature across all the training data.
This value is the average of the absolute values of the importance
for this feature.
</dd>
<dt>
<span class="term">
<code class="literal">max</code>
</span>
</dt>
<dd>
(int)
The maximum importance value across all the training data for this
feature.
</dd>
<dt>
<span class="term">
<code class="literal">min</code>
</span>
</dt>
<dd>
(int)
The minimum importance value across all the training data for this
feature.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">model_id</code>
</span>
</dt>
<dd>
(string)
Identifier for the trained model.
</dd>
<dt>
<span class="term">
<code class="literal">model_type</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
The created model type. By default the model type is <code class="literal">tree_ensemble</code>.
Appropriate types are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">tree_ensemble</code>: The model definition is an ensemble model of decision trees.
</li>
<li class="listitem">
<code class="literal">lang_ident</code>: A special type reserved for language identification models.
</li>
<li class="listitem">
<code class="literal">pytorch</code>: The stored definition is a PyTorch (specifically a TorchScript) model. Currently only
NLP models are supported.
</li>
</ul>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">tags</code>
</span>
</dt>
<dd>
(string)
A comma delimited string of tags. A trained model can have many tags, or none.
</dd>
<dt>
<span class="term">
<code class="literal">version</code>
</span>
</dt>
<dd>
(string)
The Elasticsearch version number in which the trained model was created.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-get-trained-models-response-codes"></a>Response codes<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.7/docs/reference/ml/trained-models/apis/get-trained-models.asciidoc">edit</a></h3>
</div></div></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">400</code>
</span>
</dt>
<dd>
If <code class="literal">include_model_definition</code> is <code class="literal">true</code>, this code indicates that more than
one models match the ID pattern.
</dd>
<dt>
<span class="term">
<code class="literal">404</code> (Missing resources)
</span>
</dt>
<dd>
If <code class="literal">allow_no_match</code> is <code class="literal">false</code>, this code indicates that there are no
resources that match the request or only partial matches for the request.
</dd>
</dl>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-get-trained-models-example"></a>Examples<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.7/docs/reference/ml/trained-models/apis/get-trained-models.asciidoc">edit</a></h3>
</div></div></div>
<p>The following example gets configuration information for all the trained models:</p>
<div class="pre_wrapper lang-ruby alternative">
<pre class="programlisting prettyprint lang-ruby alternative">response = client.ml.get_trained_models
puts response</pre>
</div>
<a id="4c174e228b6b74497b73ef2be80de7ad"></a>
<div class="pre_wrapper lang-console default has-ruby">
<pre class="programlisting prettyprint lang-console default has-ruby">GET _ml/trained_models/</pre>
</div>
<div class="console_widget has-ruby" data-snippet="snippets/2579.console"></div>
</div>

</div>
<div class="navfooter">
<span class="prev">
<a href="delete-trained-models.html">« Delete trained models API</a>
</span>
<span class="next">
<a href="get-trained-models-stats.html">Get trained models statistics API »</a>
</span>
</div>
</div>
</body>
</html>
