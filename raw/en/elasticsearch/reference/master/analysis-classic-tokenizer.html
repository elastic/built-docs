<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Classic tokenizer | Elasticsearch Guide [master] | Elastic</title>
<meta class="elastic" name="content" content="Classic tokenizer | Elasticsearch Guide [master]">

<link rel="home" href="index.html" title="Elasticsearch Guide [master]"/>
<link rel="up" href="analysis-tokenizers.html" title="Tokenizer reference"/>
<link rel="prev" href="analysis-chargroup-tokenizer.html" title="Character group tokenizer"/>
<link rel="next" href="analysis-edgengram-tokenizer.html" title="Edge n-gram tokenizer"/>
<meta class="elastic" name="product_version" content="master"/>
<meta class="elastic" name="product_name" content="Elasticsearch"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/Elasticsearch/Reference/master"/>
<meta name="DC.subject" content="Elasticsearch"/>
<meta name="DC.identifier" content="master"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body>
<div class="page_header">
This documentation contains work-in-progress information for future Elastic Stack and Cloud releases. Use the version selector to view supported release docs. It also contains some Elastic Cloud serverless information. Check out our <a href="https://www.elastic.co/docs/current/serverless">serverless docs</a> for more details.
</div>
<div class="navheader">
<span class="prev">
<a href="analysis-chargroup-tokenizer.html">« Character group tokenizer</a>
</span>
<span class="next">
<a href="analysis-edgengram-tokenizer.html">Edge n-gram tokenizer »</a>
</span>
</div>
<div class="book" lang="en">
<div class="titlepage">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Elasticsearch Guide [master]</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="analysis.html">Text analysis</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="analysis-tokenizers.html">Tokenizer reference</a></span>
</div>
<div>
<div><h1 class="title"><a id="id-1"></a>Classic tokenizer</h1><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/analysis/tokenizers/classic-tokenizer.asciidoc">edit</a></div>
</div>
<!--EXTRA-->
</div>
<div id="content">
<div class="section">
<div class="titlepage"><div><div>
<h2 class="title"><a id="analysis-classic-tokenizer"></a>Classic tokenizer<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/analysis/tokenizers/classic-tokenizer.asciidoc">edit</a></h2>
</div></div></div>

<p>The <code class="literal">classic</code> tokenizer is a grammar based tokenizer that is good for English
language documents. This tokenizer has heuristics for special treatment of
acronyms, company names, email addresses, and internet host names. However,
these rules don&#8217;t always work, and the tokenizer doesn&#8217;t work well for most
languages other than English:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
It splits words at most punctuation characters, removing punctuation. However, a
dot that&#8217;s not followed by whitespace is considered part of a token.
</li>
<li class="listitem">
It splits words at hyphens, unless there&#8217;s a number in the token, in which case
the whole token is interpreted as a product number and is not split.
</li>
<li class="listitem">
It recognizes email addresses and internet hostnames as one token.
</li>
</ul>
</div>
<h3><a id="_example_output_8"></a>Example output<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/analysis/tokenizers/classic-tokenizer.asciidoc">edit</a></h3>
<div class="pre_wrapper lang-ruby alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-ruby alternative">response = client.indices.analyze(
  body: {
    tokenizer: 'classic',
    text: "The 2 QUICK Brown-Foxes jumped over the lazy dog's bone."
  }
)
puts response</pre>
</div>
<div class="pre_wrapper lang-js alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js alternative">const response = await client.indices.analyze({
  tokenizer: "classic",
  text: "The 2 QUICK Brown-Foxes jumped over the lazy dog's bone.",
});
console.log(response);</pre>
</div>
<a id="c6d39d22188dc7bbfdad811a94cbcc2b"></a>
<div class="pre_wrapper lang-console default has-ruby has-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console default has-ruby has-js">POST _analyze
{
  "tokenizer": "classic",
  "text": "The 2 QUICK Brown-Foxes jumped over the lazy dog's bone."
}</pre>
</div>
<div class="console_widget has-ruby has-js" data-snippet="snippets/470.console"></div>
<p>The above sentence would produce the following terms:</p>
<div class="pre_wrapper lang-text">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-text">[ The, 2, QUICK, Brown, Foxes, jumped, over, the, lazy, dog's, bone ]</pre>
</div>
<h3><a id="_configuration_9"></a>Configuration<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/analysis/tokenizers/classic-tokenizer.asciidoc">edit</a></h3>
<p>The <code class="literal">classic</code> tokenizer accepts the following parameters:</p>
<div class="informaltable">
<table border="0" cellpadding="4px">
<colgroup>
<col/>
<col/>
</colgroup>
<tbody valign="top">
<tr>
<td valign="top">
<p>
<code class="literal">max_token_length</code>
</p>
</td>
<td valign="top">
<p>
The maximum token length. If a token is seen that exceeds this length then
it is split at <code class="literal">max_token_length</code> intervals. Defaults to <code class="literal">255</code>.
</p>
</td>
</tr>
</tbody>
</table>
</div>
<h3><a id="_example_configuration_6"></a>Example configuration<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/analysis/tokenizers/classic-tokenizer.asciidoc">edit</a></h3>
<p>In this example, we configure the <code class="literal">classic</code> tokenizer to have a
<code class="literal">max_token_length</code> of 5 (for demonstration purposes):</p>
<div class="pre_wrapper lang-ruby alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-ruby alternative">response = client.indices.create(
  index: 'my-index-000001',
  body: {
    settings: {
      analysis: {
        analyzer: {
          my_analyzer: {
            tokenizer: 'my_tokenizer'
          }
        },
        tokenizer: {
          my_tokenizer: {
            type: 'classic',
            max_token_length: 5
          }
        }
      }
    }
  }
)
puts response

response = client.indices.analyze(
  index: 'my-index-000001',
  body: {
    analyzer: 'my_analyzer',
    text: "The 2 QUICK Brown-Foxes jumped over the lazy dog's bone."
  }
)
puts response</pre>
</div>
<div class="pre_wrapper lang-js alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js alternative">const response = await client.indices.create({
  index: "my-index-000001",
  settings: {
    analysis: {
      analyzer: {
        my_analyzer: {
          tokenizer: "my_tokenizer",
        },
      },
      tokenizer: {
        my_tokenizer: {
          type: "classic",
          max_token_length: 5,
        },
      },
    },
  },
});
console.log(response);

const response1 = await client.indices.analyze({
  index: "my-index-000001",
  analyzer: "my_analyzer",
  text: "The 2 QUICK Brown-Foxes jumped over the lazy dog's bone.",
});
console.log(response1);</pre>
</div>
<a id="ba9a5f66a6148612de0ad2491fd6c90d"></a>
<div class="pre_wrapper lang-console default has-ruby has-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console default has-ruby has-js">PUT my-index-000001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "my_tokenizer"
        }
      },
      "tokenizer": {
        "my_tokenizer": {
          "type": "classic",
          "max_token_length": 5
        }
      }
    }
  }
}

POST my-index-000001/_analyze
{
  "analyzer": "my_analyzer",
  "text": "The 2 QUICK Brown-Foxes jumped over the lazy dog's bone."
}</pre>
</div>
<div class="console_widget has-ruby has-js" data-snippet="snippets/471.console"></div>
<p>The above example produces the following terms:</p>
<div class="pre_wrapper lang-text">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-text">[ The, 2, QUICK, Brown, Foxes, jumpe, d, over, the, lazy, dog's, bone ]</pre>
</div>
</div>
</div>
</div><div class="navfooter">
<span class="prev">
<a href="analysis-chargroup-tokenizer.html">« Character group tokenizer</a>
</span>
<span class="next">
<a href="analysis-edgengram-tokenizer.html">Edge n-gram tokenizer »</a>
</span>
</div>
</body>
</html>
