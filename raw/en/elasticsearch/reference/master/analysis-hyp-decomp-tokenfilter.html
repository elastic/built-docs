<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Hyphenation decompounder token filter | Elasticsearch Guide [master] | Elastic</title>
<meta class="elastic" name="content" content="Hyphenation decompounder token filter | Elasticsearch Guide [master]">

<link rel="home" href="index.html" title="Elasticsearch Guide [master]"/>
<link rel="up" href="analysis-tokenfilters.html" title="Token filter reference"/>
<link rel="prev" href="analysis-hunspell-tokenfilter.html" title="Hunspell token filter"/>
<link rel="next" href="analysis-keep-types-tokenfilter.html" title="Keep types token filter"/>
<meta class="elastic" name="product_version" content="master"/>
<meta class="elastic" name="product_name" content="Elasticsearch"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/Elasticsearch/Reference/master"/>
<meta name="DC.subject" content="Elasticsearch"/>
<meta name="DC.identifier" content="master"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body>
<div class="page_header">
This documentation contains work-in-progress information for future Elastic Stack and Cloud releases. Use the version selector to view supported release docs. It also contains some Elastic Cloud serverless information. Check out our <a href="https://www.elastic.co/docs/current/serverless">serverless docs</a> for more details.
</div>
<div class="navheader">
<span class="prev">
<a href="analysis-hunspell-tokenfilter.html">« Hunspell token filter</a>
</span>
<span class="next">
<a href="analysis-keep-types-tokenfilter.html">Keep types token filter »</a>
</span>
</div>
<div class="book" lang="en">
<div class="titlepage">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Elasticsearch Guide [master]</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="analysis.html">Text analysis</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="analysis-tokenfilters.html">Token filter reference</a></span>
</div>
<div>
<div><h1 class="title"><a id="id-1"></a>Hyphenation decompounder token filter</h1><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/analysis/tokenfilters/hyphenation-decompounder-tokenfilter.asciidoc">edit</a></div>
</div>
<!--EXTRA-->
</div>
<div id="content">
<div class="section">
<div class="titlepage"><div><div>
<h2 class="title"><a id="analysis-hyp-decomp-tokenfilter"></a>Hyphenation decompounder token filter<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/analysis/tokenfilters/hyphenation-decompounder-tokenfilter.asciidoc">edit</a></h2>
</div></div></div>

<p>Uses XML-based hyphenation patterns to find potential subwords in compound
words. These subwords are then checked against the specified word list. Subwords not
in the list are excluded from the token output.</p>
<p>This filter uses Lucene&#8217;s
<a href="https://lucene.apache.org/core/9_11_1/analysis/common/org/apache/lucene/analysis/compound/HyphenationCompoundWordTokenFilter.html" class="ulink" target="_top">HyphenationCompoundWordTokenFilter</a>,
which was built for Germanic languages.</p>
<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="analysis-hyp-decomp-tokenfilter-analyze-ex"></a>Example<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/analysis/tokenfilters/hyphenation-decompounder-tokenfilter.asciidoc">edit</a></h3>
</div></div></div>
<p>The following <a class="xref" href="indices-analyze.html" title="Analyze API">analyze API</a> request uses the
<code class="literal">hyphenation_decompounder</code> filter to find subwords in <code class="literal">Kaffeetasse</code> based on
German hyphenation patterns in the <code class="literal">analysis/hyphenation_patterns.xml</code> file. The
filter then checks these subwords against a list of specified words: <code class="literal">kaffee</code>,
<code class="literal">zucker</code>, and <code class="literal">tasse</code>.</p>
<div class="pre_wrapper lang-js alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js alternative">const response = await client.indices.analyze({
  tokenizer: "standard",
  filter: [
    {
      type: "hyphenation_decompounder",
      hyphenation_patterns_path: "analysis/hyphenation_patterns.xml",
      word_list: ["Kaffee", "zucker", "tasse"],
    },
  ],
  text: "Kaffeetasse",
});
console.log(response);</pre>
</div>
<a id="f34c02351662481dd61a5c2a3e206c60"></a>
<div class="pre_wrapper lang-console default has-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console default has-js">GET _analyze
{
  "tokenizer": "standard",
  "filter": [
    {
      "type": "hyphenation_decompounder",
      "hyphenation_patterns_path": "analysis/hyphenation_patterns.xml",
      "word_list": ["Kaffee", "zucker", "tasse"]
    }
  ],
  "text": "Kaffeetasse"
}</pre>
</div>
<div class="console_widget has-js" data-snippet="snippets/541.console"></div>
<p>The filter produces the following tokens:</p>
<div class="pre_wrapper lang-text">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-text">[ Kaffeetasse, Kaffee, tasse ]</pre>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="analysis-hyp-decomp-tokenfilter-configure-parms"></a>Configurable parameters<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/analysis/tokenfilters/hyphenation-decompounder-tokenfilter.asciidoc">edit</a></h3>
</div></div></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">hyphenation_patterns_path</code>
</span>
</dt>
<dd>
<p>(Required, string)
Path to an Apache FOP (Formatting Objects Processor) XML hyphenation pattern file.</p>
<p>This path must be absolute or relative to the <code class="literal">config</code> location. Only FOP v1.2
compatible files are supported.</p>
<p>For example FOP XML hyphenation pattern files, refer to:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<a href="http://offo.sourceforge.net/#FOP+XML+Hyphenation+Patterns" class="ulink" target="_top">Objects For Formatting Objects (OFFO) Sourceforge project</a>
</li>
<li class="listitem">
<a href="https://sourceforge.net/projects/offo/files/offo-hyphenation/1.2/offo-hyphenation_v1.2.zip/download" class="ulink" target="_top">offo-hyphenation_v1.2.zip direct download</a> (v2.0 and above hyphenation pattern files are not supported)
</li>
</ul>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">word_list</code>
</span>
</dt>
<dd>
<p>(Required*, array of strings)
A list of subwords. Subwords found using the hyphenation pattern but not in this
list are excluded from the token output.</p>
<p>You can use the <a class="xref" href="analysis-dict-decomp-tokenfilter.html" title="Dictionary decompounder token filter"><code class="literal">dictionary_decompounder</code></a>
filter to test the quality of word lists before implementing them.</p>
<p>Either this parameter or <code class="literal">word_list_path</code> must be specified.</p>
</dd>
<dt>
<span class="term">
<code class="literal">word_list_path</code>
</span>
</dt>
<dd>
<p>(Required*, string)
Path to a file containing a list of subwords. Subwords found using the
hyphenation pattern but not in this list are excluded from the token output.</p>
<p>This path must be absolute or relative to the <code class="literal">config</code> location, and the file
must be UTF-8 encoded. Each token in the file must be separated by a line break.</p>
<p>You can use the <a class="xref" href="analysis-dict-decomp-tokenfilter.html" title="Dictionary decompounder token filter"><code class="literal">dictionary_decompounder</code></a>
filter to test the quality of word lists before implementing them.</p>
<p>Either this parameter or <code class="literal">word_list</code> must be specified.</p>
</dd>
<dt>
<span class="term">
<code class="literal">max_subword_size</code>
</span>
</dt>
<dd>
(Optional, integer)
Maximum subword character length. Longer subword tokens are excluded from the
output. Defaults to <code class="literal">15</code>.
</dd>
<dt>
<span class="term">
<code class="literal">min_subword_size</code>
</span>
</dt>
<dd>
(Optional, integer)
Minimum subword character length. Shorter subword tokens are excluded from the
output. Defaults to <code class="literal">2</code>.
</dd>
<dt>
<span class="term">
<code class="literal">min_word_size</code>
</span>
</dt>
<dd>
(Optional, integer)
Minimum word character length. Shorter word tokens are excluded from the
output. Defaults to <code class="literal">5</code>.
</dd>
<dt>
<span class="term">
<code class="literal">only_longest_match</code>
</span>
</dt>
<dd>
(Optional, Boolean)
If <code class="literal">true</code>, only include the longest matching subword. Defaults to <code class="literal">false</code>.
</dd>
</dl>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="analysis-hyp-decomp-tokenfilter-customize"></a>Customize and add to an analyzer<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/analysis/tokenfilters/hyphenation-decompounder-tokenfilter.asciidoc">edit</a></h3>
</div></div></div>
<p>To customize the <code class="literal">hyphenation_decompounder</code> filter, duplicate it to create the
basis for a new custom token filter. You can modify the filter using its
configurable parameters.</p>
<p>For example, the following <a class="xref" href="indices-create-index.html" title="Create index API">create index API</a> request
uses a custom <code class="literal">hyphenation_decompounder</code> filter to configure a new
<a class="xref" href="analysis-custom-analyzer.html" title="Create a custom analyzer">custom analyzer</a>.</p>
<p>The custom <code class="literal">hyphenation_decompounder</code> filter find subwords based on hyphenation
patterns in the <code class="literal">analysis/hyphenation_patterns.xml</code> file. The filter then checks
these subwords against the list of words specified in the
<code class="literal">analysis/example_word_list.txt</code> file. Subwords longer than 22 characters are
excluded from the token output.</p>
<div class="pre_wrapper lang-js alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js alternative">const response = await client.indices.create({
  index: "hyphenation_decompound_example",
  settings: {
    analysis: {
      analyzer: {
        standard_hyphenation_decompound: {
          tokenizer: "standard",
          filter: ["22_char_hyphenation_decompound"],
        },
      },
      filter: {
        "22_char_hyphenation_decompound": {
          type: "hyphenation_decompounder",
          word_list_path: "analysis/example_word_list.txt",
          hyphenation_patterns_path: "analysis/hyphenation_patterns.xml",
          max_subword_size: 22,
        },
      },
    },
  },
});
console.log(response);</pre>
</div>
<a id="5f8acd1e367b048b5542dbc6079bcc88"></a>
<div class="pre_wrapper lang-console default has-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console default has-js">PUT hyphenation_decompound_example
{
  "settings": {
    "analysis": {
      "analyzer": {
        "standard_hyphenation_decompound": {
          "tokenizer": "standard",
          "filter": [ "22_char_hyphenation_decompound" ]
        }
      },
      "filter": {
        "22_char_hyphenation_decompound": {
          "type": "hyphenation_decompounder",
          "word_list_path": "analysis/example_word_list.txt",
          "hyphenation_patterns_path": "analysis/hyphenation_patterns.xml",
          "max_subword_size": 22
        }
      }
    }
  }
}</pre>
</div>
<div class="console_widget has-js" data-snippet="snippets/542.console"></div>
</div>

</div>
</div>
</div><div class="navfooter">
<span class="prev">
<a href="analysis-hunspell-tokenfilter.html">« Hunspell token filter</a>
</span>
<span class="next">
<a href="analysis-keep-types-tokenfilter.html">Keep types token filter »</a>
</span>
</div>
</body>
</html>
