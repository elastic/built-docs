<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Letter tokenizer | Elasticsearch Guide [master] | Elastic</title>
<meta class="elastic" name="content" content="Letter tokenizer | Elasticsearch Guide [master]">

<link rel="home" href="index.html" title="Elasticsearch Guide [master]"/>
<link rel="up" href="analysis-tokenizers.html" title="Tokenizer reference"/>
<link rel="prev" href="analysis-keyword-tokenizer.html" title="Keyword tokenizer"/>
<link rel="next" href="analysis-lowercase-tokenizer.html" title="Lowercase tokenizer"/>
<meta class="elastic" name="product_version" content="master"/>
<meta class="elastic" name="product_name" content="Elasticsearch"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/Elasticsearch/Reference/master"/>
<meta name="DC.subject" content="Elasticsearch"/>
<meta name="DC.identifier" content="master"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body>
<div class="page_header">
This documentation contains work-in-progress information for future Elastic Stack and Cloud releases. Use the version selector to view supported release docs. It also contains some Elastic Cloud serverless information. Check out our <a href="https://www.elastic.co/docs/current/serverless">serverless docs</a> for more details.
</div>
<div class="navheader">
<span class="prev">
<a href="analysis-keyword-tokenizer.html">« Keyword tokenizer</a>
</span>
<span class="next">
<a href="analysis-lowercase-tokenizer.html">Lowercase tokenizer »</a>
</span>
</div>
<div class="book" lang="en">
<div class="titlepage">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Elasticsearch Guide [master]</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="analysis.html">Text analysis</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="analysis-tokenizers.html">Tokenizer reference</a></span>
</div>
<div>
<div><h1 class="title"><a id="id-1"></a>Letter tokenizer</h1><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/analysis/tokenizers/letter-tokenizer.asciidoc">edit</a></div>
</div>
<!--EXTRA-->
</div>
<div id="content">
<div class="section">
<div class="titlepage"><div><div>
<h2 class="title"><a id="analysis-letter-tokenizer"></a>Letter tokenizer<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/analysis/tokenizers/letter-tokenizer.asciidoc">edit</a></h2>
</div></div></div>

<p>The <code class="literal">letter</code> tokenizer breaks text into terms whenever it encounters a
character which is not a letter. It does a reasonable job for most European
languages, but does a terrible job for some Asian languages, where words are
not separated by spaces.</p>
<h3><a id="_example_output_11"></a>Example output<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/analysis/tokenizers/letter-tokenizer.asciidoc">edit</a></h3>
<div class="pre_wrapper lang-ruby alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-ruby alternative">response = client.indices.analyze(
  body: {
    tokenizer: 'letter',
    text: "The 2 QUICK Brown-Foxes jumped over the lazy dog's bone."
  }
)
puts response</pre>
</div>
<div class="pre_wrapper lang-js alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js alternative">const response = await client.indices.analyze({
  tokenizer: "letter",
  text: "The 2 QUICK Brown-Foxes jumped over the lazy dog's bone.",
});
console.log(response);</pre>
</div>
<a id="76448aaaaa2c352bb6e09d2f83a3fbb3"></a>
<div class="pre_wrapper lang-console default has-ruby has-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console default has-ruby has-js">POST _analyze
{
  "tokenizer": "letter",
  "text": "The 2 QUICK Brown-Foxes jumped over the lazy dog's bone."
}</pre>
</div>
<div class="console_widget has-ruby has-js" data-snippet="snippets/477.console"></div>
<p>The above sentence would produce the following terms:</p>
<div class="pre_wrapper lang-text">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-text">[ The, QUICK, Brown, Foxes, jumped, over, the, lazy, dog, s, bone ]</pre>
</div>
<h3><a id="_configuration_12"></a>Configuration<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/analysis/tokenizers/letter-tokenizer.asciidoc">edit</a></h3>
<p>The <code class="literal">letter</code> tokenizer is not configurable.</p>
</div>
</div>
</div><div class="navfooter">
<span class="prev">
<a href="analysis-keyword-tokenizer.html">« Keyword tokenizer</a>
</span>
<span class="next">
<a href="analysis-lowercase-tokenizer.html">Lowercase tokenizer »</a>
</span>
</div>
</body>
</html>
