<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>N-gram tokenizer | Elasticsearch Guide [master] | Elastic</title>
<meta class="elastic" name="content" content="N-gram tokenizer | Elasticsearch Guide [master]">

<link rel="home" href="index.html" title="Elasticsearch Guide [master]"/>
<link rel="up" href="analysis-tokenizers.html" title="Tokenizer reference"/>
<link rel="prev" href="analysis-lowercase-tokenizer.html" title="Lowercase tokenizer"/>
<link rel="next" href="analysis-pathhierarchy-tokenizer.html" title="Path hierarchy tokenizer"/>
<meta class="elastic" name="product_version" content="master"/>
<meta class="elastic" name="product_name" content="Elasticsearch"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/Elasticsearch/Reference/master"/>
<meta name="DC.subject" content="Elasticsearch"/>
<meta name="DC.identifier" content="master"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body>
<div class="page_header">
This documentation contains work-in-progress information for future Elastic Stack and Cloud releases. Use the version selector to view supported release docs. It also contains some Elastic Cloud serverless information. Check out our <a href="https://www.elastic.co/docs/current/serverless">serverless docs</a> for more details.
</div>
<div class="navheader">
<span class="prev">
<a href="analysis-lowercase-tokenizer.html">« Lowercase tokenizer</a>
</span>
<span class="next">
<a href="analysis-pathhierarchy-tokenizer.html">Path hierarchy tokenizer »</a>
</span>
</div>
<div class="book" lang="en">
<div class="titlepage">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Elasticsearch Guide [master]</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="analysis.html">Text analysis</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="analysis-tokenizers.html">Tokenizer reference</a></span>
</div>
<div>
<div><h1 class="title"><a id="id-1"></a>N-gram tokenizer</h1><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/analysis/tokenizers/ngram-tokenizer.asciidoc">edit</a></div>
</div>
<!--EXTRA-->
</div>
<div id="content">
<div class="section">
<div class="titlepage"><div><div>
<h2 class="title"><a id="analysis-ngram-tokenizer"></a>N-gram tokenizer<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/analysis/tokenizers/ngram-tokenizer.asciidoc">edit</a></h2>
</div></div></div>

<p>The <code class="literal">ngram</code> tokenizer first breaks text down into words whenever it encounters
one of a list of specified characters, then it emits
<a href="https://en.wikipedia.org/wiki/N-gram" class="ulink" target="_top">N-grams</a> of each word of the specified
length.</p>
<p>N-grams are like a sliding window that moves across the word - a continuous
sequence of characters of the specified length. They are useful for querying
languages that don&#8217;t use spaces or that have long compound words, like German.</p>
<h3><a id="_example_output_13"></a>Example output<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/analysis/tokenizers/ngram-tokenizer.asciidoc">edit</a></h3>
<p>With the default settings, the <code class="literal">ngram</code> tokenizer treats the initial text as a
single token and produces N-grams with minimum length <code class="literal">1</code> and maximum length
<code class="literal">2</code>:</p>
<div class="pre_wrapper lang-ruby alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-ruby alternative">response = client.indices.analyze(
  body: {
    tokenizer: 'ngram',
    text: 'Quick Fox'
  }
)
puts response</pre>
</div>
<a id="39963032d423e2f20f53c4621b6ca3c6"></a>
<div class="pre_wrapper lang-console default has-ruby">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console default has-ruby">POST _analyze
{
  "tokenizer": "ngram",
  "text": "Quick Fox"
}</pre>
</div>
<div class="console_widget has-ruby" data-snippet="snippets/477.console"></div>
<p>The above sentence would produce the following terms:</p>
<div class="pre_wrapper lang-text">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-text">[ Q, Qu, u, ui, i, ic, c, ck, k, "k ", " ", " F", F, Fo, o, ox, x ]</pre>
</div>
<h3><a id="_configuration_14"></a>Configuration<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/analysis/tokenizers/ngram-tokenizer.asciidoc">edit</a></h3>
<p>The <code class="literal">ngram</code> tokenizer accepts the following parameters:</p>
<div class="informaltable">
<table border="0" cellpadding="4px">
<colgroup>
<col/>
<col/>
</colgroup>
<tbody valign="top">
<tr>
<td valign="top">
<p>
<code class="literal">min_gram</code>
</p>
</td>
<td valign="top">
<p>
Minimum length of characters in a gram. Defaults to <code class="literal">1</code>.
</p>
</td>
</tr>
<tr>
<td valign="top">
<p>
<code class="literal">max_gram</code>
</p>
</td>
<td valign="top">
<p>
Maximum length of characters in a gram. Defaults to <code class="literal">2</code>.
</p>
</td>
</tr>
<tr>
<td valign="top">
<p>
<code class="literal">token_chars</code>
</p>
</td>
<td valign="top">
<p>
<p>
Character classes that should be included in a token. Elasticsearch
will split on characters that don&#8217;t belong to the classes specified.
Defaults to <code class="literal">[]</code> (keep all characters).
</p>
<p>Character classes may be any of the following:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">letter</code>&#8201;&#8212;&#8201;     for example <code class="literal">a</code>, <code class="literal">b</code>, <code class="literal">ï</code> or <code class="literal">京</code>
</li>
<li class="listitem">
<code class="literal">digit</code>&#8201;&#8212;&#8201;      for example <code class="literal">3</code> or <code class="literal">7</code>
</li>
<li class="listitem">
<code class="literal">whitespace</code>&#8201;&#8212;&#8201; for example <code class="literal">" "</code> or <code class="literal">"\n"</code>
</li>
<li class="listitem">
<code class="literal">punctuation</code>&#8201;&#8212;&#8201;for example <code class="literal">!</code> or <code class="literal">"</code>
</li>
<li class="listitem">
<code class="literal">symbol</code>&#8201;&#8212;&#8201;     for example <code class="literal">$</code> or <code class="literal">√</code>
</li>
<li class="listitem">
<code class="literal">custom</code>&#8201;&#8212;&#8201;     custom characters which need to be set using the
<code class="literal">custom_token_chars</code> setting.
</li>
</ul>
</div>
</p>
</td>
</tr>
<tr>
<td valign="top">
<p>
<code class="literal">custom_token_chars</code>
</p>
</td>
<td valign="top">
<p>
Custom characters that should be treated as part of a token. For example,
setting this to <code class="literal">+-_</code> will make the tokenizer treat the plus, minus and
underscore sign as part of a token.
</p>
</td>
</tr>
</tbody>
</table>
</div>
<div class="tip admon">
<div class="icon"></div>
<div class="admon_content">
<p>It usually makes sense to set <code class="literal">min_gram</code> and <code class="literal">max_gram</code> to the same
value. The smaller the length, the more documents will match but the lower
the quality of the matches. The longer the length, the more specific the
matches. A tri-gram (length <code class="literal">3</code>) is a good place to start.</p>
</div>
</div>
<p>The index level setting <code class="literal">index.max_ngram_diff</code> controls the maximum allowed
difference between <code class="literal">max_gram</code> and <code class="literal">min_gram</code>.</p>
<h3><a id="_example_configuration_8"></a>Example configuration<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/analysis/tokenizers/ngram-tokenizer.asciidoc">edit</a></h3>
<p>In this example, we configure the <code class="literal">ngram</code> tokenizer to treat letters and
digits as tokens, and to produce tri-grams (grams of length <code class="literal">3</code>):</p>
<div class="pre_wrapper lang-ruby alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-ruby alternative">response = client.indices.create(
  index: 'my-index-000001',
  body: {
    settings: {
      analysis: {
        analyzer: {
          my_analyzer: {
            tokenizer: 'my_tokenizer'
          }
        },
        tokenizer: {
          my_tokenizer: {
            type: 'ngram',
            min_gram: 3,
            max_gram: 3,
            token_chars: [
              'letter',
              'digit'
            ]
          }
        }
      }
    }
  }
)
puts response

response = client.indices.analyze(
  index: 'my-index-000001',
  body: {
    analyzer: 'my_analyzer',
    text: '2 Quick Foxes.'
  }
)
puts response</pre>
</div>
<a id="d8c401a5b7359ec65947b9f35ecf6927"></a>
<div class="pre_wrapper lang-console default has-ruby">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console default has-ruby">PUT my-index-000001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "my_tokenizer"
        }
      },
      "tokenizer": {
        "my_tokenizer": {
          "type": "ngram",
          "min_gram": 3,
          "max_gram": 3,
          "token_chars": [
            "letter",
            "digit"
          ]
        }
      }
    }
  }
}

POST my-index-000001/_analyze
{
  "analyzer": "my_analyzer",
  "text": "2 Quick Foxes."
}</pre>
</div>
<div class="console_widget has-ruby" data-snippet="snippets/478.console"></div>
<p>The above example produces the following terms:</p>
<div class="pre_wrapper lang-text">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-text">[ Qui, uic, ick, Fox, oxe, xes ]</pre>
</div>
</div>
</div>
</div><div class="navfooter">
<span class="prev">
<a href="analysis-lowercase-tokenizer.html">« Lowercase tokenizer</a>
</span>
<span class="next">
<a href="analysis-pathhierarchy-tokenizer.html">Path hierarchy tokenizer »</a>
</span>
</div>
</body>
</html>
