<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Pattern tokenizer | Elasticsearch Guide [master] | Elastic</title>
<meta class="elastic" name="content" content="Pattern tokenizer | Elasticsearch Guide [master]">

<link rel="home" href="index.html" title="Elasticsearch Guide [master]"/>
<link rel="up" href="analysis-tokenizers.html" title="Tokenizer reference"/>
<link rel="prev" href="analysis-pathhierarchy-tokenizer.html" title="Path hierarchy tokenizer"/>
<link rel="next" href="analysis-simplepattern-tokenizer.html" title="Simple pattern tokenizer"/>
<meta class="elastic" name="product_version" content="master"/>
<meta class="elastic" name="product_name" content="Elasticsearch"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/Elasticsearch/Reference/master"/>
<meta name="DC.subject" content="Elasticsearch"/>
<meta name="DC.identifier" content="master"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body>
<div class="page_header">
This documentation contains work-in-progress information for future Elastic Stack and Cloud releases. Use the version selector to view supported release docs. It also contains some Elastic Cloud serverless information. Check out our <a href="https://www.elastic.co/docs/current/serverless">serverless docs</a> for more details.
</div>
<div class="navheader">
<span class="prev">
<a href="analysis-pathhierarchy-tokenizer.html">« Path hierarchy tokenizer</a>
</span>
<span class="next">
<a href="analysis-simplepattern-tokenizer.html">Simple pattern tokenizer »</a>
</span>
</div>
<div class="book" lang="en">
<div class="titlepage">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Elasticsearch Guide [master]</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="analysis.html">Text analysis</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="analysis-tokenizers.html">Tokenizer reference</a></span>
</div>
<div>
<div><h1 class="title"><a id="id-1"></a>Pattern tokenizer</h1><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/analysis/tokenizers/pattern-tokenizer.asciidoc">edit</a></div>
</div>
<!--EXTRA-->
</div>
<div id="content">
<div class="section">
<div class="titlepage"><div><div>
<h2 class="title"><a id="analysis-pattern-tokenizer"></a>Pattern tokenizer<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/analysis/tokenizers/pattern-tokenizer.asciidoc">edit</a></h2>
</div></div></div>

<p>The <code class="literal">pattern</code> tokenizer uses a regular expression to either split text into
terms whenever it matches a word separator, or to capture matching text as
terms.</p>
<p>The default pattern is <code class="literal">\W+</code>, which splits text whenever it encounters
non-word characters.</p>
<div class="warning admon">
<div class="icon"></div>
<div class="admon_content">
<h3>Beware of Pathological Regular Expressions</h3>
<p>The pattern tokenizer uses
<a href="https://docs.oracle.com/javase/8/docs/api/java/util/regex/Pattern.html" class="ulink" target="_top">Java Regular Expressions</a>.</p>
<p>A badly written regular expression could run very slowly or even throw a
StackOverflowError and cause the node it is running on to exit suddenly.</p>
<p>Read more about <a href="https://www.regular-expressions.info/catastrophic.html" class="ulink" target="_top">pathological regular expressions and how to avoid them</a>.</p>
</div>
</div>
<h3><a id="_example_output_15"></a>Example output<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/analysis/tokenizers/pattern-tokenizer.asciidoc">edit</a></h3>
<div class="pre_wrapper lang-ruby alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-ruby alternative">response = client.indices.analyze(
  body: {
    tokenizer: 'pattern',
    text: "The foo_bar_size's default is 5."
  }
)
puts response</pre>
</div>
<div class="pre_wrapper lang-js alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js alternative">const response = await client.indices.analyze({
  tokenizer: "pattern",
  text: "The foo_bar_size's default is 5.",
});
console.log(response);</pre>
</div>
<a id="1a6dbe5df488c4a16e2f1101ba8a25d9"></a>
<div class="pre_wrapper lang-console default has-ruby has-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console default has-ruby has-js">POST _analyze
{
  "tokenizer": "pattern",
  "text": "The foo_bar_size's default is 5."
}</pre>
</div>
<div class="console_widget has-ruby has-js" data-snippet="snippets/489.console"></div>
<p>The above sentence would produce the following terms:</p>
<div class="pre_wrapper lang-text">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-text">[ The, foo_bar_size, s, default, is, 5 ]</pre>
</div>
<h3><a id="_configuration_16"></a>Configuration<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/analysis/tokenizers/pattern-tokenizer.asciidoc">edit</a></h3>
<p>The <code class="literal">pattern</code> tokenizer accepts the following parameters:</p>
<div class="informaltable">
<table border="0" cellpadding="4px">
<colgroup>
<col/>
<col/>
</colgroup>
<tbody valign="top">
<tr>
<td valign="top">
<p>
<code class="literal">pattern</code>
</p>
</td>
<td valign="top">
<p>
A <a href="https://docs.oracle.com/javase/8/docs/api/java/util/regex/Pattern.html" class="ulink" target="_top">Java regular expression</a>, defaults to <code class="literal">\W+</code>.
</p>
</td>
</tr>
<tr>
<td valign="top">
<p>
<code class="literal">flags</code>
</p>
</td>
<td valign="top">
<p>
Java regular expression <a href="https://docs.oracle.com/javase/8/docs/api/java/util/regex/Pattern.html#field.summary" class="ulink" target="_top">flags</a>.
Flags should be pipe-separated, eg <code class="literal">"CASE_INSENSITIVE|COMMENTS"</code>.
</p>
</td>
</tr>
<tr>
<td valign="top">
<p>
<code class="literal">group</code>
</p>
</td>
<td valign="top">
<p>
Which capture group to extract as tokens. Defaults to <code class="literal">-1</code> (split).
</p>
</td>
</tr>
</tbody>
</table>
</div>
<h3><a id="_example_configuration_10"></a>Example configuration<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/analysis/tokenizers/pattern-tokenizer.asciidoc">edit</a></h3>
<p>In this example, we configure the <code class="literal">pattern</code> tokenizer to break text into
tokens when it encounters commas:</p>
<div class="pre_wrapper lang-ruby alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-ruby alternative">response = client.indices.create(
  index: 'my-index-000001',
  body: {
    settings: {
      analysis: {
        analyzer: {
          my_analyzer: {
            tokenizer: 'my_tokenizer'
          }
        },
        tokenizer: {
          my_tokenizer: {
            type: 'pattern',
            pattern: ','
          }
        }
      }
    }
  }
)
puts response

response = client.indices.analyze(
  index: 'my-index-000001',
  body: {
    analyzer: 'my_analyzer',
    text: 'comma,separated,values'
  }
)
puts response</pre>
</div>
<div class="pre_wrapper lang-js alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js alternative">const response = await client.indices.create({
  index: "my-index-000001",
  settings: {
    analysis: {
      analyzer: {
        my_analyzer: {
          tokenizer: "my_tokenizer",
        },
      },
      tokenizer: {
        my_tokenizer: {
          type: "pattern",
          pattern: ",",
        },
      },
    },
  },
});
console.log(response);

const response1 = await client.indices.analyze({
  index: "my-index-000001",
  analyzer: "my_analyzer",
  text: "comma,separated,values",
});
console.log(response1);</pre>
</div>
<a id="118f249a3b26c33416f641b33f2b74f8"></a>
<div class="pre_wrapper lang-console default has-ruby has-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console default has-ruby has-js">PUT my-index-000001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "my_tokenizer"
        }
      },
      "tokenizer": {
        "my_tokenizer": {
          "type": "pattern",
          "pattern": ","
        }
      }
    }
  }
}

POST my-index-000001/_analyze
{
  "analyzer": "my_analyzer",
  "text": "comma,separated,values"
}</pre>
</div>
<div class="console_widget has-ruby has-js" data-snippet="snippets/490.console"></div>
<p>The above example produces the following terms:</p>
<div class="pre_wrapper lang-text">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-text">[ comma, separated, values ]</pre>
</div>
<p>In the next example, we configure the <code class="literal">pattern</code> tokenizer to capture values
enclosed in double quotes (ignoring embedded escaped quotes <code class="literal">\"</code>). The regex
itself looks like this:</p>
<pre class="literallayout">"((?:\\"|[^"]|\\")*)"</pre>

<p>And reads as follows:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
A literal <code class="literal">"</code>
</li>
<li class="listitem">
<p>Start capturing:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
A literal <code class="literal">\"</code> OR any character except <code class="literal">"</code>
</li>
<li class="listitem">
Repeat until no more characters match
</li>
</ul>
</div>
</li>
<li class="listitem">
A literal closing <code class="literal">"</code>
</li>
</ul>
</div>
<p>When the pattern is specified in JSON, the <code class="literal">"</code> and <code class="literal">\</code> characters need to be
escaped, so the pattern ends up looking like:</p>
<pre class="literallayout">\"((?:\\\\\"|[^\"]|\\\\\")+)\"</pre>

<div class="pre_wrapper lang-ruby alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-ruby alternative">response = client.indices.create(
  index: 'my-index-000001',
  body: {
    settings: {
      analysis: {
        analyzer: {
          my_analyzer: {
            tokenizer: 'my_tokenizer'
          }
        },
        tokenizer: {
          my_tokenizer: {
            type: 'pattern',
            pattern: '"((?:\\\"|[^"]|\\\")+)"',
            group: 1
          }
        }
      }
    }
  }
)
puts response

response = client.indices.analyze(
  index: 'my-index-000001',
  body: {
    analyzer: 'my_analyzer',
    text: '"value", "value with embedded \" quote"'
  }
)
puts response</pre>
</div>
<div class="pre_wrapper lang-js alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js alternative">const response = await client.indices.create({
  index: "my-index-000001",
  settings: {
    analysis: {
      analyzer: {
        my_analyzer: {
          tokenizer: "my_tokenizer",
        },
      },
      tokenizer: {
        my_tokenizer: {
          type: "pattern",
          pattern: '"((?:\\\\"|[^"]|\\\\")+)"',
          group: 1,
        },
      },
    },
  },
});
console.log(response);

const response1 = await client.indices.analyze({
  index: "my-index-000001",
  analyzer: "my_analyzer",
  text: '"value", "value with embedded \\" quote"',
});
console.log(response1);</pre>
</div>
<a id="1598a0fec6b1ca78cadbaba65f465196"></a>
<div class="pre_wrapper lang-console default has-ruby has-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console default has-ruby has-js">PUT my-index-000001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "my_tokenizer"
        }
      },
      "tokenizer": {
        "my_tokenizer": {
          "type": "pattern",
          "pattern": "\"((?:\\\\\"|[^\"]|\\\\\")+)\"",
          "group": 1
        }
      }
    }
  }
}

POST my-index-000001/_analyze
{
  "analyzer": "my_analyzer",
  "text": "\"value\", \"value with embedded \\\" quote\""
}</pre>
</div>
<div class="console_widget has-ruby has-js" data-snippet="snippets/491.console"></div>
<p>The above example produces the following two terms:</p>
<div class="pre_wrapper lang-text">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-text">[ value, value with embedded \" quote ]</pre>
</div>
</div>
</div>
</div><div class="navfooter">
<span class="prev">
<a href="analysis-pathhierarchy-tokenizer.html">« Path hierarchy tokenizer</a>
</span>
<span class="next">
<a href="analysis-simplepattern-tokenizer.html">Simple pattern tokenizer »</a>
</span>
</div>
</body>
</html>
