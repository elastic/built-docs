<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Azure AI studio inference service | Elasticsearch Guide [master] | Elastic</title>
<meta class="elastic" name="content" content="Azure AI studio inference service | Elasticsearch Guide [master]">

<link rel="home" href="index.html" title="Elasticsearch Guide [master]"/>
<link rel="up" href="inference-apis.html" title="Inference APIs"/>
<link rel="prev" href="infer-service-anthropic.html" title="Anthropic inference service"/>
<link rel="next" href="infer-service-azure-openai.html" title="Azure OpenAI inference service"/>
<meta class="elastic" name="product_version" content="master"/>
<meta class="elastic" name="product_name" content="Elasticsearch"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/Elasticsearch/Reference/master"/>
<meta name="DC.subject" content="Elasticsearch"/>
<meta name="DC.identifier" content="master"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body>
<div class="page_header">
This documentation contains work-in-progress information for future Elastic Stack and Cloud releases. Use the version selector to view supported release docs. It also contains some Elastic Cloud serverless information. Check out our <a href="https://www.elastic.co/docs/current/serverless">serverless docs</a> for more details.
</div>
<div class="navheader">
<span class="prev">
<a href="infer-service-anthropic.html">« Anthropic inference service</a>
</span>
<span class="next">
<a href="infer-service-azure-openai.html">Azure OpenAI inference service »</a>
</span>
</div>
<div class="book" lang="en">
<div class="titlepage">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Elasticsearch Guide [master]</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="rest-apis.html">REST APIs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="inference-apis.html">Inference APIs</a></span>
</div>
<div>
<div><h1 class="title"><a id="id-1"></a>Azure AI studio inference service</h1><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/inference/service-azure-ai-studio.asciidoc">edit</a></div>
</div>
<!--EXTRA-->
</div>
<div id="content">
<div class="section">
<div class="titlepage"><div><div>
<div class="position-relative"><h2 class="title"><a id="infer-service-azure-ai-studio"></a>Azure AI studio inference service</h2><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/inference/service-azure-ai-studio.asciidoc">edit</a></div>
</div></div></div>
<p>Creates an inference endpoint to perform an inference task with the <code class="literal">azureaistudio</code> service.</p>
<div class="position-relative"><h4><a id="infer-service-azure-ai-studio-api-request"></a>Request</h4><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/inference/service-azure-ai-studio.asciidoc">edit</a></div>
<p><code class="literal">PUT /_inference/&lt;task_type&gt;/&lt;inference_id&gt;</code></p>
<div class="position-relative"><h4><a id="infer-service-azure-ai-studio-api-path-params"></a>Path parameters</h4><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/inference/service-azure-ai-studio.asciidoc">edit</a></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">&lt;inference_id&gt;</code>
</span>
</dt>
<dd>
(Required, string)
The unique identifier of the inference endpoint.
</dd>
<dt>
<span class="term">
<code class="literal">&lt;task_type&gt;</code>
</span>
</dt>
<dd>
<p>
(Required, string)
The type of the inference task that the model will perform.
</p>
<p>Available task types:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">completion</code>,
</li>
<li class="listitem">
<code class="literal">text_embedding</code>.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="position-relative"><h4><a id="infer-service-azure-ai-studio-api-request-body"></a>Request body</h4><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/inference/service-azure-ai-studio.asciidoc">edit</a></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">chunking_settings</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Chunking configuration object.
Refer to <a class="xref" href="inference-apis.html#infer-chunking-config" title="Configuring chunking">Configuring chunking</a> to learn more about chunking.
</p>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">max_chunking_size</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum size of a chunk in words.
Defaults to <code class="literal">250</code>.
This value cannot be higher than <code class="literal">300</code> or lower than <code class="literal">20</code> (for <code class="literal">sentence</code> strategy) or <code class="literal">10</code> (for <code class="literal">word</code> strategy).
</dd>
<dt>
<span class="term">
<code class="literal">overlap</code>
</span>
</dt>
<dd>
(Optional, integer)
Only for <code class="literal">word</code> chunking strategy.
Specifies the number of overlapping words for chunks.
Defaults to <code class="literal">100</code>.
This value cannot be higher than the half of <code class="literal">max_chunking_size</code>.
</dd>
<dt>
<span class="term">
<code class="literal">sentence_overlap</code>
</span>
</dt>
<dd>
(Optional, integer)
Only for <code class="literal">sentence</code> chunking strategy.
Specifies the numnber of overlapping sentences for chunks.
It can be either <code class="literal">1</code> or <code class="literal">0</code>.
Defaults to <code class="literal">1</code>.
</dd>
<dt>
<span class="term">
<code class="literal">strategy</code>
</span>
</dt>
<dd>
(Optional, string)
Specifies the chunking strategy.
It could be either <code class="literal">sentence</code> or <code class="literal">word</code>.
</dd>
</dl>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">service</code>
</span>
</dt>
<dd>
(Required, string)
The type of service supported for the specified task type. In this case,
<code class="literal">azureaistudio</code>.
</dd>
<dt>
<span class="term">
<code class="literal">service_settings</code>
</span>
</dt>
<dd>
<p>
(Required, object)
Settings used to install the inference model.
</p>
<p>These settings are specific to the <code class="literal">azureaistudio</code> service.</p>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">api_key</code>
</span>
</dt>
<dd>
<p>
(Required, string)
A valid API key of your Azure AI Studio model deployment.
This key can be found on the overview page for your deployment in the management section of your <a href="https://ai.azure.com/" class="ulink" target="_top">Azure AI Studio</a> account.
</p>
<div class="important admon">
<div class="icon"></div>
<div class="admon_content">
<p>You need to provide the API key only once, during the inference model creation.
The <a class="xref" href="get-inference-api.html" title="Get inference API">Get inference API</a> does not retrieve your API key.
After creating the inference model, you cannot change the associated API key.
If you want to use a different API key, delete the inference model and recreate it with the same name and the updated API key.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">target</code>
</span>
</dt>
<dd>
(Required, string)
The target URL of your Azure AI Studio model deployment.
This can be found on the overview page for your deployment in the management section of your <a href="https://ai.azure.com/" class="ulink" target="_top">Azure AI Studio</a> account.
</dd>
<dt>
<span class="term">
<code class="literal">provider</code>
</span>
</dt>
<dd>
<p>
(Required, string)
The model provider for your deployment.
Note that some providers may support only certain task types.
Supported providers include:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">cohere</code> - available for <code class="literal">text_embedding</code> and <code class="literal">completion</code> task types
</li>
<li class="listitem">
<code class="literal">databricks</code> - available for <code class="literal">completion</code> task type only
</li>
<li class="listitem">
<code class="literal">meta</code> - available for <code class="literal">completion</code> task type only
</li>
<li class="listitem">
<code class="literal">microsoft_phi</code> - available for <code class="literal">completion</code> task type only
</li>
<li class="listitem">
<code class="literal">mistral</code> - available for <code class="literal">completion</code> task type only
</li>
<li class="listitem">
<code class="literal">openai</code> - available for <code class="literal">text_embedding</code> and <code class="literal">completion</code> task types
</li>
</ul>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">endpoint_type</code>
</span>
</dt>
<dd>
(Required, string)
One of <code class="literal">token</code> or <code class="literal">realtime</code>.
Specifies the type of endpoint that is used in your model deployment.
There are <a href="https://learn.microsoft.com/en-us/azure/ai-studio/concepts/deployments-overview#billing-for-deploying-and-inferencing-llms-in-azure-ai-studio" class="ulink" target="_top">two endpoint types available</a> for deployment through Azure AI Studio.
"Pay as you go" endpoints are billed per token.
For these, you must specify <code class="literal">token</code> for your <code class="literal">endpoint_type</code>.
For "real-time" endpoints which are billed per hour of usage, specify <code class="literal">realtime</code>.
</dd>
<dt>
<span class="term">
<code class="literal">rate_limit</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
By default, the <code class="literal">azureaistudio</code> service sets the number of requests allowed per minute to <code class="literal">240</code>.
This helps to minimize the number of rate limit errors returned from Azure AI Studio.
To modify this, set the <code class="literal">requests_per_minute</code> setting of this object in your service settings:
</p>
<div class="pre_wrapper lang-text">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-text">"rate_limit": {
    "requests_per_minute": &lt;&lt;number_of_requests&gt;&gt;
}</pre>
</div>
</dd>
</dl>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">task_settings</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Settings to configure the inference task.
These settings are specific to the <code class="literal">&lt;task_type&gt;</code> you specified.
</p>
<details>
<summary class="title"><code class="literal">task_settings</code> for the <code class="literal">completion</code> task type</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_sample</code>
</span>
</dt>
<dd>
(Optional, float)
Instructs the inference process to perform sampling or not.
Has no effect unless <code class="literal">temperature</code> or <code class="literal">top_p</code> is specified.
</dd>
<dt>
<span class="term">
<code class="literal">max_new_tokens</code>
</span>
</dt>
<dd>
(Optional, integer)
Provides a hint for the maximum number of output tokens to be generated.
Defaults to 64.
</dd>
<dt>
<span class="term">
<code class="literal">temperature</code>
</span>
</dt>
<dd>
(Optional, float)
A number in the range of 0.0 to 2.0 that specifies the sampling temperature to use that controls the apparent creativity of generated completions.
Should not be used if <code class="literal">top_p</code> is specified.
</dd>
<dt>
<span class="term">
<code class="literal">top_p</code>
</span>
</dt>
<dd>
(Optional, float)
A number in the range of 0.0 to 2.0 that is an alternative value to temperature that causes the model to consider the results of the tokens with nucleus sampling probability.
Should not be used if <code class="literal">temperature</code> is specified.
</dd>
</dl>
</div>
</div>
</details>
<details>
<summary class="title"><code class="literal">task_settings</code> for the <code class="literal">text_embedding</code> task type</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">user</code>
</span>
</dt>
<dd>
(optional, string)
Specifies the user issuing the request, which can be used for abuse detection.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
<div class="position-relative"><h4><a id="inference-example-azureaistudio"></a>Azure AI Studio service example</h4><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/inference/service-azure-ai-studio.asciidoc">edit</a></div>
<p>The following example shows how to create an inference endpoint called <code class="literal">azure_ai_studio_embeddings</code> to perform a <code class="literal">text_embedding</code> task type.
Note that we do not specify a model here, as it is defined already via our Azure AI Studio deployment.</p>
<p>The list of embeddings models that you can choose from in your deployment can be found in the <a href="https://ai.azure.com/explore/models?selectedTask=embeddings" class="ulink" target="_top">Azure AI Studio model explorer</a>.</p>
<div class="pre_wrapper lang-python alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-python alternative">resp = client.inference.put(
    task_type="text_embedding",
    inference_id="azure_ai_studio_embeddings",
    inference_config={
        "service": "azureaistudio",
        "service_settings": {
            "api_key": "&lt;api_key&gt;",
            "target": "&lt;target_uri&gt;",
            "provider": "&lt;model_provider&gt;",
            "endpoint_type": "&lt;endpoint_type&gt;"
        }
    },
)
print(resp)</pre>
</div>
<div class="pre_wrapper lang-js alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js alternative">const response = await client.inference.put({
  task_type: "text_embedding",
  inference_id: "azure_ai_studio_embeddings",
  inference_config: {
    service: "azureaistudio",
    service_settings: {
      api_key: "&lt;api_key&gt;",
      target: "&lt;target_uri&gt;",
      provider: "&lt;model_provider&gt;",
      endpoint_type: "&lt;endpoint_type&gt;",
    },
  },
});
console.log(response);</pre>
</div>
<a id="1dadb7efe27b6c0c231eb6535e413bd9"></a>
<div class="pre_wrapper lang-console default has-python has-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console default has-python has-js">PUT _inference/text_embedding/azure_ai_studio_embeddings
{
    "service": "azureaistudio",
    "service_settings": {
        "api_key": "&lt;api_key&gt;",
        "target": "&lt;target_uri&gt;",
        "provider": "&lt;model_provider&gt;",
        "endpoint_type": "&lt;endpoint_type&gt;"
    }
}</pre>
</div>
<div class="console_widget has-python has-js" data-snippet="snippets/2957.console"></div>
<p>The next example shows how to create an inference endpoint called <code class="literal">azure_ai_studio_completion</code> to perform a <code class="literal">completion</code> task type.</p>
<div class="pre_wrapper lang-python alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-python alternative">resp = client.inference.put(
    task_type="completion",
    inference_id="azure_ai_studio_completion",
    inference_config={
        "service": "azureaistudio",
        "service_settings": {
            "api_key": "&lt;api_key&gt;",
            "target": "&lt;target_uri&gt;",
            "provider": "&lt;model_provider&gt;",
            "endpoint_type": "&lt;endpoint_type&gt;"
        }
    },
)
print(resp)</pre>
</div>
<div class="pre_wrapper lang-js alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js alternative">const response = await client.inference.put({
  task_type: "completion",
  inference_id: "azure_ai_studio_completion",
  inference_config: {
    service: "azureaistudio",
    service_settings: {
      api_key: "&lt;api_key&gt;",
      target: "&lt;target_uri&gt;",
      provider: "&lt;model_provider&gt;",
      endpoint_type: "&lt;endpoint_type&gt;",
    },
  },
});
console.log(response);</pre>
</div>
<a id="6ddd4e657efbf45def430a6419825796"></a>
<div class="pre_wrapper lang-console default has-python has-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console default has-python has-js">PUT _inference/completion/azure_ai_studio_completion
{
    "service": "azureaistudio",
    "service_settings": {
        "api_key": "&lt;api_key&gt;",
        "target": "&lt;target_uri&gt;",
        "provider": "&lt;model_provider&gt;",
        "endpoint_type": "&lt;endpoint_type&gt;"
    }
}</pre>
</div>
<div class="console_widget has-python has-js" data-snippet="snippets/2958.console"></div>
<p>The list of chat completion models that you can choose from in your deployment can be found in the <a href="https://ai.azure.com/explore/models?selectedTask=chat-completion" class="ulink" target="_top">Azure AI Studio model explorer</a>.</p>
</div>
</div>
</div><div class="navfooter">
<span class="prev">
<a href="infer-service-anthropic.html">« Anthropic inference service</a>
</span>
<span class="next">
<a href="infer-service-azure-openai.html">Azure OpenAI inference service »</a>
</span>
</div>
</body>
</html>
