<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="keywords" content="Elasticsearch diagnostic, diagnostics">
<title>Create inference API | Elasticsearch Guide [master] | Elastic</title>
<meta class="elastic" name="content" content="Create inference API | Elasticsearch Guide [master]">

<link rel="home" href="index.html" title="Elasticsearch Guide [master]"/>
<link rel="up" href="inference-apis.html" title="Inference APIs"/>
<link rel="prev" href="post-inference-api.html" title="Perform inference API"/>
<link rel="next" href="info-api.html" title="Info API"/>
<meta class="elastic" name="product_version" content="master"/>
<meta class="elastic" name="product_name" content="Elasticsearch"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/Elasticsearch/Reference/master"/>
<meta name="DC.subject" content="Elasticsearch"/>
<meta name="DC.identifier" content="master"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body><div class="page_header">
You are looking at preliminary documentation for a future release.
Not what you want? See the
<a href="../current/index.html">current release documentation</a>.
</div>
<div id="content">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Elasticsearch Guide [master]</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="rest-apis.html">REST APIs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="inference-apis.html">Inference APIs</a></span>
</div>
<div class="navheader">
<span class="prev">
<a href="post-inference-api.html">« Perform inference API</a>
</span>
<span class="next">
<a href="info-api.html">Info API »</a>
</span>
</div>
<div class="section xpack">
<div class="titlepage"><div><div>
<h2 class="title"><a id="put-inference-api"></a>Create inference API<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/inference/put-inference.asciidoc">edit</a></h2>
</div></div></div>
<div class="warning admon">
<div class="icon"></div>
<div class="admon_content">
<p>This functionality is in technical preview and may be changed or removed in a future release. Elastic will work to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.</p>
</div>
</div>
<p>Creates an inference endpoint to perform an inference task.</p>
<div class="important admon">
<div class="icon"></div>
<div class="admon_content">
<p>The inference APIs enable you to use certain services, such as built-in
machine learning models (ELSER, E5), models uploaded through Eland, Cohere, OpenAI, Azure
OpenAI, Google AI Studio or Hugging Face. For built-in models and models
uploaded though Eland, the inference APIs offer an alternative way to use and
manage trained models. However, if you do not plan to use the inference APIs to
use these models or if you want to use non-NLP models, use the
<a class="xref" href="ml-df-trained-models-apis.html" title="Machine learning trained model APIs"><em>Machine learning trained model APIs</em></a>.</p>
</div>
</div>
<h4><a id="put-inference-api-request"></a>Request<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/inference/put-inference.asciidoc">edit</a></h4>
<p><code class="literal">PUT /_inference/&lt;task_type&gt;/&lt;inference_id&gt;</code></p>
<h4><a id="put-inference-api-prereqs"></a>Prerequisites<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/inference/put-inference.asciidoc">edit</a></h4>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
Requires the <code class="literal">manage_inference</code> <a class="xref" href="security-privileges.html#privileges-list-cluster" title="Cluster privileges">cluster privilege</a>
(the built-in <code class="literal">inference_admin</code> role grants this privilege)
</li>
</ul>
</div>
<h4><a id="put-inference-api-desc"></a>Description<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/inference/put-inference.asciidoc">edit</a></h4>
<p>The create inference API enables you to create an inference endpoint and configure a
machine learning model to perform a specific inference task.</p>
<p>The following services are available through the inference API:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
Azure AI Studio
</li>
<li class="listitem">
Azure OpenAI
</li>
<li class="listitem">
Cohere
</li>
<li class="listitem">
Elasticsearch (for built-in models and models uploaded through Eland)
</li>
<li class="listitem">
ELSER
</li>
<li class="listitem">
Google AI Studio
</li>
<li class="listitem">
Hugging Face
</li>
<li class="listitem">
OpenAI
</li>
</ul>
</div>
<h4><a id="put-inference-api-path-params"></a>Path parameters<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/inference/put-inference.asciidoc">edit</a></h4>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">&lt;inference_id&gt;</code>
</span>
</dt>
<dd>
(Required, string)
The unique identifier of the inference endpoint.
</dd>
<dt>
<span class="term">
<code class="literal">&lt;task_type&gt;</code>
</span>
</dt>
<dd>
<p>
(Required, string)
The type of the inference task that the model will perform. Available task types:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">completion</code>,
</li>
<li class="listitem">
<code class="literal">rerank</code>,
</li>
<li class="listitem">
<code class="literal">sparse_embedding</code>,
</li>
<li class="listitem">
<code class="literal">text_embedding</code>.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<h4><a id="put-inference-api-request-body"></a>Request body<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/inference/put-inference.asciidoc">edit</a></h4>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">service</code>
</span>
</dt>
<dd>
<p>
(Required, string)
The type of service supported for the specified task type.
Available services:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">azureopenai</code>: specify the <code class="literal">completion</code> or <code class="literal">text_embedding</code> task type to use the Azure OpenAI service.
</li>
<li class="listitem">
<code class="literal">azureaistudio</code>: specify the <code class="literal">completion</code> or <code class="literal">text_embedding</code> task type to use the Azure AI Studio service.
</li>
<li class="listitem">
<code class="literal">cohere</code>: specify the <code class="literal">completion</code>, <code class="literal">text_embedding</code> or the <code class="literal">rerank</code> task type to use the
Cohere service.
</li>
<li class="listitem">
<code class="literal">elasticsearch</code>: specify the <code class="literal">text_embedding</code> task type to use the E5
built-in model or text embedding models uploaded by Eland.
</li>
<li class="listitem">
<code class="literal">elser</code>: specify the <code class="literal">sparse_embedding</code> task type to use the ELSER service.
</li>
<li class="listitem">
<code class="literal">googleaistudio</code>: specify the <code class="literal">completion</code> task to use the Google AI Studio service.
</li>
<li class="listitem">
<code class="literal">hugging_face</code>: specify the <code class="literal">text_embedding</code> task type to use the Hugging Face
service.
</li>
<li class="listitem">
<code class="literal">openai</code>: specify the <code class="literal">completion</code> or <code class="literal">text_embedding</code> task type to use the
OpenAI service.
</li>
</ul>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">service_settings</code>
</span>
</dt>
<dd>
<p>
(Required, object)
Settings used to install the inference model. These settings are specific to the
<code class="literal">service</code> you specified.
</p>
<details>
<summary class="title"><code class="literal">service_settings</code> for the <code class="literal">azureaistudio</code> service</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">api_key</code>
</span>
</dt>
<dd>
(Required, string)
A valid API key of your Azure AI Studio model deployment.
This key can be found on the overview page for your deployment in the management section of your <a href="https://ai.azure.com/" class="ulink" target="_top">Azure AI Studio</a> account.
</dd>
</dl>
</div>
<div class="important admon">
<div class="icon"></div>
<div class="admon_content">
<p>You need to provide the API key only once, during the inference model
creation. The <a class="xref" href="get-inference-api.html" title="Get inference API">Get inference API</a> does not retrieve your API key. After
creating the inference model, you cannot change the associated API key. If you
want to use a different API key, delete the inference model and recreate it with
the same name and the updated API key.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">target</code>
</span>
</dt>
<dd>
(Required, string)
The target URL of your Azure AI Studio model deployment.
This can be found on the overview page for your deployment in the management section of your <a href="https://ai.azure.com/" class="ulink" target="_top">Azure AI Studio</a> account.
</dd>
<dt>
<span class="term">
<code class="literal">provider</code>
</span>
</dt>
<dd>
<p>
(Required, string)
The model provider for your deployment.
Note that some providers may support only certain task types.
Supported providers include:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">cohere</code> - available for <code class="literal">text_embedding</code> and <code class="literal">completion</code> task types
</li>
<li class="listitem">
<code class="literal">databricks</code> - available for <code class="literal">completion</code> task type only
</li>
<li class="listitem">
<code class="literal">meta</code> - available for <code class="literal">completion</code> task type only
</li>
<li class="listitem">
<code class="literal">microsoft_phi</code> - available for <code class="literal">completion</code> task type only
</li>
<li class="listitem">
<code class="literal">mistral</code> - available for <code class="literal">completion</code> task type only
</li>
<li class="listitem">
<code class="literal">openai</code> - available for <code class="literal">text_embedding</code> and <code class="literal">completion</code> task types
</li>
</ul>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">endpoint_type</code>
</span>
</dt>
<dd>
(Required, string)
One of <code class="literal">token</code> or <code class="literal">realtime</code>.
Specifies the type of endpoint that is used in your model deployment.
There are <a href="https://learn.microsoft.com/en-us/azure/ai-studio/concepts/deployments-overview#billing-for-deploying-and-inferencing-llms-in-azure-ai-studio" class="ulink" target="_top">two endpoint types available</a> for deployment through Azure AI Studio.
"Pay as you go" endpoints are billed per token.
For these, you must specify <code class="literal">token</code> for your <code class="literal">endpoint_type</code>.
For "real-time" endpoints which are billed per hour of usage, specify <code class="literal">realtime</code>.
</dd>
<dt>
<span class="term">
<code class="literal">rate_limit</code>
</span>
</dt>
<dd>
(Optional, object)
By default, the <code class="literal">azureaistudio</code> service sets the number of requests allowed per minute to <code class="literal">240</code>.
This helps to minimize the number of rate limit errors returned from Azure AI Studio.
To modify this, set the <code class="literal">requests_per_minute</code> setting of this object in your service settings:
</dd>
</dl>
</div>
<pre class="screen">"rate_limit": {
    "requests_per_minute": &lt;&lt;number_of_requests&gt;&gt;
}</pre>
</div>
</details>
<details>
<summary class="title"><code class="literal">service_settings</code> for the <code class="literal">azureopenai</code> service</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">api_key</code> or <code class="literal">entra_id</code>
</span>
</dt>
<dd>
(Required, string)
You must provide <em>either</em> an API key or an Entra ID.
If you do not provide either, or provide both, you will receive an error when trying to create your model.
See the <a href="https://learn.microsoft.com/en-us/azure/ai-services/openai/reference#authentication" class="ulink" target="_top">Azure OpenAI Authentication documentation</a> for more details on these authentication types.
</dd>
</dl>
</div>
<div class="important admon">
<div class="icon"></div>
<div class="admon_content">
<p>You need to provide the API key or Entra ID only once, during the inference model creation.
The <a class="xref" href="get-inference-api.html" title="Get inference API">Get inference API</a> does not retrieve your authentication credentials.
After creating the inference model, you cannot change the associated API key or Entra ID.
If you want to use a different API key or Entra ID, delete the inference model and recreate it with the same name and the updated API key.
You <em>must</em> have either an <code class="literal">api_key</code> or an <code class="literal">entra_id</code> defined.
If neither are present, an error will occur.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">resource_name</code>
</span>
</dt>
<dd>
(Required, string)
The name of your Azure OpenAI resource.
You can find this from the <a href="https://portal.azure.com/#view/HubsExtension/BrowseAll" class="ulink" target="_top">list of resources</a> in the Azure Portal for your subscription.
</dd>
<dt>
<span class="term">
<code class="literal">deployment_id</code>
</span>
</dt>
<dd>
(Required, string)
The deployment name of your deployed models.
Your Azure OpenAI deployments can be found though the <a href="https://oai.azure.com/" class="ulink" target="_top">Azure OpenAI Studio</a> portal that is linked to your subscription.
</dd>
<dt>
<span class="term">
<code class="literal">api_version</code>
</span>
</dt>
<dd>
(Required, string)
The Azure API version ID to use.
We recommend using the <a href="https://learn.microsoft.com/en-us/azure/ai-services/openai/reference#embeddings" class="ulink" target="_top">latest supported non-preview version</a>.
</dd>
</dl>
</div>
</div>
</details>
<details>
<summary class="title"><code class="literal">service_settings</code> for the <code class="literal">cohere</code> service</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">api_key</code>
</span>
</dt>
<dd>
(Required, string)
A valid API key of your Cohere account. You can find your Cohere API keys or you
can create a new one
<a href="https://dashboard.cohere.com/api-keys" class="ulink" target="_top">on the API keys settings page</a>.
</dd>
</dl>
</div>
<div class="important admon">
<div class="icon"></div>
<div class="admon_content">
<p>You need to provide the API key only once, during the inference model
creation. The <a class="xref" href="get-inference-api.html" title="Get inference API">Get inference API</a> does not retrieve your API key. After
creating the inference model, you cannot change the associated API key. If you
want to use a different API key, delete the inference model and recreate it with
the same name and the updated API key.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">embedding_type</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Only for <code class="literal">text_embedding</code>. Specifies the types of embeddings you want to get
back. Defaults to <code class="literal">float</code>.
Valid values are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">byte</code>: use it for signed int8 embeddings (this is a synonym of <code class="literal">int8</code>).
</li>
<li class="listitem">
<code class="literal">float</code>: use it for the default float embeddings.
</li>
<li class="listitem">
<code class="literal">int8</code>: use it for signed int8 embeddings.
</li>
</ul>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">model_id</code>
</span>
</dt>
<dd>
(Optional, string)
The name of the model to use for the inference task.
To review the available <code class="literal">rerank</code> models, refer to the
<a href="https://docs.cohere.com/reference/rerank-1" class="ulink" target="_top">Cohere docs</a>.
</dd>
</dl>
</div>
<p>To review the available <code class="literal">text_embedding</code> models, refer to the
<a href="https://docs.cohere.com/reference/embed" class="ulink" target="_top">Cohere docs</a>. The default value for
<code class="literal">text_embedding</code> is <code class="literal">embed-english-v2.0</code>.</p>
</div>
</details>
<details>
<summary class="title"><code class="literal">service_settings</code> for the <code class="literal">elasticsearch</code> service</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">model_id</code>
</span>
</dt>
<dd>
(Required, string)
The name of the model to use for the inference task. It can be the
ID of either a built-in model (for example, <code class="literal">.multilingual-e5-small</code> for E5) or
a text embedding model already
<a href="/guide/en/machine-learning/master/ml-nlp-import-model.html#ml-nlp-import-script" class="ulink" target="_top">uploaded through Eland</a>.
</dd>
<dt>
<span class="term">
<code class="literal">num_allocations</code>
</span>
</dt>
<dd>
(Required, integer)
The number of model allocations to create. <code class="literal">num_allocations</code> must not exceed the
number of available processors per node divided by the <code class="literal">num_threads</code>.
</dd>
<dt>
<span class="term">
<code class="literal">num_threads</code>
</span>
</dt>
<dd>
(Required, integer)
The number of threads to use by each model allocation. <code class="literal">num_threads</code> must not
exceed the number of available processors per node divided by the number of
allocations. Must be a power of 2. Max allowed value is 32.
</dd>
</dl>
</div>
</div>
</details>
<details>
<summary class="title"><code class="literal">service_settings</code> for the <code class="literal">elser</code> service</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">num_allocations</code>
</span>
</dt>
<dd>
(Required, integer)
The number of model allocations to create. <code class="literal">num_allocations</code> must not exceed the
number of available processors per node divided by the <code class="literal">num_threads</code>.
</dd>
<dt>
<span class="term">
<code class="literal">num_threads</code>
</span>
</dt>
<dd>
(Required, integer)
The number of threads to use by each model allocation. <code class="literal">num_threads</code> must not
exceed the number of available processors per node divided by the number of
allocations. Must be a power of 2. Max allowed value is 32.
</dd>
</dl>
</div>
</div>
</details>
<details>
<summary class="title"><code class="literal">service_settings</code> for the <code class="literal">googleiastudio</code> service</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">api_key</code>
</span>
</dt>
<dd>
(Required, string)
A valid API key for the Google Gemini API.
</dd>
<dt>
<span class="term">
<code class="literal">model_id</code>
</span>
</dt>
<dd>
(Required, string)
The name of the model to use for the inference task.
You can find the supported models at <a href="https://ai.google.dev/gemini-api/docs/models/gemini" class="ulink" target="_top">Gemini API models</a>.
</dd>
<dt>
<span class="term">
<code class="literal">rate_limit</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
By default, the <code class="literal">googleaistudio</code> service sets the number of requests allowed per minute to <code class="literal">360</code>.
This helps to minimize the number of rate limit errors returned from Google AI Studio.
To modify this, set the <code class="literal">requests_per_minute</code> setting of this object in your service settings:
</p>
<pre class="screen">"rate_limit": {
    "requests_per_minute": &lt;&lt;number_of_requests&gt;&gt;
}</pre>
</dd>
</dl>
</div>
</div>
</details>
<details>
<summary class="title"><code class="literal">service_settings</code> for the <code class="literal">hugging_face</code> service</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">api_key</code>
</span>
</dt>
<dd>
(Required, string)
A valid access token of your Hugging Face account. You can find your Hugging
Face access tokens or you can create a new one
<a href="https://huggingface.co/settings/tokens" class="ulink" target="_top">on the settings page</a>.
</dd>
</dl>
</div>
<div class="important admon">
<div class="icon"></div>
<div class="admon_content">
<p>You need to provide the API key only once, during the inference model
creation. The <a class="xref" href="get-inference-api.html" title="Get inference API">Get inference API</a> does not retrieve your API key. After
creating the inference model, you cannot change the associated API key. If you
want to use a different API key, delete the inference model and recreate it with
the same name and the updated API key.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">url</code>
</span>
</dt>
<dd>
(Required, string)
The URL endpoint to use for the requests.
</dd>
</dl>
</div>
</div>
</details>
<details>
<summary class="title"><code class="literal">service_settings</code> for the <code class="literal">openai</code> service</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">api_key</code>
</span>
</dt>
<dd>
(Required, string)
A valid API key of your OpenAI account. You can find your OpenAI API keys in
your OpenAI account under the
<a href="https://platform.openai.com/api-keys" class="ulink" target="_top">API keys section</a>.
</dd>
</dl>
</div>
<div class="important admon">
<div class="icon"></div>
<div class="admon_content">
<p>You need to provide the API key only once, during the inference model
creation. The <a class="xref" href="get-inference-api.html" title="Get inference API">Get inference API</a> does not retrieve your API key. After
creating the inference model, you cannot change the associated API key. If you
want to use a different API key, delete the inference model and recreate it with
the same name and the updated API key.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">model_id</code>
</span>
</dt>
<dd>
(Required, string)
The name of the model to use for the inference task. Refer to the
<a href="https://platform.openai.com/docs/guides/embeddings/what-are-embeddings" class="ulink" target="_top">OpenAI documentation</a>
for the list of available text embedding models.
</dd>
<dt>
<span class="term">
<code class="literal">organization_id</code>
</span>
</dt>
<dd>
(Optional, string)
The unique identifier of your organization. You can find the Organization ID in
your OpenAI account under
<a href="https://platform.openai.com/account/organization" class="ulink" target="_top"><span class="strong strong"><strong>Settings</strong></span> &gt; <span class="strong strong"><strong>Organizations</strong></span></a>.
</dd>
<dt>
<span class="term">
<code class="literal">url</code>
</span>
</dt>
<dd>
(Optional, string)
The URL endpoint to use for the requests. Can be changed for testing purposes.
Defaults to <code class="literal">https://api.openai.com/v1/embeddings</code>.
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">task_settings</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Settings to configure the inference task. These settings are specific to the
<code class="literal">&lt;task_type&gt;</code> you specified.
</p>
<details>
<summary class="title"><code class="literal">task_settings</code> for the <code class="literal">completion</code> task type</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_sample</code>
</span>
</dt>
<dd>
(Optional, float)
For the <code class="literal">azureaistudio</code> service only.
Instructs the inference process to perform sampling or not.
Has not affect unless <code class="literal">temperature</code> or <code class="literal">top_p</code> is specified.
</dd>
<dt>
<span class="term">
<code class="literal">max_new_tokens</code>
</span>
</dt>
<dd>
(Optional, integer)
For the <code class="literal">azureaistudio</code> service only.
Provides a hint for the maximum number of output tokens to be generated.
Defaults to 64.
</dd>
<dt>
<span class="term">
<code class="literal">user</code>
</span>
</dt>
<dd>
(Optional, string)
For <code class="literal">openai</code> service only. Specifies the user issuing the request, which can be
used for abuse detection.
</dd>
<dt>
<span class="term">
<code class="literal">temperature</code>
</span>
</dt>
<dd>
(Optional, float)
For the <code class="literal">azureaistudio</code> service only.
A number in the range of 0.0 to 2.0 that specifies the sampling temperature to use that controls the apparent creativity of generated completions.
Should not be used if <code class="literal">top_p</code> is specified.
</dd>
<dt>
<span class="term">
<code class="literal">top_p</code>
</span>
</dt>
<dd>
(Optional, float)
For the <code class="literal">azureaistudio</code> service only.
A number in the range of 0.0 to 2.0 that is an alternative value to temperature that causes the model to consider the results of the tokens with nucleus sampling probability.
Should not be used if <code class="literal">temperature</code> is specified.
</dd>
</dl>
</div>
</div>
</details>
<details>
<summary class="title"><code class="literal">task_settings</code> for the <code class="literal">rerank</code> task type</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">return_documents</code>
</span>
</dt>
<dd>
(Optional, boolean)
For <code class="literal">cohere</code> service only. Specify whether to return doc text within the
results.
</dd>
<dt>
<span class="term">
<code class="literal">top_n</code>
</span>
</dt>
<dd>
(Optional, integer)
The number of most relevant documents to return, defaults to the number of the
documents.
</dd>
</dl>
</div>
</div>
</details>
<details>
<summary class="title"><code class="literal">task_settings</code> for the <code class="literal">text_embedding</code> task type</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">input_type</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
For <code class="literal">cohere</code> service only. Specifies the type of input passed to the model.
Valid values are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">classification</code>: use it for embeddings passed through a text classifier.
</li>
<li class="listitem">
<code class="literal">clusterning</code>: use it for the embeddings run through a clustering algorithm.
</li>
<li class="listitem">
<code class="literal">ingest</code>: use it for storing document embeddings in a vector database.
</li>
<li class="listitem">
<code class="literal">search</code>: use it for storing embeddings of search queries run against a
vector database to find relevant documents.
</li>
</ul>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
For <code class="literal">cohere</code> service only. Specifies how the API handles inputs longer than the
maximum token length. Defaults to <code class="literal">END</code>. Valid values are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">NONE</code>: when the input exceeds the maximum input token length an error is
returned.
</li>
<li class="listitem">
<code class="literal">START</code>: when the input exceeds the maximum input token length the start of
the input is discarded.
</li>
<li class="listitem">
<code class="literal">END</code>: when the input exceeds the maximum input token length the end of
the input is discarded.
</li>
</ul>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">user</code>
</span>
</dt>
<dd>
(optional, string)
For <code class="literal">openai</code>, <code class="literal">azureopenai</code> and <code class="literal">azureaistudio</code> services only. Specifies the user issuing the
request, which can be used for abuse detection.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
<h4><a id="put-inference-api-example"></a>Examples<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/inference/put-inference.asciidoc">edit</a></h4>
<p>This section contains example API calls for every service type.</p>
<h5><a id="inference-example-azureaistudio"></a>Azure AI Studio service<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/inference/put-inference.asciidoc">edit</a></h5>
<p>The following example shows how to create an inference endpoint called
<code class="literal">azure_ai_studio_embeddings</code> to perform a <code class="literal">text_embedding</code> task type.
Note that we do not specify a model here, as it is defined already via our Azure AI Studio deployment.</p>
<p>The list of embeddings models that you can choose from in your deployment can be found in the <a href="https://ai.azure.com/explore/models?selectedTask=embeddings" class="ulink" target="_top">Azure AI Studio model explorer</a>.</p>
<a id="1dadb7efe27b6c0c231eb6535e413bd9"></a>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">PUT _inference/text_embedding/azure_ai_studio_embeddings
{
    "service": "azureaistudio",
    "service_settings": {
        "api_key": "&lt;api_key&gt;",
        "target": "&lt;target_uri&gt;",
        "provider": "&lt;model_provider&gt;",
        "endpoint_type": "&lt;endpoint_type&gt;"
    }
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/2805.console"></div>
<p>The next example shows how to create an inference endpoint called
<code class="literal">azure_ai_studio_completion</code> to perform a <code class="literal">completion</code> task type.</p>
<a id="6ddd4e657efbf45def430a6419825796"></a>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">PUT _inference/completion/azure_ai_studio_completion
{
    "service": "azureaistudio",
    "service_settings": {
        "api_key": "&lt;api_key&gt;",
        "target": "&lt;target_uri&gt;",
        "provider": "&lt;model_provider&gt;",
        "endpoint_type": "&lt;endpoint_type&gt;"
    }
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/2806.console"></div>
<p>The list of chat completion models that you can choose from in your deployment can be found in the <a href="https://ai.azure.com/explore/models?selectedTask=chat-completion" class="ulink" target="_top">Azure AI Studio model explorer</a>.</p>
<h5><a id="inference-example-azureopenai"></a>Azure OpenAI service<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/inference/put-inference.asciidoc">edit</a></h5>
<p>The following example shows how to create an inference endpoint called
<code class="literal">azure_openai_embeddings</code> to perform a <code class="literal">text_embedding</code> task type.
Note that we do not specify a model here, as it is defined already via our Azure OpenAI deployment.</p>
<p>The list of embeddings models that you can choose from in your deployment can be found in the <a href="https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models#embeddings" class="ulink" target="_top">Azure models documentation</a>.</p>
<div class="pre_wrapper lang-python alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-python alternative">resp = client.inference.put_model(
    task_type="text_embedding",
    inference_id="azure_openai_embeddings",
    body={
        "service": "azureopenai",
        "service_settings": {
            "api_key": "&lt;api_key&gt;",
            "resource_name": "&lt;resource_name&gt;",
            "deployment_id": "&lt;deployment_id&gt;",
            "api_version": "2024-02-01",
        },
    },
)
print(resp)</pre>
</div>
<a id="77b90f6787195767b6da60d8532714b4"></a>
<div class="pre_wrapper lang-console default has-python">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console default has-python">PUT _inference/text_embedding/azure_openai_embeddings
{
    "service": "azureopenai",
    "service_settings": {
        "api_key": "&lt;api_key&gt;",
        "resource_name": "&lt;resource_name&gt;",
        "deployment_id": "&lt;deployment_id&gt;",
        "api_version": "2024-02-01"
    }
}</pre>
</div>
<div class="console_widget has-python" data-snippet="snippets/2807.console"></div>
<p>The next example shows how to create an inference endpoint called
<code class="literal">azure_openai_completion</code> to perform a <code class="literal">completion</code> task type.</p>
<a id="f57ce7de0946e9416ddb9150e95f4b74"></a>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">PUT _inference/completion/azure_openai_completion
{
    "service": "azureopenai",
    "service_settings": {
        "api_key": "&lt;api_key&gt;",
        "resource_name": "&lt;resource_name&gt;",
        "deployment_id": "&lt;deployment_id&gt;",
        "api_version": "2024-02-01"
    }
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/2808.console"></div>
<p>The list of chat completion models that you can choose from in your Azure OpenAI deployment can be found at the following places:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<a href="https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-models" class="ulink" target="_top">GPT-4 and GPT-4 Turbo models</a>
</li>
<li class="listitem">
<a href="https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models#gpt-35" class="ulink" target="_top">GPT-3.5</a>
</li>
</ul>
</div>
<h5><a id="inference-example-cohere"></a>Cohere service<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/inference/put-inference.asciidoc">edit</a></h5>
<p>The following example shows how to create an inference endpoint called
<code class="literal">cohere-embeddings</code> to perform a <code class="literal">text_embedding</code> task type.</p>
<div class="pre_wrapper lang-python alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-python alternative">resp = client.inference.put_model(
    task_type="text_embedding",
    inference_id="cohere-embeddings",
    body={
        "service": "cohere",
        "service_settings": {
            "api_key": "&lt;api_key&gt;",
            "model_id": "embed-english-light-v3.0",
            "embedding_type": "byte",
        },
    },
)
print(resp)</pre>
</div>
<a id="9a203aae3e1412d919546276fb52a5ca"></a>
<div class="pre_wrapper lang-console default has-python">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console default has-python">PUT _inference/text_embedding/cohere-embeddings
{
    "service": "cohere",
    "service_settings": {
        "api_key": "&lt;api_key&gt;",
        "model_id": "embed-english-light-v3.0",
        "embedding_type": "byte"
    }
}</pre>
</div>
<div class="console_widget has-python" data-snippet="snippets/2809.console"></div>
<p>The following example shows how to create an inference endpoint called
<code class="literal">cohere-rerank</code> to perform a <code class="literal">rerank</code> task type.</p>
<div class="pre_wrapper lang-python alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-python alternative">resp = client.inference.put_model(
    task_type="rerank",
    inference_id="cohere-rerank",
    body={
        "service": "cohere",
        "service_settings": {
            "api_key": "&lt;API-KEY&gt;",
            "model_id": "rerank-english-v3.0",
        },
        "task_settings": {"top_n": 10, "return_documents": True},
    },
)
print(resp)</pre>
</div>
<a id="8619bd17bbfe33490b1f277007f654db"></a>
<div class="pre_wrapper lang-console default has-python">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console default has-python">PUT _inference/rerank/cohere-rerank
{
    "service": "cohere",
    "service_settings": {
        "api_key": "&lt;API-KEY&gt;",
        "model_id": "rerank-english-v3.0"
    },
    "task_settings": {
        "top_n": 10,
        "return_documents": true
    }
}</pre>
</div>
<div class="console_widget has-python" data-snippet="snippets/2810.console"></div>
<p>For more examples, also review the
<a href="https://docs.cohere.com/docs/elasticsearch-and-cohere#rerank-search-results-with-cohere-and-elasticsearch" class="ulink" target="_top">Cohere documentation</a>.</p>
<h5><a id="inference-example-e5"></a>E5 via the <code class="literal">elasticsearch</code> service<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/inference/put-inference.asciidoc">edit</a></h5>
<p>The following example shows how to create an inference endpoint called
<code class="literal">my-e5-model</code> to perform a <code class="literal">text_embedding</code> task type.</p>
<div class="pre_wrapper lang-python alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-python alternative">resp = client.inference.put_model(
    task_type="text_embedding",
    inference_id="my-e5-model",
    body={
        "service": "elasticsearch",
        "service_settings": {
            "num_allocations": 1,
            "num_threads": 1,
            "model_id": ".multilingual-e5-small",
        },
    },
)
print(resp)</pre>
</div>
<a id="00fea15cbca83be9d5f1a024ff2ec708"></a>
<div class="pre_wrapper lang-console default has-python">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console default has-python">PUT _inference/text_embedding/my-e5-model
{
  "service": "elasticsearch",
  "service_settings": {
    "num_allocations": 1,
    "num_threads": 1,
    "model_id": ".multilingual-e5-small" <a id="CO780-1"></a><i class="conum" data-value="1"></i>
  }
}</pre>
</div>
<div class="console_widget has-python" data-snippet="snippets/2811.console"></div>
<div class="calloutlist default has-python lang-console">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO780-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>The <code class="literal">model_id</code> must be the ID of one of the built-in E5 models. Valid values
are <code class="literal">.multilingual-e5-small</code> and <code class="literal">.multilingual-e5-small_linux-x86_64</code>. For
further details, refer to the <a href="/guide/en/machine-learning/master/ml-nlp-e5.html" class="ulink" target="_top">E5 model documentation</a>.</p>
</td>
</tr>
</table>
</div>
<h5><a id="inference-example-elser"></a>ELSER service<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/inference/put-inference.asciidoc">edit</a></h5>
<p>The following example shows how to create an inference endpoint called
<code class="literal">my-elser-model</code> to perform a <code class="literal">sparse_embedding</code> task type.
Refer to the <a href="/guide/en/machine-learning/master/ml-nlp-elser.html" class="ulink" target="_top">ELSER model documentation</a> for more
info.</p>
<div class="pre_wrapper lang-python alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-python alternative">resp = client.inference.put_model(
    task_type="sparse_embedding",
    inference_id="my-elser-model",
    body={
        "service": "elser",
        "service_settings": {"num_allocations": 1, "num_threads": 1},
    },
)
print(resp)</pre>
</div>
<a id="cedb56a71cc743d80263ce352bb21720"></a>
<div class="pre_wrapper lang-console default has-python">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console default has-python">PUT _inference/sparse_embedding/my-elser-model
{
  "service": "elser",
  "service_settings": {
    "num_allocations": 1,
    "num_threads": 1
  }
}</pre>
</div>
<div class="console_widget has-python" data-snippet="snippets/2812.console"></div>
<p>Example response:</p>
<a id="85eb7282ac0193478132d3de11f3ffec"></a>
<div class="pre_wrapper lang-console-result">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console-result">{
  "inference_id": "my-elser-model",
  "task_type": "sparse_embedding",
  "service": "elser",
  "service_settings": {
    "num_allocations": 1,
    "num_threads": 1
  },
  "task_settings": {}
}</pre>
</div>
<h5><a id="inference-example-googleaistudio"></a>Google AI Studio service<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/inference/put-inference.asciidoc">edit</a></h5>
<p>The following example shows how to create an inference endpoint called
<code class="literal">google_ai_studio_completion</code> to perform a <code class="literal">completion</code> task type.</p>
<a id="e9fc47015922d51c2b05e502ce9c622e"></a>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">PUT _inference/completion/google_ai_studio_completion
{
    "service": "googleaistudio",
    "service_settings": {
        "api_key": "&lt;api_key&gt;",
        "model_id": "&lt;model_id&gt;"
    }
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/2813.console"></div>
<h5><a id="inference-example-hugging-face"></a>Hugging Face service<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/inference/put-inference.asciidoc">edit</a></h5>
<p>The following example shows how to create an inference endpoint called
<code class="literal">hugging-face-embeddings</code> to perform a <code class="literal">text_embedding</code> task type.</p>
<div class="pre_wrapper lang-python alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-python alternative">resp = client.inference.put_model(
    task_type="text_embedding",
    inference_id="hugging-face-embeddings",
    body={
        "service": "hugging_face",
        "service_settings": {
            "api_key": "&lt;access_token&gt;",
            "url": "&lt;url_endpoint&gt;",
        },
    },
)
print(resp)</pre>
</div>
<a id="eee6110831c08b9c1b3f56b24656e95b"></a>
<div class="pre_wrapper lang-console default has-python">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console default has-python">PUT _inference/text_embedding/hugging-face-embeddings
{
  "service": "hugging_face",
  "service_settings": {
    "api_key": "&lt;access_token&gt;", <a id="CO781-1"></a><i class="conum" data-value="1"></i>
    "url": "&lt;url_endpoint&gt;" <a id="CO781-2"></a><i class="conum" data-value="2"></i>
  }
}</pre>
</div>
<div class="console_widget has-python" data-snippet="snippets/2814.console"></div>
<div class="calloutlist default has-python lang-console">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO781-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>A valid Hugging Face access token. You can find on the
<a href="https://huggingface.co/settings/tokens" class="ulink" target="_top">settings page of your account</a>.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO781-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p>The inference endpoint URL you created on Hugging Face.</p>
</td>
</tr>
</table>
</div>
<p>Create a new inference endpoint on
<a href="https://ui.endpoints.huggingface.co/" class="ulink" target="_top">the Hugging Face endpoint page</a> to get an
endpoint URL. Select the model you want to use on the new endpoint creation page
- for example <code class="literal">intfloat/e5-small-v2</code> - then select the <code class="literal">Sentence Embeddings</code>
task under the Advanced configuration section. Create the endpoint. Copy the URL
after the endpoint initialization has been finished.</p>
<p><a id="inference-example-hugging-face-supported-models"></a>The list of recommended models for the Hugging Face service:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<a href="https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2" class="ulink" target="_top">all-MiniLM-L6-v2</a>
</li>
<li class="listitem">
<a href="https://huggingface.co/sentence-transformers/all-MiniLM-L12-v2" class="ulink" target="_top">all-MiniLM-L12-v2</a>
</li>
<li class="listitem">
<a href="https://huggingface.co/sentence-transformers/all-mpnet-base-v2" class="ulink" target="_top">all-mpnet-base-v2</a>
</li>
<li class="listitem">
<a href="https://huggingface.co/intfloat/e5-base-v2" class="ulink" target="_top">e5-base-v2</a>
</li>
<li class="listitem">
<a href="https://huggingface.co/intfloat/e5-small-v2" class="ulink" target="_top">e5-small-v2</a>
</li>
<li class="listitem">
<a href="https://huggingface.co/intfloat/multilingual-e5-base" class="ulink" target="_top">multilingual-e5-base</a>
</li>
<li class="listitem">
<a href="https://huggingface.co/intfloat/multilingual-e5-small" class="ulink" target="_top">multilingual-e5-small</a>
</li>
</ul>
</div>
<h5><a id="inference-example-eland"></a>Models uploaded by Eland via the elasticsearch service<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/inference/put-inference.asciidoc">edit</a></h5>
<p>The following example shows how to create an inference endpoint called
<code class="literal">my-msmarco-minilm-model</code> to perform a <code class="literal">text_embedding</code> task type.</p>
<div class="pre_wrapper lang-python alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-python alternative">resp = client.inference.put_model(
    task_type="text_embedding",
    inference_id="my-msmarco-minilm-model",
    body={
        "service": "elasticsearch",
        "service_settings": {
            "num_allocations": 1,
            "num_threads": 1,
            "model_id": "msmarco-MiniLM-L12-cos-v5",
        },
    },
)
print(resp)</pre>
</div>
<a id="10c3fe2265bb34964bd1005f9da66773"></a>
<div class="pre_wrapper lang-console default has-python">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console default has-python">PUT _inference/text_embedding/my-msmarco-minilm-model
{
  "service": "elasticsearch",
  "service_settings": {
    "num_allocations": 1,
    "num_threads": 1,
    "model_id": "msmarco-MiniLM-L12-cos-v5" <a id="CO782-1"></a><i class="conum" data-value="1"></i>
  }
}</pre>
</div>
<div class="console_widget has-python" data-snippet="snippets/2815.console"></div>
<div class="calloutlist default has-python lang-console">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO782-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>The <code class="literal">model_id</code> must be the ID of a text embedding model which has already
been
<a href="/guide/en/machine-learning/master/ml-nlp-import-model.html#ml-nlp-import-script" class="ulink" target="_top">uploaded through Eland</a>.</p>
</td>
</tr>
</table>
</div>
<h5><a id="inference-example-openai"></a>OpenAI service<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/inference/put-inference.asciidoc">edit</a></h5>
<p>The following example shows how to create an inference endpoint called
<code class="literal">openai-embeddings</code> to perform a <code class="literal">text_embedding</code> task type.</p>
<div class="pre_wrapper lang-python alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-python alternative">resp = client.inference.put_model(
    task_type="text_embedding",
    inference_id="openai-embeddings",
    body={
        "service": "openai",
        "service_settings": {
            "api_key": "&lt;api_key&gt;",
            "model_id": "text-embedding-ada-002",
        },
    },
)
print(resp)</pre>
</div>
<a id="9f16fca9813304e398ee052aa857dbcd"></a>
<div class="pre_wrapper lang-console default has-python">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console default has-python">PUT _inference/text_embedding/openai-embeddings
{
    "service": "openai",
    "service_settings": {
        "api_key": "&lt;api_key&gt;",
        "model_id": "text-embedding-ada-002"
    }
}</pre>
</div>
<div class="console_widget has-python" data-snippet="snippets/2816.console"></div>
<p>The next example shows how to create an inference endpoint called
<code class="literal">openai-completion</code> to perform a <code class="literal">completion</code> task type.</p>
<div class="pre_wrapper lang-python alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-python alternative">resp = client.inference.put_model(
    task_type="completion",
    inference_id="openai-completion",
    body={
        "service": "openai",
        "service_settings": {
            "api_key": "&lt;api_key&gt;",
            "model_id": "gpt-3.5-turbo",
        },
    },
)
print(resp)</pre>
</div>
<a id="59d736a4d064ed2013c7ead8e32e0998"></a>
<div class="pre_wrapper lang-console default has-python">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console default has-python">PUT _inference/completion/openai-completion
{
    "service": "openai",
    "service_settings": {
        "api_key": "&lt;api_key&gt;",
        "model_id": "gpt-3.5-turbo"
    }
}</pre>
</div>
<div class="console_widget has-python" data-snippet="snippets/2817.console"></div>
</div>
<div class="navfooter">
<span class="prev">
<a href="post-inference-api.html">« Perform inference API</a>
</span>
<span class="next">
<a href="info-api.html">Info API »</a>
</span>
</div>
</div>
</body>
</html>
