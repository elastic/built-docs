<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="keywords" content="Elasticsearch, high watermark, low watermark, full disk">
<title>Red or yellow cluster health status | Elasticsearch Guide [master] | Elastic</title>
<meta class="elastic" name="content" content="Red or yellow cluster health status | Elasticsearch Guide [master]">

<link rel="home" href="index.html" title="Elasticsearch Guide [master]"/>
<link rel="up" href="fix-common-cluster-issues.html" title="Fix common cluster issues"/>
<link rel="prev" href="high-jvm-memory-pressure.html" title="High JVM memory pressure"/>
<link rel="next" href="rejected-requests.html" title="Rejected requests"/>
<meta class="elastic" name="product_version" content="master"/>
<meta class="elastic" name="product_name" content="Elasticsearch"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/Elasticsearch/Reference/master"/>
<meta name="DC.subject" content="Elasticsearch"/>
<meta name="DC.identifier" content="master"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body>
<div class="page_header">
This documentation contains work-in-progress information for future Elastic Stack and Cloud releases. Use the version selector to view supported release docs. It also contains some Elastic Cloud serverless information. Check out our <a href="https://www.elastic.co/docs/current/serverless">serverless docs</a> for more details.
</div>
<div class="navheader">
<span class="prev">
<a href="high-jvm-memory-pressure.html">« High JVM memory pressure</a>
</span>
<span class="next">
<a href="rejected-requests.html">Rejected requests »</a>
</span>
</div>
<div class="book" lang="en">
<div class="titlepage">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Elasticsearch Guide [master]</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="troubleshooting.html">Troubleshooting</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="fix-common-cluster-issues.html">Fix common cluster issues</a></span>
</div>
<div>
<div><h1 class="title"><a id="id-1"></a>Red or yellow cluster health status</h1><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/troubleshooting/common-issues/red-yellow-cluster-status.asciidoc">edit</a></div>
</div>
<!--EXTRA-->
</div>
<div id="content">
<div class="section">
<div class="titlepage"><div><div>
<h2 class="title"><a id="red-yellow-cluster-status"></a>Red or yellow cluster health status<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/troubleshooting/common-issues/red-yellow-cluster-status.asciidoc">edit</a></h2>
</div></div></div>
<p>A red or yellow cluster health status indicates one or more shards are not assigned to
a node.</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<span class="strong strong"><strong>Red health status</strong></span>: The cluster has some unassigned primary shards, which
means that some operations such as searches and indexing may fail.
</li>
<li class="listitem">
<span class="strong strong"><strong>Yellow health status</strong></span>: The cluster has no unassigned primary shards but some
unassigned replica shards. This increases your risk of data loss and can degrade
cluster performance.
</li>
</ul>
</div>
<p>When your cluster has a red or yellow health status, it will continue to process
searches and indexing where possible, but may delay certain management and
cleanup activities until the cluster returns to green health status. For instance,
some <a class="xref" href="index-lifecycle-management.html" title="ILM: Manage the index lifecycle">ILM</a> actions require the index on which they
operate to have a green health status.</p>
<p>In many cases, your cluster will recover to green health status automatically.
If the cluster doesn&#8217;t automatically recover, then you must <a class="xref" href="red-yellow-cluster-status.html#fix-red-yellow-cluster-status" title="Fix a red or yellow cluster status">manually address</a>
the remaining problems so management and cleanup activities can proceed.</p>
<h4><a id="diagnose-cluster-status"></a>Diagnose your cluster status<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/troubleshooting/common-issues/red-yellow-cluster-status.asciidoc">edit</a></h4>
<p><span class="strong strong"><strong>Check your cluster status</strong></span></p>
<p>Use the <a class="xref" href="cluster-health.html" title="Cluster health API">cluster health API</a>.</p>
<div class="pre_wrapper lang-ruby alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-ruby alternative">response = client.cluster.health(
  filter_path: 'status,*_shards'
)
puts response</pre>
</div>
<div class="pre_wrapper lang-js alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js alternative">const response = await client.cluster.health({
  filter_path: "status,*_shards",
});
console.log(response);</pre>
</div>
<a id="b7df0848b2dc3093f931976db5b8cfff"></a>
<div class="pre_wrapper lang-console default has-ruby has-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console default has-ruby has-js">GET _cluster/health?filter_path=status,*_shards</pre>
</div>
<div class="console_widget has-ruby has-js" data-snippet="snippets/2154.console"></div>
<p>A healthy cluster has a green <code class="literal">status</code> and zero <code class="literal">unassigned_shards</code>. A yellow
status means only replicas are unassigned. A red status means one or
more primary shards are unassigned.</p>
<p><span class="strong strong"><strong>View unassigned shards</strong></span></p>
<p>To view unassigned shards, use the <a class="xref" href="cat-shards.html" title="cat shards API">cat shards API</a>.</p>
<div class="pre_wrapper lang-ruby alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-ruby alternative">response = client.cat.shards(
  v: true,
  h: 'index,shard,prirep,state,node,unassigned.reason',
  s: 'state'
)
puts response</pre>
</div>
<div class="pre_wrapper lang-js alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js alternative">const response = await client.cat.shards({
  v: "true",
  h: "index,shard,prirep,state,node,unassigned.reason",
  s: "state",
});
console.log(response);</pre>
</div>
<a id="6705eca2095ade294548cfb25bf2dd86"></a>
<div class="pre_wrapper lang-console default has-ruby has-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console default has-ruby has-js">GET _cat/shards?v=true&amp;h=index,shard,prirep,state,node,unassigned.reason&amp;s=state</pre>
</div>
<div class="console_widget has-ruby has-js" data-snippet="snippets/2155.console"></div>
<p>Unassigned shards have a <code class="literal">state</code> of <code class="literal">UNASSIGNED</code>. The <code class="literal">prirep</code> value is <code class="literal">p</code> for
primary shards and <code class="literal">r</code> for replicas.</p>
<p>To understand why an unassigned shard is not being assigned and what action
you must take to allow Elasticsearch to assign it, use the
<a class="xref" href="cluster-allocation-explain.html" title="Cluster allocation explain API">cluster allocation explanation API</a>.</p>
<div class="pre_wrapper lang-ruby alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-ruby alternative">response = client.cluster.allocation_explain(
  filter_path: 'index,node_allocation_decisions.node_name,node_allocation_decisions.deciders.*',
  body: {
    index: 'my-index',
    shard: 0,
    primary: false
  }
)
puts response</pre>
</div>
<div class="pre_wrapper lang-js alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js alternative">const response = await client.cluster.allocationExplain({
  filter_path:
    "index,node_allocation_decisions.node_name,node_allocation_decisions.deciders.*",
  index: "my-index",
  shard: 0,
  primary: false,
});
console.log(response);</pre>
</div>
<a id="5e415c490a46358643ee2aab554b4876"></a>
<div class="pre_wrapper lang-console default has-ruby has-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console default has-ruby has-js">GET _cluster/allocation/explain?filter_path=index,node_allocation_decisions.node_name,node_allocation_decisions.deciders.*
{
  "index": "my-index",
  "shard": 0,
  "primary": false
}</pre>
</div>
<div class="console_widget has-ruby has-js" data-snippet="snippets/2156.console"></div>
<h4><a id="fix-red-yellow-cluster-status"></a>Fix a red or yellow cluster status<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/troubleshooting/common-issues/red-yellow-cluster-status.asciidoc">edit</a></h4>
<p>A shard can become unassigned for several reasons. The following tips outline the
most common causes and their solutions.</p>
<h5><a id="fix-cluster-status-reenable-allocation"></a>Re-enable shard allocation<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/troubleshooting/common-issues/red-yellow-cluster-status.asciidoc">edit</a></h5>
<p>You typically disable allocation during a <a class="xref" href="restart-cluster.html" title="Full-cluster restart and rolling restart">restart</a> or other
cluster maintenance. If you forgot to re-enable allocation afterward, Elasticsearch will
be unable to assign shards. To re-enable allocation, reset the
<code class="literal">cluster.routing.allocation.enable</code> cluster setting.</p>
<div class="pre_wrapper lang-ruby alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-ruby alternative">response = client.cluster.put_settings(
  body: {
    persistent: {
      'cluster.routing.allocation.enable' =&gt; nil
    }
  }
)
puts response</pre>
</div>
<div class="pre_wrapper lang-js alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js alternative">const response = await client.cluster.putSettings({
  persistent: {
    "cluster.routing.allocation.enable": null,
  },
});
console.log(response);</pre>
</div>
<a id="73ebc89cb32adb389ae16bb088d7c7e6"></a>
<div class="pre_wrapper lang-console default has-ruby has-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console default has-ruby has-js">PUT _cluster/settings
{
  "persistent" : {
    "cluster.routing.allocation.enable" : null
  }
}</pre>
</div>
<div class="console_widget has-ruby has-js" data-snippet="snippets/2157.console"></div>
<h5><a id="fix-cluster-status-recover-nodes"></a>Recover lost nodes<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/troubleshooting/common-issues/red-yellow-cluster-status.asciidoc">edit</a></h5>
<p>Shards often become unassigned when a data node leaves the cluster. This can
occur for several reasons, ranging from connectivity issues to hardware failure.
After you resolve the issue and recover the node, it will rejoin the cluster.
Elasticsearch will then automatically allocate any unassigned shards.</p>
<p>To avoid wasting resources on temporary issues, Elasticsearch <a class="xref" href="delayed-allocation.html" title="Delaying allocation when a node leaves">delays
allocation</a> by one minute by default. If you&#8217;ve recovered a node and don’t want
to wait for the delay period, you can call the <a class="xref" href="cluster-reroute.html" title="Cluster reroute API">cluster reroute
API</a> with no arguments to start the allocation process. The process runs
asynchronously in the background.</p>
<div class="pre_wrapper lang-ruby alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-ruby alternative">response = client.cluster.reroute(
  metric: 'none'
)
puts response</pre>
</div>
<div class="pre_wrapper lang-js alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js alternative">const response = await client.cluster.reroute({
  metric: "none",
});
console.log(response);</pre>
</div>
<a id="611c1e05f4ebb48a1a8c8488238ce34d"></a>
<div class="pre_wrapper lang-console default has-ruby has-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console default has-ruby has-js">POST _cluster/reroute?metric=none</pre>
</div>
<div class="console_widget has-ruby has-js" data-snippet="snippets/2158.console"></div>
<h5><a id="fix-cluster-status-allocation-settings"></a>Fix allocation settings<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/troubleshooting/common-issues/red-yellow-cluster-status.asciidoc">edit</a></h5>
<p>Misconfigured allocation settings can result in an unassigned primary shard.
These settings include:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<a class="xref" href="shard-allocation-filtering.html" title="Index-level shard allocation filtering">Shard allocation</a> index settings
</li>
<li class="listitem">
<a class="xref" href="modules-cluster.html#cluster-shard-allocation-filtering" title="Cluster-level shard allocation filtering">Allocation filtering</a> cluster settings
</li>
<li class="listitem">
<a class="xref" href="modules-cluster.html#shard-allocation-awareness" title="Shard allocation awareness">Allocation awareness</a> cluster settings
</li>
</ul>
</div>
<p>To review your allocation settings, use the <a class="xref" href="indices-get-settings.html" title="Get index settings API">get index
settings</a> and <a class="xref" href="cluster-get-settings.html" title="Cluster get settings API">cluster get settings</a> APIs.</p>
<div class="pre_wrapper lang-ruby alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-ruby alternative">response = client.indices.get_settings(
  index: 'my-index',
  flat_settings: true,
  include_defaults: true
)
puts response

response = client.cluster.get_settings(
  flat_settings: true,
  include_defaults: true
)
puts response</pre>
</div>
<div class="pre_wrapper lang-js alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js alternative">const response = await client.indices.getSettings({
  index: "my-index",
  flat_settings: "true",
  include_defaults: "true",
});
console.log(response);

const response1 = await client.cluster.getSettings({
  flat_settings: "true",
  include_defaults: "true",
});
console.log(response1);</pre>
</div>
<a id="674bb755111c6fbaa4c5ac759395c122"></a>
<div class="pre_wrapper lang-console default has-ruby has-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console default has-ruby has-js">GET my-index/_settings?flat_settings=true&amp;include_defaults=true

GET _cluster/settings?flat_settings=true&amp;include_defaults=true</pre>
</div>
<div class="console_widget has-ruby has-js" data-snippet="snippets/2159.console"></div>
<p>You can change the settings using the <a class="xref" href="indices-update-settings.html" title="Update index settings API">update index
settings</a> and <a class="xref" href="cluster-update-settings.html" title="Cluster update settings API">cluster update settings</a> APIs.</p>
<h5><a id="fix-cluster-status-allocation-replicas"></a>Allocate or reduce replicas<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/troubleshooting/common-issues/red-yellow-cluster-status.asciidoc">edit</a></h5>
<p>To protect against hardware failure, Elasticsearch will not assign a replica to the same
node as its primary shard. If no other data nodes are available to host the
replica, it remains unassigned. To fix this, you can:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
Add a data node to the same tier to host the replica.
</li>
<li class="listitem">
Change the <code class="literal">index.number_of_replicas</code> index setting to reduce the number of
replicas for each primary shard. We recommend keeping at least one replica per
primary.
</li>
</ul>
</div>
<div class="pre_wrapper lang-ruby alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-ruby alternative">response = client.indices.put_settings(
  body: {
    'index.number_of_replicas' =&gt; 1
  }
)
puts response</pre>
</div>
<div class="pre_wrapper lang-js alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js alternative">const response = await client.indices.putSettings({
  settings: {
    "index.number_of_replicas": 1,
  },
});
console.log(response);</pre>
</div>
<a id="cdfd4fef983c1c0fe8d7417f67d01eae"></a>
<div class="pre_wrapper lang-console default has-ruby has-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console default has-ruby has-js">PUT _settings
{
  "index.number_of_replicas": 1
}</pre>
</div>
<div class="console_widget has-ruby has-js" data-snippet="snippets/2160.console"></div>
<h5><a id="fix-cluster-status-disk-space"></a>Free up or increase disk space<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/troubleshooting/common-issues/red-yellow-cluster-status.asciidoc">edit</a></h5>
<p>Elasticsearch uses a <a class="xref" href="modules-cluster.html#disk-based-shard-allocation" title="Disk-based shard allocation settings">low disk watermark</a> to ensure data
nodes have enough disk space for incoming shards. By default, Elasticsearch does not
allocate shards to nodes using more than 85% of disk space.</p>
<p>To check the current disk space of your nodes, use the <a class="xref" href="cat-allocation.html" title="cat allocation API">cat
allocation API</a>.</p>
<div class="pre_wrapper lang-ruby alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-ruby alternative">response = client.cat.allocation(
  v: true,
  h: 'node,shards,disk.*'
)
puts response</pre>
</div>
<div class="pre_wrapper lang-js alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js alternative">const response = await client.cat.allocation({
  v: "true",
  h: "node,shards,disk.*",
});
console.log(response);</pre>
</div>
<a id="b728d6ba226dba719aadcd8b8099cc74"></a>
<div class="pre_wrapper lang-console default has-ruby has-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console default has-ruby has-js">GET _cat/allocation?v=true&amp;h=node,shards,disk.*</pre>
</div>
<div class="console_widget has-ruby has-js" data-snippet="snippets/2161.console"></div>
<p>If your nodes are running low on disk space, you have a few options:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
Upgrade your nodes to increase disk space.
</li>
<li class="listitem">
Delete unneeded indices to free up space. If you use ILM, you can
update your lifecycle policy to use <a class="xref" href="ilm-searchable-snapshot.html" title="Searchable snapshot">searchable
snapshots</a> or add a delete phase. If you no longer need to search the data, you
can use a <a class="xref" href="snapshot-restore.html" title="Snapshot and restore">snapshot</a> to store it off-cluster.
</li>
<li class="listitem">
<p>If you no longer write to an index, use the <a class="xref" href="indices-forcemerge.html" title="Force merge API">force merge
API</a> or ILM&#8217;s <a class="xref" href="ilm-forcemerge.html" title="Force merge">force merge action</a> to merge its
segments into larger ones.</p>
<div class="pre_wrapper lang-ruby alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-ruby alternative">response = client.indices.forcemerge(
  index: 'my-index'
)
puts response</pre>
</div>
<div class="pre_wrapper lang-js alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js alternative">const response = await client.indices.forcemerge({
  index: "my-index",
});
console.log(response);</pre>
</div>
<a id="4c5f0d7af287618062bb627b44ccb23e"></a>
<div class="pre_wrapper lang-console default has-ruby has-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console default has-ruby has-js">POST my-index/_forcemerge</pre>
</div>
<div class="console_widget has-ruby has-js" data-snippet="snippets/2162.console"></div>
</li>
<li class="listitem">
<p>If an index is read-only, use the <a class="xref" href="indices-shrink-index.html" title="Shrink index API">shrink index API</a> or
ILM&#8217;s <a class="xref" href="ilm-shrink.html" title="Shrink">shrink action</a> to reduce its primary shard count.</p>
<div class="pre_wrapper lang-ruby alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-ruby alternative">response = client.indices.shrink(
  index: 'my-index',
  target: 'my-shrunken-index'
)
puts response</pre>
</div>
<div class="pre_wrapper lang-js alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js alternative">const response = await client.indices.shrink({
  index: "my-index",
  target: "my-shrunken-index",
});
console.log(response);</pre>
</div>
<a id="44231f7cdd5c3a21025861cdef31e355"></a>
<div class="pre_wrapper lang-console default has-ruby has-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console default has-ruby has-js">POST my-index/_shrink/my-shrunken-index</pre>
</div>
<div class="console_widget has-ruby has-js" data-snippet="snippets/2163.console"></div>
</li>
<li class="listitem">
<p>If your node has a large disk capacity, you can increase the low disk
watermark or set it to an explicit byte value.</p>
<div class="pre_wrapper lang-js alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js alternative">const response = await client.cluster.putSettings({
  persistent: {
    "cluster.routing.allocation.disk.watermark.low": "30gb",
  },
});
console.log(response);</pre>
</div>
<a id="9d47f02a063444da9f098858a1830d28"></a>
<div class="pre_wrapper lang-console default has-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console default has-js">PUT _cluster/settings
{
  "persistent": {
    "cluster.routing.allocation.disk.watermark.low": "30gb"
  }
}</pre>
</div>
<div class="console_widget has-js" data-snippet="snippets/2164.console"></div>
</li>
</ul>
</div>
<h5><a id="fix-cluster-status-jvm"></a>Reduce JVM memory pressure<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/troubleshooting/common-issues/red-yellow-cluster-status.asciidoc">edit</a></h5>
<p>Shard allocation requires JVM heap memory. High JVM memory pressure can trigger
<a class="xref" href="circuit-breaker.html" title="Circuit breaker settings">circuit breakers</a> that stop allocation and leave shards
unassigned. See <a class="xref" href="high-jvm-memory-pressure.html" title="High JVM memory pressure">High JVM memory pressure</a>.</p>
<h5><a id="fix-cluster-status-restore"></a>Recover data for a lost primary shard<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/troubleshooting/common-issues/red-yellow-cluster-status.asciidoc">edit</a></h5>
<p>If a node containing a primary shard is lost, Elasticsearch can typically replace it
using a replica on another node. If you can&#8217;t recover the node and replicas
don&#8217;t exist or are irrecoverable, <a class="xref" href="cluster-allocation-explain.html" title="Cluster allocation explain API">Allocation
Explain</a> will report <code class="literal">no_valid_shard_copy</code> and you&#8217;ll need to do one of the following:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
restore the missing data from <a class="xref" href="snapshot-restore.html" title="Snapshot and restore">snapshot</a>
</li>
<li class="listitem">
index the missing data from its original data source
</li>
<li class="listitem">
accept data loss on the index-level by running <a class="xref" href="indices-delete-index.html" title="Delete index API">Delete Index</a>
</li>
<li class="listitem">
<p>accept data loss on the shard-level by executing <a class="xref" href="cluster-reroute.html" title="Cluster reroute API">Cluster Reroute</a> allocate_stale_primary or allocate_empty_primary command with <code class="literal">accept_data_loss: true</code></p>
<div class="warning admon">
<div class="icon"></div>
<div class="admon_content">
<p>Only use this option if node recovery is no longer possible. This
process allocates an empty primary shard. If the node later rejoins the cluster,
Elasticsearch will overwrite its primary shard with data from this newer empty shard,
resulting in data loss.</p>
</div>
</div>
<div class="pre_wrapper lang-js alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js alternative">const response = await client.cluster.reroute({
  metric: "none",
  commands: [
    {
      allocate_empty_primary: {
        index: "my-index",
        shard: 0,
        node: "my-node",
        accept_data_loss: "true",
      },
    },
  ],
});
console.log(response);</pre>
</div>
<a id="35b686d9d9e915d0dea7a4251781767d"></a>
<div class="pre_wrapper lang-console default has-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console default has-js">POST _cluster/reroute?metric=none
{
  "commands": [
    {
      "allocate_empty_primary": {
        "index": "my-index",
        "shard": 0,
        "node": "my-node",
        "accept_data_loss": "true"
      }
    }
  ]
}</pre>
</div>
<div class="console_widget has-js" data-snippet="snippets/2165.console"></div>
</li>
</ul>
</div>
</div>
</div>
</div><div class="navfooter">
<span class="prev">
<a href="high-jvm-memory-pressure.html">« High JVM memory pressure</a>
</span>
<span class="next">
<a href="rejected-requests.html">Rejected requests »</a>
</span>
</div>
</body>
</html>
