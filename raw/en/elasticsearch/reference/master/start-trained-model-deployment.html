<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="keywords" content="Elasticsearch diagnostic, diagnostics">
<title>Start trained model deployment API | Elasticsearch Guide [master] | Elastic</title>
<meta class="elastic" name="content" content="Start trained model deployment API | Elasticsearch Guide [master]">

<link rel="home" href="index.html" title="Elasticsearch Guide [master]"/>
<link rel="up" href="ml-df-trained-models-apis.html" title="Machine learning trained model APIs"/>
<link rel="prev" href="infer-trained-model.html" title="Infer trained model API"/>
<link rel="next" href="stop-trained-model-deployment.html" title="Stop trained model deployment API"/>
<meta class="elastic" name="product_version" content="master"/>
<meta class="elastic" name="product_name" content="Elasticsearch"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/Elasticsearch/Reference/master"/>
<meta name="DC.subject" content="Elasticsearch"/>
<meta name="DC.identifier" content="master"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body>
<div class="page_header">
This documentation contains work-in-progress information for future Elastic Stack and Cloud releases. Use the version selector to view supported release docs. It also contains some Elastic Cloud serverless information. Check out our <a href="https://www.elastic.co/docs/current/serverless">serverless docs</a> for more details.
</div>
<div class="navheader">
<span class="prev">
<a href="infer-trained-model.html">« Infer trained model API</a>
</span>
<span class="next">
<a href="stop-trained-model-deployment.html">Stop trained model deployment API »</a>
</span>
</div>
<div class="book" lang="en">
<div class="titlepage">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Elasticsearch Guide [master]</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="rest-apis.html">REST APIs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="ml-df-trained-models-apis.html">Machine learning trained model APIs</a></span>
</div>
<div>
<div><h1 class="title"><a id="id-1"></a>Start trained model deployment API</h1><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/ml/trained-models/apis/start-trained-model-deployment.asciidoc">edit</a></div>
</div>
<!--EXTRA-->
</div>
<div id="content">
<div class="section xpack">
<div class="titlepage"><div><div>
<h2 class="title"><a id="start-trained-model-deployment"></a>Start trained model deployment API<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/ml/trained-models/apis/start-trained-model-deployment.asciidoc">edit</a></h2>
</div></div></div>

<p>Starts a new trained model deployment.</p>
<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="start-trained-model-deployment-request"></a>Request<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/ml/trained-models/apis/start-trained-model-deployment.asciidoc">edit</a></h3>
</div></div></div>
<p><code class="literal">POST _ml/trained_models/&lt;model_id&gt;/deployment/_start</code></p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="start-trained-model-deployment-prereq"></a>Prerequisites<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/ml/trained-models/apis/start-trained-model-deployment.asciidoc">edit</a></h3>
</div></div></div>
<p>Requires the <code class="literal">manage_ml</code> cluster privilege. This privilege is included in the
<code class="literal">machine_learning_admin</code> built-in role.</p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="start-trained-model-deployment-desc"></a>Description<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/ml/trained-models/apis/start-trained-model-deployment.asciidoc">edit</a></h3>
</div></div></div>
<p>Currently only <code class="literal">pytorch</code> models are supported for deployment. Once deployed
the model can be used by the <a class="xref" href="inference-processor.html" title="Inference processor">Inference processor</a>
in an ingest pipeline or directly in the <a class="xref" href="infer-trained-model.html" title="Infer trained model API">Infer trained model</a> API.</p>
<p>A model can be deployed multiple times by using deployment IDs. A deployment ID
must be unique and should not match any other deployment ID or model ID, unless
it is the same as the ID of the model being deployed. If <code class="literal">deployment_id</code> is not
set, it defaults to the <code class="literal">model_id</code>.</p>
<p>Scaling inference performance can be achieved by setting the parameters
<code class="literal">number_of_allocations</code> and <code class="literal">threads_per_allocation</code>.</p>
<p>Increasing <code class="literal">threads_per_allocation</code> means more threads are used when an
inference request is processed on a node. This can improve inference speed for
certain models. It may also result in improvement to throughput.</p>
<p>Increasing <code class="literal">number_of_allocations</code> means more threads are used to process
multiple inference requests in parallel resulting in throughput improvement.
Each model allocation uses a number of threads defined by
<code class="literal">threads_per_allocation</code>.</p>
<p>Model allocations are distributed across machine learning nodes. All allocations assigned to
a node share the same copy of the model in memory. To avoid thread
oversubscription which is detrimental to performance, model allocations are
distributed in such a way that the total number of used threads does not surpass
the node&#8217;s allocated processors.</p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="start-trained-model-deployment-path-params"></a>Path parameters<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/ml/trained-models/apis/start-trained-model-deployment.asciidoc">edit</a></h3>
</div></div></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">&lt;model_id&gt;</code>
</span>
</dt>
<dd>
(Required, string)
The unique identifier of the trained model.
</dd>
</dl>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="start-trained-model-deployment-query-params"></a>Query parameters<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/ml/trained-models/apis/start-trained-model-deployment.asciidoc">edit</a></h3>
</div></div></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">cache_size</code>
</span>
</dt>
<dd>
(Optional, <a class="xref" href="api-conventions.html#byte-units" title="Byte size units">byte value</a>)
The inference cache size (in memory outside the JVM heap) per node for the
model. In serverless, the cache is disabled by default. Otherwise, the default value is the size of the model as reported by the
<code class="literal">model_size_bytes</code> field in the <a class="xref" href="get-trained-models-stats.html" title="Get trained models statistics API">Get trained models stats</a>. To disable the
cache, <code class="literal">0b</code> can be provided.
</dd>
<dt>
<span class="term">
<code class="literal">deployment_id</code>
</span>
</dt>
<dd>
(Optional, string)
A unique identifier for the deployment of the model.
</dd>
</dl>
</div>
<p>Defaults to <code class="literal">model_id</code>.</p>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">number_of_allocations</code>
</span>
</dt>
<dd>
(Optional, integer)
The total number of allocations this model is assigned across machine learning nodes.
Increasing this value generally increases the throughput. Defaults to 1.
</dd>
<dt>
<span class="term">
<code class="literal">priority</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
The priority of the deployment. The default value is <code class="literal">normal</code>.
There are two priority settings:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">normal</code>: Use this for deployments in production. The deployment allocations
are distributed so that node processors are not oversubscribed.
</li>
<li class="listitem">
<code class="literal">low</code>: Use this for testing model functionality. The intention is that these
deployments are not sent a high volume of input. The deployment is required to
have a single allocation with just one thread. Low priority deployments may be
assigned on nodes that already utilize all their processors but will be given a
lower CPU priority than normal deployments. Low priority deployments may be
unassigned in order to satisfy more allocations of normal priority deployments.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="warning admon">
<div class="icon"></div>
<div class="admon_content">
<p>Heavy usage of low priority deployments may impact performance of
normal priority deployments.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">queue_capacity</code>
</span>
</dt>
<dd>
(Optional, integer)
Controls how many inference requests are allowed in the queue at a time.
Every machine learning node in the cluster where the model can be allocated
has a queue of this size; when the number of requests exceeds the total value,
new requests are rejected with a 429 error. Defaults to 1024. Max allowed value
is 1000000.
</dd>
<dt>
<span class="term">
<code class="literal">threads_per_allocation</code>
</span>
</dt>
<dd>
(Optional, integer)
Sets the number of threads used by each model allocation during inference. This
generally increases the speed per inference request. The inference process is a
compute-bound process; <code class="literal">threads_per_allocations</code> must not exceed the number of
available allocated processors per node. Defaults to 1. Must be a power of 2.
Max allowed value is 32.
</dd>
<dt>
<span class="term">
<code class="literal">timeout</code>
</span>
</dt>
<dd>
(Optional, time)
Controls the amount of time to wait for the model to deploy. Defaults to 30
seconds.
</dd>
<dt>
<span class="term">
<code class="literal">wait_for</code>
</span>
</dt>
<dd>
(Optional, string)
Specifies the allocation status to wait for before returning. Defaults to
<code class="literal">started</code>. The value <code class="literal">starting</code> indicates deployment is starting but not yet on
any node. The value <code class="literal">started</code> indicates the model has started on at least one
node. The value <code class="literal">fully_allocated</code> indicates the deployment has started on all
valid nodes.
</dd>
</dl>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="start-trained-model-deployment-example"></a>Examples<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/ml/trained-models/apis/start-trained-model-deployment.asciidoc">edit</a></h3>
</div></div></div>
<p>The following example starts a new deployment for a
<code class="literal">elastic__distilbert-base-uncased-finetuned-conll03-english</code> trained model:</p>
<div class="pre_wrapper lang-python alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-python alternative">resp = client.ml.start_trained_model_deployment(
    model_id="elastic__distilbert-base-uncased-finetuned-conll03-english",
    wait_for="started",
    timeout="1m",
)
print(resp)</pre>
</div>
<div class="pre_wrapper lang-js alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js alternative">const response = await client.ml.startTrainedModelDeployment({
  model_id: "elastic__distilbert-base-uncased-finetuned-conll03-english",
  wait_for: "started",
  timeout: "1m",
});
console.log(response);</pre>
</div>
<a id="aa6282d4bc92c753c4bd7a5b166abece"></a>
<div class="pre_wrapper lang-console default has-python has-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console default has-python has-js">POST _ml/trained_models/elastic__distilbert-base-uncased-finetuned-conll03-english/deployment/_start?wait_for=started&amp;timeout=1m</pre>
</div>
<div class="console_widget has-python has-js" data-snippet="snippets/2998.console"></div>
<p>The API returns the following results:</p>
<a id="18c8fb9396116f39eaa8179d4e70987a"></a>
<div class="pre_wrapper lang-console-result">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console-result">{
    "assignment": {
        "task_parameters": {
            "model_id": "elastic__distilbert-base-uncased-finetuned-conll03-english",
            "model_bytes": 265632637,
            "threads_per_allocation" : 1,
            "number_of_allocations" : 1,
            "queue_capacity" : 1024,
            "priority": "normal"
        },
        "routing_table": {
            "uckeG3R8TLe2MMNBQ6AGrw": {
                "routing_state": "started",
                "reason": ""
            }
        },
        "assignment_state": "started",
        "start_time": "2022-11-02T11:50:34.766591Z"
    }
}</pre>
</div>
<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="start-trained-model-deployment-deployment-id-example"></a>Using deployment IDs<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/main/docs/reference/ml/trained-models/apis/start-trained-model-deployment.asciidoc">edit</a></h4>
</div></div></div>
<p>The following example starts a new deployment for the <code class="literal">my_model</code> trained model
with the ID <code class="literal">my_model_for_ingest</code>. The deployment ID an be used in inference API
calls or in inference processors.</p>
<div class="pre_wrapper lang-python alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-python alternative">resp = client.ml.start_trained_model_deployment(
    model_id="my_model",
    deployment_id="my_model_for_ingest",
)
print(resp)</pre>
</div>
<div class="pre_wrapper lang-js alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js alternative">const response = await client.ml.startTrainedModelDeployment({
  model_id: "my_model",
  deployment_id: "my_model_for_ingest",
});
console.log(response);</pre>
</div>
<a id="0e5d25c7bb738c42d471020d678e2966"></a>
<div class="pre_wrapper lang-console default has-python has-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console default has-python has-js">POST _ml/trained_models/my_model/deployment/_start?deployment_id=my_model_for_ingest</pre>
</div>
<div class="console_widget has-python has-js" data-snippet="snippets/2999.console"></div>
<p>The <code class="literal">my_model</code> trained model can be deployed again with a different ID:</p>
<div class="pre_wrapper lang-python alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-python alternative">resp = client.ml.start_trained_model_deployment(
    model_id="my_model",
    deployment_id="my_model_for_search",
)
print(resp)</pre>
</div>
<div class="pre_wrapper lang-js alternative">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js alternative">const response = await client.ml.startTrainedModelDeployment({
  model_id: "my_model",
  deployment_id: "my_model_for_search",
});
console.log(response);</pre>
</div>
<a id="5837d5f50665ac0a26181d3aaeb3f204"></a>
<div class="pre_wrapper lang-console default has-python has-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console default has-python has-js">POST _ml/trained_models/my_model/deployment/_start?deployment_id=my_model_for_search</pre>
</div>
<div class="console_widget has-python has-js" data-snippet="snippets/3000.console"></div>
</div>

</div>

</div>
</div>
</div><div class="navfooter">
<span class="prev">
<a href="infer-trained-model.html">« Infer trained model API</a>
</span>
<span class="next">
<a href="stop-trained-model-deployment.html">Stop trained model deployment API »</a>
</span>
</div>
</body>
</html>
