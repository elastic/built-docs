<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Elastic web crawler known issues | Enterprise Search documentation [8.15] | Elastic</title>
<meta class="elastic" name="content" content="Elastic web crawler known issues | Enterprise Search documentation [8.15]">

<link rel="home" href="index.html" title="Enterprise Search documentation [8.15]"/>
<link rel="up" href="crawler.html" title="Elastic web crawler"/>
<link rel="prev" href="crawler-extraction-rules.html" title="Web crawler content extraction rules"/>
<link rel="next" href="crawler-troubleshooting.html" title="Troubleshooting crawls"/>
<meta class="elastic" name="product_version" content="8.15"/>
<meta class="elastic" name="product_name" content="Enterprise Search"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/Enterprise Search/Guide/8.15"/>
<meta name="DC.subject" content="Enterprise Search"/>
<meta name="DC.identifier" content="8.15"/>
</head>
<body>
<div class="navheader">
<span class="prev">
<a href="crawler-extraction-rules.html">« Web crawler content extraction rules</a>
</span>
<span class="next">
<a href="crawler-troubleshooting.html">Troubleshooting crawls »</a>
</span>
</div>
<div class="book" lang="en">
<div class="titlepage">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link">
<div id="related-products" class="dropdown">
<div class="related-products-title"></div>
<div class="dropdown-anchor" tabindex="0">Enterprise Search<span class="dropdown-icon"></span></div>
<div class="dropdown-content">
<ul>
<li class="dropdown-category">Enterprise Search guides</li>
<ul>
<li><a href="/guide/en/enterprise-search/current/index.html" target="_blank">Enterprise Search</a></li>
<li><a href="/guide/en/app-search/current/index.html" target="_blank">App Search</a></li>
<li><a href="/guide/en/workplace-search/current/index.html" target="_blank">Workplace Search</a></li>
</ul>
<li class="dropdown-category">Programming language clients</li>
<ul>
<li><a href="https://www.elastic.co/guide/en/enterprise-search-clients/enterprise-search-node/current/index.html" target="_blank">Node.js client</a></li>
<li><a href="https://www.elastic.co/guide/en/enterprise-search-clients/php/current/index.html" target="_blank">PHP client</a></li>
<li><a href="https://www.elastic.co/guide/en/enterprise-search-clients/python/current/index.html" target="_blank">Python client</a></li>
<li><a href="https://www.elastic.co/guide/en/enterprise-search-clients/ruby/current/index.html" target="_blank">Ruby client</a></li>
</ul>
</ul>
</div>
</div>
</span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="crawler.html">Elastic web crawler</a></span>
</div>
<div>
<div><h1 class="title"><a id="id-1"></a>Elastic web crawler known issues</h1><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/8.15/enterprise-search-docs/crawler-known-issues.asciidoc">edit</a></div>
</div>
<!--EXTRA-->
</div>
<div id="content">
<div class="chapter">
<div class="titlepage"><div><div>
<h2 class="title"><a id="crawler-known-issues"></a>Elastic web crawler known issues<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/8.15/enterprise-search-docs/crawler-known-issues.asciidoc">edit</a></h2>
</div></div></div>

<p>The Elastic web crawler has the following known issues:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<p><span class="strong strong"><strong>The crawler does not crawl pure JavaScript single-page applications (SPAs)</strong></span>.</p>
<p>We recommend looking at <a href="https://developers.google.com/search/docs/advanced/javascript/dynamic-rendering" class="ulink" target="_blank" rel="noopener">dynamic rendering</a> to help your crawler properly index your JavaScript websites.
Another option is to serve a static HTML version of your Javascript website, using a solution such as <a href="https://prerender.io/" class="ulink" target="_blank" rel="noopener">Prerender</a>.</p>
</li>
<li class="listitem">
<p><span class="strong strong"><strong>The crawler does not support dynamic content</strong></span>.</p>
<p>The crawler does not execute JavaScript, and it only pulls text from HTML elements.</p>
</li>
<li class="listitem">
<p><span class="strong strong"><strong>The crawler does not support form-based authentication</strong></span>.</p>
<p>The crawler currently only supports basic authentication and authentication header (e.g. bearer tokens) authentication methods.</p>
</li>
<li class="listitem">
<p><span class="strong strong"><strong>URLs being indexed despite having duplicate content and a canonical URL setting</strong></span>.</p>
<p><a class="xref" href="crawler-content.html#crawler-content-canonical-url-link-tag" title="Canonical URL link tags">Canonical URL link tags</a> are embedded within HTML source for pages that duplicate the content of other pages.
Refer to <a class="xref" href="crawler-managing.html#crawler-managing-duplicate-documents" title="Duplicate document handling">Duplicate document handling</a> for details.
The crawler identifies duplicate content by hashing the content of default deduplication fields derived from the page.
These fields are defined by the configuration setting <code class="literal">connector.crawler.extraction.default_deduplication_fields</code>.</p>
<p>The web crawler checks your index for an existing document with the same content hash.
Users have faced issues where they set canonical link tags for a page that does not have <span class="strong strong"><strong><em>identical</em></strong></span> content, because the hashes are different.
However, upon inspection, the content is the same.</p>
<p>Use the following <span class="strong strong"><strong>workaround</strong></span>:</p>
<p>You can manage which <span class="strong strong"><strong>fields</strong></span> the web crawler uses to create the content hash.
If your pages all define canonical URLs, you could safely change your deduplication fields settings to include only the <code class="literal">url</code> field.
Otherwise, you may need more fields to help check for duplicates.
By default, the web crawler checks <code class="literal">body_content</code>, <code class="literal">headings</code>, <code class="literal">links</code>, <code class="literal">meta_description</code>, <code class="literal">meta_keywords</code>, and <code class="literal">title</code> fields.</p>
</li>
<li class="listitem">
<p><span class="strong strong"><strong>Custom scheduling might break when upgrading from version 8.6 or earlier.</strong></span></p>
<p>If you encounter the error <code class="literal">'custom_schedule_triggered': undefined method 'each' for nil:NilClass (NoMethodError)</code>, it means the custom scheduling feature migration failed.
You can use the following manual workaround:</p>
<div class="pre_wrapper lang-sh">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-sh">POST /.elastic-connectors/_update/&lt;connector-id&gt;
{
  "doc": {
    "custom_scheduling": {}
  }
}</pre>
</div>
<p>This error can appear on Connectors or Crawlers that aren&#8217;t the cause of the issue.
If the error continues, try running the above command for every document in the <code class="literal">.elastic-connectors</code> index.</p>
</li>
<li class="listitem">
<p><span class="strong strong"><strong>The web crawler ignores uppercase <code class="literal">noindex</code> tags.</strong></span></p>
<p>Make sure these tags are lowercase.</p>
</li>
<li class="listitem">
<p><span class="strong strong"><strong>Updates to the default <code class="literal">connector.crawler.http.user_agent</code> are not applied.</strong></span></p>
<p>A workaround is to remove the <code class="literal">connector</code> prefix and update the <code class="literal">crawler.http_agent</code> setting in your Enterprise Search configuration file.</p>
</li>
<li class="listitem">
<p><span class="strong strong"><strong>The web crawler uses a non-deterministic method to determine thread pool size, which can lead to unexpected behavior.</strong></span></p>
<p>This can be worked around by overriding the <code class="literal">crawler.workers.pool_size.limit</code> value in the <code class="literal">elasticsearch.yml</code> file.</p>
</li>
<li class="listitem">
<p><span class="strong strong"><strong>Entry points should not have leading spaces.</strong></span></p>
<p>Whitespace is not stripped from entry points, so leading spaces will be included in the URL, leading to errors.</p>
</li>
<li class="listitem">
<p><span class="strong strong"><strong>Updates to the default <code class="literal">connector.crawler.http.user_agent</code> are not applied.</strong></span></p>
<p>A workaround is to remove the <code class="literal">connector</code> prefix and update the <code class="literal">crawler.http_agent</code> setting in your Enterprise Search configuration file.</p>
</li>
<li class="listitem">
<p><span class="strong strong"><strong>Crawler does not support UTF16-LE encoding.</strong></span></p>
<p>The crawler does not support UTF16 little endian encoding.
A workaround is to encode your files in a supported format such as UTF-8.</p>
</li>
</ul>
</div>
</div>
</div>
</div><div class="navfooter">
<span class="prev">
<a href="crawler-extraction-rules.html">« Web crawler content extraction rules</a>
</span>
<span class="next">
<a href="crawler-troubleshooting.html">Troubleshooting crawls »</a>
</span>
</div>
</body>
</html>
