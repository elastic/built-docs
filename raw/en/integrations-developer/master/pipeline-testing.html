<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Pipeline testing | Integrations Developer Guide | Elastic</title>
<link rel="home" href="index.html" title="Integrations Developer Guide"/>
<link rel="up" href="testing.html" title="Test an integration"/>
<link rel="prev" href="asset-testing.html" title="Asset testing"/>
<link rel="next" href="static-testing.html" title="Static testing"/>
<meta name="DC.type" content="Learn/Docs/Integrations/Developer"/>
<meta name="DC.subject" content="Integrations"/>
<meta name="DC.identifier" content="master"/>
</head>
<body>
<div id="content">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Integrations Developer Guide</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="testing.html">Test an integration</a></span>
</div>
<div class="navheader">
<span class="prev">
<a href="asset-testing.html">« Asset testing</a>
</span>
<span class="next">
<a href="static-testing.html">Static testing »</a>
</span>
</div>
<div class="section">
<div class="titlepage"><div><div>
<h2 class="title"><a id="pipeline-testing"></a>Pipeline testing<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/observability-docs/edit/main/docs/en/integrations/pipeline-testing.asciidoc">edit</a></h2>
</div></div></div>
<p>Elastic Packages comprise of data streams. A pipeline test exercises Elasticsearch Ingest Node pipelines defined for a package&#8217;s data stream.</p>
<h4><a id="pipeline-concepts"></a>Conceptual process<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/observability-docs/edit/main/docs/en/integrations/pipeline-testing.asciidoc">edit</a></h4>
<p>Conceptually, running a pipeline test involves the following steps:</p>
<div class="olist orderedlist">
<ol class="orderedlist">
<li class="listitem">
Deploy the Elasticsearch instance (part of the Elastic Stack). This step takes time, so you should typically do it once as a prerequisite to running pipeline tests on multiple data streams.
</li>
<li class="listitem">
Upload ingest pipelines to be tested.
</li>
<li class="listitem">
Use the <a href="/guide/en/elasticsearch/reference/master/simulate-pipeline-api.html" class="ulink" target="_top">Simulate API</a> to process logs/metrics with the ingest pipeline.
</li>
<li class="listitem">
Compare generated results with expected ones.
</li>
</ol>
</div>
<h4><a id="pipeline-limitations"></a>Limitations<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/observability-docs/edit/main/docs/en/integrations/pipeline-testing.asciidoc">edit</a></h4>
<p>At the moment, pipeline tests have limitations. The main ones are:
* As you&#8217;re only testing the ingest pipeline, you can prepare mocked documents with imaginary fields, different from ones collected in Beats. Also, the other way round, you can skip most of the example fields and use tiny documents with a minimal set of fields just to satisfy the pipeline validation.
* There might be integrations that transform data mainly using Beats processors instead of ingest pipelines. In such cases, ingest pipelines are rather plain.</p>
<h4><a id="pipeline-defining-test"></a>Defining a pipeline test<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/observability-docs/edit/main/docs/en/integrations/pipeline-testing.asciidoc">edit</a></h4>
<p>Packages have a specific folder structure (only relevant parts shown).</p>
<div class="pre_wrapper lang-terminal">
<pre class="programlisting prettyprint lang-terminal">&lt;package root&gt;/
  data_stream/
    &lt;data stream&gt;/
      manifest.yml
  manifest.yml</pre>
</div>
<p>To define a pipeline test we must define configuration at each dataset&#8217;s level:</p>
<div class="pre_wrapper lang-terminal">
<pre class="programlisting prettyprint lang-terminal">&lt;package root&gt;/
  data_stream/
    &lt;data stream&gt;/
      _dev/
        test/
          pipeline/
            (test case definitions, both raw files and input events, optional configuration)
      manifest.yml
  manifest.yml</pre>
</div>
<h5><a id="pipeline-test-case"></a>Test case definitions<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/observability-docs/edit/main/docs/en/integrations/pipeline-testing.asciidoc">edit</a></h5>
<p>There are two types of test case definitions - <span class="strong strong"><strong>raw files</strong></span> and <span class="strong strong"><strong>input events</strong></span>.</p>
<h6><a id="pipeline-raw-files"></a>Raw files<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/observability-docs/edit/main/docs/en/integrations/pipeline-testing.asciidoc">edit</a></h6>
<p>The raw files simplify preparing test cases using real application <code class="literal">.log</code> files. A sample log (e.g. <code class="literal">test-access-sample.log</code>) file may look like the following one for Nginx:</p>
<div class="pre_wrapper lang-terminal">
<pre class="programlisting prettyprint lang-terminal">127.0.0.1 - - [07/Dec/2016:11:04:37 +0100] "GET /test1 HTTP/1.1" 404 571 "-" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.98 Safari/537.36"
127.0.0.1 - - [07/Dec/2016:11:04:58 +0100] "GET / HTTP/1.1" 304 0 "-" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.12; rv:49.0) Gecko/20100101 Firefox/49.0"
127.0.0.1 - - [07/Dec/2016:11:04:59 +0100] "GET / HTTP/1.1" 304 0 "-" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.12; rv:49.0) Gecko/20100101 Firefox/49.0"</pre>
</div>
<h6><a id="pipeline-input-events"></a>Input events<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/observability-docs/edit/main/docs/en/integrations/pipeline-testing.asciidoc">edit</a></h6>
<p>The input events contain mocked JSON events that are ready to be passed to the ingest pipeline as-is. Such events can be helpful in situations in which an input event can&#8217;t be serialized to a standard log file, e.g. Redis input. A sample file with input events  (e.g. <code class="literal">test-access-event.json</code>) looks as follows:</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json">{
    "events": [
        {
            "@timestamp": "2016-10-25T12:49:34.000Z",
            "message": "127.0.0.1 - - [07/Dec/2016:11:04:37 +0100] \"GET /test1 HTTP/1.1\" 404 571 \"-\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.98 Safari/537.36\"\n"
        },
        {
            "@timestamp": "2016-10-25T12:49:34.000Z",
            "message": "127.0.0.1 - - [07/Dec/2016:11:05:07 +0100] \"GET /taga HTTP/1.1\" 404 169 \"-\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.12; rv:49.0) Gecko/20100101 Firefox/49.0\"\n"
        }
    ]
}</pre>
</div>
<h6><a id="pipeline-test-config"></a>Test configuration<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/observability-docs/edit/main/docs/en/integrations/pipeline-testing.asciidoc">edit</a></h6>
<p>Before sending log events to the ingest pipeline, a data transformation process is applied. The process can be customized using an optional configuration stored as a YAML file with the suffix <code class="literal">-config.yml</code> (e.g. <code class="literal">test-access-sample.log-config.yml</code>):</p>
<div class="pre_wrapper lang-yml">
<pre class="programlisting prettyprint lang-yml">multiline:
  first_line_pattern: "^(?:[0-9]{1,3}\\.){3}[0-9]{1,3}"
fields:
  "@timestamp": "2020-04-28T11:07:58.223Z"
  ecs:
    version: "1.5.0"
  event.category:
    - "web"
dynamic_fields:
  url.original: "^/.*$"
numeric_keyword_fields:
  - network.iana_number</pre>
</div>
<p>The <code class="literal">multiline</code> section <a class="xref" href="pipeline-testing.html#pipeline-raw-files" title="Raw files">raw files only</a> configures the log file reader to detect multiline log entries using the <code class="literal">first_line_pattern</code>. Use this property if you may split your logs into multiple lines, e.g. Java stack traces.</p>
<p>The <code class="literal">fields</code> section allows for customizing extra fields to be added to every read log entry (e.g. <code class="literal">@timestamp</code>, <code class="literal">ecs</code>). Use this property to extend your logs with data that can&#8217;t be extracted from log content, but it&#8217;s fine to have the same field values for every record (e.g. timezone, hostname).</p>
<p>The <code class="literal">dynamic_fields</code> section allows for marking fields as dynamic (every time they have different non-static values), so that pattern matching instead of strict value check is applied.</p>
<p>The <code class="literal">numeric_keyword_fields</code> section identifies fields whose values are numbers but are expected to be stored in Elasticsearch as <code class="literal">keyword</code> fields.</p>
<h6><a id="pipeline-expected-results"></a>Expected results<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/observability-docs/edit/main/docs/en/integrations/pipeline-testing.asciidoc">edit</a></h6>
<p>Once the Simulate API processes the input data, the pipeline test runner will compare them with expected results. Test results are stored as JSON files with the suffix <code class="literal">-expected.json</code>. A sample test results file is shown below.</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json">{
    "expected": [
        {
            "@timestamp": "2016-12-07T10:04:37.000Z",
            "nginx": {
                "access": {
                    "remote_ip_list": [
                        "127.0.0.1"
                    ]
                }
            },
            ...
        },
        {
            "@timestamp": "2016-12-07T10:05:07.000Z",
            "nginx": {
                "access": {
                    "remote_ip_list": [
                        "127.0.0.1"
                    ]
                }
            },
            ...
        }
    ]
}</pre>
</div>
<p>It&#8217;s possible to generate the expected test results from the output of the Simulate API. To do so, use the <code class="literal">--generate</code> switch:</p>
<div class="pre_wrapper lang-terminal">
<pre class="programlisting prettyprint lang-terminal">elastic-package test pipeline --generate</pre>
</div>
<h4><a id="pipeline-running-test"></a>Running a pipeline test<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/observability-docs/edit/main/docs/en/integrations/pipeline-testing.asciidoc">edit</a></h4>
<p>Once the configurations are defined as described in the previous section, you are ready to run pipeline tests for a package&#8217;s data streams.</p>
<p>First, you must deploy the Elasticsearch instance. This corresponds to step 1 as described in the <a class="xref" href="pipeline-testing.html#pipeline-concepts" title="Conceptual process">Conceptual-process</a> section.</p>
<div class="pre_wrapper lang-terminal">
<pre class="programlisting prettyprint lang-terminal">elastic-package stack up -d --services=elasticsearch</pre>
</div>
<p>For a complete listing of options available for this command, run <code class="literal">elastic-package stack up -h</code> or <code class="literal">elastic-package help stack up</code>.</p>
<p>Next, you must set environment variables needed for further <code class="literal">elastic-package</code> commands.</p>
<div class="pre_wrapper lang-terminal">
<pre class="programlisting prettyprint lang-terminal">$(elastic-package stack shellinit)</pre>
</div>
<p>Next, you must invoke the pipeline tests runner. This corresponds to steps 2 through 4 as described in the <a class="xref" href="pipeline-testing.html#pipeline-concepts" title="Conceptual process">Conceptual-process</a> section.</p>
<p>If you want to run pipeline tests for <span class="strong strong"><strong>all data streams</strong></span> in a package, navigate to the package&#8217;s root folder (or any sub-folder under it) and run the following command.</p>
<div class="pre_wrapper lang-terminal">
<pre class="programlisting prettyprint lang-terminal">elastic-package test pipeline</pre>
</div>
<p>If you want to run pipeline tests for <span class="strong strong"><strong>specific data streams</strong></span> in a package, navigate to the package&#8217;s root folder (or any sub-folder under it) and run the following command.</p>
<div class="pre_wrapper lang-terminal">
<pre class="programlisting prettyprint lang-terminal">elastic-package test pipeline --data-streams &lt;data stream 1&gt;[,&lt;data stream 2&gt;,...]</pre>
</div>
<p>Finally, when you are done running all pipeline tests, bring down the Elastic Stack. This corresponds to step 4 as described in the <a class="xref" href="pipeline-testing.html#pipeline-concepts" title="Conceptual process">Conceptual-process</a> section.</p>
<div class="pre_wrapper lang-terminal">
<pre class="programlisting prettyprint lang-terminal">elastic-package stack down</pre>
</div>
</div>
<div class="navfooter">
<span class="prev">
<a href="asset-testing.html">« Asset testing</a>
</span>
<span class="next">
<a href="static-testing.html">Static testing »</a>
</span>
</div>
</div>
</body>
</html>
