<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Task Manager | Kibana Guide [7.12] | Elastic</title>
<link rel="home" href="index.html" title="Kibana Guide [7.12]"/>
<link rel="up" href="production.html" title="Use Kibana in a production environment"/>
<link rel="prev" href="alerting-production-considerations.html" title="Alerting production considerations"/>
<link rel="next" href="task-manager-health-monitoring.html" title="Task Manager health monitoring"/>
<meta name="DC.type" content="Learn/Docs/Kibana/Reference/7.12"/>
<meta name="DC.subject" content="Kibana"/>
<meta name="DC.identifier" content="7.12"/>
</head>
<body><div class="page_header">
You are looking at preliminary documentation for a future release.
Not what you want? See the
<a href="../current/index.html">current release documentation</a>.
</div>
<div id="content">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="index.html">Kibana Guide [7.12]</a></span>
»
<span class="breadcrumb-link"><a href="production.html">Use Kibana in a production environment</a></span>
»
<span class="breadcrumb-node">Task Manager</span>
</div>
<div class="navheader">
<span class="prev">
<a href="alerting-production-considerations.html">« Alerting production considerations</a>
</span>
<span class="next">
<a href="task-manager-health-monitoring.html">Task Manager health monitoring »</a>
</span>
</div>
<div class="chapter xpack">
<div class="titlepage"><div><div>
<h2 class="title"><a id="task-manager-production-considerations"></a>Task Manager<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/kibana/edit/7.12/docs/user/production-considerations/task-manager-production-considerations.asciidoc">edit</a><a class="xpack_tag" href="/subscriptions"></a></h2>
</div></div></div>
<p>Kibana Task Manager is leveraged by features such as Alerting, Actions, and Reporting to run mission critical work as persistent background tasks.
These background tasks distribute work across multiple Kibana instances.
This has three major benefits:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<span class="strong strong"><strong>Persistence</strong></span>: All task state and scheduling is stored in Elasticsearch, so if you restart Kibana, tasks will pick up where they left off.
</li>
<li class="listitem">
<span class="strong strong"><strong>Scaling</strong></span>: Multiple Kibana instances can read from and update the same task queue in Elasticsearch, allowing the work load to be distributed across instances. If a Kibana instance no longer has capacity to run tasks, you can increase capacity by adding additional Kibana instances.
</li>
<li class="listitem">
<span class="strong strong"><strong>Load Balancing</strong></span>: Task Manager is equipped with a reactive self-healing mechanism, which allows it to reduce the amount of work it executes in reaction to an increased load related error rate in Elasticsearch. Additionally, when Task Manager experiences an increase in recurring tasks, it attempts to space out the work to better balance the load.
</li>
</ul>
</div>
<div class="important admon">
<div class="icon"></div>
<div class="admon_content">
<pre class="literallayout">Task definitions for alerts and actions are stored in the index specified by &lt;&lt;task-manager-settings, `xpack.task_manager.index`&gt;&gt;.
The default is `.kibana_task_manager`.</pre>

<pre class="literallayout">You must have at least one replica of this index for production deployments.
If you lose this index, all scheduled alerts and actions are lost.</pre>

</div>
</div>
<h3><a id="task-manager-background-tasks"></a>Running background tasks<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/kibana/edit/7.12/docs/user/production-considerations/task-manager-production-considerations.asciidoc">edit</a></h3>
<p>Kibana background tasks are managed as follows:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
An Elasticsearch task index is polled for overdue tasks at 3-second intervals. You can change this interval using the <a class="xref" href="task-manager-settings-kb.html#task-manager-settings" title="Task Manager settings"><code class="literal">xpack.task_manager.poll_interval</code></a> setting.
</li>
<li class="listitem">
Tasks are claimed by updating them in the Elasticsearch index, using optimistic concurrency control to prevent conflicts. Each Kibana instance can run a maximum of 10 concurrent tasks, so a maximum of 10 tasks are claimed each interval.
</li>
<li class="listitem">
Tasks are run on the Kibana server.
</li>
<li class="listitem">
<p>Task Manager ensures that tasks:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
Are only executed once
</li>
<li class="listitem">
Are retried when they fail (if configured to do so)
</li>
<li class="listitem">
Are rescheduled to run again at a future point in time (if configured to do so)
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="important admon">
<div class="icon"></div>
<div class="admon_content">
<p>It is possible for tasks to run late or at an inconsistent schedule.</p>
<p>This is usually a symptom of the specific usage or scaling strategy of the cluster in question.</p>
<p>To address these issues, tweak the Kibana Task Manager settings or the cluster scaling strategy to better suit the unique use case.</p>
<p>For details on the settings that can influence the performance and throughput of Task Manager, see <a class="xref" href="task-manager-settings-kb.html" title="Task Manager settings in Kibana">Task Manager Settings</a>.</p>
<p>For detailed troubleshooting guidance, see <a class="xref" href="task-manager-troubleshooting.html" title="Task Manager troubleshooting">Troubleshooting</a>.</p>
</div>
</div>
<h3><a id="_deployment_considerations"></a>Deployment considerations<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/kibana/edit/7.12/docs/user/production-considerations/task-manager-production-considerations.asciidoc">edit</a></h3>
<p>Elasticsearch and Kibana instances use the system clock to determine the current time. To ensure schedules are triggered when expected, synchronize the clocks of all nodes in the cluster using a time service such as <a href="http://www.ntp.org/" class="ulink" target="_top">Network Time Protocol</a>.</p>
<h3><a id="task-manager-scaling-guidance"></a>Scaling guidance<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/kibana/edit/7.12/docs/user/production-considerations/task-manager-production-considerations.asciidoc">edit</a></h3>
<p>How you deploy Kibana largely depends on your use case. Predicting the throughout a deployment might require to support Task Management is difficult because features can schedule an unpredictable number of tasks at a variety of scheduled cadences.</p>
<p>However, there is a relatively straight forward method you can follow to produce a rough estimate based on your expected usage.</p>
<h4><a id="task-manager-default-scaling"></a>Default scale<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/kibana/edit/7.12/docs/user/production-considerations/task-manager-production-considerations.asciidoc">edit</a></h4>
<p>By default, Kibana polls for tasks at a rate of 10 tasks every 3 seconds.
This means that you can expect a single Kibana instance to support up to 200 <em>tasks per minute</em> (<code class="literal">200/tpm</code>).</p>
<p>In practice, a Kibana instance will only achieve the upper bound of <code class="literal">200/tpm</code> if the duration of task execution is below the polling rate of 3 seconds. For the most part, the duration of tasks is below that threshold, but it can vary greatly as Elasticsearch and Kibana usage grow and task complexity increases (such as alerts executing heavy queries across large datasets).</p>
<p>By <a class="xref" href="task-manager-troubleshooting.html#task-manager-health-evaluate-the-workload" title="Evaluate the Workload">evaluating the workload</a>, you can make a rough estimate as to the required throughput as a <em>tasks per minute</em> measurement.</p>
<p>For example, suppose your current workload reveals a required throughput of <code class="literal">440/tpm</code>.  You can address this scale by provisioning 3 Kibana instances, with an upper throughput of <code class="literal">600/tpm</code>. This scale would provide aproximately 25% additional capacity to handle ad-hoc non-recurring tasks and potential growth in recurring tasks.</p>
<p>It is highly recommended that you maintain at least 20% additional capacity, beyond your expected workload, as spikes in ad-hoc tasks is possible at times of high activity (such as a spike in actions in response to an active alert).</p>
<p>For details on monitoring the health of Kibana Task Manager, follow the guidance in <a class="xref" href="task-manager-health-monitoring.html" title="Task Manager health monitoring">Health monitoring</a>.</p>
<h4><a id="task-manager-scaling-horizontally"></a>Scaling horizontally<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/kibana/edit/7.12/docs/user/production-considerations/task-manager-production-considerations.asciidoc">edit</a></h4>
<p>At times, the sustainable approach might be to expand the throughput of your cluster by provisioning additional Kibana instances.
By default, each additional Kibana instance will add an additional 10 tasks that your cluster can run concurrently, but you can also scale each Kibana instance vertically, if your diagnosis indicates that they can handle the additional workload.</p>
<h4><a id="task-manager-scaling-vertically"></a>Scaling vertically<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/kibana/edit/7.12/docs/user/production-considerations/task-manager-production-considerations.asciidoc">edit</a></h4>
<p>Other times it, might be preferable to increase the throughput of individual Kibana instances.</p>
<p>Tweak the <span class="strong strong"><strong>Max Workers</strong></span> via the <a class="xref" href="task-manager-settings-kb.html#task-manager-settings" title="Task Manager settings"><code class="literal">xpack.task_manager.max_workers</code></a> setting, which allows each Kibana to pull a higher number of tasks per interval. This could impact the performance of each Kibana instance as the workload will be higher.</p>
<p>Tweak the <span class="strong strong"><strong>Poll Interval</strong></span> via the <a class="xref" href="task-manager-settings-kb.html#task-manager-settings" title="Task Manager settings"><code class="literal">xpack.task_manager.poll_interval</code></a> setting, which allows each Kibana to pull scheduled tasks at a higher rate.  This could impact the performance of the Elasticsearch cluster as the workload will be higher.</p>
<h4><a id="task-manager-choosing-scaling-strategy"></a>Choosing a scaling strategy<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/kibana/edit/7.12/docs/user/production-considerations/task-manager-production-considerations.asciidoc">edit</a></h4>
<p>Each scaling strategy comes with its own considerations, and the appropriate strategy largely depends on your use case.</p>
<p>Scaling Kibana instances vertically causes higher resource usage in each Kibana instance, as it will perform more concurrent work.
Scaling Kibana instances horizontally requires a higher degree of coordination, which can impact overall performance.</p>
<p>A recommended strategy is to follow these steps:</p>
<div class="olist orderedlist">
<ol class="orderedlist">
<li class="listitem">
Produce a <a class="xref" href="task-manager-production-considerations.html#task-manager-rough-throughput-estimation" title="Rough throughput estimation">rough throughput estimate</a> as a guide to provisioning as many Kibana instances as needed. Include any growth in tasks that you predict experiencing in the near future, and a buffer to better address ad-hoc tasks.
</li>
<li class="listitem">
After provisioning a deployment, assess whether the provisioned Kibana instances achieve the required throughput by evaluating the <a class="xref" href="task-manager-health-monitoring.html" title="Task Manager health monitoring">Health monitoring</a> as described in <a class="xref" href="task-manager-troubleshooting.html#task-manager-theory-insufficient-throughput">Insufficient throughtput to handle the scheduled workload</a>.
</li>
<li class="listitem">
If the throughput is insufficient, and Kibana instances exhibit low resource usage, incrementally scale vertically while <a class="xref" href="kibana-page.html" title="Kibana Monitoring Metrics">monitoring</a> the impact of these changes.
</li>
<li class="listitem">
If the throughput is insufficient, and Kibana instances are exhibiting high resource usage, incrementally scale horizontally by provisioning new Kibana instances and reassess.
</li>
</ol>
</div>
<p>Task Manager, like the rest of the Elastic Stack, is designed to scale horizontally. Take advantage of this ability to ensure mission critical services, such as Alerting and Reporting, always have the capacity they need.</p>
<p>Scaling horizontally requires a higher degree of coordination between Kibana instances. One way Task Manager coordinates with other instances is by delaying its polling schedule to avoid conflicts with other instances.
By using <a class="xref" href="task-manager-health-monitoring.html" title="Task Manager health monitoring">health monitoring</a> to evaluate the <a class="xref" href="task-manager-troubleshooting.html#task-manager-health-evaluate-the-runtime" title="Evaluate the Runtime">date of the <code class="literal">last_polling_delay</code></a> across a deployment, you can estimate the frequency at which Task Manager resets its delay mechanism.
A higher frequency suggests Kibana instances conflict at a high rate, which you can address by scaling vertically rather than horizontally, reducing the required coordination.</p>
<h4><a id="task-manager-rough-throughput-estimation"></a>Rough throughput estimation<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/kibana/edit/7.12/docs/user/production-considerations/task-manager-production-considerations.asciidoc">edit</a></h4>
<p>Predicting the required throughput a deployment might need to support Task Management is difficult, as features can schedule an unpredictable number of tasks at a variety of scheduled cadences.
However, a rough lower bound can be estimated, which is then used as a guide.</p>
<p>Throughput is best thought of as a measurements in tasks per minute.</p>
<p>A default Kibana instance can support up to <code class="literal">200/tpm</code>.</p>
<p>Given a deployment of 100 recurring tasks, estimating the required throughput depends on the scheduled cadence.
Suppose you expect to run 50 tasks at a cadence of <code class="literal">10s</code>, the other 50 tasks at <code class="literal">20m</code>. In addition, you expect a couple dozen non-recurring tasks every minute.</p>
<p>A non-recurring task requires a single execution, which means that a single Kibana instance could execute all 100 tasks in less than a minute, using only half of its capacity. As these tasks are only executed once, the Kibana instance will sit idle once all tasks are executed.
For that reason, don&#8217;t include non-recurring tasks in your <em>tasks per minute</em> calculation. Instead, include a buffer in the final <em>lower bound</em> to incur the cost of ad-hoc non-recurring tasks.</p>
<p>A recurring task requires as many executions as its cadence can fit in a minute. A recurring task with a <code class="literal">10s</code> schedule will require <code class="literal">6/tpm</code>, as it will execute 6 times per minute. A recurring task with a <code class="literal">20m</code> schedule only executes 3 times per hour and only requires a throughput of <code class="literal">0.05/tpm</code>, a number so small it that is difficult to take it into account.</p>
<p>For this reason, we recommend grouping tasks by <em>tasks per minute</em> and <em>tasks per hour</em>, as demonstrated in <a class="xref" href="task-manager-troubleshooting.html#task-manager-health-evaluate-the-workload" title="Evaluate the Workload">Evaluate your workload</a>, averaging the <em>per hour</em> measurement across all minutes.</p>
<p>Given the predicted workload, you can estimate a lower bound throughput of <code class="literal">340/tpm</code> (<code class="literal">6/tpm</code> * 50 + <code class="literal">3/tph</code> * 50 + 20% buffer).
As a default, a Kibana instance provides a throughput of <code class="literal">200/tpm</code>. A good starting point for your deployment is to provision 2 Kibana instances. You could then monitor their performance and reassess as the required throughput becomes clearer.</p>
<p>Although this is a <em>rough</em> estimate, the  <em>tasks per minute</em> provides the lower bound needed to execute tasks on time.
Once you calculate the rough <em>tasks per minute</em> estimate, add a 20% buffer for non-recurring tasks. How much of a buffer is required largely depends on your use case, so <a class="xref" href="task-manager-troubleshooting.html#task-manager-health-evaluate-the-workload" title="Evaluate the Workload">evaluate your workload</a> as it grows to ensure enough of a buffer is provisioned.</p>


</div>
<div class="navfooter">
<span class="prev">
<a href="alerting-production-considerations.html">« Alerting production considerations</a>
</span>
<span class="next">
<a href="task-manager-health-monitoring.html">Task Manager health monitoring »</a>
</span>
</div>
</div>
</body>
</html>
