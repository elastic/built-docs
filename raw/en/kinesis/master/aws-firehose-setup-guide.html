<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Amazon Kinesis Data Firehose setup guide | Amazon Kinesis Data Firehose Ingest Guide | Elastic</title>
<meta class="elastic" name="content" content="Amazon Kinesis Data Firehose setup guide | Amazon Kinesis Data Firehose Ingest Guide">

<link rel="home" href="index.html" title="Amazon Kinesis Data Firehose Ingest Guide"/>
<link rel="up" href="index.html" title="Amazon Kinesis Data Firehose Ingest Guide"/>
<link rel="prev" href="aws-firehose.html" title="Amazon Kinesis Data Firehose overview"/>
<link rel="next" href="aws-firehose-troubleshooting.html" title="Amazon Kinesis Data Firehose troubleshooting"/>
<meta class="elastic" name="product_version" content="master"/>
<meta class="elastic" name="product_name" content="cloud native ingest"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/Cloud Native Ingest/Reference"/>
<meta name="DC.subject" content="cloud native ingest"/>
<meta name="DC.identifier" content="master"/>
</head>
<body>
<div id="content">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Amazon Kinesis Data Firehose Ingest Guide</a></span>
</div>
<div class="navheader">
<span class="prev">
<a href="aws-firehose.html">« Amazon Kinesis Data Firehose overview</a>
</span>
<span class="next">
<a href="aws-firehose-troubleshooting.html">Amazon Kinesis Data Firehose troubleshooting »</a>
</span>
</div>
<div class="chapter">
<div class="titlepage"><div><div>
<h1 class="title"><a id="aws-firehose-setup-guide"></a>Amazon Kinesis Data Firehose setup guide<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/observability-docs/edit/main/docs/en/aws-firehose/aws-firehose-setup.asciidoc">edit</a></h1>
</div></div></div>

<div class="warning admon">
<div class="icon"></div>
<div class="admon_content">
<p>This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.</p>
</div>
</div>
<h3><a id="aws-firehose-prerequisites"></a>Prerequisites<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/observability-docs/edit/main/docs/en/aws-firehose/aws-firehose-setup.asciidoc">edit</a></h3>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
You have an AWS account where you can create a Firehose delivery stream.
</li>
<li class="listitem">
You have a deployment in Elastic Cloud running Elastic Stack version 7.17 or greater on AWS.
</li>
</ul>
</div>
<h3><a id="aws-firehose-limitations"></a>Limitations<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/observability-docs/edit/main/docs/en/aws-firehose/aws-firehose-setup.asciidoc">edit</a></h3>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<p>When using <a href="/integrations" class="ulink" target="_top">Elastic integrations</a> with Firehose, only a single log type may be sent per delivery stream, e.g. VPC Flow Logs.
This is due to how Firehose records are routed into <a href="/guide/en/elasticsearch/reference/master/data-streams.html" class="ulink" target="_top">data streams</a> in Elasticsearch.</p>
<p>It is possible to combine multiple log types in one delivery stream, but this will preclude the use of Elastic integrations (by default all Firehose logs are sent to the <code class="literal">logs-generic-default</code> data stream).</p>
</li>
<li class="listitem">
It is not possible to configure a delivery stream to send data to Elastic Cloud via PrivateLink (VPC endpoint).
This is a current limitation in Firehose, which we are working with AWS to resolve.
</li>
</ul>
</div>
<h3><a id="aws-firehose-instructions"></a>Instructions<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/observability-docs/edit/main/docs/en/aws-firehose/aws-firehose-setup.asciidoc">edit</a></h3>
<div class="olist orderedlist">
<ol class="orderedlist">
<li class="listitem">
<p><a id="aws-firehose-install-integrations"></a> Install the relevant integrations in Kibana.</p>
<p>In order to make the most of your data, install AWS integrations to load index templates, ingest pipelines, and dashboards into Kibana.</p>
<p>In Kibana, navigate to <span class="strong strong"><strong>Management &gt; Integrations</strong></span> in the sidebar.</p>
<p>Find the <span class="strong strong"><strong>AWS</strong></span> integration by searching or browsing the catalog.</p>
<div class="imageblock screenshot">
<div class="content">
<img src="images/firehose-integrations-page.png" alt="Integrations catalogue with the &quot;AWS&quot; integration highlighted">
</div>
</div>
<p>Navigate to the <span class="strong strong"><strong>Settings</strong></span> tab and click <span class="strong strong"><strong>Install AWS assets</strong></span>.
Confirm by clicking <span class="strong strong"><strong>Install AWS</strong></span> in the popup.</p>
<div class="imageblock screenshot">
<div class="content">
<img src="images/firehose-integrations-install-assets.png" alt="AWS integration settings page with the &quot;Install AWS assets&quot; button highlighted">
</div>
</div>
</li>
<li class="listitem">
<p><a id="aws-firehose-create-delivery-stream"></a> Create a delivery stream in Amazon Kinesis Data Firehose.</p>
<p>Sign into the AWS console and navigate to Amazon Kinesis.
Click <span class="strong strong"><strong>Create delivery stream</strong></span>.</p>
<div class="imageblock screenshot">
<div class="content">
<img src="images/firehose-create-delivery-stream.png" alt="Amazon Kinesis dashboard with the &quot;Create delivery stream&quot; button highlighted">
</div>
</div>
<p>Configure the delivery stream using the following settings:</p>
<h4><a id="aws-firehose-config-source-and-destination"></a>Choose source and destination<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/observability-docs/edit/main/docs/en/aws-firehose/aws-firehose-setup.asciidoc">edit</a></h4>
<p>Unless you are streaming data from Kinesis Data Streams, set source to <span class="strong strong"><strong>Direct PUT</strong></span> (see <a class="xref" href="aws-firehose-setup-guide.html#aws-firehose-send-data-to-delivery-stream"><em>Setup guide</em></a> for more details on data sources).</p>
<p>Set destination to <span class="strong strong"><strong>Elastic</strong></span>.</p>
<h4><a id="aws-firehose-config-delivery-stream-name"></a>Delivery stream name<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/observability-docs/edit/main/docs/en/aws-firehose/aws-firehose-setup.asciidoc">edit</a></h4>
<p>Provide a meaningful name that will allow you to identify this delivery stream later.</p>
<h4><a id="aws-firehose-config-transform-records"></a>Transform records - optional<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/observability-docs/edit/main/docs/en/aws-firehose/aws-firehose-setup.asciidoc">edit</a></h4>
<p>For advanced use cases, source records can be transformed by invoking a custom Lambda function.
When using Elastic integrations, this should not be required.</p>
<div class="imageblock screenshot">
<div class="content">
<img src="images/firehose-config-1.png" alt="Amazon Kinesis Data Firehose delivery stream settings showing 'Choose source and destination'" width="Delivery stream name" height="and 'Transform records' sections">
</div>
</div>
<h4><a id="aws-firehose-config-destination-settings"></a>Destination settings<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/observability-docs/edit/main/docs/en/aws-firehose/aws-firehose-setup.asciidoc">edit</a></h4>
<p>Set <span class="strong strong"><strong>Elastic endpoint URL</strong></span> to point to your Elasticsearch cluster running in Elastic Cloud.
This endpoint can be found in the <a href="https://cloud.elastic.co?baymax=docs-body&amp;elektra=docs" class="ulink" target="_top">Elastic Cloud console</a>.
An example is <code class="literal">\https://my-deployment-28u274.es.eu-west-1.aws.found.io</code>.</p>
<p><span class="strong strong"><strong>API key</strong></span> should be a Base64 encoded Elastic API key, which can be created in Kibana by following the instructions under <a href="/guide/en/kibana/master/api-keys.html" class="ulink" target="_top">API Keys</a>.
If you are using an API key with “Restrict privileges”, be sure to review the <a href="/guide/en/elasticsearch/reference/master/security-privileges.html#privileges-list-indices" class="ulink" target="_top">Indices privileges</a> to provide at least  "auto_configure" &amp; "write" permissions for the indices you will be using with this delivery stream.</p>
<p>We recommend leaving <span class="strong strong"><strong>Content encoding</strong></span> set to <span class="strong strong"><strong>GZIP</strong></span> for improved network efficiency.</p>
<p><span class="strong strong"><strong>Retry duration</strong></span> determines how long Firehose continues retrying the request in the event of an error.
A duration of 60-300s should be suitable for most use cases.</p>
<p><span class="strong strong"><strong>Parameters</strong></span>:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<p>When using Elastic integrations, setting the <span class="strong strong"><strong><code class="literal">es_datastream_name</code></strong></span> parameter is required.</p>
<p>Elastic integrations use data streams with specific naming conventions, and Firehose records need to be routed to the relevant data stream to use preconfigured index mappings, ingest pipelines, and dashboards.</p>
<p><em>A separate Firehose delivery stream is required for each log type in AWS to make use of Elastic integrations.</em></p>
<p>The following is a list of common AWS log types and the <span class="strong strong"><strong><code class="literal">es_datastream_name</code></strong></span> value that needs to be set to route the logs to the correct integration.</p>
<div class="informaltable">
<table border="1" cellpadding="4px">
<colgroup>
<col class="col_1"/>
<col class="col_2"/>
</colgroup>
<thead>
<tr>
<th align="left" valign="top">AWS log type</th>
<th align="left" valign="top"><span class="strong strong"><strong><code class="literal">es_datastream_name</code></strong></span> value</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" valign="top"><p><a href="https://docs.elastic.co/en/integrations/aws/cloudfront" class="ulink" target="_top">Cloudfront</a></p></td>
<td align="left" valign="top"><p><code class="literal">logs-aws.cloudfront_logs-default</code></p></td>
</tr>
<tr>
<td align="left" valign="top"><p><a href="https://docs.elastic.co/en/integrations/aws/ec2" class="ulink" target="_top">EC2 (via Cloudwatch)</a></p></td>
<td align="left" valign="top"><p><code class="literal">logs-aws.ec2_logs-default</code></p></td>
</tr>
<tr>
<td align="left" valign="top"><p><a href="https://docs.elastic.co/en/integrations/aws/elb" class="ulink" target="_top">ELB</a></p></td>
<td align="left" valign="top"><p><code class="literal">logs-aws.elb_logs-default</code></p></td>
</tr>
<tr>
<td align="left" valign="top"><p><a href="https://docs.elastic.co/en/integrations/aws/firewall" class="ulink" target="_top">Network firewall</a></p></td>
<td align="left" valign="top"><p><code class="literal">logs-aws.firewall_logs-default</code></p></td>
</tr>
<tr>
<td align="left" valign="top"><p><a href="https://docs.elastic.co/en/integrations/aws/route53" class="ulink" target="_top">Route 53 public DNS queries</a></p></td>
<td align="left" valign="top"><p><code class="literal">logs-aws.route53_public_logs-default</code></p></td>
</tr>
<tr>
<td align="left" valign="top"><p><a href="https://docs.elastic.co/en/integrations/aws/route53" class="ulink" target="_top">Route 53 resolver queries</a></p></td>
<td align="left" valign="top"><p><code class="literal">logs-aws.route53_resolver_logs-default</code></p></td>
</tr>
<tr>
<td align="left" valign="top"><p><a href="https://docs.elastic.co/en/integrations/aws/s3" class="ulink" target="_top">S3 server access</a></p></td>
<td align="left" valign="top"><p><code class="literal">logs-aws.s3access-default</code></p></td>
</tr>
<tr>
<td align="left" valign="top"><p><a href="https://docs.elastic.co/en/integrations/aws/vpcflow" class="ulink" target="_top">VPC Flow Logs</a></p></td>
<td align="left" valign="top"><p><code class="literal">logs-aws.vpcflow-default</code></p></td>
</tr>
<tr>
<td align="left" valign="top"><p><a href="https://docs.elastic.co/en/integrations/aws/waf" class="ulink" target="_top">WAF</a></p></td>
<td align="left" valign="top"><p><code class="literal">logs-aws.waf-default</code></p></td>
</tr>
</tbody>
</table>
</div>
<p>As per the <a href="/guide/en/fleet/master/data-streams.html#data-streams-naming-scheme" class="ulink" target="_top">data stream naming conventions</a>, the "namespace" is a user-configurable arbitrary grouping and can be changed from <code class="literal">default</code> to fit your use case. For example, you may want to organize WAF Logs per environment into <code class="literal">logs-aws.waf-production</code> and <code class="literal">logs-aws.waf-qa</code> data streams for more granular control over rollover, retention, and security permissions.</p>
<p>For log types not listed above, review the relevant <a href="https://docs.elastic.co/integrations/aws" class="ulink" target="_top">integration documentation</a> to determine the correct <span class="strong strong"><strong><code class="literal">es_datastream_name</code></strong></span> value.
The data stream components can be found in the example event for each integration.</p>
<div class="imageblock screenshot">
<div class="content">
<img src="images/firehose-integration-data-stream.png" alt="AWS WAF integration documentation showing a sample event with the data stream components highlighted">
</div>
</div>
</li>
<li class="listitem">
The <span class="strong strong"><strong><code class="literal">include_cw_extracted_fields</code></strong></span> parameter is optional and can be set when using a CloudWatch logs subscription filter as the Firehose data source.
When set to <code class="literal">true</code>, extracted fields generated by the filter pattern in the subscription filter will be collected.
Setting this parameter can add many fields into each record and <em>may significantly increase data volume in Elasticsearch</em>.
As such, use of this parameter should be carefully considered and used only when the extracted fields are required for specific filtering and/or aggregation.
</li>
<li class="listitem">
<p>The <span class="strong strong"><strong><code class="literal">include_event_original</code></strong></span> field is optional and <em>should only be used for debugging purposes</em>.
When set to <code class="literal">true</code>, each log record will contain an additional field named <code class="literal">event.original</code>, which contains the raw (unprocessed) log message.
This parameter will increase the data volume in Elasticsearch and should be used with care.</p>
<p>Elastic requires a <span class="strong strong"><strong>Buffer size</strong></span> of 1MiB to avoid exceeding the Elasticsearch <code class="literal">http.max_content_length</code> setting (typically 100MB) when the buffer is uncompressed.</p>
<p>The default <span class="strong strong"><strong>Buffer interval</strong></span> of 60s is recommended to ensure data freshness in Elastic.</p>
<div class="imageblock screenshot">
<div class="content">
<img src="images/firehose-config-2.png" alt="Amazon Kinesis Data Firehose delivery stream settings showing 'Destination settings' section">
</div>
</div>
</li>
</ul>
</div>
<h4><a id="aws-firehose-config-backup-settings"></a>Backup settings<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/observability-docs/edit/main/docs/en/aws-firehose/aws-firehose-setup.asciidoc">edit</a></h4>
<p>It&#8217;s recommended to configure S3 backup for failed records.
It&#8217;s then possible to configure workflows to automatically re-try failed records, for example using <a href="/guide/en/observability/master/aws-elastic-serverless-forwarder.html" class="ulink" target="_top">Elastic Serverless Forwarder</a>.</p>
<div class="imageblock screenshot">
<div class="content">
<img src="images/firehose-config-3.png" alt="Amazon Kinesis Data Firehose delivery stream settings showing 'Backup settings' section">
</div>
</div>
<p>Whilst Firehose guarantees at-least-once delivery of data to the destination, if your data is highly sensitive, it&#8217;s also recommended to backup all records to S3 in case there are any ingest issues in Elasticsearch.</p>
</li>
<li class="listitem">
<p><a id="aws-firehose-send-data-to-delivery-stream"></a> Send data to the Firehose delivery stream.</p>
<p>Consult the <a href="https://docs.aws.amazon.com/firehose/latest/dev/basic-write.html" class="ulink" target="_top">AWS documentation</a> for details on how to configure a variety of log sources to send data to Firehose delivery streams.</p>
<p>Several services support writing data directly to delivery streams, including Cloudwatch logs.
In addition, there are other ways to create streaming data pipelines to Firehose, e.g. <a href="https://aws.amazon.com/blogs/big-data/streaming-data-from-amazon-s3-to-amazon-kinesis-data-streams-using-aws-dms/" class="ulink" target="_top">using AWS DMS</a>.</p>
<p>An example workflow for sending VPC Flow Logs to Firehose would be:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
Publish VPC Flow Logs to a Cloudwatch log group. To learn how, refer to the <a href="https://docs.aws.amazon.com/vpc/latest/userguide/flow-logs-cwl.html" class="ulink" target="_top">AWS documentation about publishing flow logs</a>.
</li>
<li class="listitem">
Create a subscription filter in the CloudWatch log group to the Firehose delivery stream. To learn how, refer to the <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/SubscriptionFilters.html#FirehoseExample" class="ulink" target="_top">AWS documentation about using subscription filters</a>.
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
<div class="navfooter">
<span class="prev">
<a href="aws-firehose.html">« Amazon Kinesis Data Firehose overview</a>
</span>
<span class="next">
<a href="aws-firehose-troubleshooting.html">Amazon Kinesis Data Firehose troubleshooting »</a>
</span>
</div>
</div>
</body>
</html>
