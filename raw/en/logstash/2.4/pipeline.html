<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Logstash Processing Pipeline | Logstash Reference [2.4] | Elastic</title>
<meta class="elastic" name="content" content="Logstash Processing Pipeline | Logstash Reference [2.4]">

<link rel="home" href="index.html" title="Logstash Reference [2.4]"/>
<link rel="up" href="getting-started-with-logstash.html" title="Getting Started with Logstash"/>
<link rel="prev" href="stalled-shutdown.html" title="Stalled Shutdown Detection"/>
<link rel="next" href="breaking-changes.html" title="Breaking Changes"/>
<meta class="elastic" name="product_version" content="2.4"/>
<meta class="elastic" name="product_name" content="Logstash"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/Logstash/Reference/2.4"/>
<meta name="DC.subject" content="Logstash"/>
<meta name="DC.identifier" content="2.4"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body>
<div class="page_header">
<strong>IMPORTANT</strong>: No additional bug fixes or documentation updates
will be released for this version. For the latest information, see the
<a href="../current/index.html">current release documentation</a>.
</div>
<div class="navheader">
<span class="prev">
<a href="stalled-shutdown.html">« Stalled Shutdown Detection</a>
</span>
<span class="next">
<a href="breaking-changes.html">Breaking Changes »</a>
</span>
</div>
<div class="book" lang="en">
<div class="titlepage">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Logstash Reference [2.4]</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="getting-started-with-logstash.html">Getting Started with Logstash</a></span>
</div>
<div>
<div><h1 class="title"><a id="id-1"></a>Logstash Processing Pipeline</h1><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/logstash/edit/master/docs/static/life-of-an-event.asciidoc">edit</a></div>
</div>
<!--EXTRA-->
</div>
<div id="content">
<div id="url-to-v3" class="version-warning">
    <strong>IMPORTANT</strong>: This documentation is no longer updated. Refer to <a href="https://www.elastic.co/support/eol">Elastic's version policy</a> and the <a href="https://www.elastic.co/docs/reference/logstash/how-logstash-works">latest documentation</a>.
</div>
<div class="section">
<div class="titlepage"><div><div>
<div class="position-relative"><h2 class="title"><a id="pipeline"></a>Logstash Processing Pipeline</h2><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/logstash/edit/master/docs/static/life-of-an-event.asciidoc">edit</a></div>
</div></div></div>
<p>The Logstash event processing pipeline has three stages: inputs &#8594; filters &#8594;
outputs. Inputs generate events, filters modify them, and outputs ship them
elsewhere. Inputs and outputs support codecs that enable you to encode or decode
the data as it enters or exits the pipeline without having to use a separate
filter.</p>
<div class="position-relative"><h4><a id="_inputs"></a>Inputs</h4><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/logstash/edit/master/docs/static/life-of-an-event.asciidoc">edit</a></div>
<p>You use inputs to get data into Logstash. Some of the more commonly-used inputs
are:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<span class="strong strong"><strong>file</strong></span>: reads from a file on the filesystem, much like the UNIX command
<code class="literal">tail -0F</code>
</li>
<li class="listitem">
<span class="strong strong"><strong>syslog</strong></span>: listens on the well-known port 514 for syslog messages and parses
according to the RFC3164 format
</li>
<li class="listitem">
<span class="strong strong"><strong>redis</strong></span>: reads from a redis server, using both redis channels and redis lists.
Redis is often used as a "broker" in a centralized Logstash installation, which
queues Logstash events from remote Logstash "shippers".
</li>
<li class="listitem">
<span class="strong strong"><strong>beats</strong></span>: processes events sent by <a href="/downloads/beats/filebeat" class="ulink" target="_top">Filebeat</a>.
</li>
</ul>
</div>
<p>For more information about the available inputs, see
<a class="xref" href="input-plugins.html" title="Input plugins">Input Plugins</a>.</p>
<div class="position-relative"><h4><a id="_filters"></a>Filters</h4><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/logstash/edit/master/docs/static/life-of-an-event.asciidoc">edit</a></div>
<p>Filters are intermediary processing devices in the Logstash pipeline. You can
combine filters with conditionals to perform an action on an event if it meets
certain criteria. Some useful filters include:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<span class="strong strong"><strong>grok</strong></span>: parse and structure arbitrary text. Grok is currently the best way in
Logstash to parse unstructured log data into something structured and queryable.
With 120 patterns built-in to Logstash, it&#8217;s more than likely you&#8217;ll find one
that meets your needs!
</li>
<li class="listitem">
<span class="strong strong"><strong>mutate</strong></span>: perform general transformations on event fields. You can rename,
remove, replace, and modify fields in your events.
</li>
<li class="listitem">
<span class="strong strong"><strong>drop</strong></span>: drop an event completely, for example, <em>debug</em> events.
</li>
<li class="listitem">
<span class="strong strong"><strong>clone</strong></span>: make a copy of an event, possibly adding or removing fields.
</li>
<li class="listitem">
<span class="strong strong"><strong>geoip</strong></span>: add information about geographical location of IP addresses (also
displays amazing charts in Kibana!)
</li>
</ul>
</div>
<p>For more information about the available filters, see
<a class="xref" href="filter-plugins.html" title="Filter plugins">Filter Plugins</a>.</p>
<div class="position-relative"><h4><a id="_outputs"></a>Outputs</h4><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/logstash/edit/master/docs/static/life-of-an-event.asciidoc">edit</a></div>
<p>Outputs are the final phase of the Logstash pipeline. An event can pass through
multiple outputs, but once all output processing is complete, the event has
finished its execution. Some commonly used outputs include:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<span class="strong strong"><strong>elasticsearch</strong></span>: send event data to Elasticsearch. If you&#8217;re planning to save
your data in an efficient, convenient, and easily queryable format&#8230;&#8203;
Elasticsearch is the way to go. Period. Yes, we&#8217;re biased :)
</li>
<li class="listitem">
<span class="strong strong"><strong>file</strong></span>: write event data to a file on disk.
</li>
<li class="listitem">
<span class="strong strong"><strong>graphite</strong></span>: send event data to graphite, a popular open source tool for
storing and graphing metrics. <a href="http://graphite.readthedocs.io/en/latest/" class="ulink" target="_top">http://graphite.readthedocs.io/en/latest/</a>
</li>
<li class="listitem">
<span class="strong strong"><strong>statsd</strong></span>: send event data to statsd, a service that "listens for statistics,
like counters and timers, sent over UDP and sends aggregates to one or more
pluggable backend services". If you&#8217;re already using statsd, this could be
useful for you!
</li>
</ul>
</div>
<p>For more information about the available outputs, see
<a class="xref" href="output-plugins.html" title="Output plugins">Output Plugins</a>.</p>
<div class="position-relative"><h4><a id="_codecs"></a>Codecs</h4><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/logstash/edit/master/docs/static/life-of-an-event.asciidoc">edit</a></div>
<p>Codecs are basically stream filters that can operate as part of an input or
output. Codecs enable you to easily separate the transport of your messages from
the serialization process. Popular codecs include <code class="literal">json</code>, <code class="literal">msgpack</code>, and <code class="literal">plain</code>
(text).</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<span class="strong strong"><strong>json</strong></span>: encode or decode data in the JSON format.
</li>
<li class="listitem">
<span class="strong strong"><strong>multiline</strong></span>: merge multiple-line text events such as java exception and
stacktrace messages into a single event.
</li>
</ul>
</div>
<p>For more information about the available codecs, see
<a class="xref" href="codec-plugins.html" title="Codec plugins">Codec Plugins</a>.</p>
<div class="position-relative"><h3><a id="_fault_tolerance"></a>Fault Tolerance</h3><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/logstash/edit/master/docs/static/life-of-an-event.asciidoc">edit</a></div>
<p>Logstash keeps all events in main memory during processing. Logstash responds to a SIGTERM by attempting to halt inputs and waiting for pending events to finish processing before shutting down. When the pipeline cannot be flushed due to a stuck output or filter, Logstash waits indefinitely. For example, when a pipeline sends output to a database that is unreachable by the Logstash instance, the instance waits indefinitely after receiving a SIGTERM.</p>
<p>To enable Logstash to detect these situations and terminate with a stalled pipeline, use the <code class="literal">--allow-unsafe-shutdown</code> flag.</p>
<div class="warning admon">
<div class="icon"></div>
<div class="admon_content">
<p>Unsafe shutdowns, force-kills of the Logstash process, or crashes of the Logstash process for any other reason result in data loss. Shut down Logstash safely whenever possible.</p>
</div>
</div>
<div class="position-relative"><h4><a id="_execution_model"></a>Execution Model</h4><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/logstash/edit/master/docs/static/life-of-an-event.asciidoc">edit</a></div>
<p>The Logstash pipeline coordinates the execution of inputs, filters, and outputs. The following schematic sketches the data flow of a pipeline:</p>
<div class="pre_wrapper lang-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js">input threads | pipeline worker threads</pre>
</div>
<p>Pipelines in the current release of Logstash process filtering and output in the same thread. Prior to the 2.2 release of Logstash, filtering and output were distinct stages handled by distinct threads.
This change to the Logstash architecture improves performance and enables future persistence capabilities. The new pipeline substantially improves thread liveness, decreases resource usage, and increases throughput. The current Logstash pipeline is a micro-batching pipeline, which is inherently more efficient than a one-at-a-time approach. These efficiencies come in many places, two of the more prominent ones being a reduction in contention and a consequent improvement in thread liveness. These efficiencies are especially noticeable on many-core machines.</p>
<p>Each <code class="literal">input {}</code> statement in the Logstash configuration file runs in its own thread. Inputs write events to a common Java <a href="https://docs.oracle.com/javase/7/docs/api/java/util/concurrent/SynchronousQueue.html" class="ulink" target="_top">SynchronousQueue</a>. This queue holds no events, instead transferring each pushed event to a free worker, blocking if all workers are busy. Each pipeline worker thread takes a batch of events off this queue, creating a buffer per worker, runs the batch of  events through the configured filters, then runs the filtered events through any outputs. The size of the batch and number of pipeline worker threads are configurable. The following pseudocode illustrates the process flow:</p>
<div class="pre_wrapper lang-ruby">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-ruby">synchronous_queue = SynchronousQueue.new
inputs.each do |input|
  Thread.new do
    input.run(synchronous_queue)
  end
end
num_pipeline_workers.times do
  Thread.new do
    while true
      batch = take_batch(synchronous_queue, batch_size, batch_delay)
      output_batch(filter_batch(batch))
    end
  end
end
wait_for_threads_to_terminate()</pre>
</div>
<p>There are three configurable options in the pipeline, <code class="literal">--pipeline-workers</code>, <code class="literal">--pipeline-batch-size</code>, and <code class="literal">--pipeline-batch-delay</code>.
The <code class="literal">--pipeline-workers</code> or <code class="literal">-w</code> parameter determines how many threads to run for filter and output processing. If you find that events are backing up, or that the CPU is not saturated, consider increasing the value of this parameter to make better use of available processing power. Good results can even be found increasing this number past the number of available processors as these threads may spend significant time in an I/O wait state when writing to external systems. Legal values for this parameter are positive integers.</p>
<p>The <code class="literal">--pipeline-batch-size</code> or <code class="literal">-b</code> parameter defines the maximum number of events an individual worker thread collects before attempting to execute filters and outputs. Larger batch sizes are generally more efficient, but increase memory overhead. Some hardware configurations require you to increase JVM heap size by setting the <code class="literal">LS_HEAP_SIZE</code> variable to avoid performance degradation with this option. Values of this parameter in excess of the optimum range cause performance degradation due to frequent garbage collection or JVM crashes related to out-of-memory exceptions. Output plugins can process each batch as a logical unit. The Elasticsearch output, for example, issues <a href="/guide/en/elasticsearch/reference/current/docs-bulk.html" class="ulink" target="_top">bulk requests</a> for each batch received. Tuning the <code class="literal">-b</code> parameter adjusts the size of bulk requests sent to Elasticsearch.</p>
<p>The <code class="literal">--pipeline-batch-delay</code> option rarely needs to be tuned. This option adjusts the latency of the Logstash pipeline. Pipeline batch delay is the maximum amount of time in milliseconds that Logstash waits for new messages after receiving an event in the current pipeline worker thread. After this time elapses, Logstash begins to execute filters and outputs.The maximum time that Logstash waits between receiving an event and processing that event in a filter is the product of the <code class="literal">pipeline_batch_delay</code> and  <code class="literal">pipeline_batch_size</code> settings.</p>
<div class="position-relative"><h4><a id="_notes_on_pipeline_configuration_and_performance"></a>Notes on Pipeline Configuration and Performance</h4><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/logstash/edit/master/docs/static/life-of-an-event.asciidoc">edit</a></div>
<p>The total number of inflight events is determined by the product of the  <code class="literal">pipeline_workers</code> and <code class="literal">pipeline_batch_size</code> parameters. This product is referred to as the <em>inflight count</em>.  Keep the value of the inflight count in mind as you adjust the <code class="literal">pipeline_workers</code> and <code class="literal">pipeline_batch_size</code> parameters. Pipelines that intermittently receive large events at irregular intervals require sufficient memory to handle these spikes. Configure the <code class="literal">LS_HEAP_SIZE</code> option accordingly.</p>
<p>The Logstash defaults are chosen to provide fast, safe performance for most users. To increase performance, increase the number of pipeline workers or the batch size, taking into account the following suggestions:</p>
<p>Measure each change to make sure it increases, rather than decreases, performance.
Ensure that you leave enough memory available to cope with a sudden increase in event size. For example, an application that generates exceptions that are represented as large blobs of text.
The number of workers may be set higher than the number of CPU cores since outputs often spend idle time in I/O wait conditions.</p>
<p>Threads in Java have names and you can use the <code class="literal">jstack</code>, <code class="literal">top</code>, and the VisualVM graphical tools to figure out which resources a given thread uses.</p>
<p>On Linux platforms, Logstash labels all the threads it can with something descriptive. For example, inputs show up as <code class="literal">[base]&lt;inputname</code>, filter/output workers show up as <code class="literal">[base]&gt;workerN</code>, where N is an integer.  Where possible, other threads are also labeled to help you identify their purpose.</p>
<div class="position-relative"><h4><a id="_profiling_the_heap"></a>Profiling the Heap</h4><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/logstash/edit/master/docs/static/life-of-an-event.asciidoc">edit</a></div>
<p>When tuning Logstash you may have to adjust the heap size. You can use the <a href="https://visualvm.java.net/" class="ulink" target="_top">VisualVM</a> tool to profile the heap. The <span class="strong strong"><strong>Monitor</strong></span> pane in particular is useful for checking whether your heap allocation is sufficient for the current workload. The screenshots below show sample <span class="strong strong"><strong>Monitor</strong></span> panes. The first pane examines a Logstash instance configured with too many inflight events. The second pane examines a Logstash instance configured with an appropriate amount of inflight events. Note that the specific batch sizes used here are most likely not applicable to your specific workload, as the memory demands of Logstash vary in large part based on the type of messages you are sending.</p>
<div class="imageblock">
<div class="content">
<img src="static/images/pipeline_overload.png" alt="pipeline overload">
</div>
</div>
<div class="imageblock">
<div class="content">
<img src="static/images/pipeline_correct_load.png" alt="pipeline correct load">
</div>
</div>
<p>In the first example we see that the CPU isn’t being used very efficiently. In fact, the JVM is often times having to stop the VM for “full GCs”. Full garbage collections are a common symptom of excessive memory pressure. This is visible in the spiky pattern on the CPU chart. In the more efficiently configured example, the GC graph pattern is more smooth, and the CPU is used in a more uniform manner. You can also see that there is ample headroom between the allocated heap size, and the maximum allowed, giving the JVM GC a lot of room to work with.</p>
<p>Examining the in-depth GC statistics with a tool similar to the excellent <a href="https://visualvm.java.net/plugins.html" class="ulink" target="_top">VisualGC</a> plugin shows that the over-allocated VM spends very little time in the efficient Eden GC, compared to the time spent in the more resource-intensive Old Gen “Full” GCs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>As long as the GC pattern is acceptable, heap sizes that occasionally increase to the maximum are acceptable. Such heap size spikes happen in response to a burst of large events passing through the pipeline. In general practice, maintain a gap between the used amount of heap memory and the maximum.
This document is not a comprehensive guide to JVM GC tuning. Read the official <a href="http://www.oracle.com/webfolder/technetwork/tutorials/obe/java/gc01/index.html" class="ulink" target="_top">Oracle guide</a> for more information on the topic. We also recommend reading <a href="http://www.semicomplete.com/blog/geekery/debugging-java-performance.html" class="ulink" target="_top">Debugging Java Performance</a>.</p>
</div>
</div>
</div>
</div>
</div><div class="navfooter">
<span class="prev">
<a href="stalled-shutdown.html">« Stalled Shutdown Detection</a>
</span>
<span class="next">
<a href="breaking-changes.html">Breaking Changes »</a>
</span>
</div>
</body>
</html>
