<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Configuration Examples | Logstash Reference [6.1] | Elastic</title>
<link rel="home" href="index.html" title="Logstash Reference [6.1]"/>
<link rel="up" href="filebeat-modules.html" title="Working with Filebeat Modules"/>
<link rel="prev" href="filebeat-modules.html" title="Working with Filebeat Modules"/>
<link rel="next" href="resiliency.html" title="Data Resiliency"/>
<meta name="DC.type" content="Learn/Docs/Logstash/Reference/6.1"/>
<meta name="DC.subject" content="Logstash"/>
<meta name="DC.identifier" content="6.1"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body><div class="page_header">
<strong>IMPORTANT</strong>: No additional bug fixes or documentation updates
will be released for this version. For the latest information, see the
<a href="../current/index.html">current release documentation</a>.
</div>
<div id="content">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="index.html">Logstash Reference [6.1]</a></span>
»
<span class="breadcrumb-link"><a href="filebeat-modules.html">Working with Filebeat Modules</a></span>
»
<span class="breadcrumb-node">Configuration Examples</span>
</div>
<div class="navheader">
<span class="prev">
<a href="filebeat-modules.html">« Working with Filebeat Modules</a>
</span>
<span class="next">
<a href="resiliency.html">Data Resiliency »</a>
</span>
</div>
<div class="section">
<div class="titlepage"><div><div>
<h2 class="title"><a id="logstash-config-for-filebeat-modules"></a>Configuration Examples<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/logstash/edit/6.1/docs/static/filebeat-modules.asciidoc">edit</a></h2>
</div></div></div>
<p>The examples in this section show you how to build Logstash pipelines that parse
data sent collected by Filebeat modules:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<a class="xref" href="logstash-config-for-filebeat-modules.html#parsing-apache2" title="Apache 2 Logs">Apache 2 Logs</a>
</li>
<li class="listitem">
<a class="xref" href="logstash-config-for-filebeat-modules.html#parsing-mysql" title="MySQL Logs">MySQL Logs</a>
</li>
<li class="listitem">
<a class="xref" href="logstash-config-for-filebeat-modules.html#parsing-nginx" title="Nginx Logs">Nginx Logs</a>
</li>
<li class="listitem">
<a class="xref" href="logstash-config-for-filebeat-modules.html#parsing-system" title="System Logs">System Logs</a>
</li>
</ul>
</div>
<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="parsing-apache2"></a>Apache 2 Logs<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/logstash/edit/6.1/docs/static/filebeat-modules.asciidoc">edit</a></h3>
</div></div></div>
<p>The Logstash pipeline configuration in this example shows how to ship and parse
access and error logs collected by the
Filebeatfilebeat-module-apache2.html[<code class="literal">apache2</code> Filebeat module].</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json">input {
  beats {
    port =&gt; 5044
    host =&gt; "0.0.0.0"
  }
}
filter {
  if [fileset][module] == "apache2" {
    if [fileset][name] == "access" {
      grok {
        match =&gt; { "message" =&gt; ["%{IPORHOST:[apache2][access][remote_ip]} - %{DATA:[apache2][access][user_name]} \[%{HTTPDATE:[apache2][access][time]}\] \"%{WORD:[apache2][access][method]} %{DATA:[apache2][access][url]} HTTP/%{NUMBER:[apache2][access][http_version]}\" %{NUMBER:[apache2][access][response_code]} %{NUMBER:[apache2][access][body_sent][bytes]}( \"%{DATA:[apache2][access][referrer]}\")?( \"%{DATA:[apache2][access][agent]}\")?",
          "%{IPORHOST:[apache2][access][remote_ip]} - %{DATA:[apache2][access][user_name]} \\[%{HTTPDATE:[apache2][access][time]}\\] \"-\" %{NUMBER:[apache2][access][response_code]} -" ] }
        remove_field =&gt; "message"
      }
      mutate {
        add_field =&gt; { "read_timestamp" =&gt; "%{@timestamp}" }
      }
      date {
        match =&gt; [ "[apache2][access][time]", "dd/MMM/YYYY:H:m:s Z" ]
        remove_field =&gt; "[apache2][access][time]"
      }
      useragent {
        source =&gt; "[apache2][access][agent]"
        target =&gt; "[apache2][access][user_agent]"
        remove_field =&gt; "[apache2][access][agent]"
      }
      geoip {
        source =&gt; "[apache2][access][remote_ip]"
        target =&gt; "[apache2][access][geoip]"
      }
    }
    else if [fileset][name] == "error" {
      grok {
        match =&gt; { "message" =&gt; ["\[%{APACHE_TIME:[apache2][error][timestamp]}\] \[%{LOGLEVEL:[apache2][error][level]}\]( \[client %{IPORHOST:[apache2][error][client]}\])? %{GREEDYDATA:[apache2][error][message]}",
          "\[%{APACHE_TIME:[apache2][error][timestamp]}\] \[%{DATA:[apache2][error][module]}:%{LOGLEVEL:[apache2][error][level]}\] \[pid %{NUMBER:[apache2][error][pid]}(:tid %{NUMBER:[apache2][error][tid]})?\]( \[client %{IPORHOST:[apache2][error][client]}\])? %{GREEDYDATA:[apache2][error][message1]}" ] }
        pattern_definitions =&gt; {
          "APACHE_TIME" =&gt; "%{DAY} %{MONTH} %{MONTHDAY} %{TIME} %{YEAR}"
        }
        remove_field =&gt; "message"
      }
      mutate {
        rename =&gt; { "[apache2][error][message1]" =&gt; "[apache2][error][message]" }
      }
      date {
        match =&gt; [ "[apache2][error][timestamp]", "EEE MMM dd H:m:s YYYY", "EEE MMM dd H:m:s.SSSSSS YYYY" ]
        remove_field =&gt; "[apache2][error][timestamp]"
      }
    }
  }
}
output {
  elasticsearch {
    hosts =&gt; localhost
    manage_template =&gt; false
    index =&gt; "%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}"
  }
}</pre>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="parsing-mysql"></a>MySQL Logs<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/logstash/edit/6.1/docs/static/filebeat-modules.asciidoc">edit</a></h3>
</div></div></div>
<p>The Logstash pipeline configuration in this example shows how to ship and parse
error and slowlog logs collected by the
Filebeatfilebeat-module-mysql.html[<code class="literal">mysql</code> Filebeat module].</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json">input {
  beats {
    port =&gt; 5044
    host =&gt; "0.0.0.0"
  }
}
filter {
  if [fileset][module] == "mysql" {
    if [fileset][name] == "error" {
      grok {
        match =&gt; { "message" =&gt; ["%{LOCALDATETIME:[mysql][error][timestamp]} (\[%{DATA:[mysql][error][level]}\] )?%{GREEDYDATA:[mysql][error][message]}",
          "%{TIMESTAMP_ISO8601:[mysql][error][timestamp]} %{NUMBER:[mysql][error][thread_id]} \[%{DATA:[mysql][error][level]}\] %{GREEDYDATA:[mysql][error][message1]}",
          "%{GREEDYDATA:[mysql][error][message2]}"] }
        pattern_definitions =&gt; {
          "LOCALDATETIME" =&gt; "[0-9]+ %{TIME}"
        }
        remove_field =&gt; "message"
      }
      mutate {
        rename =&gt; { "[mysql][error][message1]" =&gt; "[mysql][error][message]" }
      }
      mutate {
        rename =&gt; { "[mysql][error][message2]" =&gt; "[mysql][error][message]" }
      }
      date {
        match =&gt; [ "[mysql][error][timestamp]", "ISO8601", "YYMMdd H:m:s" ]
        remove_field =&gt; "[mysql][error][time]"
      }
    }
    else if [fileset][name] == "slowlog" {
      grok {
        match =&gt; { "message" =&gt; ["^# User@Host: %{USER:[mysql][slowlog][user]}(\[[^\]]+\])? @ %{HOSTNAME:[mysql][slowlog][host]} \[(IP:[mysql][slowlog][ip])?\](\s*Id:\s* %{NUMBER:[mysql][slowlog][id]})?\n# Query_time: %{NUMBER:[mysql][slowlog][query_time][sec]}\s* Lock_time: %{NUMBER:[mysql][slowlog][lock_time][sec]}\s* Rows_sent: %{NUMBER:[mysql][slowlog][rows_sent]}\s* Rows_examined: %{NUMBER:[mysql][slowlog][rows_examined]}\n(SET timestamp=%{NUMBER:[mysql][slowlog][timestamp]};\n)?%{GREEDYMULTILINE:[mysql][slowlog][query]}"] }
        pattern_definitions =&gt; {
          "GREEDYMULTILINE" =&gt; "(.|\n)*"
        }
        remove_field =&gt; "message"
      }
      date {
        match =&gt; [ "[mysql][slowlog][timestamp]", "UNIX" ]
      }
      mutate {
        gsub =&gt; ["[mysql][slowlog][query]", "\n# Time: [0-9]+ [0-9][0-9]:[0-9][0-9]:[0-9][0-9](\\.[0-9]+)?$", ""]
      }
    }
  }
}
output {
  elasticsearch {
    hosts =&gt; localhost
    manage_template =&gt; false
    index =&gt; "%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}"
  }
}</pre>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="parsing-nginx"></a>Nginx Logs<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/logstash/edit/6.1/docs/static/filebeat-modules.asciidoc">edit</a></h3>
</div></div></div>
<p>The Logstash pipeline configuration in this example shows how to ship and parse
access and error logs collected by the
Filebeatfilebeat-module-nginx.html[<code class="literal">nginx</code> Filebeat module].</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json">input {
  beats {
    port =&gt; 5044
    host =&gt; "0.0.0.0"
  }
}
filter {
  if [fileset][module] == "nginx" {
    if [fileset][name] == "access" {
      grok {
        match =&gt; { "message" =&gt; ["%{IPORHOST:[nginx][access][remote_ip]} - %{DATA:[nginx][access][user_name]} \[%{HTTPDATE:[nginx][access][time]}\] \"%{WORD:[nginx][access][method]} %{DATA:[nginx][access][url]} HTTP/%{NUMBER:[nginx][access][http_version]}\" %{NUMBER:[nginx][access][response_code]} %{NUMBER:[nginx][access][body_sent][bytes]} \"%{DATA:[nginx][access][referrer]}\" \"%{DATA:[nginx][access][agent]}\""] }
        remove_field =&gt; "message"
      }
      mutate {
        add_field =&gt; { "read_timestamp" =&gt; "%{@timestamp}" }
      }
      date {
        match =&gt; [ "[nginx][access][time]", "dd/MMM/YYYY:H:m:s Z" ]
        remove_field =&gt; "[nginx][access][time]"
      }
      useragent {
        source =&gt; "[nginx][access][agent]"
        target =&gt; "[nginx][access][user_agent]"
        remove_field =&gt; "[nginx][access][agent]"
      }
      geoip {
        source =&gt; "[nginx][access][remote_ip]"
        target =&gt; "[nginx][access][geoip]"
      }
    }
    else if [fileset][name] == "error" {
      grok {
        match =&gt; { "message" =&gt; ["%{DATA:[nginx][error][time]} \[%{DATA:[nginx][error][level]}\] %{NUMBER:[nginx][error][pid]}#%{NUMBER:[nginx][error][tid]}: (\*%{NUMBER:[nginx][error][connection_id]} )?%{GREEDYDATA:[nginx][error][message]}"] }
        remove_field =&gt; "message"
      }
      mutate {
        rename =&gt; { "@timestamp" =&gt; "read_timestamp" }
      }
      date {
        match =&gt; [ "[nginx][error][time]", "YYYY/MM/dd H:m:s" ]
        remove_field =&gt; "[nginx][error][time]"
      }
    }
  }
}
output {
  elasticsearch {
    hosts =&gt; localhost
    manage_template =&gt; false
    index =&gt; "%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}"
  }
}</pre>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="parsing-system"></a>System Logs<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/logstash/edit/6.1/docs/static/filebeat-modules.asciidoc">edit</a></h3>
</div></div></div>
<p>The Logstash pipeline configuration in this example shows how to ship and parse
system logs collected by the
Filebeatfilebeat-module-system.html[<code class="literal">system</code> Filebeat module].</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json">input {
  beats {
    port =&gt; 5044
    host =&gt; "0.0.0.0"
  }
}
filter {
  if [fileset][module] == "system" {
    if [fileset][name] == "auth" {
      grok {
        match =&gt; { "message" =&gt; ["%{SYSLOGTIMESTAMP:[system][auth][timestamp]} %{SYSLOGHOST:[system][auth][hostname]} sshd(?:\[%{POSINT:[system][auth][pid]}\])?: %{DATA:[system][auth][ssh][event]} %{DATA:[system][auth][ssh][method]} for (invalid user )?%{DATA:[system][auth][user]} from %{IPORHOST:[system][auth][ssh][ip]} port %{NUMBER:[system][auth][ssh][port]} ssh2(: %{GREEDYDATA:[system][auth][ssh][signature]})?",
                  "%{SYSLOGTIMESTAMP:[system][auth][timestamp]} %{SYSLOGHOST:[system][auth][hostname]} sshd(?:\[%{POSINT:[system][auth][pid]}\])?: %{DATA:[system][auth][ssh][event]} user %{DATA:[system][auth][user]} from %{IPORHOST:[system][auth][ssh][ip]}",
                  "%{SYSLOGTIMESTAMP:[system][auth][timestamp]} %{SYSLOGHOST:[system][auth][hostname]} sshd(?:\[%{POSINT:[system][auth][pid]}\])?: Did not receive identification string from %{IPORHOST:[system][auth][ssh][dropped_ip]}",
                  "%{SYSLOGTIMESTAMP:[system][auth][timestamp]} %{SYSLOGHOST:[system][auth][hostname]} sudo(?:\[%{POSINT:[system][auth][pid]}\])?: \s*%{DATA:[system][auth][user]} :( %{DATA:[system][auth][sudo][error]} ;)? TTY=%{DATA:[system][auth][sudo][tty]} ; PWD=%{DATA:[system][auth][sudo][pwd]} ; USER=%{DATA:[system][auth][sudo][user]} ; COMMAND=%{GREEDYDATA:[system][auth][sudo][command]}",
                  "%{SYSLOGTIMESTAMP:[system][auth][timestamp]} %{SYSLOGHOST:[system][auth][hostname]} groupadd(?:\[%{POSINT:[system][auth][pid]}\])?: new group: name=%{DATA:system.auth.groupadd.name}, GID=%{NUMBER:system.auth.groupadd.gid}",
                  "%{SYSLOGTIMESTAMP:[system][auth][timestamp]} %{SYSLOGHOST:[system][auth][hostname]} useradd(?:\[%{POSINT:[system][auth][pid]}\])?: new user: name=%{DATA:[system][auth][user][add][name]}, UID=%{NUMBER:[system][auth][user][add][uid]}, GID=%{NUMBER:[system][auth][user][add][gid]}, home=%{DATA:[system][auth][user][add][home]}, shell=%{DATA:[system][auth][user][add][shell]}$",
                  "%{SYSLOGTIMESTAMP:[system][auth][timestamp]} %{SYSLOGHOST:[system][auth][hostname]} %{DATA:[system][auth][program]}(?:\[%{POSINT:[system][auth][pid]}\])?: %{GREEDYMULTILINE:[system][auth][message]}"] }
        pattern_definitions =&gt; {
          "GREEDYMULTILINE"=&gt; "(.|\n)*"
        }
        remove_field =&gt; "message"
      }
      date {
        match =&gt; [ "[system][auth][timestamp]", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss" ]
      }
      geoip {
        source =&gt; "[system][auth][ssh][ip]"
        target =&gt; "[system][auth][ssh][geoip]"
      }
    }
    else if [fileset][name] == "syslog" {
      grok {
        match =&gt; { "message" =&gt; ["%{SYSLOGTIMESTAMP:[system][syslog][timestamp]} %{SYSLOGHOST:[system][syslog][hostname]} %{DATA:[system][syslog][program]}(?:\[%{POSINT:[system][syslog][pid]}\])?: %{GREEDYMULTILINE:[system][syslog][message]}"] }
        pattern_definitions =&gt; { "GREEDYMULTILINE" =&gt; "(.|\n)*" }
        remove_field =&gt; "message"
      }
      date {
        match =&gt; [ "[system][syslog][timestamp]", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss" ]
      }
    }
  }
}
output {
  elasticsearch {
    hosts =&gt; localhost
    manage_template =&gt; false
    index =&gt; "%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}"
  }
}</pre>
</div>
</div>

</div>
<div class="navfooter">
<span class="prev">
<a href="filebeat-modules.html">« Working with Filebeat Modules</a>
</span>
<span class="next">
<a href="resiliency.html">Data Resiliency »</a>
</span>
</div>
</div>
</body>
</html>
