<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Dead Letter Queues (DLQ) | Logstash Reference [7.10] | Elastic</title>
<link rel="home" href="index.html" title="Logstash Reference [7.10]"/>
<link rel="up" href="resiliency.html" title="Data Resiliency"/>
<link rel="prev" href="persistent-queues.html" title="Persistent Queues"/>
<link rel="next" href="transformation.html" title="Transforming Data"/>
<meta name="DC.type" content="Learn/Docs/Logstash/Reference/7.10"/>
<meta name="DC.subject" content="Logstash"/>
<meta name="DC.identifier" content="7.10"/>
</head>
<body><div class="page_header">
You are looking at preliminary documentation for a future release.
Not what you want? See the
<a href="../current/index.html">current release documentation</a>.
</div>
<div id="content">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="index.html">Logstash Reference [7.10]</a></span>
»
<span class="breadcrumb-link"><a href="resiliency.html">Data Resiliency</a></span>
»
<span class="breadcrumb-node">Dead Letter Queues (DLQ)</span>
</div>
<div class="navheader">
<span class="prev">
<a href="persistent-queues.html">« Persistent Queues</a>
</span>
<span class="next">
<a href="transformation.html">Transforming Data »</a>
</span>
</div>
<div class="section">
<div class="titlepage"><div><div>
<h2 class="title"><a id="dead-letter-queues"></a>Dead Letter Queues (DLQ)<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/logstash/edit/7.10/docs/static/dead-letter-queues.asciidoc">edit</a></h2>
</div></div></div>
<p>The dead letter queue (DLQ) can provide another layer of data resilience.</p>
<p>By default, when Logstash encounters an event that it cannot process because the
data contains a mapping error or some other issue, the Logstash pipeline
either hangs or drops the unsuccessful event. In order to protect against data
loss in this situation, you can <a class="xref" href="dead-letter-queues.html#configuring-dlq" title="Configuring Logstash to use dead letter queues">configure Logstash</a> to write
unsuccessful events to a dead letter queue instead of dropping them.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>The dead letter queue is currently supported only for the
<a class="xref" href="plugins-outputs-elasticsearch.html" title="Elasticsearch output plugin">Elasticsearch output</a>. The dead letter queue is used for
documents with response codes of 400 or 404, both of which indicate an event
that cannot be retried.</p>
</div>
</div>
<p>Each event written to the dead letter queue includes the original event,
metadata that describes the reason the event could not be processed, information
about the plugin that wrote the event, and the timestamp when the event
entered the dead letter queue.</p>
<p>To process events in the dead letter queue, create a Logstash pipeline
configuration that uses the
<a class="xref" href="plugins-inputs-dead_letter_queue.html" title="Dead_letter_queue input plugin"><code class="literal">dead_letter_queue</code> input plugin</a> to read
from the queue. See <a class="xref" href="dead-letter-queues.html#processing-dlq-events" title="Processing events in the dead letter queue">Processing events in the dead letter queue</a> for more information.</p>
<div class="imageblock">
<div class="content">
<img src="static/images/dead_letter_queue.png" alt="Diagram showing pipeline reading from the dead letter queue">
</div>
</div>
<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="es-proc-dlq"></a>Elasticsearch processing and the dead letter queue<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/logstash/edit/7.10/docs/static/dead-letter-queues.asciidoc">edit</a></h3>
</div></div></div>
<p><span class="strong strong"><strong>HTTP request failure.</strong></span> If the HTTP request fails (because Elasticsearch is unreachable
or because it returned an HTTP error code), the Elasticsearch output retries the entire
request indefinitely. In these scenarios, the dead letter queue has no
opportunity to intercept.</p>
<p><span class="strong strong"><strong>HTTP request success.</strong></span> The <a href="/guide/en/elasticsearch/reference/7.10/docs-bulk.html" class="ulink" target="_top">Elasticsearch Bulk API</a> can perform
multiple actions using the same request. If the Bulk API request is successful,
it returns <code class="literal">200 OK</code>, even if some documents in the batch have
<a href="/guide/en/elasticsearch/reference/7.10/docs-bulk.html#bulk-failures-ex" class="ulink" target="_top">failed</a>. In this situation, the <code class="literal">errors</code>
flag for the request will be <code class="literal">true</code>.</p>
<p>The response body can include metadata indicating that one or more specific
actions in the bulk request could not be performed, along with an HTTP-style
status code per entry to indicate why the action could not be performed.
If the DLQ is configured, individual indexing failures are routed there.</p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="configuring-dlq"></a>Configuring Logstash to use dead letter queues<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/logstash/edit/7.10/docs/static/dead-letter-queues.asciidoc">edit</a></h3>
</div></div></div>
<p>Dead letter queues are disabled by default. To enable dead letter queues, set
the <code class="literal">dead_letter_queue_enable</code> option in the <code class="literal">logstash.yml</code>
<a class="xref" href="logstash-settings-file.html" title="logstash.yml">settings file</a>:</p>
<div class="pre_wrapper lang-yaml">
<pre class="programlisting prettyprint lang-yaml">dead_letter_queue.enable: true</pre>
</div>
<p>Dead letter queues are stored as files in the local directory of the Logstash
instance. By default, the dead letter queue files are stored in
<code class="literal">path.data/dead_letter_queue</code>. Each pipeline has a separate queue. For example,
the dead letter queue for the <code class="literal">main</code> pipeline is stored in
<code class="literal">LOGSTASH_HOME/data/dead_letter_queue/main</code> by default. The queue files are
numbered sequentially: <code class="literal">1.log</code>, <code class="literal">2.log</code>, and so on.</p>
<p>You can set <code class="literal">path.dead_letter_queue</code> in the <code class="literal">logstash.yml</code> file to
specify a different path for the files:</p>
<div class="pre_wrapper lang-yaml">
<pre class="programlisting prettyprint lang-yaml">path.dead_letter_queue: "path/to/data/dead_letter_queue"</pre>
</div>
<p>Dead letter queue entries are written to a temporary file, which is then renamed
 to a dead letter queue segment file, which is then eligible for ingestion. The rename
 happens either when this temporary file is considered <em>full</em>, or when a period
 of time has elapsed since the last dead letter queue eligible event was written
 to the temporary file.</p>
<p>This length of time can be set using the <code class="literal">dead_letter_queue.flush_interval</code> setting.
 This setting is in milliseconds, and defaults to 5000ms. A low value here will mean
 in the event of infrequent writes to the dead letter queue more, smaller, queue
 files may be written, while a larger value will introduce more latency between
 items being "written" to the dead letter queue, and being made available for
 reading by the dead_letter_queue input.</p>
<pre class="literallayout">Note that this value cannot be set to lower than 1000ms.</pre>

<div class="pre_wrapper lang-yaml">
<pre class="programlisting prettyprint lang-yaml">dead_letter_queue.flush_interval: 5000</pre>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>You may not use the same <code class="literal">dead_letter_queue</code> path for two different
Logstash instances.</p>
</div>
</div>
<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="_file_rotation"></a>File rotation<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/logstash/edit/7.10/docs/static/dead-letter-queues.asciidoc">edit</a></h4>
</div></div></div>
<p>Dead letter queues have a built-in file rotation policy that manages the file
size of the queue. When the file size reaches a preconfigured threshold, a new
file is created automatically.</p>
<p>By default, the maximum size of each dead letter queue is set to 1024mb. To
change this setting, use the <code class="literal">dead_letter_queue.max_bytes</code> option.  Entries
will be dropped if they would increase the size of the dead letter queue beyond
this setting.</p>
</div>

</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="processing-dlq-events"></a>Processing events in the dead letter queue<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/logstash/edit/7.10/docs/static/dead-letter-queues.asciidoc">edit</a></h3>
</div></div></div>
<p>When you are ready to process events in the dead letter queue, you create a
pipeline that uses the
<a class="xref" href="plugins-inputs-dead_letter_queue.html" title="Dead_letter_queue input plugin"><code class="literal">dead_letter_queue</code> input plugin</a> to read
from the dead letter queue. The pipeline configuration that you use depends, of
course, on what you need to do. For example, if the dead letter queue contains
events that resulted from a mapping error in Elasticsearch, you can create a
pipeline that reads the "dead" events, removes the field that caused the mapping
issue, and re-indexes the clean events into Elasticsearch.</p>
<p>The following example shows a simple pipeline that reads events from the dead
letter queue and writes the events, including metadata, to standard output:</p>
<div class="pre_wrapper lang-yaml">
<pre class="programlisting prettyprint lang-yaml">input {
  dead_letter_queue {
    path =&gt; "/path/to/data/dead_letter_queue" <a id="CO24-1"></a><i class="conum" data-value="1"></i>
    commit_offsets =&gt; true <a id="CO24-2"></a><i class="conum" data-value="2"></i>
    pipeline_id =&gt; "main" <a id="CO24-3"></a><i class="conum" data-value="3"></i>
  }
}

output {
  stdout {
    codec =&gt; rubydebug { metadata =&gt; true }
  }
}</pre>
</div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO24-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>The path to the top-level directory containing the dead letter queue. This
directory contains a separate folder for each pipeline that writes to the dead
letter queue. To find the path to this directory, look at the <code class="literal">logstash.yml</code>
<a class="xref" href="logstash-settings-file.html" title="logstash.yml">settings file</a>. By default, Logstash creates the
<code class="literal">dead_letter_queue</code> directory under the location used for persistent
storage (<code class="literal">path.data</code>), for example, <code class="literal">LOGSTASH_HOME/data/dead_letter_queue</code>.
However, if <code class="literal">path.dead_letter_queue</code> is set, it uses that location instead.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO24-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p>When <code class="literal">true</code>, saves the offset. When the pipeline restarts, it will continue
reading from the position where it left off rather than reprocessing all the
items in the queue. You can set <code class="literal">commit_offsets</code> to <code class="literal">false</code> when you are
exploring events in the dead letter queue and want to iterate over the events
multiple times.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO24-3"><i class="conum" data-value="3"></i></a></p>
</td>
<td align="left" valign="top">
<p>The ID of the pipeline that&#8217;s writing to the dead letter queue. The default
is <code class="literal">"main"</code>.</p>
</td>
</tr>
</table>
</div>
<p>For another example, see <a class="xref" href="dead-letter-queues.html#dlq-example" title="Example: Processing data that has mapping errors">Example: Processing data that has mapping errors</a>.</p>
<p>When the pipeline has finished processing all the events in the dead letter
queue, it will continue to run and process new events as they stream into the
queue. This means that you do not need to stop your production system to handle
events in the dead letter queue.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>Events emitted from the
<a class="xref" href="plugins-inputs-dead_letter_queue.html" title="Dead_letter_queue input plugin"><code class="literal">dead_letter_queue</code> input plugin</a> plugin
will not be resubmitted to the dead letter queue if they cannot be processed
correctly.</p>
</div>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="dlq-timestamp"></a>Reading from a timestamp<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/logstash/edit/7.10/docs/static/dead-letter-queues.asciidoc">edit</a></h3>
</div></div></div>
<p>When you read from the dead letter queue, you might not want to process all the
events in the queue, especially if there are a lot of old events in the queue.
You can start processing events at a specific point in the queue by using the
<code class="literal">start_timestamp</code> option. This option configures the pipeline to start
processing events based on the timestamp of when they entered the queue:</p>
<div class="pre_wrapper lang-yaml">
<pre class="programlisting prettyprint lang-yaml">input {
  dead_letter_queue {
    path =&gt; "/path/to/data/dead_letter_queue"
    start_timestamp =&gt; "2017-06-06T23:40:37"
    pipeline_id =&gt; "main"
  }
}</pre>
</div>
<p>For this example, the pipeline starts reading all events that were delivered to
the dead letter queue on or after June 6, 2017, at 23:40:37.</p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="dlq-example"></a>Example: Processing data that has mapping errors<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/logstash/edit/7.10/docs/static/dead-letter-queues.asciidoc">edit</a></h3>
</div></div></div>
<p>In this example, the user attempts to index a document that includes geo_ip data,
but the data cannot be processed because it contains a mapping error:</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json">{"geoip":{"location":"home"}}</pre>
</div>
<p>Indexing fails because the Logstash output plugin expects a <code class="literal">geo_point</code> object in
the <code class="literal">location</code> field, but the value is a string. The failed event is written to
the dead letter queue, along with metadata about the error that caused the
failure:</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json">{
   "@metadata" =&gt; {
    "dead_letter_queue" =&gt; {
       "entry_time" =&gt; #&lt;Java::OrgLogstash::Timestamp:0x5b5dacd5&gt;,
        "plugin_id" =&gt; "fb80f1925088497215b8d037e622dec5819b503e-4",
      "plugin_type" =&gt; "elasticsearch",
           "reason" =&gt; "Could not index event to Elasticsearch. status: 400, action: [\"index\", {:_id=&gt;nil, :_index=&gt;\"logstash-2017.06.22\", :_type=&gt;\"doc\", :_routing=&gt;nil}, 2017-06-22T01:29:29.804Z My-MacBook-Pro-2.local {\"geoip\":{\"location\":\"home\"}}], response: {\"index\"=&gt;{\"_index\"=&gt;\"logstash-2017.06.22\", \"_type\"=&gt;\"doc\", \"_id\"=&gt;\"AVzNayPze1iR9yDdI2MD\", \"status\"=&gt;400, \"error\"=&gt;{\"type\"=&gt;\"mapper_parsing_exception\", \"reason\"=&gt;\"failed to parse\", \"caused_by\"=&gt;{\"type\"=&gt;\"illegal_argument_exception\", \"reason\"=&gt;\"illegal latitude value [266.30859375] for geoip.location\"}}}}"
    }
  },
  "@timestamp" =&gt; 2017-06-22T01:29:29.804Z,
    "@version" =&gt; "1",
       "geoip" =&gt; {
    "location" =&gt; "home"
  },
        "host" =&gt; "My-MacBook-Pro-2.local",
     "message" =&gt; "{\"geoip\":{\"location\":\"home\"}}"
}</pre>
</div>
<p>To process the failed event, you create the following pipeline that reads from
the dead letter queue and removes the mapping problem:</p>
<div class="pre_wrapper lang-json">
<pre class="programlisting prettyprint lang-json">input {
  dead_letter_queue {
    path =&gt; "/path/to/data/dead_letter_queue/" <a id="CO25-1"></a><i class="conum" data-value="1"></i>
  }
}
filter {
  mutate {
    remove_field =&gt; "[geoip][location]" <a id="CO25-2"></a><i class="conum" data-value="2"></i>
  }
}
output {
  elasticsearch{
    hosts =&gt; [ "localhost:9200" ] <a id="CO25-3"></a><i class="conum" data-value="3"></i>
  }
}</pre>
</div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO25-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>The <a class="xref" href="plugins-inputs-dead_letter_queue.html" title="Dead_letter_queue input plugin"><code class="literal">dead_letter_queue</code> input</a> reads from the dead letter queue.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO25-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p>The <code class="literal">mutate</code> filter removes the problem field called <code class="literal">location</code>.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO25-3"><i class="conum" data-value="3"></i></a></p>
</td>
<td align="left" valign="top">
<p>The clean event is sent to Elasticsearch, where it can be indexed because
the mapping issue is resolved.</p>
</td>
</tr>
</table>
</div>
</div>

</div>
<div class="navfooter">
<span class="prev">
<a href="persistent-queues.html">« Persistent Queues</a>
</span>
<span class="next">
<a href="transformation.html">Transforming Data »</a>
</span>
</div>
</div>
</body>
</html>
