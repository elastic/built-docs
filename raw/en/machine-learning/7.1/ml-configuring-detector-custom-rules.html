<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Customizing detectors with custom rules | Machine Learning in the Elastic Stack [7.1] | Elastic</title>
<link rel="home" href="index.html" title="Machine Learning in the Elastic Stack [7.1]"/>
<link rel="up" href="ml-configuring.html" title="Configuring machine learning"/>
<link rel="prev" href="ml-configuring-aggregation.html" title="Aggregating data for faster performance"/>
<link rel="next" href="ml-configuring-categories.html" title="Categorizing log messages"/>
<meta name="DC.type" content="Learn/Docs/Elastic Stack/Machine Learning/7.1"/>
<meta name="DC.subject" content="Machine Learning"/>
<meta name="DC.identifier" content="7.1"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body><div class="page_header">
<strong>IMPORTANT</strong>: No additional bug fixes or documentation updates
will be released for this version. For the latest information, see the
<a href="../current/index.html">current release documentation</a>.
</div>
<div id="content">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="index.html">Machine Learning in the Elastic Stack [7.1]</a></span>
»
<span class="breadcrumb-link"><a href="ml-configuring.html">Configuring machine learning</a></span>
»
<span class="breadcrumb-node">Customizing detectors with custom rules</span>
</div>
<div class="navheader">
<span class="prev">
<a href="ml-configuring-aggregation.html">« Aggregating data for faster performance</a>
</span>
<span class="next">
<a href="ml-configuring-categories.html">Categorizing log messages »</a>
</span>
</div>
<div class="section xpack">
<div class="titlepage"><div><div>
<h2 class="title"><a id="ml-configuring-detector-custom-rules"></a>Customizing detectors with custom rules<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/7.1/docs/reference/ml/detector-custom-rules.asciidoc">edit</a><a class="xpack_tag" href="/subscriptions"></a></h2>
</div></div></div>
<p><a class="xref" href="ml-rules.html" title="Custom rules">Custom rules</a> enable you to change the behavior of anomaly
detectors based on domain-specific knowledge.</p>
<p>Custom rules describe <em>when</em> a detector should take a certain <em>action</em> instead
of following its default behavior. To specify the <em>when</em> a rule uses
a <code class="literal">scope</code> and <code class="literal">conditions</code>. You can think of <code class="literal">scope</code> as the categorical
specification of a rule, while <code class="literal">conditions</code> are the numerical part.
A rule can have a scope, one or more conditions, or a combination of
scope and conditions.</p>
<p>Let us see how those can be configured by examples.</p>
<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="_specifying_custom_rule_scope"></a>Specifying custom rule scope<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/7.1/docs/reference/ml/detector-custom-rules.asciidoc">edit</a></h3>
</div></div></div>
<p>Let us assume we are configuring a job in order to detect DNS data exfiltration.
Our data contain fields "subdomain" and "highest_registered_domain".
We can use a detector that looks like <code class="literal">high_info_content(subdomain) over highest_registered_domain</code>.
If we run such a job it is possible that we discover a lot of anomalies on
frequently used domains that we have reasons to trust. As security analysts, we
are not interested in such anomalies. Ideally, we could instruct the detector to
skip results for domains that we consider safe. Using a rule with a scope allows
us to achieve this.</p>
<p>First, we need to create a list of our safe domains. Those lists are called
<em>filters</em> in machine learning. Filters can be shared across jobs.</p>
<p>We create our filter using the <a href="/guide/en/elasticsearch/reference/7.1/ml-put-filter.html" class="ulink" target="_top">put filter API</a>:</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">PUT _ml/filters/safe_domains
{
  "description": "Our list of safe domains",
  "items": ["safe.com", "trusted.com"]
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/7.console"></div>
<p>Now, we can create our job specifying a scope that uses the <code class="literal">safe_domains</code>
filter for the <code class="literal">highest_registered_domain</code> field:</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">PUT _ml/anomaly_detectors/dns_exfiltration_with_rule
{
  "analysis_config" : {
    "bucket_span":"5m",
    "detectors" :[{
      "function":"high_info_content",
      "field_name": "subdomain",
      "over_field_name": "highest_registered_domain",
      "custom_rules": [{
        "actions": ["skip_result"],
        "scope": {
          "highest_registered_domain": {
            "filter_id": "safe_domains",
            "filter_type": "include"
          }
        }
      }]
    }]
  },
  "data_description" : {
    "time_field":"timestamp"
  }
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/8.console"></div>
<p>As time advances and we see more data and more results, we might encounter new
domains that we want to add in the filter. We can do that by using the
<a href="/guide/en/elasticsearch/reference/7.1/ml-update-filter.html" class="ulink" target="_top">update filter API</a>:</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">POST _ml/filters/safe_domains/_update
{
  "add_items": ["another-safe.com"]
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/9.console"></div>
<p>Note that we can use any of the <code class="literal">partition_field_name</code>, <code class="literal">over_field_name</code>, or
<code class="literal">by_field_name</code> fields in the <code class="literal">scope</code>.</p>
<p>In the following example we scope multiple fields:</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">PUT _ml/anomaly_detectors/scoping_multiple_fields
{
  "analysis_config" : {
    "bucket_span":"5m",
    "detectors" :[{
      "function":"count",
      "partition_field_name": "my_partition",
      "over_field_name": "my_over",
      "by_field_name": "my_by",
      "custom_rules": [{
        "actions": ["skip_result"],
        "scope": {
          "my_partition": {
            "filter_id": "filter_1"
          },
          "my_over": {
            "filter_id": "filter_2"
          },
          "my_by": {
            "filter_id": "filter_3"
          }
        }
      }]
    }]
  },
  "data_description" : {
    "time_field":"timestamp"
  }
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/10.console"></div>
<p>Such a detector will skip results when the values of all 3 scoped fields
are included in the referenced filters.</p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="_specifying_custom_rule_conditions"></a>Specifying custom rule conditions<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/7.1/docs/reference/ml/detector-custom-rules.asciidoc">edit</a></h3>
</div></div></div>
<p>Imagine a detector that looks for anomalies in CPU utilization.
Given a machine that is idle for long enough, small movement in CPU could
result in anomalous results where the <code class="literal">actual</code> value is quite small, for
example, 0.02. Given our knowledge about how CPU utilization behaves we might
determine that anomalies with such small actual values are not interesting for
investigation.</p>
<p>Let us now configure a job with a rule that will skip results where CPU
utilization is less than 0.20.</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">PUT _ml/anomaly_detectors/cpu_with_rule
{
  "analysis_config" : {
    "bucket_span":"5m",
    "detectors" :[{
      "function":"high_mean",
      "field_name": "cpu_utilization",
      "custom_rules": [{
        "actions": ["skip_result"],
        "conditions": [
          {
            "applies_to": "actual",
            "operator": "lt",
            "value": 0.20
          }
        ]
      }]
    }]
  },
  "data_description" : {
    "time_field":"timestamp"
  }
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/11.console"></div>
<p>When there are multiple conditions they are combined with a logical <code class="literal">and</code>.
This is useful when we want the rule to apply to a range. We simply create
a rule with two conditions, one for each end of the desired range.</p>
<p>Here is an example where a count detector will skip results when the count
is greater than 30 and less than 50:</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">PUT _ml/anomaly_detectors/rule_with_range
{
  "analysis_config" : {
    "bucket_span":"5m",
    "detectors" :[{
      "function":"count",
      "custom_rules": [{
        "actions": ["skip_result"],
        "conditions": [
          {
            "applies_to": "actual",
            "operator": "gt",
            "value": 30
          },
          {
            "applies_to": "actual",
            "operator": "lt",
            "value": 50
          }
        ]
      }]
    }]
  },
  "data_description" : {
    "time_field":"timestamp"
  }
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/12.console"></div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="_custom_rules_in_the_life_cycle_of_a_job"></a>Custom rules in the life-cycle of a job<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/7.1/docs/reference/ml/detector-custom-rules.asciidoc">edit</a></h3>
</div></div></div>
<p>Custom rules only affect results created after the rules were applied.
Let us imagine that we have configured a job and it has been running
for some time. After observing its results we decide that we can employ
rules in order to get rid of some uninteresting results. We can use
the <a href="/guide/en/elasticsearch/reference/7.1/ml-update-job.html" class="ulink" target="_top">update job API</a> to do so. However, the rule we
added will only be in effect for any results created from the moment we added
the rule onwards. Past results will remain unaffected.</p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="_using_custom_rules_vs_filtering_data"></a>Using custom rules VS filtering data<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/7.1/docs/reference/ml/detector-custom-rules.asciidoc">edit</a></h3>
</div></div></div>
<p>It might appear like using rules is just another way of filtering the data
that feeds into a job. For example, a rule that skips results when the
partition field value is in a filter sounds equivalent to having a query
that filters out such documents. But it is not. There is a fundamental
difference. When the data is filtered before reaching a job it is as if they
never existed for the job. With rules, the data still reaches the job and
affects its behavior (depending on the rule actions).</p>
<p>For example, a rule with the <code class="literal">skip_result</code> action means all data will still
be modeled. On the other hand, a rule with the <code class="literal">skip_model_update</code> action means
results will still be created even though the model will not be updated by
data matched by a rule.</p>
</div>

</div>
<div class="navfooter">
<span class="prev">
<a href="ml-configuring-aggregation.html">« Aggregating data for faster performance</a>
</span>
<span class="next">
<a href="ml-configuring-categories.html">Categorizing log messages »</a>
</span>
</div>
</div>
</body>
</html>
