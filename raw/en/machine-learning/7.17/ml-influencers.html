<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="description" content="An introduction to machine learning anomaly detection, which analyzes time series data to identify and predict anomalous patterns in your data.">
<meta name="keywords" content="ML, Elastic Stack, anomaly detection, overview">
<title>Influencers | Machine Learning in the Elastic Stack [7.17] | Elastic</title>
<meta class="elastic" name="content" content="Influencers | Machine Learning in the Elastic Stack [7.17]">

<link rel="home" href="index.html" title="Machine Learning in the Elastic Stack [7.17]"/>
<link rel="up" href="ml-concepts.html" title="Concepts"/>
<link rel="prev" href="ml-buckets.html" title="Buckets"/>
<link rel="next" href="ml-calendars.html" title="Calendars and scheduled events"/>
<meta class="elastic" name="product_version" content="7.17"/>
<meta class="elastic" name="product_name" content="Machine Learning"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/Elastic Stack/Machine Learning/7.17"/>
<meta name="DC.subject" content="Machine Learning"/>
<meta name="DC.identifier" content="7.17"/>
</head>
<body><div class="page_header">
A newer version is available. For the latest information, see the
<a href="../current/index.html">current release documentation</a>.
</div>
<div id="content">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Machine Learning in the Elastic Stack [7.17]</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="xpack-ml.html">Anomaly detection</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="ml-concepts.html">Concepts</a></span>
</div>
<div class="navheader">
<span class="prev">
<a href="ml-buckets.html">« Buckets</a>
</span>
<span class="next">
<a href="ml-calendars.html">Calendars and scheduled events »</a>
</span>
</div>
<div class="section xpack">
<div class="titlepage"><div><div>
<h2 class="title"><a id="ml-influencers"></a>Influencers<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/7.17/docs/en/stack/ml/anomaly-detection/ml-influencers.asciidoc">edit</a></h2>
</div></div></div>
<p>When anomalous events occur, we want to know why. To determine the cause,
however, you often need a broader knowledge of the domain. If you have
suspicions about which entities in your dataset are likely causing
irregularities, you can identify them as influencers in your anomaly detection jobs.
That is to say, <em>influencers</em> are fields that you suspect contain information
about someone or something that influences or contributes to anomalies in your
data.</p>
<p>Influencers can be any field in your data. If you use datafeeds, however, the
field must exist in your datafeed query or aggregation; otherwise it is not
included in the job analysis. If you use a query in your datafeed, there is an
additional requirement: influencer fields must exist in the query results in the
same hit as the detector fields. Datafeeds process data by paging through the
query results; since search hits cannot span multiple indices or documents,
datafeeds have the same limitation.</p>
<p>Influencers do not need to be fields that are specified in your anomaly detection job
detectors, though they often are. If you use aggregations in your datafeed, it is
possible to use influencers that come from different indices than the detector
fields. However, both indices must have a date field with the same name, which you
specify in the <code class="literal">data_description</code>.<code class="literal">time_field</code> property for the datafeed.</p>
<p>Picking an influencer is strongly recommended for the following reasons:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
It allows you to more easily assign blame for anomalies
</li>
<li class="listitem">
It simplifies and aggregates the results
</li>
</ul>
</div>
<p>If you use Kibana, the job creation wizards can suggest which fields to use as
influencers. The best influencer is the person or thing that you want to blame
for the anomaly. In many cases, users or client IP addresses make excellent
influencers.</p>
<div class="tip admon">
<div class="icon"></div>
<div class="admon_content">
<p>As a best practice, do not pick too many influencers. For example, you
generally do not need more than three. If you pick many influencers, the results
can be overwhelming and there is a small overhead to the analysis.</p>
</div>
</div>
<h4><a id="ml-influencer-results"></a>Influencer results<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/7.17/docs/en/stack/ml/anomaly-detection/ml-influencers.asciidoc">edit</a></h4>
<p>The influencer results show which entities were anomalous and when. One
influencer result is written per bucket for each influencer that affects the
anomalousness of the bucket. The machine learning analytics determine the impact of an
influencer by performing a series of experiments that remove all data points
with a specific influencer value and check whether the bucket is still
anomalous. That means that only influencers with statistically significant
impact on the anomaly are reported in the results. For jobs with more than one
detector, influencer scores provide a powerful view of the most anomalous
entities.</p>
<p>For example, the <code class="literal">high_sum_total_sales</code> anomaly detection job for the eCommerce orders
sample data uses <code class="literal">customer_full_name.keyword</code> and <code class="literal">category.keyword</code> as
influencers. You can examine the influencer results with the
<a href="/guide/en/elasticsearch/reference/7.17/ml-get-influencer.html" class="ulink" target="_top">get influencers API</a>. Alternatively, you can use
the <span class="strong strong"><strong>Anomaly Explorer</strong></span> in Kibana:</p>
<div class="imageblock screenshot">
<div class="content">
<img src="images/influencers.jpg" alt="Influencers in the Kibana Anomaly Explorer">
</div>
</div>
<p>On the left is a list of the top influencers for all of the detected anomalies
in that same time period. The list includes maximum anomaly scores, which in
this case are aggregated for each influencer, for each bucket, across all
detectors. There is also a total sum of the anomaly scores for each influencer.
You can use this list to help you narrow down the contributing factors and focus
on the most anomalous entities.</p>
<p>You can also explore swim lanes that correspond to the values of an influencer.
In this example, the swim lanes correspond to the values for the
<code class="literal">customer_full_name.keyword</code>. By default, the swim lanes are sorted according to
which entity has the maximum anomaly score values. You can click on the sections
in the swim lane to see details about the anomalies that occurred in that time
interval.</p>
<div class="tip admon">
<div class="icon"></div>
<div class="admon_content">
<p>The anomaly scores that you see in each section of the <span class="strong strong"><strong>Anomaly Explorer</strong></span>
might differ slightly. This disparity occurs because for each anomaly detection job,
there are bucket results, influencer results, and record results. Anomaly scores
are generated for each type of result. The anomaly timeline in Kibana uses the
bucket-level anomaly scores. If you view swim lanes by influencer, it uses the
influencer-level anomaly scores, as does the list of top influencers. The list
of anomalies uses the record-level anomaly scores.</p>
</div>
</div>
<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="further-reading"></a>Further reading<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/7.17/docs/en/stack/ml/anomaly-detection/ml-influencers.asciidoc">edit</a></h3>
</div></div></div>
<p><a href="/blog/interpretability-in-ml-identifying-anomalies-influencers-root-causes" class="ulink" target="_top">Interpretability in ML: Identifying anomalies, influencers, and root causes</a></p>
</div>

</div>
<div class="navfooter">
<span class="prev">
<a href="ml-buckets.html">« Buckets</a>
</span>
<span class="next">
<a href="ml-calendars.html">Calendars and scheduled events »</a>
</span>
</div>
</div>
</body>
</html>
