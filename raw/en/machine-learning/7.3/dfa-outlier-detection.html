<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Outlier detection | Machine Learning in the Elastic Stack [7.3] | Elastic</title>
<link rel="home" href="index.html" title="Machine Learning in the Elastic Stack [7.3]"/>
<link rel="up" href="ml-dfa-concepts.html" title="Concepts"/>
<link rel="prev" href="ml-dfa-concepts.html" title="Concepts"/>
<link rel="next" href="ml-dfanalytics-evaluate.html" title="Evaluating data frame analytics"/>
<meta name="DC.type" content="Learn/Docs/Elastic Stack/Machine Learning/7.3"/>
<meta name="DC.subject" content="Machine Learning"/>
<meta name="DC.identifier" content="7.3"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body><div class="page_header">
<strong>IMPORTANT</strong>: No additional bug fixes or documentation updates
will be released for this version. For the latest information, see the
<a href="../current/index.html">current release documentation</a>.
</div>
<div id="content">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="index.html">Machine Learning in the Elastic Stack [7.3]</a></span>
»
<span class="breadcrumb-link"><a href="ml-dfanalytics.html">Data frame analytics</a></span>
»
<span class="breadcrumb-link"><a href="ml-dfa-concepts.html">Concepts</a></span>
»
<span class="breadcrumb-node">Outlier detection</span>
</div>
<div class="navheader">
<span class="prev">
<a href="ml-dfa-concepts.html">« Concepts</a>
</span>
<span class="next">
<a href="ml-dfanalytics-evaluate.html">Evaluating data frame analytics »</a>
</span>
</div>
<div class="section xpack">
<div class="titlepage"><div><div>
<h2 class="title"><a id="dfa-outlier-detection"></a>Outlier detection<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/stack-docs/edit/7.3/docs/en/stack/ml/df-analytics/dfa-outlierdetection.asciidoc">edit</a><a class="xpack_tag" href="/subscriptions"></a></h2>
</div></div></div>
<div class="warning admon">
<div class="icon"></div>
<div class="admon_content">
<p>This functionality is experimental and may be changed or removed completely in a future release. Elastic will take a best effort approach to fix any issues, but experimental features are not subject to the support SLA of official GA features.</p>
</div>
</div>
<p>Outlier detection is an analysis for identifying data points (outliers) whose
feature values are different from those of the normal data points in a
particular data set. Outliers may denote errors or unusual behavior.</p>
<p>We use unsupervised outlier detection which means there is no need to provide a
training data set to teach outlier detection to recognize outliers. Unsupervised
outlier detection uses various machine learning techniques to find which data points
are unusual compared to the majority of the data points.</p>
<h4><a id="dfa-outlier-algorithms"></a>Outlier detection algorithms<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/stack-docs/edit/7.3/docs/en/stack/ml/df-analytics/dfa-outlierdetection.asciidoc">edit</a></h4>
<p>In the Elastic Stack, we use an ensemble of four different distance and density based
outlier detection methods. By default, you don&#8217;t need to select the methods or
provide any parameters, but you can override the default behavior if you like.
The basic assumption of the <span class="strong strong"><strong>distance based methods</strong></span> is that normal data
points – in other words, points that are not outliers – have a lot of neighbors
nearby, because we expect that in a population the majority of the data points
have similar feature values, while the minority of the data points – the
outliers – have different feature values and will, therefore, be far away from
the normal points.</p>
<p>The distance of K<sup>th</sup> nearest neighbor method (<code class="literal">distance_kth_nn</code>) computes the
distance of the data point to its K<sup>th</sup> nearest neighbor where K is a small
number and usually independent of the total number of data points. The higher
this distance the more the data point is an outlier.</p>
<p>The distance of K-nearest neighbors method (<code class="literal">distance_knn</code>) calculates the
average distance of the data points to their nearest neighbors. Points with the
largest average distance will be the most outlying.</p>
<p>While the results of the distance based methods are easy to interpret, their
drawback is that they don&#8217;t take into account the density variations of a
data set. This is the point where <span class="strong strong"><strong>density based methods</strong></span> come into the
picture, they are used for mitigating this problem. These methods take into
account not only the distance of the points to their K nearest neighbors but
also the distance of these neighbors to their neighbors.</p>
<p>Based on this approach, a metric is computed called local outlier factor
(<code class="literal">lof</code>) for each data point. The higher the local outlier factor, the more
outlying is the data point.</p>
<p>The other density based method that outlier detection uses is the local
distance-based outlier factor (<code class="literal">ldof</code>). Ldof is a ratio of two measures: the
first computes the average distance of the data point to its K nearest
neighbors; the second computes the average of the pairwise distances of the
neighbors themselves. Again, the higher the value the more the data point is an
outlier.</p>
<p>As you can see, these four algorithms work differently, so they don&#8217;t always
agree on which points are outliers. By default, we use all these methods during
outlier detection, then normalize and combine their results and give every datapoint
in the index an outlier score. The outlier score ranges from 0 to 1, where the higher
number represents the chance that the data point is an outlier compared to the
other data points in the index.</p>
<div class="important admon">
<div class="icon"></div>
<div class="admon_content">
<p>Outlier detection is a batch analysis, it runs against your data
once. If new data comes into the index, you need to do the analysis again on the
altered data.</p>
</div>
</div>
<h4><a id="dfa-feature-influence"></a>Feature influence<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/stack-docs/edit/7.3/docs/en/stack/ml/df-analytics/dfa-outlierdetection.asciidoc">edit</a></h4>
<p>Besides the outlier score, another value is calculated during outlier detection:
the feature influence score. As we mentioned, there are multiple features of a
data point that are analyzed during outlier detection. An influential feature is a
feature of a data point that is responsible for the point being an outlier. The
value of feature influence provides a relative ranking of features by their
contribution to a point being an outlier. Therefore, while outlier score tells us
whether a data point is an outlier, feature influence shows which features make
the point an outlier. By doing this, this value provides context to help
understand more about the reasons for the data point being unusual and can drive
visualizations.</p>
</div>
<div class="navfooter">
<span class="prev">
<a href="ml-dfa-concepts.html">« Concepts</a>
</span>
<span class="next">
<a href="ml-dfanalytics-evaluate.html">Evaluating data frame analytics »</a>
</span>
</div>
</div>
</body>
</html>
