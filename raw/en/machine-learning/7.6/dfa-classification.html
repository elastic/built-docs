<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Classification | Machine Learning in the Elastic Stack [7.6] | Elastic</title>
<meta class="elastic" name="content" content="Classification | Machine Learning in the Elastic Stack [7.6]">

<link rel="home" href="index.html" title="Machine Learning in the Elastic Stack [7.6]"/>
<link rel="up" href="ml-dfa-concepts.html" title="Concepts"/>
<link rel="prev" href="dfa-regression.html" title="Regression"/>
<link rel="next" href="ml-inference.html" title="Inference"/>
<meta class="elastic" name="product_version" content="7.6"/>
<meta class="elastic" name="product_name" content="Machine Learning"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/Elastic Stack/Machine Learning/7.6"/>
<meta name="DC.subject" content="Machine Learning"/>
<meta name="DC.identifier" content="7.6"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body><div class="page_header">
<strong>IMPORTANT</strong>: No additional bug fixes or documentation updates
will be released for this version. For the latest information, see the
<a href="../current/index.html">current release documentation</a>.
</div>
<div id="content">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Machine Learning in the Elastic Stack [7.6]</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="ml-dfanalytics.html">Data frame analytics</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="ml-dfa-concepts.html">Concepts</a></span>
</div>
<div class="navheader">
<span class="prev">
<a href="dfa-regression.html">« Regression</a>
</span>
<span class="next">
<a href="ml-inference.html">Inference »</a>
</span>
</div>
<div class="section xpack">
<div class="titlepage"><div><div>
<h2 class="title"><a id="dfa-classification"></a>Classification<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/stack-docs/edit/7.6/docs/en/stack/ml/df-analytics/dfa-classification.asciidoc">edit</a><a class="xpack_tag" href="/subscriptions"></a></h2>
</div></div></div>
<div class="warning admon">
<div class="icon"></div>
<div class="admon_content">
<p>This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.</p>
</div>
</div>
<p>Classification is a machine learning process for predicting the class or category of a
given data point in a dataset. Typical examples of classification problems are
predicting loan risk, classifying music, or detecting cancer in a DNA sequence.
In the first case, for example, our dataset consists of data on loan applicants
that covers investment history, employment status, debit status, and so on.
Based on historical data, the classification analysis predicts whether it is
safe or risky to lend money to a given loan applicant. In the second case, the
data we have represents songs and the analysis – based on the features of the
data points – classifies the songs as hip-hop, country, classical, or any
other genres available in the set of categories we have. Therefore,
classification is for predicting discrete, categorical values, unlike
regression analysis which predicts continuous, numerical values.</p>
<p>From the perspective of the possible output, there are two types of
classification: binary and multi-class classification. In binary
classification the variable you want to predict has only two potential values.
The loan example above is a binary classification problem where the two
potential outputs are <code class="literal">safe</code> or <code class="literal">risky</code>. The music classification problem is an
example of multi-class classification where there are many different potential
outputs; one for every possible music genre. In the 7.6.2 version of the
Elastic Stack, you can perform only binary classification analysis.</p>
<h4><a id="dfa-classification-features"></a>Feature variables<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/stack-docs/edit/7.6/docs/en/stack/ml/df-analytics/dfa-classification.asciidoc">edit</a></h4>
<p>When you perform classification, you must identify a subset of fields that you
want to use to create a model for predicting another field value. We refer to
these fields as <em>feature variables</em> and <em>dependent variable</em>, respectively.
Feature variables are the values that the dependent variable value depends on. There are
three different types of feature variables that you can use with our
classification algorithm: numerical, categorical, and boolean. Arrays are not
supported in the feature variable fields.</p>
<h4><a id="dfa-classification-supervised"></a>Training the classification model<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/stack-docs/edit/7.6/docs/en/stack/ml/df-analytics/dfa-classification.asciidoc">edit</a></h4>
<p>Classification – just like regression – is a supervised machine learning process. It
means that you need to supply a labeled training dataset that has some
feature variables and a dependent variable. The classification algorithm learns the
relationships between the features and the dependent variable. Once you’ve trained the
model on your training dataset, you can reuse the knowledge that the model has
learned about the relationships between the data points to classify new data.
Your training dataset should be approximately balanced which means the number of
data points belonging to the various classes should not be widely different,
otherwise the classification analysis may not provide the best predictions. Read
<a class="xref" href="ml-dfa-limitations.html#dfa-classification-imbalanced-classes" title="Imbalanced class sizes affect classification performance">Imbalanced class sizes affect classification performance</a> to learn more.</p>
<h5><a id="dfa-classification-algorithm"></a>Classification algorithms<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/stack-docs/edit/7.6/docs/en/stack/ml/df-analytics/dfa-classification.asciidoc">edit</a></h5>
<p>The ensemble algorithm that we use in the Elastic Stack is a type of boosting called
boosted tree regression model which combines multiple weak models into a
composite one. We use decision trees to learn to predict the probability that
a data point belongs to a certain class.</p>
<h4><a id="dfa-classification-interpret"></a>Interpreting classification results<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/stack-docs/edit/7.6/docs/en/stack/ml/df-analytics/dfa-classification.asciidoc">edit</a></h4>
<p>The following sections help you understand and interpret the results of a
classification analysis.</p>
<h5><a id="dfa-classification-class-probability"></a><code class="literal">class_probability</code><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/stack-docs/edit/7.6/docs/en/stack/ml/df-analytics/dfa-classification.asciidoc">edit</a></h5>
<p>The value of <code class="literal">class_probability</code> shows how likely it is that a given datapoint
belongs to a certain class. It is a value between 0 and 1. The higher the
number, the higher the probability that the data point belongs to the named
class. This information is stored in the <code class="literal">top_classes</code> array for each document in your destination index. See the
<a href="/guide/en/machine-learning/7.6/flightdata-classification.html#flightdata-classification-results" class="ulink" target="_top">Viewing classification results</a>
section in the classification example.</p>
<h5><a id="dfa-classification-class-score"></a><code class="literal">class_score</code><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/stack-docs/edit/7.6/docs/en/stack/ml/df-analytics/dfa-classification.asciidoc">edit</a></h5>
<p>The value of <code class="literal">class_score</code> controls the probability at which a class label is
assigned to a datapoint. In normal case – that you maximize the number of
correct labels – a class label is assigned when its predicted probability is
greater than 0.5. The <code class="literal">class_score</code> makes it possible to change this behavior,
so it can be less than or greater than 0.5. For example, suppose our two classes
are denoted <code class="literal">class 0</code> and <code class="literal">class 1</code>, then the value of <code class="literal">class_score</code> is always
non-negative and its definition is:</p>
<pre class="screen">class_score(class 0) = 0.5 / (1.0 - k) * probability(class 0)
class_score(class 1) = 0.5 / k * probability(class 1)</pre>
<p>Here, <code class="literal">k</code> is a positive constant less than one. It represents the predicted
probability of <code class="literal">class 1</code> for a datapoint at which to label it <code class="literal">class 1</code> and is
chosen to maximise the minimum recall of any class. This is useful for example
in case of highly imbalanced data. If <code class="literal">class 0</code> is much more frequent in the
training data than <code class="literal">class 1</code>, then it can mean that you achieve the best
accuracy by assigning <code class="literal">class 0</code> to every datapoint. This is equivalent to zero
recall for <code class="literal">class 1</code>. Instead of this behavior, the default scheme of the
Elastic Stack classification analysis is to choose <code class="literal">k &lt; 0.5</code> and accept a higher rate of
actual <code class="literal">class 0</code> predicted <code class="literal">class 1</code> errors, or in other words, a slight
degradation of the overall accuracy.</p>
<h5><a id="dfa-classification-feature-importance"></a>Feature importance<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/stack-docs/edit/7.6/docs/en/stack/ml/df-analytics/dfa-classification.asciidoc">edit</a></h5>
<p>Feature importance is calculated for supervised machine learning methods such as
regression and classification. This value provides further insight into the
results of a data frame analytics job and therefore helps interpret these results. As we
mentioned, there are multiple features of a data point that are analyzed during
data frame analytics. These features are responsible for a particular prediction to
varying degrees. Feature importance shows to what degree a given feature of a
data point contributes to the prediction. The feature importance value of a
feature can be either positive or negative depending on its effect on the
prediction. If the feature reduces the prediction value, the value is negative.
If the feature increases the prediction, the feature importance value positive.
The magnitude of the feature importance value shows how significantly the
feature affects the prediction both locally (for a given data point) or
generally (for the whole data set).</p>
<p>Feature importance in the Elastic Stack is calculated using the SHAP (SHapley Additive
exPlanations) method as described in
<a href="https://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf" class="ulink" target="_top">Lundberg, S. M., &amp; Lee, S.-I. A Unified Approach to Interpreting Model Predictions. In NeurIPS 2017</a>.</p>
<p>By default, feature importance values are not calculated. To generate this
information, when you create a data frame analytics job you must specify the
<code class="literal">num_top_feature_importance_values</code> property. The feature importance values are
stored in the destination index in fields prefixed by <code class="literal">ml.feature_importance</code>.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>The number of feature importance values for each document might be less
than the <code class="literal">num_top_feature_importance_values</code> property value. For example, it
returns only features that had a positive or negative effect on the prediction.</p>
</div>
</div>
<h4><a id="dfa-classification-evaluation"></a>Measuring model performance<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/stack-docs/edit/7.6/docs/en/stack/ml/df-analytics/dfa-classification.asciidoc">edit</a></h4>
<p>You can measure how well the model has performed on your dataset by using the
<code class="literal">classification</code> evaluation type of the
<a href="/guide/en/elasticsearch/reference/7.6/evaluate-dfanalytics.html" class="ulink" target="_top">evaluate data frame analytics API</a>. The metric that the
evaluation provides you is the multi-class confusion matrix which tells you how
many times a given data point that belongs to a given class was classified
correctly and incorrectly. In other words, how many times your data point that
belongs to the X class was mistakenly classified as Y.</p>
<p>Another crucial measurement is how well your model performs on unseen data
points. To assess how well the trained model will perform on data it has never
seen before, you must set aside a proportion of the training dataset for
testing. This split of the dataset is the testing dataset. Once the model has
been trained, you can let the model predict the value of the data points it has
never seen before and compare the prediction to the actual value by using the
evaluate data frame analytics API.</p>
</div>
<div class="navfooter">
<span class="prev">
<a href="dfa-regression.html">« Regression</a>
</span>
<span class="next">
<a href="ml-inference.html">Inference »</a>
</span>
</div>
</div>
</body>
</html>
