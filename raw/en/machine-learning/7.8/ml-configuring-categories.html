<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Detecting anomalous categories of data | Machine Learning in the Elastic Stack [7.8] | Elastic</title>
<link rel="home" href="index.html" title="Machine Learning in the Elastic Stack [7.8]"/>
<link rel="up" href="anomaly-examples.html" title="Anomaly detection examples"/>
<link rel="prev" href="ml-configuring-detector-custom-rules.html" title="Customizing detectors with custom rules"/>
<link rel="next" href="ml-configuring-populations.html" title="Performing population analysis"/>
<meta name="DC.type" content="Learn/Docs/Elastic Stack/Machine learning/7.8"/>
<meta name="DC.subject" content="Machine learning"/>
<meta name="DC.identifier" content="7.8"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body><div class="page_header">
<strong>IMPORTANT</strong>: No additional bug fixes or documentation updates
will be released for this version. For the latest information, see the
<a href="../current/index.html">current release documentation</a>.
</div>
<div id="content">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="index.html">Machine Learning in the Elastic Stack [7.8]</a></span>
»
<span class="breadcrumb-link"><a href="xpack-ml.html">Anomaly detection</a></span>
»
<span class="breadcrumb-link"><a href="anomaly-examples.html">Anomaly detection examples</a></span>
»
<span class="breadcrumb-node">Detecting anomalous categories of data</span>
</div>
<div class="navheader">
<span class="prev">
<a href="ml-configuring-detector-custom-rules.html">« Customizing detectors with custom rules</a>
</span>
<span class="next">
<a href="ml-configuring-populations.html">Performing population analysis »</a>
</span>
</div>
<div class="section xpack">
<div class="titlepage"><div><div>
<h2 class="title"><a id="ml-configuring-categories"></a>Detecting anomalous categories of data<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/7.8/docs/reference/ml/anomaly-detection/ml-configuring-categories.asciidoc">edit</a><a class="xpack_tag" href="/subscriptions"></a></h2>
</div></div></div>
<p>Categorization is a machine learning process that tokenizes a text field, clusters similar
data together, and classifies it into categories. It works best on
machine-written messages and application output that typically consist of
repeated elements. For example, it works well on logs that contain a finite set
of possible messages:</p>
<div class="pre_wrapper lang-js">
<pre class="programlisting prettyprint lang-js">{"@timestamp":1549596476000,
"message":"org.jdbi.v2.exceptions.UnableToExecuteStatementException: com.mysql.jdbc.exceptions.MySQLTimeoutException: Statement cancelled due to timeout or client request [statement:\"SELECT id, customer_id, name, force_disabled, enabled FROM customers\"]",
"type":"logs"}</pre>
</div>
<p>Categorization is tuned to work best on data like log messages by taking token
order into account, including stop words, and not considering synonyms in its
analysis. Complete sentences in human communication or literary text (for
example email, wiki pages, prose, or other human-generated content) can be
extremely diverse in structure. Since categorization is tuned for machine data,
it gives poor results for human-generated data. It would create so many
categories that they couldn&#8217;t be handled effectively. Categorization is <em>not</em>
natural language processing (NLP).</p>
<p>When you create a categorization anomaly detection job, the machine learning model learns what
volume and pattern is normal for each category over time. You can then detect
anomalies and surface rare events or unusual types of messages by using
<a class="xref" href="ml-count-functions.html" title="Count functions">count</a> or <a class="xref" href="ml-rare-functions.html" title="Rare functions">rare</a> functions.</p>
<p>In Kibana, there is a categorization wizard to help you create this type of
anomaly detection job. For example, the following job generates categories from the
contents of the <code class="literal">message</code> field and uses the count function to determine when
certain categories are occurring at anomalous rates:</p>
<div class="imageblock screenshot">
<div class="content">
<img src="images/ml-category-wizard.jpg" alt="Creating a categorization job in Kibana">
</div>
</div>
<details>
<summary class="title">API example</summary>
<div class="content">
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">PUT _ml/anomaly_detectors/it_ops_app_logs
{
  "description" : "IT ops application logs",
  "analysis_config" : {
    "categorization_field_name": "message",<a id="CO3-1"></a><i class="conum" data-value="1"></i>
    "bucket_span":"30m",
    "detectors" :[{
      "function":"count",
      "by_field_name": "mlcategory"<a id="CO3-2"></a><i class="conum" data-value="2"></i>
    }]
  },
  "data_description" : {
    "time_field":"@timestamp"
  }
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/22.console"></div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO3-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>This field is used to derive categories.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO3-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p>The categories are used in a detector by setting <code class="literal">by_field_name</code>,
<code class="literal">over_field_name</code>, or <code class="literal">partition_field_name</code> to the keyword <code class="literal">mlcategory</code>. If you
do not specify this keyword in one of those properties, the API request fails.</p>
</td>
</tr>
</table>
</div>
</div>
</details>
<p>You can use the <span class="strong strong"><strong>Anomaly Explorer</strong></span> in Kibana to view the analysis results:</p>
<div class="imageblock screenshot">
<div class="content">
<img src="images/ml-category-anomalies.jpg" alt="Categorization results in the Anomaly Explorer">
</div>
</div>
<p>For this type of job, the results contain extra information for each anomaly:
the name of the category (for example, <code class="literal">mlcategory 2</code>) and examples of the
messages in that category. You can use these details to investigate occurrences
of unusually high message counts.</p>
<p>If you use the advanced anomaly detection job wizard in Kibana or the
<a href="/guide/en/elasticsearch/reference/7.8/ml-put-job.html" class="ulink" target="_top">create anomaly detection jobs API</a>, there are additional
configuration options. For example, the optional <code class="literal">categorization_examples_limit</code>
property specifies the maximum number of examples that are stored in memory and
in the results data store for each category. The default value is <code class="literal">4</code>. Note that
this setting does not affect the categorization; it just affects the list of
visible examples. If you increase this value, more examples are available, but
you must have more storage available. If you set this value to <code class="literal">0</code>, no examples
are stored.</p>
<p>Another advanced option is the <code class="literal">categorization_filters</code> property, which can
contain an array of regular expressions. If a categorization field value matches
the regular expression, the portion of the field that is matched is not taken
into consideration when defining categories. The categorization filters are
applied in the order they are listed in the job configuration, which enables you
to disregard multiple sections of the categorization field value. In this
example, you might create a filter like <code class="literal">[ "\\[statement:.*\\]"]</code> to remove the
SQL statement from the categorization algorithm.</p>
<h4><a id="ml-configuring-analyzer"></a>Customizing the categorization analyzer<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/elasticsearch/edit/7.8/docs/reference/ml/anomaly-detection/ml-configuring-categories.asciidoc">edit</a></h4>
<p>Categorization uses English dictionary words to identify log message categories.
By default, it also uses English tokenization rules. For this reason, if you use
the default categorization analyzer, only English language log messages are
supported, as described in the <a class="xref" href="ml-limitations.html" title="Machine learning anomaly detection limitations"><em>Limitations</em></a>.</p>
<p>If you use the categorization wizard in Kibana, you can see which categorization
analyzer it uses and highlighted examples of the tokens that it identifies. You
can also change the tokenization rules by customizing the way the categorization
field values are interpreted:</p>
<div class="imageblock screenshot">
<div class="content">
<img src="images/ml-category-analyzer.jpg" alt="Editing the categorization analyzer in Kibana">
</div>
</div>
<p>The categorization analyzer can refer to a built-in Elasticsearch analyzer or a
combination of zero or more character filters, a tokenizer, and zero or more
token filters. In this example, adding a
<a href="/guide/en/elasticsearch/reference/7.8/analysis-pattern-replace-charfilter.html" class="ulink" target="_top"><code class="literal">pattern_replace</code> character filter</a>
achieves exactly the same behavior as the <code class="literal">categorization_filters</code> job
configuration option described earlier. For more details about these properties,
see the
<a href="/guide/en/elasticsearch/reference/7.8/ml-put-job.html#ml-put-job-request-body" class="ulink" target="_top"><code class="literal">categorization_analyzer</code> API object</a>.</p>
<p>If you use the default categorization analyzer in Kibana or omit the
<code class="literal">categorization_analyzer</code> property from the API, the following default values
are used:</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">POST _ml/anomaly_detectors/_validate
{
  "analysis_config" : {
    "categorization_analyzer" : {
      "tokenizer" : "ml_classic",
      "filter" : [
        { "type" : "stop", "stopwords": [
          "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday",
          "Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun",
          "January", "February", "March", "April", "May", "June", "July", "August", "September", "October", "November", "December",
          "Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec",
          "GMT", "UTC"
        ] }
      ]
    },
    "categorization_field_name": "message",
    "detectors" :[{
      "function":"count",
      "by_field_name": "mlcategory"
    }]
  },
  "data_description" : {
  }
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/23.console"></div>
<p>If you specify any part of the <code class="literal">categorization_analyzer</code>, however, any omitted
sub-properties are <em>not</em> set to default values.</p>
<p>The <code class="literal">ml_classic</code> tokenizer and the day and month stopword filter are more or
less equivalent to the following analyzer, which is defined using only built-in
Elasticsearch <a href="/guide/en/elasticsearch/reference/7.8/analysis-tokenizers.html" class="ulink" target="_top">tokenizers</a> and
<a href="/guide/en/elasticsearch/reference/7.8/analysis-tokenfilters.html" class="ulink" target="_top">token filters</a>:</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">PUT _ml/anomaly_detectors/it_ops_new_logs3
{
  "description" : "IT Ops Application Logs",
  "analysis_config" : {
    "categorization_field_name": "message",
    "bucket_span":"30m",
    "detectors" :[{
      "function":"count",
      "by_field_name": "mlcategory",
      "detector_description": "Unusual message counts"
    }],
    "categorization_analyzer":{
      "tokenizer": {
        "type" : "simple_pattern_split",
        "pattern" : "[^-0-9A-Za-z_.]+" <a id="CO4-1"></a><i class="conum" data-value="1"></i>
      },
      "filter": [
        { "type" : "pattern_replace", "pattern": "^[0-9].*" }, <a id="CO4-2"></a><i class="conum" data-value="2"></i>
        { "type" : "pattern_replace", "pattern": "^[-0-9A-Fa-f.]+$" }, <a id="CO4-3"></a><i class="conum" data-value="3"></i>
        { "type" : "pattern_replace", "pattern": "^[^0-9A-Za-z]+" }, <a id="CO4-4"></a><i class="conum" data-value="4"></i>
        { "type" : "pattern_replace", "pattern": "[^0-9A-Za-z]+$" }, <a id="CO4-5"></a><i class="conum" data-value="5"></i>
        { "type" : "stop", "stopwords": [
          "",
          "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday",
          "Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun",
          "January", "February", "March", "April", "May", "June", "July", "August", "September", "October", "November", "December",
          "Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec",
          "GMT", "UTC"
        ] }
      ]
    }
  },
  "analysis_limits":{
    "categorization_examples_limit": 5
  },
  "data_description" : {
    "time_field":"time",
    "time_format": "epoch_ms"
  }
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/24.console"></div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO4-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>Tokens basically consist of hyphens, digits, letters, underscores and dots.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO4-2"><i class="conum" data-value="2"></i></a></p>
</td>
<td align="left" valign="top">
<p>By default, categorization ignores tokens that begin with a digit.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO4-3"><i class="conum" data-value="3"></i></a></p>
</td>
<td align="left" valign="top">
<p>By default, categorization also ignores tokens that are hexadecimal numbers.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO4-4"><i class="conum" data-value="4"></i></a></p>
</td>
<td align="left" valign="top">
<p>Underscores, hyphens, and dots are removed from the beginning of tokens.</p>
</td>
</tr>
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO4-5"><i class="conum" data-value="5"></i></a></p>
</td>
<td align="left" valign="top">
<p>Underscores, hyphens, and dots are also removed from the end of tokens.</p>
</td>
</tr>
</table>
</div>
<p>The key difference between the default <code class="literal">categorization_analyzer</code> and this
example analyzer is that using the <code class="literal">ml_classic</code> tokenizer is several times
faster. The difference in behavior is that this custom analyzer does not include
accented letters in tokens whereas the <code class="literal">ml_classic</code> tokenizer does, although
that could be fixed by using more complex regular expressions.</p>
<p>If you are categorizing non-English messages in a language where words are
separated by spaces, you might get better results if you change the day or month
words in the stop token filter to the appropriate words in your language. If you
are categorizing messages in a language where words are not separated by spaces,
you must use a different tokenizer as well in order to get sensible
categorization results.</p>
<p>It is important to be aware that analyzing for categorization of machine
generated log messages is a little different from tokenizing for search.
Features that work well for search, such as stemming, synonym substitution, and
lowercasing are likely to make the results of categorization worse. However, in
order for drill down from machine learning results to work correctly, the tokens that the
categorization analyzer produces must be similar to those produced by the search
analyzer. If they are sufficiently similar, when you search for the tokens that
the categorization analyzer produces then you find the original document that
the categorization field value came from.</p>
</div>
<div class="navfooter">
<span class="prev">
<a href="ml-configuring-detector-custom-rules.html">« Customizing detectors with custom rules</a>
</span>
<span class="next">
<a href="ml-configuring-populations.html">Performing population analysis »</a>
</span>
</div>
</div>
</body>
</html>
