<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Working with data frame analytics at scale | Machine Learning in the Elastic Stack [7.9] | Elastic</title>
<link rel="home" href="index.html" title="Machine Learning in the Elastic Stack [7.9]"/>
<link rel="up" href="ml-dfa-overview.html" title="Overview"/>
<link rel="prev" href="ml-dfa-phases.html" title="How a data frame analytics job works"/>
<link rel="next" href="ml-dfa-concepts.html" title="Concepts"/>
<meta name="DC.type" content="Learn/Docs/Elastic Stack/Machine Learning/7.9"/>
<meta name="DC.subject" content="Machine Learning"/>
<meta name="DC.identifier" content="7.9"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body><div class="page_header">
<strong>IMPORTANT</strong>: No additional bug fixes or documentation updates
will be released for this version. For the latest information, see the
<a href="../current/index.html">current release documentation</a>.
</div>
<div id="content">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="index.html">Machine Learning in the Elastic Stack [7.9]</a></span>
»
<span class="breadcrumb-link"><a href="ml-dfanalytics.html">Data frame analytics</a></span>
»
<span class="breadcrumb-link"><a href="ml-dfa-overview.html">Overview</a></span>
»
<span class="breadcrumb-node">Working with data frame analytics at scale</span>
</div>
<div class="navheader">
<span class="prev">
<a href="ml-dfa-phases.html">« How a data frame analytics job works</a>
</span>
<span class="next">
<a href="ml-dfa-concepts.html">Concepts »</a>
</span>
</div>
<div class="section xpack">
<div class="titlepage"><div><div>
<h2 class="title"><a id="ml-dfa-scale"></a>Working with data frame analytics at scale<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/stack-docs/edit/7.9/docs/en/stack/ml/df-analytics/ml-dfa-scale.asciidoc">edit</a><a class="xpack_tag" href="/subscriptions"></a></h2>
</div></div></div>
<p>A data frame analytics job has numerous configuration options. Some of them may have a
significant effect on the time taken to train a model. The training time depends
on various factors, like the statistical characteristics of your data, the
number of provided hyperparameters, the number of features included in the
analysis, the hardware you use, and so on. This guide contains a list of
considerations to help you plan for training data frame analytics models at scale and
optimizing training time.</p>
<p>In this guide, you’ll learn how to:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
Understand the impact of configuration options on the time taken to train
models for data frame analytics jobs.
</li>
</ul>
</div>
<p><span class="strong strong"><strong>Prerequisites:</strong></span></p>
<p>This guide assumes you’re already familiar with:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
How to create data frame analytics jobs. If not, refer to <a class="xref" href="ml-dfa-overview.html" title="Overview"><em>Overview</em></a>.
</li>
<li class="listitem">
How data frame analytics jobs work. If not, refer to <a class="xref" href="ml-dfa-phases.html" title="How a data frame analytics job works">How it works</a>.
</li>
</ul>
</div>
<p>It is important to note that there is a correlation between the training time,
the complexity of the model, the size of the data, and the quality of the
analysis results. Improvements in quality, however, are not linear with the
amount of training data; for very large source data, it might take hours to
train a model for very small gains in quality. When you work at scale with
data frame analytics, you need to decide what quality of results is acceptable for your
use case. When you have determined your acceptance criteria, you have a better
picture of the factors you can trade off while still achieving your goal.</p>
<p>The following recommendations are not sequential – the numbers just help to
navigate between the list items; you can take action on one or more of them in
any order.</p>
<h4><a id="rapid-iteration"></a>0. Start small and iterate rapidly<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/stack-docs/edit/7.9/docs/en/stack/ml/df-analytics/ml-dfa-scale.asciidoc">edit</a></h4>
<p>Training is an iterative process. Experiment with different settings and
configuration options (including but not limited to hyperparameters and feature
importance), then evaluate the results and decide whether they are good enough
or need further experimentation.</p>
<p>Every iteration takes time, so it is useful to start with a small set of data so
you can iterate rapidly and then build up from here.</p>
<h4><a id="small-training-percent"></a>1. Set a small training percent<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/stack-docs/edit/7.9/docs/en/stack/ml/df-analytics/ml-dfa-scale.asciidoc">edit</a></h4>
<p>(This step only applies to regression and classification jobs.)</p>
<p>The number of documents used for training a model has an effect on the training
time. A higher training percent means a longer training time.</p>
<p>Consider starting with a small percentage of training data so you can complete
iterations more quickly. Once you are happy with your configuration, increase
the training percent.  As a rule of thumb, if you have a data set with more than
100,000 data points, start with a training percent of 5 or 10.</p>
<h4><a id="disable-feature-importance"></a>2. Disable feature importance calculation<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/stack-docs/edit/7.9/docs/en/stack/ml/df-analytics/ml-dfa-scale.asciidoc">edit</a></h4>
<p>(This step only applies to regression and classification jobs.)</p>
<p><a class="xref" href="ml-feature-importance.html" title="Feature importance">Feature importance</a> indicates which fields had the biggest impact on each
prediction that is generated by the analysis. Depending on the size of the data
set, feature importance can take a long time to compute.</p>
<p>For a shorter runtime, consider disabling feature importance for some or all iterations
if you do not require it.</p>
<h4><a id="optimize-included-fields"></a>3. Optimize the number of included fields<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/stack-docs/edit/7.9/docs/en/stack/ml/df-analytics/ml-dfa-scale.asciidoc">edit</a></h4>
<p>You can speed up runtime by only analyzing relevant fields.</p>
<p>By default, all the fields that are supported by the analysis type are included
in the analysis. In general, more fields analyzed requires more resources and
longer training times, including the time taken for automatic feature selection.
To reduce training time, consider limiting the scope of the analysis to the
relevant fields that contribute to the prediction. You may do this by either
excluding non-relevant fields or by including relevant ones.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>Feature importance can help you determine the fields that contribute most to
the prediction. However, as calculating feature importance increases training time, this
is a trade-off that can be evaluated during an iterative training process.</p>
</div>
</div>
<h4><a id="increase-threads"></a>4. Increase the maximum number of threads<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/stack-docs/edit/7.9/docs/en/stack/ml/df-analytics/ml-dfa-scale.asciidoc">edit</a></h4>
<p>You can set the maximum number of threads that are used during the analysis. The
default value of <code class="literal">max_num_threads</code> is 1. Depending on the characteristics of the
data, using more threads may decrease the training time at the cost of increased
CPU usage. Note that trying to use more threads than the number of CPU cores has
no advantage.</p>
<p>Hyperparameter optimization and calculating feature importance gain the most benefit
from the increased number of threads. This can be seen in phases
<code class="literal">coarse_parameter_search</code>, <code class="literal">fine_tuning_parameters</code>, and <code class="literal">writing_results</code>. The
rest of the phases are not affected by the increased number of threads.</p>
<p>To learn more about the individual phases, refer to <a class="xref" href="ml-dfa-phases.html" title="How a data frame analytics job works">How it works</a>.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>If your machine learning nodes are running concurrent anomaly detection or
data frame analytics jobs, then you may want to keep the maximum number of threads set
to a low number – for example the default 1 – to prevent jobs competing for
resources.</p>
</div>
</div>
<h4><a id="optimize-source-index"></a>5. Optimize the size of the source index<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/stack-docs/edit/7.9/docs/en/stack/ml/df-analytics/ml-dfa-scale.asciidoc">edit</a></h4>
<p>Even if the training percent is low, reindexing the source index – which is a
mandatory step in the job creation process – may take a long time. During
reindexing, the documents from the source index or indices are copied to the
destination index, so you have a static  copy of the analyzed data.</p>
<p>If your data is large and you do not need to test and train on the whole source
index or indices, then reduce the cost of reindexing by using a subset of your
source data. This can be done by either defining a filter for the source index
in the data frame analytics job configuration, or by manually reindexing a subset of
this data to use as an alternate source index.</p>
<h4><a id="configure-hyperparameters"></a>6. Configure hyperparameters<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/stack-docs/edit/7.9/docs/en/stack/ml/df-analytics/ml-dfa-scale.asciidoc">edit</a></h4>
<p>(This step only applies to regression and classification jobs.)</p>
<p><a class="xref" href="hyperparameters.html" title="Hyperparameter optimization">Hyperparameter optimization</a> is the most complicated mathematical process during model
training and may take a long time.</p>
<p>By default, optimized hyperparameter values are chosen automatically. It is
possible to reduce the time taken at this step by manually configuring
hyperparameters – if you fully understand the purpose of the hyperparameters and
have a sensible value for any or all of them. This reduces the computing load
and therefore decreases training time.</p>
</div>
<div class="navfooter">
<span class="prev">
<a href="ml-dfa-phases.html">« How a data frame analytics job works</a>
</span>
<span class="next">
<a href="ml-dfa-concepts.html">Concepts »</a>
</span>
</div>
</div>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  messageStyle: "none",
  tex2jax: {
    inlineMath: [["\\(", "\\)"]],
    displayMath: [["\\[", "\\]"]],
    ignoreClass: "nostem|nolatexmath"
  },
  asciimath2jax: {
    delimiters: [["\\$", "\\$"]],
    ignoreClass: "nostem|noasciimath"
  },
  TeX: { equationNumbers: { autoNumber: "none" } }
})
MathJax.Hub.Register.StartupHook("AsciiMath Jax Ready", function () {
  MathJax.InputJax.AsciiMath.postfilterHooks.Add(function (data, node) {
    if ((node = data.script.parentNode) && (node = node.parentNode) && node.classList.contains('stemblock')) {
      data.math.root.display = "block"
    }
    return data
  })
})
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_HTMLorMML"></script>
</body>
</html>
