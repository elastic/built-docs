<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="keywords" content="ML, Elastic Stack, natural language processing, inference">
<title>Benchmark information | Machine Learning in the Elastic Stack [8.11] | Elastic</title>
<meta class="elastic" name="content" content="Benchmark information | Machine Learning in the Elastic Stack [8.11]">

<link rel="home" href="index.html" title="Machine Learning in the Elastic Stack [8.11]"/>
<link rel="up" href="ml-nlp-elser.html" title="ELSER – Elastic Learned Sparse EncodeR"/>
<link rel="prev" href="ml-nlp-elser.html" title="ELSER – Elastic Learned Sparse EncodeR"/>
<link rel="next" href="ml-nlp-model-ref.html" title="Compatible third party NLP models"/>
<meta class="elastic" name="product_version" content="8.11"/>
<meta class="elastic" name="product_name" content="Machine Learning"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/Elastic Stack/Machine Learning/8.11"/>
<meta name="DC.subject" content="Machine Learning"/>
<meta name="DC.identifier" content="8.11"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body>
<div class="page_header">
<strong>IMPORTANT</strong>: No additional bug fixes or documentation updates
will be released for this version. For the latest information, see the
<a href="../current/index.html">current release documentation</a>.
</div>
<div class="navheader">
<span class="prev">
<a href="ml-nlp-elser.html">« ELSER – Elastic Learned Sparse EncodeR</a>
</span>
<span class="next">
<a href="ml-nlp-model-ref.html">Compatible third party NLP models »</a>
</span>
</div>
<div class="book" lang="en">
<div class="titlepage">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Machine Learning in the Elastic Stack [8.11]</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="ml-nlp.html">Natural language processing</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="ml-nlp-elser.html">ELSER – Elastic Learned Sparse EncodeR</a></span>
</div>
<div>
<div><h1 class="title"><a id="id-1"></a>Benchmark information</h1><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/stack-docs/edit/8.11/docs/en/stack/ml/nlp/ml-nlp-elser.asciidoc">edit</a></div>
</div>
<!--EXTRA-->
</div>
<div id="content">
<div class="section">
<div class="titlepage"><div><div>
<div class="position-relative"><h2 class="title"><a id="elser-benchmarks"></a>Benchmark information</h2><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/stack-docs/edit/8.11/docs/en/stack/ml/nlp/ml-nlp-elser.asciidoc">edit</a></div>
</div></div></div>
<p>The following sections provide information about how ELSER performs on different
hardwares and compares the model performance to Elasticsearch BM25 and other strong
baselines.</p>
<div class="position-relative"><h4><a id="version-overview"></a>Version overview</h4><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/stack-docs/edit/8.11/docs/en/stack/ml/nlp/ml-nlp-elser.asciidoc">edit</a></div>
<p>ELSER V2 has a <span class="strong strong"><strong>optimized</strong></span> version that is designed to run only on Linux with
an x86-64 CPU architecture and a <span class="strong strong"><strong>cross-platform</strong></span> version that can be run on
any platform.</p>
<div class="position-relative"><h5><a id="_elser_v2"></a>ELSER V2</h5><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/stack-docs/edit/8.11/docs/en/stack/ml/nlp/ml-nlp-elser.asciidoc">edit</a></div>
<p>Besides the performance improvements, the biggest change in ELSER V2 is the
introduction of the first platform specific ELSER model - that is, a model
optimized to run only on Linux with an x86-64 CPU architecture. The optimized
model is designed to work best on newer Intel CPUs, but it works on AMD CPUs as
well. It is recommended to use the new optimized Linux-x86-64 model for all new
users of ELSER as it is significantly faster than the cross-platform model which
can be run on any platform. ELSER V2 produces significantly higher quality
embeddings than ELSER V1. Regardless of which ELSER V2 model you use (optimized
or cross-platform), the particular embeddings produced are the same.</p>
<div class="position-relative"><h4><a id="elser-qualitative-benchmarks"></a>Qualitative benchmarks</h4><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/stack-docs/edit/8.11/docs/en/stack/ml/nlp/ml-nlp-elser.asciidoc">edit</a></div>
<p>The metric that is used to evaluate ELSER&#8217;s ranking ability is the Normalized
Discounted Cumulative Gain (NDCG) which can handle multiple relevant documents
and fine-grained document ratings. The metric is applied to a fixed-sized list
of retrieved documents which, in this case, is the top 10 documents (NDCG@10).</p>
<p>The table below shows the performance of ELSER V2 compared to BM 25. ELSER V2
has 10 wins, 1 draw, 1 loss and an average improvement in NDCG@10 of 18%.</p>
<div class="imageblock text-center">
<div class="content">
<img src="images/ml-nlp-bm25-elser-v2.png" alt="ELSER V2 benchmarks compared to BM25">
</div>
</div>
<p><em>NDCG@10 for BEIR data sets for BM25 and ELSER V2  - higher values are better)</em></p>
<div class="position-relative"><h4><a id="elser-hw-benchmarks"></a>Hardware benchmarks</h4><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/stack-docs/edit/8.11/docs/en/stack/ml/nlp/ml-nlp-elser.asciidoc">edit</a></div>
<div class="important admon">
<div class="icon"></div>
<div class="admon_content">
<p>While the goal is to create a model that is as performant as
possible, retrieval accuracy always take precedence over speed, this is one of
the design principles of ELSER. Consult with the tables below to learn more
about the expected model performance. The values refer to operations performed
on two data sets and different hardware configurations. Your data set has an
impact on the model performance. Run tests on your own data to have a more
realistic view on the model performance for your use case.</p>
</div>
</div>
<div class="position-relative"><h5><a id="_elser_v2_2"></a>ELSER V2</h5><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/stack-docs/edit/8.11/docs/en/stack/ml/nlp/ml-nlp-elser.asciidoc">edit</a></div>
<p>Overall the optimized V2 model ingested at a max rate of 26 docs/s, compared
with the ELSER V1 max rate of 14 docs/s from the ELSER V1 benchamrk, resulting
in a 90% increase in throughput.</p>
<p>The performance of virtual cores (that is, when the number of allocations is
greater than half of the vCPUs) has increased. Previously, the increase in
performance between 8 and 16 allocations was around 7%. It has increased to 17%
(ELSER V1 on 8.11) and 20% (for ELSER V2 optimized). These tests were performed
on a 16vCPU machine, with all documents containing exactly 256 tokens.</p>
<div class="important admon">
<div class="icon"></div>
<div class="admon_content">
<p>The length of the documents in your particular dataset will have a
significant impact on your throughput numbers.</p>
</div>
</div>
<p>Refer to
<a href="/search-labs/introducing-elser-v2-part-1" class="ulink" target="_top">this blog post</a>
to learn more about ELSER V2 improved performance.</p>
<div class="imageblock text-center">
<div class="content">
<img src="images/ml-nlp-elser-bm-summary.png" alt="Summary of ELSER V1 and V2 benchmark reports">
</div>
</div>
<p><span class="strong strong"><strong>The optimized model</strong></span> results show a nearly linear growth up until 8
allocations, after which performance improvements become smaller. In this case,
the performance at 8 allocations was 22 docs/s, while the performance of 16
allocations was 26 docs/s, indicating a 20% performance increase due to virtual
cores.</p>
<div class="imageblock text-center">
<div class="content">
<img src="images/ml-nlp-elser-v2-opt-bm-results.png" alt="ELSER V2 optimized benchmarks">
</div>
</div>
<p><span class="strong strong"><strong>The cross-platform</strong></span> model performance of 8 and 16 allocations are
respectively 14 docs/s and 16 docs/s, indicating a performance improvement due
to virtual cores of 12%.</p>
<div class="imageblock text-center">
<div class="content">
<img src="images/ml-nlp-elser-v2-cp-bm-results.png" alt="ELSER V2 cross-platform benchmarks">
</div>
</div>
</div>
</div>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  messageStyle: "none",
  tex2jax: {
    inlineMath: [["\\(", "\\)"]],
    displayMath: [["\\[", "\\]"]],
    ignoreClass: "nostem|nolatexmath"
  },
  asciimath2jax: {
    delimiters: [["\\$", "\\$"]],
    ignoreClass: "nostem|noasciimath"
  },
  TeX: { equationNumbers: { autoNumber: "none" } }
})
MathJax.Hub.Register.StartupHook("AsciiMath Jax Ready", function () {
  MathJax.InputJax.AsciiMath.postfilterHooks.Add(function (data, node) {
    if ((node = data.script.parentNode) && (node = node.parentNode) && node.classList.contains('stemblock')) {
      data.math.root.display = "block"
    }
    return data
  })
})
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_HTMLorMML"></script>
</div><div class="navfooter">
<span class="prev">
<a href="ml-nlp-elser.html">« ELSER – Elastic Learned Sparse EncodeR</a>
</span>
<span class="next">
<a href="ml-nlp-model-ref.html">Compatible third party NLP models »</a>
</span>
</div>
</body>
</html>
