<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="keywords" content="ML, Elastic Stack, anomaly detection, data frame analytics">
<title>Loss functions for regression analyses | Machine Learning in the Elastic Stack [8.14] | Elastic</title>
<meta class="elastic" name="content" content="Loss functions for regression analyses | Machine Learning in the Elastic Stack [8.14]">

<link rel="home" href="index.html" title="Machine Learning in the Elastic Stack [8.14]"/>
<link rel="up" href="ml-dfa-concepts.html" title="Advanced concepts"/>
<link rel="prev" href="ml-feature-importance.html" title="Feature importance"/>
<link rel="next" href="hyperparameters.html" title="Hyperparameter optimization"/>
<meta class="elastic" name="product_version" content="8.14"/>
<meta class="elastic" name="product_name" content="Machine Learning"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/Elastic Stack/Machine Learning/8.14"/>
<meta name="DC.subject" content="Machine Learning"/>
<meta name="DC.identifier" content="8.14"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body>
<div class="page_header">
<strong>IMPORTANT</strong>: No additional bug fixes or documentation updates
will be released for this version. For the latest information, see the
<a href="../current/index.html">current release documentation</a>.
</div>
<div class="navheader">
<span class="prev">
<a href="ml-feature-importance.html">« Feature importance</a>
</span>
<span class="next">
<a href="hyperparameters.html">Hyperparameter optimization »</a>
</span>
</div>
<div class="book" lang="en">
<div class="titlepage">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Machine Learning in the Elastic Stack [8.14]</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="ml-dfanalytics.html">Data frame analytics</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="ml-dfa-concepts.html">Advanced concepts</a></span>
</div>
<div>
<div><h1 class="title"><a id="id-1"></a>Loss functions for regression analyses</h1><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/stack-docs/edit/8.14/docs/en/stack/ml/df-analytics/ml-dfa-regression-loss-functions.asciidoc">edit</a></div>
</div>
<!--EXTRA-->
</div>
<div id="content">
<div class="section xpack">
<div class="titlepage"><div><div>
<h2 class="title"><a id="dfa-regression-lossfunction"></a>Loss functions for regression analyses<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/stack-docs/edit/8.14/docs/en/stack/ml/df-analytics/ml-dfa-regression-loss-functions.asciidoc">edit</a></h2>
</div></div></div>
<p>A loss function measures how well a given machine learning model fits the specific data set.
It boils down all the different under- and overestimations of the model to a
single number, known as the prediction error. The bigger the difference between
the prediction and the ground truth, the higher the value of the loss function.
Loss functions are used automatically in the background during
<a class="xref" href="hyperparameters.html" title="Hyperparameter optimization">hyperparameter optimization</a> and when training the decision
trees to compare the performance of various iterations of the model.</p>
<p>In the Elastic Stack, there are three different types of loss function:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<a href="https://en.wikipedia.org/wiki/Mean_squared_error" class="ulink" target="_top">mean squared error (<code class="literal">mse</code>)</a>:
It is the default choice when no additional information about the data set is
available.
</li>
<li class="listitem">
mean squared logarithmic error (<code class="literal">msle</code>; a variation of <code class="literal">mse</code>): It is for
cases where the target values are all positive with a long tail distribution
(for example, prices or population).
</li>
<li class="listitem">
<a href="https://en.wikipedia.org/wiki/Huber_loss#Pseudo-Huber_loss_function" class="ulink" target="_top">Pseudo-Huber loss (<code class="literal">huber</code>)</a>:
Use it when you want to prevent the model trying to fit the outliers instead of
regular data.
</li>
</ul>
</div>
<p>The various types of loss function calculate the prediction error differently.
The appropriate loss function for your use case depends on the target
distribution in your data set, the problem that you want to model, the number of
outliers in the data, and so on.</p>
<p>You can specify the loss function to be used during regression analysis when you
create the data frame analytics job. The default is mean squared error (<code class="literal">mse</code>). If you
choose <code class="literal">msle</code> or <code class="literal">huber</code>, you can also set up a parameter for the loss function.
With the parameter, you can further refine the behavior of the chosen functions.</p>
<p>Consult
<a href="https://github.com/elastic/examples/tree/master/Machine%20Learning/Regression%20Loss%20Functions" class="ulink" target="_top">the Jupyter notebook on regression loss functions</a>
to learn more.</p>
<div class="tip admon">
<div class="icon"></div>
<div class="admon_content">
<p>The default loss function parameter values work fine for most of the cases.
It is highly recommended to use the default values, unless you fully understand
the impact of the different loss function parameters.</p>
</div>
</div>
</div>
</div>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  messageStyle: "none",
  tex2jax: {
    inlineMath: [["\\(", "\\)"]],
    displayMath: [["\\[", "\\]"]],
    ignoreClass: "nostem|nolatexmath"
  },
  asciimath2jax: {
    delimiters: [["\\$", "\\$"]],
    ignoreClass: "nostem|noasciimath"
  },
  TeX: { equationNumbers: { autoNumber: "none" } }
})
MathJax.Hub.Register.StartupHook("AsciiMath Jax Ready", function () {
  MathJax.InputJax.AsciiMath.postfilterHooks.Add(function (data, node) {
    if ((node = data.script.parentNode) && (node = node.parentNode) && node.classList.contains('stemblock')) {
      data.math.root.display = "block"
    }
    return data
  })
})
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_HTMLorMML"></script>
</div><div class="navfooter">
<span class="prev">
<a href="ml-feature-importance.html">« Feature importance</a>
</span>
<span class="next">
<a href="hyperparameters.html">Hyperparameter optimization »</a>
</span>
</div>
</body>
</html>
