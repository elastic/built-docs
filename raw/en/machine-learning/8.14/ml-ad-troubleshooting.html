<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="keywords" content="ML, Elastic Stack, anomaly detection, data frame analytics">
<title>Troubleshooting machine learning anomaly detection and frequently asked questions | Machine Learning in the Elastic Stack [8.14] | Elastic</title>
<meta class="elastic" name="content" content="Troubleshooting machine learning anomaly detection and frequently asked questions | Machine Learning in the Elastic Stack [8.14]">

<link rel="home" href="index.html" title="Machine Learning in the Elastic Stack [8.14]"/>
<link rel="up" href="ml-ad-resources.html" title="Resources"/>
<link rel="prev" href="ootb-ml-jobs.html" title="Supplied anomaly detection configurations"/>
<link rel="next" href="ootb-ml-jobs-apache.html" title="Appendix A: Apache anomaly detection configurations"/>
<meta class="elastic" name="product_version" content="8.14"/>
<meta class="elastic" name="product_name" content="Machine Learning"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/Elastic Stack/Machine Learning/8.14"/>
<meta name="DC.subject" content="Machine Learning"/>
<meta name="DC.identifier" content="8.14"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body>
<div class="page_header">
<strong>IMPORTANT</strong>: No additional bug fixes or documentation updates
will be released for this version. For the latest information, see the
<a href="../current/index.html">current release documentation</a>.
</div>
<div class="navheader">
<span class="prev">
<a href="ootb-ml-jobs.html">« Supplied anomaly detection configurations</a>
</span>
<span class="next">
<a href="ootb-ml-jobs-apache.html">Appendix A: Apache anomaly detection configurations »</a>
</span>
</div>
<div class="book" lang="en">
<div class="titlepage">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Machine Learning in the Elastic Stack [8.14]</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="ml-ad-overview.html">Anomaly detection</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="ml-ad-resources.html">Resources</a></span>
</div>
<div>
<div><h1 class="title"><a id="id-1"></a>Troubleshooting machine learning anomaly detection and frequently asked questions</h1><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/stack-docs/edit/8.14/docs/en/stack/ml/anomaly-detection/ml-ad-troubleshooting.asciidoc">edit</a></div>
</div>
<!--EXTRA-->
</div>
<div id="content">
<div class="section xpack">
<div class="titlepage"><div><div>
<h2 class="title"><a id="ml-ad-troubleshooting"></a>Troubleshooting machine learning anomaly detection and frequently asked questions<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/stack-docs/edit/8.14/docs/en/stack/ml/anomaly-detection/ml-ad-troubleshooting.asciidoc">edit</a></h2>
</div></div></div>

<p>Use the information in this section to troubleshoot common problems and find
answers for frequently asked questions.</p>
<h4><a id="ml-ad-restart-failed-jobs"></a>How to restart failed anomaly detection jobs<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/stack-docs/edit/8.14/docs/en/stack/ml/anomaly-detection/ml-ad-troubleshooting.asciidoc">edit</a></h4>
<p>If an anomaly detection job fails, try to restart the job by following the procedure
described below. If the restarted job runs as expected, then the problem that
caused the job to fail was transient and no further investigation is needed. If
the job quickly fails after the restart, then the problem is persistent and
needs further investigation. In this case, find out which node the failed job
was running on by checking the job stats on the <span class="strong strong"><strong>Job management</strong></span> pane in
Kibana. Then get the logs for that node and look for exceptions and errors where
the ID of the anomaly detection job is in the message to have a better understanding of
the issue.</p>
<p>If an anomaly detection job has failed, do the following to recover from <code class="literal">failed</code> state:</p>
<div class="olist orderedlist">
<ol class="orderedlist">
<li class="listitem">
<p><em>Force</em> stop the corresponding datafeed by using the
<a href="/guide/en/elasticsearch/reference/8.14/ml-stop-datafeed.html" class="ulink" target="_top">Stop datafeed API</a> with the <code class="literal">force</code> parameter being
<code class="literal">true</code>. For example, the following request force stops the <code class="literal">my_datafeed</code>
datafeed.</p>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">POST _ml/datafeeds/my_datafeed/_stop
{
  "force": "true"
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/30.console"></div>
</li>
<li class="listitem">
<p><em>Force</em> close the anomaly detection job by using the
<a href="/guide/en/elasticsearch/reference/8.14/ml-close-job.html" class="ulink" target="_top">Close anomaly detection job API</a> with the <code class="literal">force</code> parameter
being <code class="literal">true</code>. For example, the following request force closes the <code class="literal">my_job</code>
anomaly detection job:</p>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">POST _ml/anomaly_detectors/my_job/_close?force=true</pre>
</div>
<div class="console_widget" data-snippet="snippets/31.console"></div>
</li>
<li class="listitem">
Restart the anomaly detection job on the <span class="strong strong"><strong>Job management</strong></span> pane in Kibana.
</li>
</ol>
</div>
<h4><a id="faq-methods"></a>What machine learning methods are used for anomaly detection?<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/stack-docs/edit/8.14/docs/en/stack/ml/anomaly-detection/ml-ad-troubleshooting.asciidoc">edit</a></h4>
<p>For detailed information, refer to the paper <a href="https://www.ijmlc.org/papers/398-LC018.pdf" class="ulink" target="_top">Anomaly Detection in Application Performance Monitoring Data</a> by Thomas Veasey and Stephen Dodson, as well as our webinars on <a href="/elasticon/conf/2018/sf/the-math-behind-elastic-machine-learning" class="ulink" target="_top">The Math behind Elastic Machine Learning</a> and
<a href="/elasticon/conf/2017/sf/machine-learning-and-statistical-methods-for-time-series-analysis" class="ulink" target="_top">Machine Learning and Statistical Methods for Time Series Analysis</a>.</p>
<p>Further papers cited in the C++ code:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<a href="http://arxiv.org/pdf/1109.2378.pdf" class="ulink" target="_top">Modern hierarchical, agglomerative clustering algorithms</a>
</li>
<li class="listitem">
<a href="https://www.cs.umd.edu/~mount/Projects/KMeans/pami02.pdf" class="ulink" target="_top">An Efficient k-Means Clustering Algorithm: Analysis and Implementation</a>
</li>
<li class="listitem">
<a href="http://www.stat.columbia.edu/~madigan/PAPERS/techno.pdf" class="ulink" target="_top">Large-Scale Bayesian Logistic Regression for Text Categorization</a>
</li>
<li class="listitem">
<a href="https://www.cs.cmu.edu/~dpelleg/download/xmeans.pdf" class="ulink" target="_top">X-means: Extending K-means with Efficient Estimation of the Number of Clusters</a>
</li>
</ul>
</div>
<h4><a id="faq-features"></a>What are the input features used by the model?<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/stack-docs/edit/8.14/docs/en/stack/ml/anomaly-detection/ml-ad-troubleshooting.asciidoc">edit</a></h4>
<p>All input features are specified by the user, for example, using
<a href="/guide/en/machine-learning/current/ml-functions.html" class="ulink" target="_top">diverse statistical functions</a>
like count or mean over the data of interest.</p>
<h4><a id="faq-data"></a>Does the data used by the model only include customers' data?<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/stack-docs/edit/8.14/docs/en/stack/ml/anomaly-detection/ml-ad-troubleshooting.asciidoc">edit</a></h4>
<p>Yes. Only the data specified in the anomaly detection job configuration are used for
detection.</p>
<h4><a id="faq-output-score"></a>What does the model output score represent? How is it generated and calibrated?<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/stack-docs/edit/8.14/docs/en/stack/ml/anomaly-detection/ml-ad-troubleshooting.asciidoc">edit</a></h4>
<p>The ensemble model generates a probability value, which is then mapped to an
anomaly severity score between 0 and 100. The lower the probability of observed
data, the higher the severity score. Refer to this
<a class="xref" href="ml-ad-explain.html" title="Anomaly score explanation">advanced concept doc</a> for details. Calibration (also called as
normalization) happens on two levels:</p>
<div class="olist orderedlist">
<ol class="orderedlist">
<li class="listitem">
Within the same metric/partition, the scores are re-normalized “back in time”
within the window specified by the <code class="literal">renormalization_window_days</code> parameter.
This is the reason, for example, that both <code class="literal">record_score</code> and
<code class="literal">initial_record_score</code> exist.
</li>
<li class="listitem">
Over multiple partitions, scores are renormalized as described in
<a href="/blog/changes-to-elastic-machine-learning-anomaly-scoring-in-6-5" class="ulink" target="_top">this blog post</a>.
</li>
</ol>
</div>
<h4><a id="faq-model-update"></a>Is the model static or updated periodically?<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/stack-docs/edit/8.14/docs/en/stack/ml/anomaly-detection/ml-ad-troubleshooting.asciidoc">edit</a></h4>
<p>It&#8217;s an online model and updated continuously. Old parts of the model are pruned
out based on the parameter <code class="literal">model_prune_window</code> (usually 30 days).</p>
<h4><a id="faq-model-performance"></a>Is the performance of the model monitored?<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/stack-docs/edit/8.14/docs/en/stack/ml/anomaly-detection/ml-ad-troubleshooting.asciidoc">edit</a></h4>
<p>There is a set of benchmarks to monitor the performance of the anomaly detection
algorithms and to ensure no regression occurs as the methods are continuously
developed and refined. They are called "data scenarios" and consist of 3 things:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
a dataset (stored as an Elasticsearch snapshot),
</li>
<li class="listitem">
a machine learning config (anomaly detection, {dfanalysis}, transform, or inference),
</li>
<li class="listitem">
an arbitrary set of static assertions (bucket counts, anomaly scores, accuracy
value, and so on).
</li>
</ul>
</div>
<p>Performance metrics are collected from each and every scenario run and they are
persisted in an Elastic Cloud cluster. This information is then used to track
the performance over time, across the different builds, mainly to detect any
regressions in the performance (both result quality and compute time).</p>
<p>On the customer side, the situation is different. There is no conventional way
to monitor the model performance as it&#8217;s unsupervised. Usually,
operationalization of the model output include one or several of the following
steps:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
Creating alerts for influencers, buckets, or records based on a certain
anomaly score.
</li>
<li class="listitem">
Use the forecasting feature to predict the development of the metric of
interest in the future.
</li>
<li class="listitem">
Use one or a combination of multiple anomaly detection jobs to identify the
significant anomaly influencers.
</li>
</ul>
</div>
<h4><a id="faq-model-accuracy"></a>How to measure the accuracy of the unsupervised machine learning model?<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/stack-docs/edit/8.14/docs/en/stack/ml/anomaly-detection/ml-ad-troubleshooting.asciidoc">edit</a></h4>
<p>For each record in a given time series, anomaly detection models provide an
anomaly severity score, 95% confidence intervals, and an actual value. This data
is stored in an index and can be retrieved using the Get Records API. With this
information, you can use standard measures to assess prediction accuracy,
interval calibration, and so on. Elasticsearch aggregations can be used to
compute these statistics.</p>
<p>The purpose of anomaly detection is to achieve the best ranking of periods where
an anomaly happened. A practical way to evaluate this is to keep track of real
incidents and see how well they correlate with the predictions of
anomaly detection.</p>
<h4><a id="faq-model-drift"></a>Can the anomaly detection model experience model drift?<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/stack-docs/edit/8.14/docs/en/stack/ml/anomaly-detection/ml-ad-troubleshooting.asciidoc">edit</a></h4>
<p>Elasticsearch&#8217;s anomaly detection model continuously learns and adapts to changes
in the time series. These changes can take the form of slow drifts as well as
sudden jumps. Therefore, we take great care to manage the adaptation to changing
data characteristics. There is always a fine trade-off between fitting anomalous
periods (over-fitting) and not learning new normal behavior. The following are
the main approaches Elastic uses to manage this trade-off:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
Learning the optimal decay rate based on measuring the bias in the forecast
and the moments of the error distribution and error distribution moments.
</li>
<li class="listitem">
Allowing continuous small drifts in periodic patterns. This is achieved by
continuously minimizing the mean prediction error over the last iteration with
respect to a small bounded time shift.
</li>
<li class="listitem">
If the predictions are significantly wrong over a long period of time, the
algorithm tests whether the time series has undergone a sudden change.
Hypothesis Testing is used to test for different types of changes, such as
scaling of values, shifting of values, and large time shifts in periodic
patterns such as daylight saving time.
</li>
<li class="listitem">
Running continuous hypothesis tests on time windows of various lengths to test
for significant evidence of new or changed periodic patterns, and update the
model if the null hypothesis of unchanged features is rejected.
</li>
<li class="listitem">
Accumulating error statistics on calendar days and continuously test whether
predictive calendar features need to be added or removed from the model.
</li>
</ul>
</div>
<h4><a id="faq-minimum-data"></a>What is the minimum amount of data for an anomaly detection job?<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/stack-docs/edit/8.14/docs/en/stack/ml/anomaly-detection/ml-ad-troubleshooting.asciidoc">edit</a></h4>
<p>Elastic machine learning needs a minimum amount of data to be able to build an effective
model for anomaly detection.</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
For sampled metrics such as <code class="literal">mean</code>, <code class="literal">min</code>, <code class="literal">max</code>,
and <code class="literal">median</code>, the minimum data amount is either eight non-empty bucket spans or
two hours, whichever is greater.
</li>
<li class="listitem">
For all other non-zero/null metrics and count-based quantities, it&#8217;s four
non-empty bucket spans or two hours, whichever is greater.
</li>
<li class="listitem">
For the <code class="literal">count</code> and <code class="literal">sum</code> functions, empty buckets matter and therefore it is
the same as sampled metrics - eight buckets or two hours.
</li>
<li class="listitem">
For the <code class="literal">rare</code> function, it&#8217;s typically around 20 bucket spans. It can be faster
for population models, but it depends on the number of people that interact per
bucket.
</li>
</ul>
</div>
<p>Rules of thumb:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
more than three weeks for periodic data or a few hundred buckets for
non-periodic data
</li>
<li class="listitem">
at least as much data as you want to forecast
</li>
</ul>
</div>
<h4><a id="faq-data-integrity"></a>Are there any checks or processes to ensure data integrity?<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/stack-docs/edit/8.14/docs/en/stack/ml/anomaly-detection/ml-ad-troubleshooting.asciidoc">edit</a></h4>
<p>The Elastic machine learning algorithms are programmed to work with missing and noisy data
and use denoising and data reputation techniques based on the learned
statistical properties.</p>
</div>
</div>
</div><div class="navfooter">
<span class="prev">
<a href="ootb-ml-jobs.html">« Supplied anomaly detection configurations</a>
</span>
<span class="next">
<a href="ootb-ml-jobs-apache.html">Appendix A: Apache anomaly detection configurations »</a>
</span>
</div>
</body>
</html>
