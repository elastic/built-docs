<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="keywords" content="ML, Elastic Stack, anomaly detection, data frame analytics">
<title>Feature importance | Machine Learning in the Elastic Stack [8.2] | Elastic</title>
<meta class="elastic" name="content" content="Feature importance | Machine Learning in the Elastic Stack [8.2]">

<link rel="home" href="index.html" title="Machine Learning in the Elastic Stack [8.2]"/>
<link rel="up" href="ml-dfa-concepts.html" title="Advanced concepts"/>
<link rel="prev" href="ml-feature-processors.html" title="Data frame analytics feature processors"/>
<link rel="next" href="dfa-regression-lossfunction.html" title="Loss functions for regression analyses"/>
<meta class="elastic" name="product_version" content="8.2"/>
<meta class="elastic" name="product_name" content="Machine Learning"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/Elastic Stack/Machine Learning/8.2"/>
<meta name="DC.subject" content="Machine Learning"/>
<meta name="DC.identifier" content="8.2"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body><div class="page_header">
<strong>IMPORTANT</strong>: No additional bug fixes or documentation updates
will be released for this version. For the latest information, see the
<a href="../current/index.html">current release documentation</a>.
</div>
<div id="content">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Machine Learning in the Elastic Stack [8.2]</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="ml-dfanalytics.html">Data frame analytics</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="ml-dfa-concepts.html">Advanced concepts</a></span>
</div>
<div class="navheader">
<span class="prev">
<a href="ml-feature-processors.html">« Data frame analytics feature processors</a>
</span>
<span class="next">
<a href="dfa-regression-lossfunction.html">Loss functions for regression analyses »</a>
</span>
</div>
<div class="section xpack">
<div class="titlepage"><div><div>
<h2 class="title"><a id="ml-feature-importance"></a>Feature importance<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/stack-docs/edit/8.2/docs/en/stack/ml/df-analytics/ml-feature-importance.asciidoc">edit</a></h2>
</div></div></div>
<p>Feature importance values indicate which fields had the biggest impact on each
prediction that is generated by classification or regression analysis. Each
feature importance value has both a magnitude and a direction (positive or negative),
which indicate how each field (or <em>feature</em> of a data point) affects a
particular prediction.</p>
<p>The purpose of feature importance is to help you determine whether the predictions are
sensible. Is the relationship between the dependent variable and the important
features supported by your domain knowledge? The lessons you learn about the
importance of specific features might also affect your decision to include them
in future iterations of your trained model.</p>
<p>You can see the average magnitude of the feature importance values for each field across
all the training data in Kibana or by using the
<a href="/guide/en/elasticsearch/reference/8.2/get-inference.html" class="ulink" target="_top">get trained model API</a>. For example, Kibana shows the
total feature importance for each field in regression or binary
classification analysis results as follows:</p>
<div class="imageblock screenshot">
<div class="content">
<img src="images/flights-regression-total-importance.jpg" alt="Total feature importance values for a regression data frame analytics job in Kibana">
</div>
</div>
<p>If the classification analysis involves more than two classes, Kibana uses colors to show
how the impact of each field varies by class. For example:</p>
<div class="imageblock screenshot">
<div class="content">
<img src="images/diamonds-classification-total-importance.png" alt="Total feature importance values for a classification data frame analytics job in Kibana">
</div>
</div>
<p>You can also examine the feature importance values for each individual
prediction. In Kibana, you can see these values in JSON objects or decision plots.
For regression analysis, each decision plot starts at a shared baseline, which is
the average of the prediction values for all the data points in the training
data set. When you add all of the feature importance values for a particular
data point to that baseline, you arrive at the numeric prediction value. If a
feature importance value is negative, it reduces the prediction value. If a feature importance
value is positive, it increases the prediction value. For example:</p>
<div class="imageblock screenshot">
<div class="content">
<img src="images/flights-regression-decision-plot.png" alt="Feature importance values for a regression data frame analytics job in Kibana" width="50%">
</div>
</div>
<p>For classification analysis, the sum of the feature importance values approximates the predicted
logarithm of odds for each data point. The simplest way to understand feature importance
in the context of classification analysis is to look at the decision plots in Kibana. For
each data point, there is a chart which shows the relative impact of each
feature on the prediction probability for that class. This information helps you
to understand which features reduces or increase the prediction probability. For
example:</p>
<div class="imageblock screenshot">
<div class="content">
<img src="images/flights-classification-decision-plot.png" alt="A decision plot in Kibanafor a classification data frame analytics job" width="50%">
</div>
</div>
<p>By default, feature importance values are not calculated. To generate this information,
when you create a data frame analytics job you must specify the
<code class="literal">num_top_feature_importance_values</code> property. For example, see
<a class="xref" href="ml-dfa-regression.html#performing-regression" title="Performing regression analysis in the sample flight data set">Performing regression analysis in the sample flight data set</a> and <a class="xref" href="ml-dfa-classification.html#performing-classification" title="Performing classification analysis in the sample flight data set">Performing classification analysis in the sample flight data set</a>.</p>
<p>The feature importance values are stored in the machine learning results field for each document in
the destination index. The number of feature importance values for each document might
be less than the <code class="literal">num_top_feature_importance_values</code> property value. For example,
it returns only features that had a positive or negative effect on the
prediction.</p>
<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-feature-importance-readings"></a>Further reading<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/stack-docs/edit/8.2/docs/en/stack/ml/df-analytics/ml-feature-importance.asciidoc">edit</a></h3>
</div></div></div>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
Feature importance in the Elastic Stack is calculated using the SHAP (SHapley Additive
exPlanations) method as described in
<a href="https://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf" class="ulink" target="_top">Lundberg, S. M., &amp; Lee, S.-I. A Unified Approach to Interpreting Model Predictions. In NeurIPS 2017</a>.
</li>
<li class="listitem">
<a href="/blog/feature-importance-for-data-frame-analytics-with-elastic-machine-learning" class="ulink" target="_top">Feature importance for data frame analytics with Elastic machine learning</a>.
</li>
<li class="listitem">
<a href="https://github.com/elastic/examples/tree/master/Machine%20Learning/Feature%20Importance" class="ulink" target="_top">Feature importance for data frame analytics (Jupyter notebook)</a>.
</li>
</ul>
</div>
</div>

</div>
<div class="navfooter">
<span class="prev">
<a href="ml-feature-processors.html">« Data frame analytics feature processors</a>
</span>
<span class="next">
<a href="dfa-regression-lossfunction.html">Loss functions for regression analyses »</a>
</span>
</div>
</div>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  messageStyle: "none",
  tex2jax: {
    inlineMath: [["\\(", "\\)"]],
    displayMath: [["\\[", "\\]"]],
    ignoreClass: "nostem|nolatexmath"
  },
  asciimath2jax: {
    delimiters: [["\\$", "\\$"]],
    ignoreClass: "nostem|noasciimath"
  },
  TeX: { equationNumbers: { autoNumber: "none" } }
})
MathJax.Hub.Register.StartupHook("AsciiMath Jax Ready", function () {
  MathJax.InputJax.AsciiMath.postfilterHooks.Add(function (data, node) {
    if ((node = data.script.parentNode) && (node = node.parentNode) && node.classList.contains('stemblock')) {
      data.math.root.display = "block"
    }
    return data
  })
})
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_HTMLorMML"></script>
</body>
</html>
