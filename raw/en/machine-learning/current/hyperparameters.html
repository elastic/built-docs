<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="keywords" content="ML, Elastic Stack, anomaly detection, data frame analytics">
<title>Hyperparameter optimization | Machine Learning in the Elastic Stack [8.15] | Elastic</title>
<meta class="elastic" name="content" content="Hyperparameter optimization | Machine Learning in the Elastic Stack [8.15]">

<link rel="home" href="index.html" title="Machine Learning in the Elastic Stack [8.15]"/>
<link rel="up" href="ml-dfa-concepts.html" title="Advanced concepts"/>
<link rel="prev" href="dfa-regression-lossfunction.html" title="Loss functions for regression analyses"/>
<link rel="next" href="ml-trained-models.html" title="Trained models"/>
<meta class="elastic" name="product_version" content="8.15"/>
<meta class="elastic" name="product_name" content="Machine Learning"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/Elastic Stack/Machine Learning/8.15"/>
<meta name="DC.subject" content="Machine Learning"/>
<meta name="DC.identifier" content="8.15"/>
</head>
<body>
<div class="navheader">
<span class="prev">
<a href="dfa-regression-lossfunction.html">« Loss functions for regression analyses</a>
</span>
<span class="next">
<a href="ml-trained-models.html">Trained models »</a>
</span>
</div>
<div class="book" lang="en">
<div class="titlepage">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Machine Learning in the Elastic Stack [8.15]</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="ml-dfanalytics.html">Data frame analytics</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="ml-dfa-concepts.html">Advanced concepts</a></span>
</div>
<div>
<div><h1 class="title"><a id="id-1"></a>Hyperparameter optimization</h1><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/8.15/docs/en/stack/ml/df-analytics/hyperparameters.asciidoc">edit</a></div>
</div>
<!--EXTRA-->
</div>
<div id="content">
<div class="section xpack">
<div class="titlepage"><div><div>
<h2 class="title"><a id="hyperparameters"></a>Hyperparameter optimization<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/8.15/docs/en/stack/ml/df-analytics/hyperparameters.asciidoc">edit</a></h2>
</div></div></div>
<p>When you create a data frame analytics job for classification or regression analysis, there
are advanced configuration options known as <em>hyperparameters</em>. The ideal
hyperparameter values vary from one data set to another. Therefore, by default
the job calculates the best combination of values through a process of
<em>hyperparameter optimization</em>.</p>
<p>Hyperparameter optimization involves multiple rounds of analysis. Each round
involves a different combination of hyperparameter values, which are determined
through a combination of random search and Bayesian optimization techniques. If
you explicitly set a hyperparameter, that value is not optimized and remains the
same in each round. To determine which round produces the best results,
stratified K-fold cross-validation methods are used to split the data set, train
a model, and calculate its performance on validation data.</p>
<p>You can view the hyperparameter values that were ultimately chosen by expanding
the job details in Kibana or by using the
<a href="/guide/en/elasticsearch/reference/8.15/get-trained-models.html" class="ulink" target="_top">get trained models API</a>. You can also see the
specific type of validation loss (such as mean squared error or binomial cross
entropy) that was used to compare each round of optimization using the
<a href="/guide/en/elasticsearch/reference/8.15/get-dfanalytics-stats.html" class="ulink" target="_top">get data frame analytics job stats API</a>.</p>
<p>Different hyperparameters may affect the model performance to a different
degree. To estimate the importance of the optimized hyperparameters, analysis of
variance decomposition is used. The resulting <code class="literal">absolute importance</code> shows how
much the variation of a hyperparameter impacts the variation in the validation
loss. Additionally, <code class="literal">relative importance</code> is also computed which gives the
importance of the hyperparameter compared to the rest of the tuneable
hyperparameters. The sum of all relative importances is 1. You can check these
results in the response of the
<a href="/guide/en/elasticsearch/reference/8.15/get-dfanalytics-stats.html" class="ulink" target="_top">get data frame analytics job stats API</a>.</p>
<div class="tip admon">
<div class="icon"></div>
<div class="admon_content">
<p>Unless you fully understand the purpose of a hyperparameter, it is highly
recommended that you leave it unset and allow hyperparameter optimization to
occur.</p>
</div>
</div>
</div>
</div>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  messageStyle: "none",
  tex2jax: {
    inlineMath: [["\\(", "\\)"]],
    displayMath: [["\\[", "\\]"]],
    ignoreClass: "nostem|nolatexmath"
  },
  asciimath2jax: {
    delimiters: [["\\$", "\\$"]],
    ignoreClass: "nostem|noasciimath"
  },
  TeX: { equationNumbers: { autoNumber: "none" } }
})
MathJax.Hub.Register.StartupHook("AsciiMath Jax Ready", function () {
  MathJax.InputJax.AsciiMath.postfilterHooks.Add(function (data, node) {
    if ((node = data.script.parentNode) && (node = node.parentNode) && node.classList.contains('stemblock')) {
      data.math.root.display = "block"
    }
    return data
  })
})
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_HTMLorMML"></script>
</div><div class="navfooter">
<span class="prev">
<a href="dfa-regression-lossfunction.html">« Loss functions for regression analyses</a>
</span>
<span class="next">
<a href="ml-trained-models.html">Trained models »</a>
</span>
</div>
</body>
</html>
