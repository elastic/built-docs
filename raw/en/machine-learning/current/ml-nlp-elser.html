<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="keywords" content="ML, Elastic Stack, natural language processing, inference">
<title>ELSER – Elastic Learned Sparse EncodeR | Machine Learning in the Elastic Stack [8.15] | Elastic</title>
<meta class="elastic" name="content" content="ELSER – Elastic Learned Sparse EncodeR | Machine Learning in the Elastic Stack [8.15]">

<link rel="home" href="index.html" title="Machine Learning in the Elastic Stack [8.15]"/>
<link rel="up" href="ml-nlp-built-in-models.html" title="Built-in NLP models"/>
<link rel="prev" href="ml-nlp-built-in-models.html" title="Built-in NLP models"/>
<link rel="next" href="ml-nlp-e5.html" title="E5 – EmbEddings from bidirEctional Encoder rEpresentations"/>
<meta class="elastic" name="product_version" content="8.15"/>
<meta class="elastic" name="product_name" content="Machine Learning"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/Elastic Stack/Machine Learning/8.15"/>
<meta name="DC.subject" content="Machine Learning"/>
<meta name="DC.identifier" content="8.15"/>
</head>
<body>
<div class="navheader">
<span class="prev">
<a href="ml-nlp-built-in-models.html">« Built-in NLP models</a>
</span>
<span class="next">
<a href="ml-nlp-e5.html">E5 – EmbEddings from bidirEctional Encoder rEpresentations »</a>
</span>
</div>
<div class="book" lang="en">
<div class="titlepage">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Machine Learning in the Elastic Stack [8.15]</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="ml-nlp.html">Natural language processing</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="ml-nlp-built-in-models.html">Built-in NLP models</a></span>
</div>
<div>
<div><h1 class="title"><a id="id-1"></a>ELSER – Elastic Learned Sparse EncodeR</h1><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/8.15/docs/en/stack/ml/nlp/ml-nlp-elser.asciidoc">edit</a></div>
</div>
<!--EXTRA-->
</div>
<div id="content">
<div class="section">
<div class="titlepage"><div><div>
<h2 class="title"><a id="ml-nlp-elser"></a>ELSER – Elastic Learned Sparse EncodeR<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/8.15/docs/en/stack/ml/nlp/ml-nlp-elser.asciidoc">edit</a></h2>
</div></div></div>

<p>Elastic Learned Sparse EncodeR - or ELSER - is a retrieval model trained by
Elastic that enables you to perform
<a href="/guide/en/elasticsearch/reference/8.15/semantic-search-elser.html" class="ulink" target="_top">semantic search</a> to retrieve more relevant
search results. This search type provides you search results based on contextual
meaning and user intent, rather than exact keyword matches.</p>
<p>ELSER is an out-of-domain model which means it does not require fine-tuning on
your own data, making it adaptable for various use cases out of the box.</p>
<p>This model is recommended for English language documents and queries. If you
want to perform semantic search on non-English language documents, use the
<a class="xref" href="ml-nlp-e5.html" title="E5 – EmbEddings from bidirEctional Encoder rEpresentations">E5</a> model.</p>
<div class="important admon">
<div class="icon"></div>
<div class="admon_content">
<p>While ELSER V2 is generally available, ELSER V1 is in <span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will work to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span>
and will remain in technical preview.</p>
</div>
</div>
<h4><a id="elser-tokens"></a>Tokens - not synonyms<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/8.15/docs/en/stack/ml/nlp/ml-nlp-elser.asciidoc">edit</a></h4>
<p>ELSER expands the indexed and searched passages into collections of terms that
are learned to co-occur frequently within a diverse set of training data. The
terms that the text is expanded into by the model <em>are not</em> synonyms for the
search terms; they are learned associations capturing relevance. These expanded
terms are weighted as some of them are more significant than others. Then the
Elasticsearch <a href="/guide/en/elasticsearch/reference/8.15/sparse-vector.html" class="ulink" target="_top">sparse vector</a>
(or <a href="/guide/en/elasticsearch/reference/8.15/rank-features.html" class="ulink" target="_top">rank features</a>) field type is used to store the
terms and weights at index time, and to search against later.</p>
<p>This approach provides a more understandable search experience compared to
vector embeddings. However, attempting to directly interpret the tokens and
weights can be misleading, as the expansion essentially results in a vector in a
very high-dimensional space. Consequently, certain tokens, especially those with
low weight, contain information that is intertwined with other low-weight tokens
in the representation. In this regard, they function similarly to a dense vector
representation, making it challenging to separate their individual
contributions. This complexity can potentially lead to misinterpretations if not
carefully considered during analysis.</p>
<h4><a id="elser-req"></a>Requirements<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/8.15/docs/en/stack/ml/nlp/ml-nlp-elser.asciidoc">edit</a></h4>
<p>To use ELSER, you must have the <a href="/subscriptions" class="ulink" target="_top">appropriate subscription</a> level
for semantic search or the trial period activated.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>The minimum dedicated ML node size for deploying and using the ELSER model
is 4 GB in Elasticsearch Service if
<a href="/guide/en/cloud/current/ec-autoscaling.html" class="ulink" target="_top">deployment autoscaling</a> is turned off. Turning on
autoscaling is recommended because it allows your deployment to dynamically
adjust resources based on demand. Better performance can be achieved by using
more allocations or more threads per allocation, which requires bigger ML nodes.
Autoscaling provides bigger nodes when required. If autoscaling is turned off,
you must provide suitably sized nodes yourself.</p>
</div>
</div>
<h4><a id="elser-v2"></a>ELSER v2<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/8.15/docs/en/stack/ml/nlp/ml-nlp-elser.asciidoc">edit</a></h4>
<p>Compared to the initial version of the model, ELSER v2 offers improved retrieval
accuracy and more efficient indexing. This enhancement is attributed to the
extension of the training data set, which includes high-quality question and
answer pairs and the improved FLOPS regularizer which reduces the cost of
computing the similarity between a query and a document.</p>
<p>ELSER v2 has two versions: one cross-platform version which runs on any hardware
and one version which is optimized for Intel® silicon. The
<span class="strong strong"><strong>Model Management</strong></span> &gt; <span class="strong strong"><strong>Trained Models</strong></span> page shows you which version of ELSER
v2 is recommended to deploy based on your cluster&#8217;s hardware. However, the
recommended way to use ELSER is through the
<a href="/guide/en/elasticsearch/reference/8.15/infer-service-elser.html" class="ulink" target="_top">inference API</a> as a service which makes it easier
to download and deploy the model and you don&#8217;t need to select from different
versions.</p>
<p>If you want to learn more about the ELSER V2 improvements, refer to
<a href="/search-labs/introducing-elser-v2-part-1" class="ulink" target="_top">this blog post</a>.</p>
<h5><a id="upgrade-elser-v2"></a>Upgrading to ELSER v2<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/8.15/docs/en/stack/ml/nlp/ml-nlp-elser.asciidoc">edit</a></h5>
<p>ELSER v2 is not backward compatible. If you indexed your data with ELSER v1, you
need to reindex it with an ingest pipeline referencing ELSER v2 to be able to
use v2 for search. This <a href="/guide/en/elasticsearch/reference/8.15/semantic-search-elser.html" class="ulink" target="_top">tutorial</a> shows you how
to create an ingest pipeline with an inference processor that uses ELSER v2, and
how to reindex your data through the pipeline.</p>
<p>Additionally, the <code class="literal">elasticearch-labs</code> GitHub repository contains an interactive
<a href="https://github.com/elastic/elasticsearch-labs/blob/main/notebooks/model-upgrades/upgrading-index-to-use-elser.ipynb" class="ulink" target="_top">Python notebook</a>
that walks through upgrading an index to ELSER V2.</p>
<h4><a id="download-deploy-elser"></a>Download and deploy ELSER<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/8.15/docs/en/stack/ml/nlp/ml-nlp-elser.asciidoc">edit</a></h4>
<p>The easiest and recommended way to download and deploy ELSER is to use the <a href="/guide/en/elasticsearch/reference/8.15/inference-apis.html" class="ulink" target="_top">inference API</a>.</p>
<div class="olist orderedlist">
<ol class="orderedlist">
<li class="listitem">
In Kibana, navigate to the <span class="strong strong"><strong>Dev Console</strong></span>.
</li>
<li class="listitem">
<p>Create an inference endpoint with the ELSER service by running the following API request:</p>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">PUT _inference/sparse_embedding/my-elser-model
{
  "service": "elser",
  "service_settings": {
    "num_allocations": 1,
    "num_threads": 1
  }
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/66.console"></div>
<p>The API request automatically initiates the model download and then deploy the model.</p>
</li>
</ol>
</div>
<p>Refer to the <a href="/guide/en/elasticsearch/reference/8.15/infer-service-elser.html" class="ulink" target="_top">ELSER inference service documentation</a> to learn more about the available settings.</p>
<p>After you created the ELSER inference endpoint, it&#8217;s ready to be used for semantic search.
The easiest way to perform semantic search in the Elastic Stack is to <a href="/guide/en/elasticsearch/reference/8.15/semantic-search-semantic-text.html" class="ulink" target="_top">follow the <code class="literal">semantic_text</code> workflow</a>.</p>
<h5><a id="alternative-download-deploy"></a>Alternative methods to download and deploy ELSER<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/8.15/docs/en/stack/ml/nlp/ml-nlp-elser.asciidoc">edit</a></h5>
<p>You can also download and deploy ELSER either from <span class="strong strong"><strong>Machine Learning</strong></span> &gt; <span class="strong strong"><strong>Trained Models</strong></span>, from <span class="strong strong"><strong>Search</strong></span> &gt; <span class="strong strong"><strong>Indices</strong></span>, or by using the trained models API in Dev Console.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
For most cases, the preferred version is the <span class="strong strong"><strong>Intel and Linux optimized</strong></span>
model, it is recommended to download and deploy that version.
</li>
<li class="listitem">
You can deploy the model multiple times by assigning a unique deployment ID
when starting the deployment. It enables you to have dedicated deployments for
different purposes, such as search and ingest. By doing so, you ensure that the
search speed remains unaffected by ingest workloads, and vice versa. Having
separate deployments for search and ingest mitigates performance issues
resulting from interactions between the two, which can be hard to diagnose.
</li>
</ul>
</div>
</div>
</div>
<details>
<summary class="title">Using the Trained Models page</summary>
<div class="content">
<h6><a id="trained-model"></a>Using the Trained Models page<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/8.15/docs/en/stack/ml/nlp/ml-nlp-elser.asciidoc">edit</a></h6>
<div class="olist orderedlist">
<ol class="orderedlist">
<li class="listitem">
In Kibana, navigate to <span class="strong strong"><strong>Machine Learning</strong></span> &gt; <span class="strong strong"><strong>Trained Models</strong></span>. ELSER can be found
in the list of trained models. There are two versions available: one portable
version which runs on any hardware and one version which is optimized for Intel®
silicon. You can see which model is recommended to use based on your hardware
configuration.
</li>
<li class="listitem">
<p>Click the <span class="strong strong"><strong>Add trained model</strong></span> button. Select the ELSER model version you
want to use in the opening modal window. The model that is recommended for you
based on your hardware configuration is highlighted. Click <span class="strong strong"><strong>Download</strong></span>. You can
check the download status on the <span class="strong strong"><strong>Notifications</strong></span> page.</p>
<div class="imageblock text-center screenshot">
<div class="content">
<img src="images/ml-nlp-elser-v2-download.png" alt="Downloading ELSER">
</div>
</div>
<p>Alternatively, click the <span class="strong strong"><strong>Download model</strong></span> button under <span class="strong strong"><strong>Actions</strong></span> in the
trained model list.</p>
</li>
<li class="listitem">
After the download is finished, start the deployment by clicking the
<span class="strong strong"><strong>Start deployment</strong></span> button.
</li>
<li class="listitem">
<p>Provide a deployment ID, select the priority, and set the number of
allocations and threads per allocation values.</p>
<div class="imageblock text-center screenshot">
<div class="content">
<img src="images/ml-nlp-deployment-id-elser-v2.png" alt="Deploying ELSER">
</div>
</div>
</li>
<li class="listitem">
Click <span class="strong strong"><strong>Start</strong></span>.
</li>
</ol>
</div>
</div>
</details>
<details>
<summary class="title">Using the search indices UI</summary>
<div class="content">
<h6><a id="elasticsearch"></a>Using the search indices UI<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/8.15/docs/en/stack/ml/nlp/ml-nlp-elser.asciidoc">edit</a></h6>
<p>Alternatively, you can download and deploy ELSER to an inference pipeline using
the search indices UI.</p>
<div class="olist orderedlist">
<ol class="orderedlist">
<li class="listitem">
In Kibana, navigate to <span class="strong strong"><strong>Search</strong></span> &gt; <span class="strong strong"><strong>Indices</strong></span>.
</li>
<li class="listitem">
Select the index from the list that has an inference pipeline in which you want
to use ELSER.
</li>
<li class="listitem">
Navigate to the <span class="strong strong"><strong>Pipelines</strong></span> tab.
</li>
<li class="listitem">
<p>Under <span class="strong strong"><strong>Machine Learning Inference Pipelines</strong></span>, click the <span class="strong strong"><strong>Deploy</strong></span> button to
begin downloading the ELSER model. This may take a few minutes depending on your
network.</p>
<div class="imageblock text-center screenshot">
<div class="content">
<img src="images/ml-nlp-deploy-elser-v2-es.png" alt="Deploying ELSER in Elasticsearch">
</div>
</div>
</li>
<li class="listitem">
<p>Once the model is downloaded, click the <span class="strong strong"><strong>Start single-threaded</strong></span> button to
start the model with basic configuration or select the <span class="strong strong"><strong>Fine-tune performance</strong></span>
option to navigate to the <span class="strong strong"><strong>Trained Models</strong></span> page where you can configure the
model deployment.</p>
<div class="imageblock text-center screenshot">
<div class="content">
<img src="images/ml-nlp-start-elser-v2-es.png" alt="Start ELSER in Elasticsearch">
</div>
</div>
</li>
</ol>
</div>
</div>
</details>
<details>
<summary class="title">Using the traned models API in Dev Console</summary>
<div class="content">
<h6><a id="dev-console"></a>Using the trained models API in Dev Console<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/8.15/docs/en/stack/ml/nlp/ml-nlp-elser.asciidoc">edit</a></h6>
<div class="olist orderedlist">
<ol class="orderedlist">
<li class="listitem">
In Kibana, navigate to the <span class="strong strong"><strong>Dev Console</strong></span>.
</li>
<li class="listitem">
<p>Create the ELSER model configuration by running the following API call:</p>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">PUT _ml/trained_models/.elser_model_2
{
  "input": {
	"field_names": ["text_field"]
  }
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/67.console"></div>
<p>The API call automatically initiates the model download if the model is not
downloaded yet.</p>
</li>
<li class="listitem">
<p>Deploy the model by using the
<a href="/guide/en/elasticsearch/reference/8.15/start-trained-model-deployment.html" class="ulink" target="_top">start trained model deployment API</a>
with a delpoyment ID:</p>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">POST _ml/trained_models/.elser_model_2/deployment/_start?deployment_id=for_search</pre>
</div>
<div class="console_widget" data-snippet="snippets/68.console"></div>
<p>You can deploy the model multiple times with different deployment IDs.</p>
</li>
</ol>
</div>
</div>
</details>
<h4><a id="air-gapped-install"></a>Deploy ELSER in an air-gapped environment<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/8.15/docs/en/stack/ml/nlp/ml-nlp-elser.asciidoc">edit</a></h4>
<p>If you want to deploy ELSER in a restricted or closed network, you have two
options:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
create your own HTTP/HTTPS endpoint with the model artifacts on it,
</li>
<li class="listitem">
put the model artifacts into a directory inside the config directory on all
<a href="/guide/en/elasticsearch/reference/8.15/modules-node.html#master-node" class="ulink" target="_top">master-eligible nodes</a>.
</li>
</ul>
</div>
<h5><a id="elser-model-artifacts"></a>Model artifact files<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/8.15/docs/en/stack/ml/nlp/ml-nlp-elser.asciidoc">edit</a></h5>
<p>For the cross-platform verison, you need the following files in your system:</p>
<pre class="screen">https://ml-models.elastic.co/elser_model_2.metadata.json
https://ml-models.elastic.co/elser_model_2.pt
https://ml-models.elastic.co/elser_model_2.vocab.json</pre>
<p>For the optimized version, you need the following files in your system:</p>
<pre class="screen">https://ml-models.elastic.co/elser_model_2_linux-x86_64.metadata.json
https://ml-models.elastic.co/elser_model_2_linux-x86_64.pt
https://ml-models.elastic.co/elser_model_2_linux-x86_64.vocab.json</pre>
<h5><a id="_using_an_http_server"></a>Using an HTTP server<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/8.15/docs/en/stack/ml/nlp/ml-nlp-elser.asciidoc">edit</a></h5>
<p>INFO: If you use an existing HTTP server, note that the model downloader only
supports passwordless HTTP servers.</p>
<p>You can use any HTTP service to deploy ELSER. This example uses the official
Nginx Docker image to set a new HTTP download service up.</p>
<div class="olist orderedlist">
<ol class="orderedlist">
<li class="listitem">
Download the <a class="xref" href="ml-nlp-elser.html#elser-model-artifacts" title="Model artifact files">model artifact files</a>.
</li>
<li class="listitem">
Put the files into a subdirectory of your choice.
</li>
<li class="listitem">
<p>Run the following commands:</p>
<div class="pre_wrapper lang-shell">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-shell">export ELASTIC_ML_MODELS="/path/to/models"
docker run --rm -d -p 8080:80 --name ml-models -v ${ELASTIC_ML_MODELS}:/usr/share/nginx/html nginx</pre>
</div>
<p>Don&#8217;t forget to change <code class="literal">/path/to/models</code> to the path of the subdirectory where
the model artifact files are located.</p>
<p>These commands start a local Docker image with an Nginx server with the
subdirectory containing the model files. As the Docker image has to be
downloaded and built, the first start might take a longer period of time.
Subsequent runs start quicker.</p>
</li>
<li class="listitem">
<p>Verify that Nginx runs properly by visiting the following URL in your
browser:</p>
<pre class="screen">http://{IP_ADDRESS_OR_HOSTNAME}:8080/elser_model_2.metadata.json</pre>
<p>If Nginx runs properly, you see the content of the metdata file of the model.</p>
</li>
<li class="listitem">
<p>Point your Elasticsearch deployment to the model artifacts on the HTTP server
by adding the following line to the <code class="literal">config/elasticsearch.yml</code> file:</p>
<pre class="screen">xpack.ml.model_repository: http://{IP_ADDRESS_OR_HOSTNAME}:8080</pre>
<p>If you use your own HTTP or HTTPS server, change the address accordingly. It is
important to specificy the protocol ("http://" or "https://"). Ensure that all
master-eligible nodes can reach the server you specify.</p>
</li>
<li class="listitem">
Repeat step 5 on all master-eligible nodes.
</li>
<li class="listitem">
<a href="/guide/en/elasticsearch/reference/8.15/restart-cluster.html#restart-cluster-rolling" class="ulink" target="_top">Restart</a> the
master-eligible nodes one by one.
</li>
<li class="listitem">
Navigate to the <span class="strong strong"><strong>Trained Models</strong></span> page in Kibana, ELSER can be found in the
list of trained models.
</li>
<li class="listitem">
Click the <span class="strong strong"><strong>Add trained model</strong></span> button, select the ELSER model version you
downloaded in step 1 and want to deploy, and click <span class="strong strong"><strong>Download</strong></span>. The selected
model will be downloaded from the HTTP/HTTPS server you configured.
</li>
<li class="listitem">
After the download is finished, start the deployment by clicking the
<span class="strong strong"><strong>Start deployment</strong></span> button.
</li>
<li class="listitem">
Provide a deployment ID, select the priority, and set the number of
allocations and threads per allocation values.
</li>
<li class="listitem">
Click <span class="strong strong"><strong>Start</strong></span>.
</li>
</ol>
</div>
<p>The HTTP server is only required for downloading the model. After the download
has finished, you can stop and delete the service. You can stop the Docker image
used in this example by running the following command:</p>
<div class="pre_wrapper lang-shell">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-shell">docker stop ml-models</pre>
</div>
<h5><a id="_using_file_based_access"></a>Using file-based access<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/8.15/docs/en/stack/ml/nlp/ml-nlp-elser.asciidoc">edit</a></h5>
<p>For a file-based access, follow these steps:</p>
<div class="olist orderedlist">
<ol class="orderedlist">
<li class="listitem">
Download the <a class="xref" href="ml-nlp-elser.html#elser-model-artifacts" title="Model artifact files">model artifact files</a>.
</li>
<li class="listitem">
Put the files into a <code class="literal">models</code> subdirectory inside the <code class="literal">config</code> directory of
your Elasticsearch deployment.
</li>
<li class="listitem">
<p>Point your Elasticsearch deployment to the model directory by adding the
following line to the <code class="literal">config/elasticsearch.yml</code> file:</p>
<pre class="screen">xpack.ml.model_repository: file://${path.home}/config/models/`</pre>
</li>
<li class="listitem">
Repeat step 2 and step 3 on all master-eligible nodes.
</li>
<li class="listitem">
<a href="/guide/en/elasticsearch/reference/8.15/restart-cluster.html#restart-cluster-rolling" class="ulink" target="_top">Restart</a> the
master-eligible nodes one by one.
</li>
<li class="listitem">
Navigate to the <span class="strong strong"><strong>Trained Models</strong></span> page in Kibana, ELSER can be found in the
list of trained models.
</li>
<li class="listitem">
Click the <span class="strong strong"><strong>Add trained model</strong></span> button, select the ELSER model version you
downloaded in step 1 and want to deploy and click <span class="strong strong"><strong>Download</strong></span>. The selected
model will be downloaded from the model directory where you put in step 2.
</li>
<li class="listitem">
After the download is finished, start the deployment by clicking the
<span class="strong strong"><strong>Start deployment</strong></span> button.
</li>
<li class="listitem">
Provide a deployment ID, select the priority, and set the number of
allocations and threads per allocation values.
</li>
<li class="listitem">
Click <span class="strong strong"><strong>Start</strong></span>.
</li>
</ol>
</div>
<h4><a id="_testing_elser"></a>Testing ELSER<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/8.15/docs/en/stack/ml/nlp/ml-nlp-elser.asciidoc">edit</a></h4>
<p>You can test the deployed model in Kibana. Navigate to <span class="strong strong"><strong>Model Management</strong></span> &gt;
<span class="strong strong"><strong>Trained Models</strong></span>, locate the deployed ELSER model in the list of trained
models, then select <span class="strong strong"><strong>Test model</strong></span> from the Actions menu.</p>
<p>You can use data from an existing index to test the model. Select the index,
then a field of the index you want to test ELSER on. Provide a search query and
click <span class="strong strong"><strong>Test</strong></span>. Evaluating model recall is simpler when using a query related to
the documents.</p>
<p>The results contain a list of ten random values for the selected field along
with a score showing how relevant each document is to the query. The higher the
score, the more relevant the document is. You can reload example documents by
clicking <span class="strong strong"><strong>Reload examples</strong></span>.</p>
<div class="imageblock text-center screenshot">
<div class="content">
<img src="images/ml-nlp-elser-v2-test.png" alt="Testing ELSER">
</div>
</div>
<h4><a id="performance"></a>Performance considerations<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/8.15/docs/en/stack/ml/nlp/ml-nlp-elser.asciidoc">edit</a></h4>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
ELSER works best on small-to-medium sized fields that contain natural
language. For connector or web crawler use cases, this aligns best with fields
like <em>title</em>, <em>description</em>, <em>summary</em>, or <em>abstract</em>. As ELSER encodes the
first 512 tokens of a field, it may not provide as relevant of results for large
fields. For example, <code class="literal">body_content</code> on web crawler documents, or body fields
resulting from extracting text from office documents with connectors. For larger
fields like these, consider "chunking" the content into multiple values, where
each chunk can be under 512 tokens.
</li>
<li class="listitem">
Larger documents take longer at ingestion time, and inference time per
document also increases the more fields in a document that need to be processed.
</li>
<li class="listitem">
The more fields your pipeline has to perform inference on, the longer it takes
per document to ingest.
</li>
</ul>
</div>
<p>To learn more about ELSER performance, refer to the <a class="xref" href="ml-nlp-elser.html#elser-benchmarks" title="Benchmark information">Benchmark information</a>.</p>
<h4><a id="further-readings"></a>Further reading<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/8.15/docs/en/stack/ml/nlp/ml-nlp-elser.asciidoc">edit</a></h4>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<a href="/guide/en/elasticsearch/reference/8.15/semantic-search-elser.html" class="ulink" target="_top">Perform semantic search with ELSER</a>
</li>
<li class="listitem">
<a href="/blog/may-2023-launch-information-retrieval-elasticsearch-ai-model" class="ulink" target="_top">Improving information retrieval in the Elastic Stack: Introducing Elastic Learned Sparse Encoder, our new retrieval model</a>
</li>
</ul>
</div>
<h4><a id="elser-benchmarks"></a>Benchmark information<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/8.15/docs/en/stack/ml/nlp/ml-nlp-elser.asciidoc">edit</a></h4>
<div class="important admon">
<div class="icon"></div>
<div class="admon_content">
<p>The recommended way to use ELSER is through the <a href="/guide/en/elasticsearch/reference/8.15/infer-service-elser.html" class="ulink" target="_top">inference API</a> as a service.</p>
</div>
</div>
<p>The following sections provide information about how ELSER performs on different
hardwares and compares the model performance to Elasticsearch BM25 and other strong
baselines.</p>
<h5><a id="version-overview"></a>Version overview<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/8.15/docs/en/stack/ml/nlp/ml-nlp-elser.asciidoc">edit</a></h5>
<p>ELSER V2 has a <span class="strong strong"><strong>optimized</strong></span> version that is designed to run only on Linux with
an x86-64 CPU architecture and a <span class="strong strong"><strong>cross-platform</strong></span> version that can be run on
any platform.</p>
<h6><a id="version-overview-v2"></a>ELSER V2<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/8.15/docs/en/stack/ml/nlp/ml-nlp-elser.asciidoc">edit</a></h6>
<p>Besides the performance improvements, the biggest change in ELSER V2 is the
introduction of the first platform specific ELSER model - that is, a model
optimized to run only on Linux with an x86-64 CPU architecture. The optimized
model is designed to work best on newer Intel CPUs, but it works on AMD CPUs as
well. It is recommended to use the new optimized Linux-x86-64 model for all new
users of ELSER as it is significantly faster than the cross-platform model which
can be run on any platform. ELSER V2 produces significantly higher quality
embeddings than ELSER V1. Regardless of which ELSER V2 model you use (optimized
or cross-platform), the particular embeddings produced are the same.</p>
<h5><a id="elser-qualitative-benchmarks"></a>Qualitative benchmarks<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/8.15/docs/en/stack/ml/nlp/ml-nlp-elser.asciidoc">edit</a></h5>
<p>The metric that is used to evaluate ELSER&#8217;s ranking ability is the Normalized
Discounted Cumulative Gain (NDCG) which can handle multiple relevant documents
and fine-grained document ratings. The metric is applied to a fixed-sized list
of retrieved documents which, in this case, is the top 10 documents (NDCG@10).</p>
<p>The table below shows the performance of ELSER V2 compared to BM 25. ELSER V2
has 10 wins, 1 draw, 1 loss and an average improvement in NDCG@10 of 18%.</p>
<div class="imageblock text-center">
<div class="content">
<img src="images/ml-nlp-bm25-elser-v2.png" alt="ELSER V2 benchmarks compared to BM25">
</div>
</div>
<p><em>NDCG@10 for BEIR data sets for BM25 and ELSER V2  - higher values are better)</em></p>
<h5><a id="elser-hw-benchmarks"></a>Hardware benchmarks<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/8.15/docs/en/stack/ml/nlp/ml-nlp-elser.asciidoc">edit</a></h5>
<div class="important admon">
<div class="icon"></div>
<div class="admon_content">
<p>While the goal is to create a model that is as performant as
possible, retrieval accuracy always take precedence over speed, this is one of
the design principles of ELSER. Consult with the tables below to learn more
about the expected model performance. The values refer to operations performed
on two data sets and different hardware configurations. Your data set has an
impact on the model performance. Run tests on your own data to have a more
realistic view on the model performance for your use case.</p>
</div>
</div>
<h6><a id="_elser_v2"></a>ELSER V2<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/8.15/docs/en/stack/ml/nlp/ml-nlp-elser.asciidoc">edit</a></h6>
<p>Overall the optimized V2 model ingested at a max rate of 26 docs/s, compared
with the ELSER V1 max rate of 14 docs/s from the ELSER V1 benchamrk, resulting
in a 90% increase in throughput.</p>
<p>The performance of virtual cores (that is, when the number of allocations is
greater than half of the vCPUs) has increased. Previously, the increase in
performance between 8 and 16 allocations was around 7%. It has increased to 17%
(ELSER V1 on 8.11) and 20% (for ELSER V2 optimized). These tests were performed
on a 16vCPU machine, with all documents containing exactly 256 tokens.</p>
<div class="important admon">
<div class="icon"></div>
<div class="admon_content">
<p>The length of the documents in your particular dataset will have a
significant impact on your throughput numbers.</p>
</div>
</div>
<p>Refer to
<a href="/search-labs/introducing-elser-v2-part-1" class="ulink" target="_top">this blog post</a>
to learn more about ELSER V2 improved performance.</p>
<div class="imageblock text-center">
<div class="content">
<img src="images/ml-nlp-elser-bm-summary.png" alt="Summary of ELSER V1 and V2 benchmark reports">
</div>
</div>
<p><span class="strong strong"><strong>The optimized model</strong></span> results show a nearly linear growth up until 8
allocations, after which performance improvements become smaller. In this case,
the performance at 8 allocations was 22 docs/s, while the performance of 16
allocations was 26 docs/s, indicating a 20% performance increase due to virtual
cores.</p>
<div class="imageblock text-center">
<div class="content">
<img src="images/ml-nlp-elser-v2-opt-bm-results.png" alt="ELSER V2 optimized benchmarks">
</div>
</div>
<p><span class="strong strong"><strong>The cross-platform</strong></span> model performance of 8 and 16 allocations are
respectively 14 docs/s and 16 docs/s, indicating a performance improvement due
to virtual cores of 12%.</p>
<div class="imageblock text-center">
<div class="content">
<img src="images/ml-nlp-elser-v2-cp-bm-results.png" alt="ELSER V2 cross-platform benchmarks">
</div>
</div>
</div>
</div>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  messageStyle: "none",
  tex2jax: {
    inlineMath: [["\\(", "\\)"]],
    displayMath: [["\\[", "\\]"]],
    ignoreClass: "nostem|nolatexmath"
  },
  asciimath2jax: {
    delimiters: [["\\$", "\\$"]],
    ignoreClass: "nostem|noasciimath"
  },
  TeX: { equationNumbers: { autoNumber: "none" } }
})
MathJax.Hub.Register.StartupHook("AsciiMath Jax Ready", function () {
  MathJax.InputJax.AsciiMath.postfilterHooks.Add(function (data, node) {
    if ((node = data.script.parentNode) && (node = node.parentNode) && node.classList.contains('stemblock')) {
      data.math.root.display = "block"
    }
    return data
  })
})
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_HTMLorMML"></script>
</div><div class="navfooter">
<span class="prev">
<a href="ml-nlp-built-in-models.html">« Built-in NLP models</a>
</span>
<span class="next">
<a href="ml-nlp-e5.html">E5 – EmbEddings from bidirEctional Encoder rEpresentations »</a>
</span>
</div>
</body>
</html>
