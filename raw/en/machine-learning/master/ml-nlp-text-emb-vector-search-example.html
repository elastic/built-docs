<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="keywords" content="ML, Elastic Stack, natural language processing">
<title>How to deploy a text embedding model and use it for semantic search | Machine Learning in the Elastic Stack [master] | Elastic</title>
<meta class="elastic" name="content" content="How to deploy a text embedding model and use it for semantic search | Machine Learning in the Elastic Stack [master]">

<link rel="home" href="index.html" title="Machine Learning in the Elastic Stack [master]"/>
<link rel="up" href="ml-nlp-examples.html" title="Examples"/>
<link rel="prev" href="ml-nlp-ner-example.html" title="How to deploy named entity recognition"/>
<link rel="next" href="ml-nlp-limitations.html" title="Limitations"/>
<meta class="elastic" name="product_version" content="master"/>
<meta class="elastic" name="product_name" content="Machine Learning"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/Elastic Stack/Machine Learning/master"/>
<meta name="DC.subject" content="Machine Learning"/>
<meta name="DC.identifier" content="master"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body>
<div class="page_header">
This documentation contains work-in-progress information for future Elastic Stack and Cloud releases. Use the version selector to view supported release docs. It also contains some Elastic Cloud serverless information. Check out our <a href="https://www.elastic.co/docs/current/serverless">serverless docs</a> for more details.
</div>
<div class="navheader">
<span class="prev">
<a href="ml-nlp-ner-example.html">« How to deploy named entity recognition</a>
</span>
<span class="next">
<a href="ml-nlp-limitations.html">Limitations »</a>
</span>
</div>
<div class="book" lang="en">
<div class="titlepage">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Machine Learning in the Elastic Stack [master]</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="ml-nlp.html">Natural language processing</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="ml-nlp-examples.html">Examples</a></span>
</div>
<div>
<div><h1 class="title"><a id="id-1"></a>How to deploy a text embedding model and use it for semantic search</h1><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/main/docs/en/stack/ml/nlp/ml-nlp-text-emb-vector-search-example.asciidoc">edit</a></div>
</div>
<!--EXTRA-->
</div>
<div id="content">
<div class="section">
<div class="titlepage"><div><div>
<h2 class="title"><a id="ml-nlp-text-emb-vector-search-example"></a>How to deploy a text embedding model and use it for semantic search<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/main/docs/en/stack/ml/nlp/ml-nlp-text-emb-vector-search-example.asciidoc">edit</a></h2>
</div></div></div>

<p>You can use these instructions to deploy a
<a class="xref" href="ml-nlp-search-compare.html#ml-nlp-text-embedding" title="Text embedding">text embedding</a> model in Elasticsearch, test the model, and
add it to an inference ingest pipeline. It enables you to generate vector
representations of text and perform vector similarity search on the generated
vectors. The model that is used in the example is publicly available on
<a href="https://huggingface.co/" class="ulink" target="_top">HuggingFace</a>.</p>
<p>The example uses a public data set from the
<a href="https://microsoft.github.io/msmarco/#ranking" class="ulink" target="_top">MS MARCO Passage Ranking Task</a>. It
consists of real questions from the Microsoft Bing search engine and human
generated answers for them. The example works with a sample of this data set,
uses a model to produce text embeddings, and then runs vector search on it.</p>
<p>You can find
<a href="https://github.com/elastic/elasticsearch-labs/blob/main/notebooks/integrations/hugging-face/loading-model-from-hugging-face.ipynb" class="ulink" target="_top">this example as a Jupyter notebook</a>
using the Python client in the <code class="literal">elasticsearch-labs</code> repo.</p>
<h4><a id="ex-te-vs-requirements"></a>Requirements<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/main/docs/en/stack/ml/nlp/ml-nlp-text-emb-vector-search-example.asciidoc">edit</a></h4>
<p>To follow along the process on this page, you must have:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
an Elasticsearch Cloud cluster that is set up properly to use the machine learning features. Refer
to <a class="xref" href="setup.html" title="Set up machine learning features"><em>Setup and security</em></a>.
</li>
<li class="listitem">
The <a href="/subscriptions" class="ulink" target="_top">appropriate subscription</a> level or the free trial period
activated.
</li>
<li class="listitem">
<a href="https://docs.docker.com/get-docker/" class="ulink" target="_top">Docker</a> installed.
</li>
</ul>
</div>
<h4><a id="ex-te-vs-deploy"></a>Deploy a text embedding model<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/main/docs/en/stack/ml/nlp/ml-nlp-text-emb-vector-search-example.asciidoc">edit</a></h4>
<p>You can use the <a href="/guide/en/elasticsearch/client/eland/current" class="ulink" target="_top">Eland client</a> to install the natural language processing model. Use the prebuilt
Docker image to run the Eland install model commands. Pull the latest image with:</p>
<div class="pre_wrapper lang-shell">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-shell">docker pull docker.elastic.co/eland/eland</pre>
</div>
<p>After the pull completes, your Eland Docker client is ready to use.</p>
<p>Select a text embedding model from the
<a href="/guide/en/machine-learning/master/ml-nlp-model-ref.html#ml-nlp-model-ref-ner" class="ulink" target="_top">third-party model reference list</a>.
This example uses the
<a href="https://huggingface.co/sentence-transformers/msmarco-MiniLM-L-12-v3" class="ulink" target="_top">msmarco-MiniLM-L-12-v3</a>
sentence-transformer model.</p>
<p>Install the model by running the <code class="literal">eland_import_model_hub</code> command in the Docker
image:</p>
<div class="pre_wrapper lang-shell">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-shell">docker run -it --rm elastic/eland \
    eland_import_hub_model \
      --cloud-id $CLOUD_ID \
      -u &lt;username&gt; -p &lt;password&gt; \
      --hub-model-id sentence-transformers/msmarco-MiniLM-L-12-v3 \
      --task-type text_embedding \
      --start</pre>
</div>
<p>You need to provide an administrator username and password and replace the
<code class="literal">$CLOUD_ID</code> with the ID of your Cloud deployment. This Cloud ID can be copied
from the deployments page on your Cloud website.</p>
<p>Since the <code class="literal">--start</code> option is used at the end of the Eland import command, Elasticsearch
deploys the model ready to use. If you have multiple models and want to select
which model to deploy, you can use the <span class="strong strong"><strong>Machine Learning &gt; Model Management</strong></span> user
interface in Kibana to manage the starting and stopping of models.</p>
<p>Go to the <span class="strong strong"><strong>Machine Learning &gt; Trained Models</strong></span> page and synchronize your trained
models. A warning message is displayed at the top of the page that says
<em>"ML job and trained model synchronization required"</em>. Follow the link to
<em>"Synchronize your jobs and trained models."</em> Then click <span class="strong strong"><strong>Synchronize</strong></span>. You
can also wait for the automatic synchronization that occurs in every hour, or
use the <a href="/guide/en/kibana/master/ml-sync.html" class="ulink" target="_top">sync machine learning objects API</a>.</p>
<h4><a id="ex-text-emb-test"></a>Test the text embedding model<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/main/docs/en/stack/ml/nlp/ml-nlp-text-emb-vector-search-example.asciidoc">edit</a></h4>
<p>Deployed models can be evaluated in Kibana under <span class="strong strong"><strong>Machine Learning</strong></span> &gt;
<span class="strong strong"><strong>Trained Models</strong></span> by selecting the <span class="strong strong"><strong>Test model</strong></span> action for the respective
model.</p>
<div class="imageblock screenshot">
<div class="content">
<img src="images/ml-nlp-text-emb-test.png" alt="Test trained model UI">
</div>
</div>
<details>
<summary class="title"><span class="strong strong"><strong>Test the model by using the _infer API</strong></span></summary>
<div class="content">
<p>You can also evaluate your models by using the
<a href="/guide/en/elasticsearch/reference/master/infer-trained-model-deployment.html" class="ulink" target="_top">_infer API</a>. In the following request,
<code class="literal">text_field</code> is the field name where the model expects to find the input, as
defined in the model configuration. By default, if the model was uploaded via
Eland, the input field is <code class="literal">text_field</code>.</p>
<div class="pre_wrapper lang-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js">POST /_ml/trained_models/sentence-transformers__msmarco-minilm-l-12-v3/_infer
{
  "docs": {
    "text_field": "How is the weather in Jamaica?"
  }
}</pre>
</div>
<p>The API returns a response similar to the following:</p>
<div class="pre_wrapper lang-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js">{
  "inference_results": [
    {
      "predicted_value": [
        0.39521875977516174,
        -0.3263707458972931,
        0.26809820532798767,
        0.30127981305122375,
        0.502890408039093,
        ...
      ]
    }
  ]
}</pre>
</div>
</div>
</details>
<p>The result is the predicted dense vector transformed from the example text.</p>
<h4><a id="ex-text-emb-data"></a>Load data<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/main/docs/en/stack/ml/nlp/ml-nlp-text-emb-vector-search-example.asciidoc">edit</a></h4>
<p>In this step, you load the data that you later use in an ingest pipeline to get
the embeddings.</p>
<p>The data set <code class="literal">msmarco-passagetest2019-top1000</code> is a subset of the MS MARCO
Passage Ranking data set used in the testing stage of the 2019 TREC Deep
Learning Track. It contains 200 queries and for each query a list of relevant
text passages extracted by a simple information retrieval (IR) system. From that
data set, all unique passages with their IDs have been extracted and put into a
<a href="https://github.com/elastic/stack-docs/blob/8.5/docs/en/stack/ml/nlp/data/msmarco-passagetest2019-unique.tsv" class="ulink" target="_top">tsv file</a>,
totaling 182469 passages. In the following, this file is used as the example
data set.</p>
<p>Upload the file by using the
<a href="/guide/en/kibana/master/connect-to-elasticsearch.html#upload-data-kibana" class="ulink" target="_top">Data Visualizer</a>.
Name the first column <code class="literal">id</code> and the second one <code class="literal">text</code>. The index name is
<code class="literal">collection</code>. After the upload is done, you can see an index named <code class="literal">collection</code>
with 182469 documents.</p>
<div class="imageblock screenshot">
<div class="content">
<img src="images/ml-nlp-text-emb-data.png" alt="Importing the data">
</div>
</div>
<h4><a id="ex-text-emb-ingest"></a>Add the text embedding model to an inference ingest pipeline<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/main/docs/en/stack/ml/nlp/ml-nlp-text-emb-vector-search-example.asciidoc">edit</a></h4>
<p>Process the initial data with an
<a href="/guide/en/elasticsearch/reference/master/inference-processor.html" class="ulink" target="_top">inference processor</a>. It adds an embedding for each
passage. For this, create a text embedding ingest pipeline and then reindex the
initial data with this pipeline.</p>
<p>Now create an ingest pipeline either in the
<a href="/guide/en/machine-learning/master/ml-nlp-inference.html#ml-nlp-inference-processor" class="ulink" target="_top">Stack Management UI</a>
or by using the API:</p>
<div class="pre_wrapper lang-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js">PUT _ingest/pipeline/text-embeddings
{
  "description": "Text embedding pipeline",
  "processors": [
    {
      "inference": {
        "model_id": "sentence-transformers__msmarco-minilm-l-12-v3",
        "target_field": "text_embedding",
        "field_map": {
          "text": "text_field"
        }
      }
    }
  ],
  "on_failure": [
    {
      "set": {
        "description": "Index document to 'failed-&lt;index&gt;'",
        "field": "_index",
        "value": "failed-{{{_index}}}"
      }
    },
    {
      "set": {
        "description": "Set error message",
        "field": "ingest.failure",
        "value": "{{_ingest.on_failure_message}}"
      }
    }
  ]
}</pre>
</div>
<p>The passages are in a field named <code class="literal">text</code>. The <code class="literal">field_map</code> maps the text to the
field <code class="literal">text_field</code> that the model expects. The <code class="literal">on_failure</code> handler is set to
index failures into a different index.</p>
<p>Before ingesting the data through the pipeline, create the mappings of the
destination index, in particular for the field <code class="literal">text_embedding.predicted_value</code>
where the ingest processor stores the embeddings. The <code class="literal">dense_vector</code> field must
be configured with the same number of dimensions (<code class="literal">dims</code>) as the text embedding
produced by the model. That value can be found in the <code class="literal">embedding_size</code> option in
the model configuration either under the Trained Models page in Kibana or in the
response body of the <a href="/guide/en/elasticsearch/reference/master/get-trained-models.html" class="ulink" target="_top">Get trained models API</a> call.
The msmarco-MiniLM-L-12-v3 model has embedding_size of 384, so <code class="literal">dims</code> is set to
384.</p>
<div class="pre_wrapper lang-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js">PUT collection-with-embeddings
{
  "mappings": {
    "properties": {
      "text_embedding.predicted_value": {
        "type": "dense_vector",
        "dims": 384
      },
      "text": {
        "type": "text"
      }
    }
  }
}</pre>
</div>
<p>Create the text embeddings by reindexing the data to the
<code class="literal">collection-with-embeddings</code> index through the inference pipeline. The inference
ingest processor inserts the embedding vector into each document.</p>
<div class="pre_wrapper lang-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js">POST _reindex?wait_for_completion=false
{
  "source": {
    "index": "collection",
    "size": 50 <a id="CO28-1"></a><i class="conum" data-value="1"></i>
  },
  "dest": {
    "index": "collection-with-embeddings",
    "pipeline": "text-embeddings"
  }
}</pre>
</div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO28-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>The default batch size for reindexing is 1000. Reducing <code class="literal">size</code> to a smaller
number makes the update of the reindexing process quicker which enables you to
follow the progress closely and detect errors early.</p>
</td>
</tr>
</table>
</div>
<p>The API call returns a task ID that can be used to monitor the progress:</p>
<div class="pre_wrapper lang-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js">GET _tasks/&lt;task_id&gt;</pre>
</div>
<p>You can also open the model stat UI to follow the progress.</p>
<div class="imageblock screenshot">
<div class="content">
<img src="images/ml-nlp-text-emb-reindex.png" alt="Model status UI">
</div>
</div>
<p>After the reindexing is finished, the documents in the new index contain the
inference results – the vector embeddings.</p>
<h4><a id="ex-text-emb-vect-search"></a>Semantic search<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/stack-docs/edit/main/docs/en/stack/ml/nlp/ml-nlp-text-emb-vector-search-example.asciidoc">edit</a></h4>
<p>After the dataset has been enriched with vector embeddings, you can query the
data using <a href="/guide/en/elasticsearch/reference/master/knn-search.html#knn-semantic-search" class="ulink" target="_top">semantic search</a>. Pass a
<code class="literal">query_vector_builder</code> to the k-nearest neighbor (kNN) vector search API, and
provide the query text and the model you have used to create vector embeddings.
This example searches for "How is the weather in Jamaica?":</p>
<div class="pre_wrapper lang-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js">GET collection-with-embeddings/_search
{
  "knn": {
    "field": "text_embedding.predicted_value",
    "query_vector_builder": {
      "text_embedding": {
        "model_id": "sentence-transformers__msmarco-minilm-l-12-v3",
        "model_text": "How is the weather in Jamaica?"
      }
    },
    "k": 10,
    "num_candidates": 100
  },
  "_source": [
    "id",
    "text"
  ]
}</pre>
</div>
<p>As a result, you receive the top 10 documents that are closest in meaning to the
query from the <code class="literal">collection-with-embedings</code> index sorted by their proximity to
the query:</p>
<div class="pre_wrapper lang-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js">"hits" : [
      {
        "_index" : "collection-with-embeddings",
        "_id" : "47TPtn8BjSkJO8zzKq_o",
        "_score" : 0.94591534,
        "_source" : {
          "id" : 434125,
          "text" : "The climate in Jamaica is tropical and humid with warm to hot temperatures all year round. The average temperature in Jamaica is between 80 and 90 degrees Fahrenheit. Jamaican nights are considerably cooler than the days, and the mountain areas are cooler than the lower land throughout the year. Continue Reading."
        }
      },
      {
        "_index" : "collection-with-embeddings",
        "_id" : "3LTPtn8BjSkJO8zzKJO1",
        "_score" : 0.94536424,
        "_source" : {
          "id" : 4498474,
          "text" : "The climate in Jamaica is tropical and humid with warm to hot temperatures all year round. The average temperature in Jamaica is between 80 and 90 degrees Fahrenheit. Jamaican nights are considerably cooler than the days, and the mountain areas are cooler than the lower land throughout the year"
        }
      },
      {
        "_index" : "collection-with-embeddings",
        "_id" : "KrXPtn8BjSkJO8zzPbDW",
        "_score" :  0.9432083,
        "_source" : {
          "id" : 190804,
          "text" : "Quick Answer. The climate in Jamaica is tropical and humid with warm to hot temperatures all year round. The average temperature in Jamaica is between 80 and 90 degrees Fahrenheit. Jamaican nights are considerably cooler than the days, and the mountain areas are cooler than the lower land throughout the year. Continue Reading"
        }
      },
      (...)
]</pre>
</div>
<p>If you want to do a quick verification of the results, follow the steps of the
<em>Quick verification</em> section of
<a href="/blog/how-to-deploy-nlp-text-embeddings-and-vector-search#" class="ulink" target="_top">this blog post</a>.</p>
</div>
</div>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  messageStyle: "none",
  tex2jax: {
    inlineMath: [["\\(", "\\)"]],
    displayMath: [["\\[", "\\]"]],
    ignoreClass: "nostem|nolatexmath"
  },
  asciimath2jax: {
    delimiters: [["\\$", "\\$"]],
    ignoreClass: "nostem|noasciimath"
  },
  TeX: { equationNumbers: { autoNumber: "none" } }
})
MathJax.Hub.Register.StartupHook("AsciiMath Jax Ready", function () {
  MathJax.InputJax.AsciiMath.postfilterHooks.Add(function (data, node) {
    if ((node = data.script.parentNode) && (node = node.parentNode) && node.classList.contains('stemblock')) {
      data.math.root.display = "block"
    }
    return data
  })
})
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_HTMLorMML"></script>
</div><div class="navfooter">
<span class="prev">
<a href="ml-nlp-ner-example.html">« How to deploy named entity recognition</a>
</span>
<span class="next">
<a href="ml-nlp-limitations.html">Limitations »</a>
</span>
</div>
</body>
</html>
