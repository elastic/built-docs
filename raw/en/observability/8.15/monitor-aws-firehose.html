<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Monitor Amazon Web Services (AWS) with Amazon Data Firehose | Elastic Observability [8.15] | Elastic</title>
<meta class="elastic" name="content" content="Monitor Amazon Web Services (AWS) with Amazon Data Firehose | Elastic Observability [8.15]">

<link rel="home" href="index.html" title="Elastic Observability [8.15]"/>
<link rel="up" href="monitor-amazon-web-services.html" title="Amazon Web Services (AWS) monitoring"/>
<link rel="prev" href="monitor-aws.html" title="Monitor Amazon Web Services (AWS) with Beats"/>
<link rel="next" href="monitor-amazon-vpc-flow-logs.html" title="Monitor Virtual Private Cloud (VPC) Flow Logs"/>
<meta class="elastic" name="product_version" content="8.15"/>
<meta class="elastic" name="product_name" content="Observability"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/Observability/Guide/8.15"/>
<meta name="DC.subject" content="Observability"/>
<meta name="DC.identifier" content="8.15"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body>
<div class="page_header">
You are looking at preliminary documentation for a future release.
Not what you want? See the
<a href="../current/index.html">current release documentation</a>.
</div>
<div class="navheader">
<span class="prev">
<a href="monitor-aws.html">« Monitor Amazon Web Services (AWS) with Beats</a>
</span>
<span class="next">
<a href="monitor-amazon-vpc-flow-logs.html">Monitor Virtual Private Cloud (VPC) Flow Logs »</a>
</span>
</div>
<div class="book" lang="en">
<div class="titlepage">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Elastic Observability [8.15]</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="monitor-amazon-web-services.html">Amazon Web Services (AWS) monitoring</a></span>
</div>
<div>
<div><h1 class="title"><a id="id-1"></a>Monitor Amazon Web Services (AWS) with Amazon Data Firehose</h1><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/observability-docs/edit/8.15/docs/en/observability/cloud-monitoring/aws/monitor-aws-firehose.asciidoc">edit</a></div>
</div>
<!--EXTRA-->
</div>
<div id="content">
<div class="section">
<div class="titlepage"><div><div>
<h2 class="title"><a id="monitor-aws-firehose"></a>Monitor Amazon Web Services (AWS) with Amazon Data Firehose<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/observability-docs/edit/8.15/docs/en/observability/cloud-monitoring/aws/monitor-aws-firehose.asciidoc">edit</a></h2>
</div></div></div>

<p>Amazon Data Firehose is a popular service that allows you to send your service logs and monitoring metrics to Elastic in minutes without a single line of code and without building or managing your own data ingestion and delivery infrastructure.</p>
<h4><a id="aws-elastic-firehose-what-you-learn"></a>What you&#8217;ll learn<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/observability-docs/edit/8.15/docs/en/observability/cloud-monitoring/aws/monitor-aws-firehose.asciidoc">edit</a></h4>
<p>In this tutorial, you&#8217;ll learn how to:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
Install AWS integration in Kibana
</li>
<li class="listitem">
Create a delivery stream in Amazon Data Firehose
</li>
<li class="listitem">
Specify the destination settings for your Firehose stream
</li>
<li class="listitem">
Send data to the Firehose delivery stream
</li>
</ul>
</div>
<h4><a id="aws-elastic-firehose-before-you-begin"></a>Before you begin<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/observability-docs/edit/8.15/docs/en/observability/cloud-monitoring/aws/monitor-aws-firehose.asciidoc">edit</a></h4>
<p>Create a deployment in AWS regions (including gov cloud) using our hosted Elasticsearch Service on <a href="/cloud/elasticsearch-service/signup?page=docs&amp;placement=docs-body" class="ulink" target="_top">Elastic Cloud</a>.
The deployment includes an Elasticsearch cluster for storing and searching your data, and Kibana for visualizing and managing your data.</p>
<h4><a id="firehose-step-one"></a>Step 1: Install AWS integration in Kibana<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/observability-docs/edit/8.15/docs/en/observability/cloud-monitoring/aws/monitor-aws-firehose.asciidoc">edit</a></h4>
<div class="olist orderedlist">
<ol class="orderedlist">
<li class="listitem">
Install AWS integrations to load index templates, ingest pipelines, and dashboards into Kibana. In Kibana, navigate to <span class="strong strong"><strong>Management</strong></span> &gt; <span class="strong strong"><strong>Integrations</strong></span> in the sidebar. Find the AWS Integration by browsing the catalog.
</li>
<li class="listitem">
Navigate to the <span class="strong strong"><strong>Settings</strong></span> tab and click <span class="strong strong"><strong>Install AWS assets</strong></span>. Confirm by clicking <span class="strong strong"><strong>Install AWS</strong></span> in the popup.
</li>
<li class="listitem">
Install Amazon Data Firehose integration assets in Kibana.
</li>
</ol>
</div>
<h4><a id="firehose-step-two"></a>Step 2: Create a delivery stream in Amazon Data Firehose<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/observability-docs/edit/8.15/docs/en/observability/cloud-monitoring/aws/monitor-aws-firehose.asciidoc">edit</a></h4>
<div class="olist orderedlist">
<ol class="orderedlist">
<li class="listitem">
Go to the <a href="https://console.aws.amazon.com/" class="ulink" target="_top">AWS console</a> and navigate to Amazon Data Firehose.
</li>
<li class="listitem">
Click <span class="strong strong"><strong>Create Firehose stream</strong></span> and choose the source and destination of your Firehose stream. Unless you are streaming data from Kinesis Data Streams, set source to <code class="literal">Direct PUT</code> and destination to <code class="literal">Elastic</code>.
</li>
<li class="listitem">
Provide a meaningful <span class="strong strong"><strong>Firehose stream name</strong></span> that will allow you to identify this delivery stream later.
</li>
</ol>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For advanced use cases, source records can be transformed by invoking a custom Lambda function. When using Elastic integrations, this should not be required.</p>
</div>
</div>
<h4><a id="firehose-step-three"></a>Step 3: Specify the destination settings for your Firehose stream<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/observability-docs/edit/8.15/docs/en/observability/cloud-monitoring/aws/monitor-aws-firehose.asciidoc">edit</a></h4>
<div class="olist orderedlist">
<ol class="orderedlist">
<li class="listitem">
<p>From the <span class="strong strong"><strong>Destination settings</strong></span> panel, specify the following settings:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<span class="strong strong"><strong>Elastic endpoint URL</strong></span>: Enter the Elastic endpoint URL of your Elasticsearch cluster. To find the Elasticsearch endpoint, go to the Elastic Cloud console and select <span class="strong strong"><strong>Connection details</strong></span>. Here is an example of how it looks like: <code class="literal">https://my-deployment.es.us-east-1.aws.elastic-cloud.com</code>.
</li>
<li class="listitem">
<span class="strong strong"><strong>API key</strong></span>: Enter the encoded Elastic API key. To create an API key, go to the Elastic Cloud console, select <span class="strong strong"><strong>Connection details</strong></span> and click <span class="strong strong"><strong>Create and manage API keys</strong></span>. If you are using an API key with <span class="strong strong"><strong>Restrict privileges</strong></span>, make sure to review the Indices privileges to provide at least "auto_configure" &amp; "write" permissions for the indices you will be using with this delivery stream.
</li>
<li class="listitem">
<span class="strong strong"><strong>Content encoding</strong></span>: For a better network efficiency, leave content encoding set to GZIP.
</li>
<li class="listitem">
<span class="strong strong"><strong>Retry duration</strong></span>: Determines how long Firehose continues retrying the request in the event of an error. A duration of 60-300s should be suitable for most use cases.
</li>
<li class="listitem">
<p><span class="strong strong"><strong>Parameters</strong></span>:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">es_datastream_name</code>: This parameter is optional and can be used to set which data stream documents will be stored. If this parameter is not specified, data is sent to the <code class="literal">logs-awsfirehose-default</code> data stream by default.
</li>
<li class="listitem">
<code class="literal">include_cw_extracted_fields</code>: This parameter is optional and can be set when using a CloudWatch logs subscription filter as the Firehose data source. When set to true, extracted fields generated by the filter pattern in the subscription filter will be collected. Setting this parameter can add many fields into each record and may significantly increase data volume in Elasticsearch. As such, use of this parameter should be carefully considered and used only when the extracted fields are required for specific filtering and/or aggregation.
</li>
<li class="listitem">
<p><code class="literal">set_es_document_id</code>: This parameter is optional and can be set to allow Elasticsearch to assign each document a random ID or use a calculated unique ID for each document. Default is true. When set to false, a random ID will be used for each document which will help indexing performance.</p>
<div class="olist orderedlist">
<ol class="orderedlist">
<li class="listitem">
In the <span class="strong strong"><strong>Backup settings</strong></span> panel, it is recommended to configure S3 backup for failed records. It’s then possible to configure workflows to automatically retry failed records, for example by using <a href="/guide/en/esf/master/aws-elastic-serverless-forwarder.html" class="ulink" target="_top">Elastic Serverless Forwarder</a>.
</li>
</ol>
</div>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
</ol>
</div>
<h4><a id="firehose-step-four"></a>Step 4: Send data to the Firehose delivery stream<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/observability-docs/edit/8.15/docs/en/observability/cloud-monitoring/aws/monitor-aws-firehose.asciidoc">edit</a></h4>
<p>You can configure a variety of log sources to send data to Firehose streams directly for example VPC flow logs.
Some services don&#8217;t support publishing logs directly to Firehose but they do support publishing logs to CloudWatch logs, such as CloudTrail and Lambda.
Refer to the <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/AWS-logs-and-resource-policy.html" class="ulink" target="_top">AWS documentation</a> for more information.</p>
<p>For example, a typical workflow for sending CloudTrail logs to Firehose would be the following:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
Publish CloudTrail logs to a Cloudwatch log group. Refer to the AWS documentation <a href="https://docs.aws.amazon.com/awscloudtrail/latest/userguide/monitor-cloudtrail-log-files-with-cloudwatch-logs.html" class="ulink" target="_top">about publishing CloudTrail logs</a>.
</li>
<li class="listitem">
Create a subscription filter in the CloudWatch log group to the Firehose stream. Refer to the AWS documentation <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/SubscriptionFilters.html#FirehoseExample" class="ulink" target="_top">about using subscription filters</a>.
</li>
</ul>
</div>
<p>We also added support for sending CloudWatch monitoring metrics to Elastic using Firehose. For example, you can configure metrics ingestion by creating a metric stream through CloudWatch.
You can select an existing Firehose stream by choosing the option <span class="strong strong"><strong>Custom setup with Firehose</strong></span>. For more information, refer to the AWS documentation <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch-metric-streams-setup-datalake.html" class="ulink" target="_top">about the custom setup with Firehose</a>.</p>
<p>For more information on Amazon Data Firehose, you can also check the <a href="https://docs.elastic.co/integrations/awsfirehose" class="ulink" target="_top">Amazon Data Firehose Integrations documentation</a>.</p>






</div>
</div>
</div><div class="navfooter">
<span class="prev">
<a href="monitor-aws.html">« Monitor Amazon Web Services (AWS) with Beats</a>
</span>
<span class="next">
<a href="monitor-amazon-vpc-flow-logs.html">Monitor Virtual Private Cloud (VPC) Flow Logs »</a>
</span>
</div>
</body>
</html>
