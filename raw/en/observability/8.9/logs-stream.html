<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Stream a log file | Elastic Observability [8.9] | Elastic</title>
<meta class="elastic" name="content" content="Stream a log file | Elastic Observability [8.9]">

<link rel="home" href="index.html" title="Elastic Observability [8.9]"/>
<link rel="up" href="logs-observability-overview.html" title="Logs overview"/>
<link rel="prev" href="logs-checklist.html" title="Logs resource guide"/>
<link rel="next" href="monitor-logs.html" title="Log monitoring"/>
<meta class="elastic" name="product_version" content="8.9"/>
<meta class="elastic" name="product_name" content="Observability"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/Observability/Guide/8.9"/>
<meta name="DC.subject" content="Observability"/>
<meta name="DC.identifier" content="8.9"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body><div class="page_header">
<strong>IMPORTANT</strong>: No additional bug fixes or documentation updates
will be released for this version. For the latest information, see the
<a href="../current/index.html">current release documentation</a>.
</div>
<div id="content">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Elastic Observability [8.9]</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="logs-observability-overview.html">Logs overview</a></span>
</div>
<div class="navheader">
<span class="prev">
<a href="logs-checklist.html">« Logs resource guide</a>
</span>
<span class="next">
<a href="monitor-logs.html">Log monitoring »</a>
</span>
</div>
<div class="section">
<div class="titlepage"><div><div>
<h2 class="title"><a id="logs-stream"></a>Stream a log file<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/observability-docs/edit/8.9/docs/en/observability/logs-stream.asciidoc">edit</a></h2>
</div></div></div>
<p>In this guide, you&#8217;ll learn how to send a log file to Elasticsearch using a standalone Elastic Agent, configure the Elastic Agent and your data streams using the <code class="literal">elastic-agent.yml</code> file, and query your logs using the data streams you&#8217;ve set up. Once your log files are in Elasticsearch, see the <a class="xref" href="logs-stream.html#logs-stream-enhance-logs" title="Get the most out of your log data">Get the most out of your log data</a> section to learn how to parse your log data and extract fields so you can filter and sort your logs effectively.</p>
<h3><a id="logs-stream-prereq"></a>Prerequisites<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/observability-docs/edit/8.9/docs/en/observability/logs-stream.asciidoc">edit</a></h3>
<p>To follow the steps in this guide, you need an Elastic Stack deployment that includes:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
Elasticsearch for storing and searching data
</li>
<li class="listitem">
Kibana for visualizing and managing data
</li>
<li class="listitem">
Kibana user with <code class="literal">All</code> privileges on Fleet and Integrations. Since many
Integrations assets are shared across spaces, users need the Kibana privileges
in all spaces.
</li>
<li class="listitem">
Integrations Server (included by default in every Elasticsearch Service deployment)
</li>
</ul>
</div>
<p>To get started quickly, spin up a deployment of our hosted Elasticsearch Service. The Elasticsearch Service is
available on AWS, GCP, and Azure. <a href="/cloud/elasticsearch-service/signup?page=docs&amp;placement=docs-body" class="ulink" target="_top">Try it out for free</a>.</p>
<h3><a id="logs-stream-install-config-agent"></a>Install and configure the standalone Elastic Agent<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/observability-docs/edit/8.9/docs/en/observability/logs-stream.asciidoc">edit</a></h3>
<p>Complete these steps to install and configure the standalone Elastic Agent and send your log data to Elasticsearch:</p>
<div class="olist orderedlist">
<ol class="orderedlist">
<li class="listitem">
<a class="xref" href="logs-stream.html#logs-stream-extract-agent" title="Step 1: Download and extract the Elastic Agent installation package">Download and extract the Elastic Agent installation package.</a>
</li>
<li class="listitem">
<a class="xref" href="logs-stream.html#logs-stream-install-agent" title="Step 2: Install and start the Elastic Agent">Install and start the Elastic Agent.</a>
</li>
<li class="listitem">
<a class="xref" href="logs-stream.html#logs-stream-agent-config" title="Step 3: Configure the Elastic Agent">Configure the Elastic Agent.</a>
</li>
</ol>
</div>
<h4><a id="logs-stream-extract-agent"></a>Step 1: Download and extract the Elastic Agent installation package<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/observability-docs/edit/8.9/docs/en/observability/logs-stream.asciidoc">edit</a></h4>
<p>On your host, download and extract the installation package that corresponds with your system:</p>
<div class="tabs" data-tab-group="os">
  <div role="tablist" aria-label="Download">
    <button role="tab"
            aria-selected="true"
            aria-controls="mac-tab-download"
            id="mac-download">
      macOS
    </button>
    <button role="tab"
            aria-selected="false"
            aria-controls="linux-tab-download"
            id="linux-download"
            tabindex="-1">
      Linux
    </button>
    <button role="tab"
            aria-selected="false"
            aria-controls="win-tab-download"
            id="win-download"
            tabindex="-1">
      Windows
    </button>
    <button role="tab"
            aria-selected="false"
            aria-controls="deb-tab-download"
            id="deb-download"
            tabindex="-1">
      DEB
    </button>
    <button role="tab"
            aria-selected="false"
            aria-controls="rpm-tab-download"
            id="rpm-download"
            tabindex="-1">
      RPM
    </button>
  </div>
  <div tabindex="0"
       role="tabpanel"
       id="mac-tab-download"
       aria-labelledby="mac-download">
<div class="pre_wrapper lang-sh">
<pre class="programlisting prettyprint lang-sh">curl -L -O https://artifacts.elastic.co/downloads/beats/elastic-agent/elastic-agent-8.9.2-darwin-x86_64.tar.gz
tar xzvf elastic-agent-8.9.2-darwin-x86_64.tar.gz</pre>
</div>
  </div>
  <div tabindex="0"
       role="tabpanel"
       id="linux-tab-download"
       aria-labelledby="linux-download"
       hidden="">
<div class="pre_wrapper lang-sh">
<pre class="programlisting prettyprint lang-sh">curl -L -O https://artifacts.elastic.co/downloads/beats/elastic-agent/elastic-agent-8.9.2-linux-x86_64.tar.gz
tar xzvf elastic-agent-8.9.2-linux-x86_64.tar.gz</pre>
</div>
  </div>
  <div tabindex="0"
       role="tabpanel"
       id="win-tab-download"
       aria-labelledby="win-download"
       hidden="">
<div class="pre_wrapper lang-powershell">
<pre class="programlisting prettyprint lang-powershell"># PowerShell 5.0+
wget https://artifacts.elastic.co/downloads/beats/elastic-agent/elastic-agent-8.9.2-windows-x86_64.zip -OutFile elastic-agent-8.9.2-windows-x86_64.zip
Expand-Archive .\elastic-agent-8.9.2-windows-x86_64.zip</pre>
</div>
<p>Or manually:</p>
<div class="olist orderedlist">
<ol class="orderedlist">
<li class="listitem">
Download the Elastic Agent Windows zip file from the
<a href="/downloads/beats/elastic-agent" class="ulink" target="_top">download page</a>.
</li>
<li class="listitem">
Extract the contents of the zip file.
</li>
</ol>
</div>
  </div>
  <div tabindex="0"
       role="tabpanel"
       id="deb-tab-download"
       aria-labelledby="deb-download"
       hidden="">
<div class="important admon">
<div class="icon"></div>
<div class="admon_content">
<p>To simplify upgrading to future versions of Elastic Agent, we recommended
that you use the tarball distribution instead of the DEB distribution.</p>
</div>
</div>
<div class="pre_wrapper lang-sh">
<pre class="programlisting prettyprint lang-sh">curl -L -O https://artifacts.elastic.co/downloads/beats/elastic-agent/elastic-agent-8.9.2-amd64.deb
sudo dpkg -i elastic-agent-8.9.2-amd64.deb</pre>
</div>
  </div>
  <div tabindex="0"
       role="tabpanel"
       id="rpm-tab-download"
       aria-labelledby="rpm-download"
       hidden="">
<div class="important admon">
<div class="icon"></div>
<div class="admon_content">
<p>To simplify upgrading to future versions of Elastic Agent, we recommended
that you use the tarball distribution instead of the RPM distribution.</p>
</div>
</div>
<div class="pre_wrapper lang-sh">
<pre class="programlisting prettyprint lang-sh">curl -L -O https://artifacts.elastic.co/downloads/beats/elastic-agent/elastic-agent-8.9.2-x86_64.rpm
sudo rpm -vi elastic-agent-8.9.2-x86_64.rpm</pre>
</div>
  </div>
</div>
<h4><a id="logs-stream-install-agent"></a>Step 2: Install and start the Elastic Agent<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/observability-docs/edit/8.9/docs/en/observability/logs-stream.asciidoc">edit</a></h4>
<p>After downloading and extracting the installation package, you&#8217;re ready to install the Elastic Agent. From the agent directory, run the install command that corresponds with your system:</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>On macOS, Linux (tar package), and Windows, run the <code class="literal">install</code> command to
install and start Elastic Agent as a managed service and start the service. The DEB and RPM
packages include a service unit for Linux systems with
systemd, For these systems, you must enable and start the service.</p>
</div>
</div>
<div class="tabs" data-tab-group="os">
  <div role="tablist" aria-label="Run the agent standalone">
    <button role="tab"
            aria-selected="true"
            aria-controls="mac-tab-run-standalone"
            id="mac-run-standalone">
      macOS
    </button>
    <button role="tab"
            aria-selected="false"
            aria-controls="linux-tab-run-standalone"
            id="linux-run-standalone"
            tabindex="-1">
      Linux
    </button>
    <button role="tab"
            aria-selected="false"
            aria-controls="win-tab-run-standalone"
            id="win-run-standalone"
            tabindex="-1">
      Windows
    </button>
    <button role="tab"
            aria-selected="false"
            aria-controls="deb-tab-run-standalone"
            id="deb-run-standalone"
            tabindex="-1">
      DEB
    </button>
    <button role="tab"
            aria-selected="false"
            aria-controls="rpm-tab-run-standalone"
            id="rpm-run-standalone"
            tabindex="-1">
      RPM
    </button>
  </div>
  <div tabindex="0"
       role="tabpanel"
       id="mac-tab-run-standalone"
       aria-labelledby="mac-run-standalone">
<div class="tip admon">
<div class="icon"></div>
<div class="admon_content">
<p>You must run this command as the root user because some
integrations require root privileges to collect sensitive data.</p>
</div>
</div>
<div class="pre_wrapper lang-shell">
<pre class="programlisting prettyprint lang-shell">sudo ./elastic-agent install</pre>
</div>
  </div>
  <div tabindex="0"
       role="tabpanel"
       id="linux-tab-run-standalone"
       aria-labelledby="linux-run-standalone"
       hidden="">
<div class="tip admon">
<div class="icon"></div>
<div class="admon_content">
<p>You must run this command as the root user because some
integrations require root privileges to collect sensitive data.</p>
</div>
</div>
<div class="pre_wrapper lang-shell">
<pre class="programlisting prettyprint lang-shell">sudo ./elastic-agent install</pre>
</div>
  </div>
  <div tabindex="0"
       role="tabpanel"
       id="win-tab-run-standalone"
       aria-labelledby="win-run-standalone"
       hidden="">
<p>Open a PowerShell prompt as an Administrator (right-click the PowerShell icon
and select <span class="strong strong"><strong>Run As Administrator</strong></span>).</p>
<p>From the PowerShell prompt, change to the directory where you installed Elastic Agent,
and run:</p>
<div class="pre_wrapper lang-shell">
<pre class="programlisting prettyprint lang-shell">.\elastic-agent.exe install</pre>
</div>
  </div>
  <div tabindex="0"
       role="tabpanel"
       id="deb-tab-run-standalone"
       aria-labelledby="deb-run-standalone"
       hidden="">
<div class="tip admon">
<div class="icon"></div>
<div class="admon_content">
<p>You must run this command as the root user because some
integrations require root privileges to collect sensitive data.</p>
</div>
</div>
<div class="pre_wrapper lang-shell">
<pre class="programlisting prettyprint lang-shell">sudo systemctl enable elastic-agent <a id="CO7-1"></a><i class="conum" data-value="1"></i>
sudo systemctl start elastic-agent</pre>
</div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO7-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>The DEB package includes a service unit for Linux systems with systemd. On
these systems, you can manage Elastic Agent by using the usual systemd commands. If
you don&#8217;t have systemd, run <code class="literal">sudo service elastic-agent start</code>.</p>
</td>
</tr>
</table>
</div>
  </div>
  <div tabindex="0"
       role="tabpanel"
       id="rpm-tab-run-standalone"
       aria-labelledby="rpm-run-standalone"
       hidden="">
<div class="tip admon">
<div class="icon"></div>
<div class="admon_content">
<p>You must run this command as the root user because some
integrations require root privileges to collect sensitive data.</p>
</div>
</div>
<div class="pre_wrapper lang-shell">
<pre class="programlisting prettyprint lang-shell">sudo systemctl enable elastic-agent <a id="CO8-1"></a><i class="conum" data-value="1"></i>
sudo systemctl start elastic-agent</pre>
</div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO8-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>The RPM package includes a service unit for Linux systems with systemd. On
these systems, you can manage Elastic Agent by using the usual systemd commands. If
you don&#8217;t have systemd, run <code class="literal">sudo service elastic-agent start</code>.</p>
</td>
</tr>
</table>
</div>
  </div>
</div>
<p>During installation, you&#8217;re prompted with some questions:</p>
<div class="olist orderedlist">
<ol class="orderedlist">
<li class="listitem">
When asked if you want to install the agent as a service, enter <code class="literal">Y</code>.
</li>
<li class="listitem">
When asked if you want to enroll the agent in Fleet, enter <code class="literal">n</code>.
</li>
</ol>
</div>
<h4><a id="logs-stream-agent-config"></a>Step 3: Configure the Elastic Agent<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/observability-docs/edit/8.9/docs/en/observability/logs-stream.asciidoc">edit</a></h4>
<p>With your agent installed, configure it by updating the <code class="literal">elastic-agent.yml</code> file.</p>
<h5><a id="logs-stream-yml-location"></a>Locate your configuration file<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/observability-docs/edit/8.9/docs/en/observability/logs-stream.asciidoc">edit</a></h5>
<p>After installing the agent, you&#8217;ll find the <code class="literal">elastic-agent.yml</code> in one of the following locations according to your system:</p>
<div class="tabs" data-tab-group="os">
  <div role="tablist" aria-label="Installation layout">
    <button role="tab"
            aria-selected="true"
            aria-controls="mac-tab-yml-location"
            id="mac-yml-location">
      macOS
    </button>
    <button role="tab"
            aria-selected="false"
            aria-controls="linux-tab-yml-location"
            id="linux-yml-location"
            tabindex="-1">
      Linux
    </button>
    <button role="tab"
            aria-selected="false"
            aria-controls="win-tab-yml-location"
            id="win-yml-location"
            tabindex="-1">
      Windows
    </button>
    <button role="tab"
            aria-selected="false"
            aria-controls="deb-tab-yml-location"
            id="deb-yml-location"
            tabindex="-1">
      DEB
    </button>
    <button role="tab"
            aria-selected="false"
            aria-controls="rpm-tab-yml-location"
            id="rpm-yml-location"
            tabindex="-1">
      RPM
    </button>
  </div>
  <div tabindex="0"
       role="tabpanel"
       id="mac-tab-yml-location"
       aria-labelledby="mac-yml-location">
<p>Main Elastic Agent configuration file location:</p>
<p><code class="literal">/Library/Elastic/Agent/elastic-agent.yml</code></p>
  </div>
  <div tabindex="0"
       role="tabpanel"
       id="linux-tab-yml-location"
       aria-labelledby="linux-yml-location"
       hidden="">
<p>Main Elastic Agent configuration file location:</p>
<p><code class="literal">/opt/Elastic/Agent/elastic-agent.yml</code></p>
  </div>
  <div tabindex="0"
       role="tabpanel"
       id="win-tab-yml-location"
       aria-labelledby="win-yml-location"
       hidden="">
<p>Main Elastic Agent configuration file location:</p>
<p><code class="literal">C:\Program Files\Elastic\Agent\elastic-agent.yml</code></p>
  </div>
  <div tabindex="0"
       role="tabpanel"
       id="deb-tab-yml-location"
       aria-labelledby="deb-yml-location"
       hidden="">
<p>Main Elastic Agent configuration file location:</p>
<p><code class="literal">/etc/elastic-agent/elastic-agent.yml</code></p>
  </div>
  <div tabindex="0"
       role="tabpanel"
       id="rpm-tab-yml-location"
       aria-labelledby="rpm-yml-location"
       hidden="">
<p>Main Elastic Agent configuration file location:</p>
<p><code class="literal">/etc/elastic-agent/elastic-agent.yml</code></p>
  </div>
</div>
<h5><a id="logs-stream-example-config"></a>Update your configuration file<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/observability-docs/edit/8.9/docs/en/observability/logs-stream.asciidoc">edit</a></h5>
<p>The following is an example of a standalone Elastic Agent configuration. To configure your Elastic Agent, replace the contents of the <code class="literal">elastic-agent.yml</code> file with this configuration:</p>
<div class="pre_wrapper lang-yaml">
<pre class="programlisting prettyprint lang-yaml">outputs:
  default:
    type: elasticsearch
    hosts: '&lt;your-elasticsearch-endpoint&gt;:&lt;port&gt;'
    api_key: 'your-api-key'
inputs:
  - id: your-log-id
    type: filestream
    streams:
      - id: your-log-stream-id
        data_stream:
          dataset: generic
        paths:
          - /var/log/your-logs.log</pre>
</div>
<p>Next, set the values for these fields:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<p><code class="literal">hosts</code> – Copy the Elasticsearch endpoint from your deployment&#8217;s page and add the port (the default port is <code class="literal">443</code>). For example, <code class="literal">https://my-deployment.es.us-central1.gcp.cloud.es.io:443</code>.</p>
<div class="imageblock screenshot">
<div class="content">
<img src="images/es-endpoint-cluster-id.png" alt="Elasticsearch endpoint and cluster id location" width="50%">
</div>
</div>
</li>
<li class="listitem">
<p><code class="literal">api-key</code> – Use an API key to grant the agent access to Elasticsearch. To create an API key for your agent, see <a href="/guide/en/fleet/8.9/grant-access-to-elasticsearch.html#create-api-key-standalone-agent" class="ulink" target="_top">Create API keys for standalone agents</a>.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>The API key format should be <code class="literal">&lt;id&gt;:&lt;key&gt;</code>. Make sure you selected <span class="strong strong"><strong>Beats</strong></span> when you created your API key. Base64 encoded API keys are not currently supported in this configuration.</p>
</div>
</div>
</li>
<li class="listitem">
<code class="literal">inputs.id</code> – A unique identifier for your input.
</li>
<li class="listitem">
<code class="literal">type</code> – The type of input. For collecting logs, set this to <code class="literal">filestream</code>.
</li>
<li class="listitem">
<code class="literal">streams.id</code> – A unique identifier for your stream of log data.
</li>
<li class="listitem">
<code class="literal">data_stream.dataset</code> – The name for your dataset data stream. Name this data stream anything that signifies the source of the data. The default value is <code class="literal">generic</code>.
</li>
<li class="listitem">
<code class="literal">paths</code> – The path to your log files. You can also use a pattern like <code class="literal">/var/log/your-logs.log*</code>.
</li>
</ul>
</div>
<h5><a id="logs-stream-restart-agent"></a>Restart the Elastic Agent<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/observability-docs/edit/8.9/docs/en/observability/logs-stream.asciidoc">edit</a></h5>
<p>After updating your configuration file, you need to restart the Elastic Agent:</p>
<p>First, stop the Elastic Agent and its related executables using the command that works with your system:</p>
<div class="tabs" data-tab-group="os">
  <div role="tablist" aria-label="Stop the agent">
    <button role="tab"
            aria-selected="true"
            aria-controls="mac-tab-stop"
            id="mac-stop">
      macOS
    </button>
    <button role="tab"
            aria-selected="false"
            aria-controls="linux-tab-stop"
            id="linux-stop"
            tabindex="-1">
      Linux
    </button>
    <button role="tab"
            aria-selected="false"
            aria-controls="win-tab-stop"
            id="win-stop"
            tabindex="-1">
      Windows
    </button>
    <button role="tab"
            aria-selected="false"
            aria-controls="deb-tab-stop"
            id="deb-stop"
            tabindex="-1">
      DEB
    </button>
    <button role="tab"
            aria-selected="false"
            aria-controls="rpm-tab-stop"
            id="rpm-stop"
            tabindex="-1">
      RPM
    </button>
  </div>
  <div tabindex="0"
       role="tabpanel"
       id="mac-tab-stop"
       aria-labelledby="mac-stop">
<div class="pre_wrapper lang-shell">
<pre class="programlisting prettyprint lang-shell">sudo launchctl unload /Library/LaunchDaemons/co.elastic.elastic-agent.plist</pre>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>Elastic Agent will restart automatically if the system is rebooted.</p>
</div>
</div>
  </div>
  <div tabindex="0"
       role="tabpanel"
       id="linux-tab-stop"
       aria-labelledby="linux-stop"
       hidden="">
<div class="pre_wrapper lang-shell">
<pre class="programlisting prettyprint lang-shell">sudo service elastic-agent stop</pre>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>Elastic Agent will restart automatically if the system is rebooted.</p>
</div>
</div>
  </div>
  <div tabindex="0"
       role="tabpanel"
       id="win-tab-stop"
       aria-labelledby="win-stop"
       hidden="">
<div class="pre_wrapper lang-shell">
<pre class="programlisting prettyprint lang-shell">Stop-Service Elastic Agent</pre>
</div>
<p>If necessary, use Task Manager on Windows to stop Elastic Agent. This will kill the
<code class="literal">elastic-agent</code> process and any sub-processes it created (such as Beats).</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>Elastic Agent will restart automatically if the system is rebooted.</p>
</div>
</div>
  </div>
  <div tabindex="0"
       role="tabpanel"
       id="deb-tab-stop"
       aria-labelledby="deb-stop"
       hidden="">
<p>The DEB package includes a service unit for Linux systems with systemd. On these
systems, you can manage Elastic Agent by using the usual systemd commands.</p>
<p>Use <code class="literal">systemctl</code> to stop the agent:</p>
<div class="pre_wrapper lang-shell">
<pre class="programlisting prettyprint lang-shell">sudo systemctl stop elastic-agent</pre>
</div>
<p>Otherwise, use:</p>
<div class="pre_wrapper lang-shell">
<pre class="programlisting prettyprint lang-shell">sudo service elastic-agent stop</pre>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>Elastic Agent will restart automatically if the system is rebooted.</p>
</div>
</div>
  </div>
  <div tabindex="0"
       role="tabpanel"
       id="rpm-tab-stop"
       aria-labelledby="rpm-stop"
       hidden="">
<p>The RPM package includes a service unit for Linux systems with systemd. On these
systems, you can manage Elastic Agent by using the usual systemd commands.</p>
<p>Use <code class="literal">systemctl</code> to stop the agent:</p>
<div class="pre_wrapper lang-shell">
<pre class="programlisting prettyprint lang-shell">sudo systemctl stop elastic-agent</pre>
</div>
<p>Otherwise, use:</p>
<div class="pre_wrapper lang-shell">
<pre class="programlisting prettyprint lang-shell">sudo service elastic-agent stop</pre>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>Elastic Agent will restart automatically if the system is rebooted.</p>
</div>
</div>
  </div>
</div>
<p>Next, restart the Elastic Agent using the command that works with your system:</p>
<div class="tabs" data-tab-group="os">
  <div role="tablist" aria-label="start the agent">
    <button role="tab"
            aria-selected="true"
            aria-controls="mac-tab-start"
            id="mac-start">
      macOS
    </button>
    <button role="tab"
            aria-selected="false"
            aria-controls="linux-tab-start"
            id="linux-start"
            tabindex="-1">
      Linux
    </button>
    <button role="tab"
            aria-selected="false"
            aria-controls="win-tab-start"
            id="win-start"
            tabindex="-1">
      Windows
    </button>
    <button role="tab"
            aria-selected="false"
            aria-controls="deb-tab-start"
            id="deb-start"
            tabindex="-1">
      DEB
    </button>
    <button role="tab"
            aria-selected="false"
            aria-controls="rpm-tab-start"
            id="rpm-start"
            tabindex="-1">
      RPM
    </button>
  </div>
  <div tabindex="0"
       role="tabpanel"
       id="mac-tab-start"
       aria-labelledby="mac-start">
<div class="pre_wrapper lang-shell">
<pre class="programlisting prettyprint lang-shell">sudo launchctl load /Library/LaunchDaemons/co.elastic.elastic-agent.plist</pre>
</div>
  </div>
  <div tabindex="0"
       role="tabpanel"
       id="linux-tab-start"
       aria-labelledby="linux-start"
       hidden="">
<div class="pre_wrapper lang-shell">
<pre class="programlisting prettyprint lang-shell">sudo service elastic-agent start</pre>
</div>
  </div>
  <div tabindex="0"
       role="tabpanel"
       id="win-tab-start"
       aria-labelledby="win-start"
       hidden="">
<div class="pre_wrapper lang-shell">
<pre class="programlisting prettyprint lang-shell">Start-Service Elastic Agent</pre>
</div>
  </div>
  <div tabindex="0"
       role="tabpanel"
       id="deb-tab-start"
       aria-labelledby="deb-start"
       hidden="">
<p>The DEB package includes a service unit for Linux systems with systemd. On these
systems, you can manage Elastic Agent by using the usual systemd commands.</p>
<p>Use <code class="literal">systemctl</code> to start the agent:</p>
<div class="pre_wrapper lang-shell">
<pre class="programlisting prettyprint lang-shell">sudo systemctl start elastic-agent</pre>
</div>
<p>Otherwise, use:</p>
<div class="pre_wrapper lang-shell">
<pre class="programlisting prettyprint lang-shell">sudo service elastic-agent start</pre>
</div>
  </div>
  <div tabindex="0"
       role="tabpanel"
       id="rpm-tab-start"
       aria-labelledby="rpm-start"
       hidden="">
<p>The RPM package includes a service unit for Linux systems with systemd. On these
systems, you can manage Elastic Agent by using the usual systemd commands.</p>
<p>Use <code class="literal">systemctl</code> to start the agent:</p>
<div class="pre_wrapper lang-shell">
<pre class="programlisting prettyprint lang-shell">sudo systemctl start elastic-agent</pre>
</div>
<p>Otherwise, use:</p>
<div class="pre_wrapper lang-shell">
<pre class="programlisting prettyprint lang-shell">sudo service elastic-agent start</pre>
</div>
  </div>
</div>
<h3><a id="logs-stream-query-datastreams"></a>View and search your data<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/observability-docs/edit/8.9/docs/en/observability/logs-stream.asciidoc">edit</a></h3>
<p>With your Elastic Agent and data streams configured, you can now view, filter, and search your log data. In Kibana, navigate to <span class="strong strong"><strong>Observability → Logs → Stream</strong></span>, and use the search bar to search for your <code class="literal">data_stream.type</code> and <code class="literal">data_stream.dataset</code>.</p>
<p>See the following examples for ways to search specific data types and datasets:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">data_stream.type: logs</code> – shows <code class="literal">logs</code> data streams.
</li>
<li class="listitem">
<code class="literal">data_stream.dataset: nginx.access</code> – shows data streams with an <code class="literal">nginx.access</code> dataset.
</li>
</ul>
</div>
<p>This example shows the search results for logs with an <code class="literal">apm.error</code> dataset and a <code class="literal">default</code> namespace:</p>
<div class="imageblock screenshot">
<div class="content">
<img src="images/stream-logs-example.png" alt="example search query on the logs stream page in Kibana">
</div>
</div>
<h3><a id="logs-stream-troubleshooting"></a>Troubleshoot your Elastic Agent configuration<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/observability-docs/edit/8.9/docs/en/observability/logs-stream.asciidoc">edit</a></h3>
<p>If you&#8217;re not seeing your log files in Kibana, verify the following in the <code class="literal">elastic-agent.yml</code> file:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
The path to your logs file under <code class="literal">paths</code> is correct.
</li>
<li class="listitem">
Your API key is in <code class="literal">&lt;id&gt;:&lt;key&gt;</code> format. If not, your API key may be in an unsupported format, and you&#8217;ll need to create an API key in <span class="strong strong"><strong>Beats</strong></span> format.
</li>
</ul>
</div>
<p>If you&#8217;re still running into issues, see <a href="/guide/en/fleet/8.9/fleet-troubleshooting.html" class="ulink" target="_top">Elastic Agent troubleshooting</a> and <a href="/guide/en/fleet/8.9/elastic-agent-configuration.html" class="ulink" target="_top">Configure standalone Elastic Agents</a>.</p>
<h3><a id="logs-stream-enhance-logs"></a>Get the most out of your log data<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/observability-docs/edit/8.9/docs/en/observability/logs-stream.asciidoc">edit</a></h3>
<p>Make your logs more useful by extracting structured fields from your unstructured log data. Extracting structured fields makes it easier to search, analyze, and filter your log data.</p>
<p>Let&#8217;s look at this log example:</p>
<div class="pre_wrapper lang-log">
<pre class="programlisting prettyprint lang-log">2023-08-08T13:45:12.123Z WARN 192.168.1.101 Disk usage exceeds 90%.</pre>
</div>
<p>Add this log to Elasticsearch using the following command in <span class="strong strong"><strong>Dev Tools</strong></span>, found in your deployment in the left navigation under <span class="strong strong"><strong>Management</strong></span>:</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">POST logs-example-default/_doc
{
  "message": "2023-08-08T13:45:12.123Z WARN 192.168.1.101 Disk usage exceeds 90%."
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/1.console"></div>
<p>The previous command stores the document in <code class="literal">logs-example-default</code>. Retrieve it with the following search:</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">GET /logs-example-default/_search</pre>
</div>
<div class="console_widget" data-snippet="snippets/2.console"></div>
<p>You see something like this:</p>
<div class="pre_wrapper lang-JSON">
<pre class="programlisting prettyprint lang-JSON">{
  ...
  "hits": {
    ...
    "hits": [
      {
        "_index": ".ds-logs-example-default-2023.08.09-000001",
        ...
        "_source": {
          "message": "2023-08-08T13:45:12.123Z WARN 192.168.1.101 Disk usage exceeds 90%.",
          "@timestamp": "2023-08-09T17:19:27.73312243Z"
        }
      }
    ]
  }
}</pre>
</div>
<p>Elasticsearch indexes the <code class="literal">message</code> field by default meaning you can search for phrases like <code class="literal">WARN</code> or <code class="literal">Disk usage exceeds</code>. For example, the following command searches for the phrase <code class="literal">WARN</code> in the log <code class="literal">message</code> field:</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">GET logs-example-default/_search
{
  "query": {
    "match": {
      "message": {
        "query": "WARN"
      }
    }
  }
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/3.console"></div>
<p>While you can search for phrases in the <code class="literal">message</code> field, you can&#8217;t use this field to filter log data. Your message, however, contains all of the following potential fields you can extract and use to filter and aggregate your log data:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<span class="strong strong"><strong>@timestamp</strong></span> – <code class="literal">2023-08-08T13:45:12.123Z</code> – Extracting this field lets you sort logs by date and time. This is helpful when you want to view your logs in the order that they occurred or identify when issues happened.
</li>
<li class="listitem">
<span class="strong strong"><strong>log.level</strong></span> – <code class="literal">WARN</code> – Extracting this field lets you filter logs by severity. This is helpful if you want to focus on high-severity WARN or ERROR-level logs, and reduce noise by filtering out low-severity INFO-level logs.
</li>
<li class="listitem">
<span class="strong strong"><strong>host.ip</strong></span> – <code class="literal">192.168.1.101</code> – Extracting this field lets you filter logs by the host IP addresses. This is helpful if you want to focus on specific hosts that you’re having issues with or if you want to find disparities between hosts.
</li>
<li class="listitem">
<span class="strong strong"><strong>message</strong></span> – <code class="literal">Disk usage exceeds 90%.</code> – You can search for keywords in the message field.
</li>
</ul>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>These fields are part of the <a href="/guide/en/ecs/8.9/ecs-reference.html" class="ulink" target="_top">Elastic Common Schema (ECS)</a>. The ECS defines a common set of fields that you can use across Elasticsearch when storing data, including log and metric data.</p>
</div>
</div>
<h4><a id="logs-stream-extract-timestamp"></a>Extract the <code class="literal">@timestamp</code> field<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/observability-docs/edit/8.9/docs/en/observability/logs-stream.asciidoc">edit</a></h4>
<p>When you ingested the document in the previous section, you&#8217;ll notice the <code class="literal">@timestamp</code> field shows when you added the data to Elasticsearch, not when the log occurred:</p>
<div class="pre_wrapper lang-JSON">
<pre class="programlisting prettyprint lang-JSON">        ...
        "_source": {
          "message": "2023-08-08T13:45:12.123Z WARN 192.168.1.101 Disk usage exceeds 90%.",
          "@timestamp": "2023-08-09T17:19:27.73312243Z"
        }
        ...</pre>
</div>
<p>This section shows you how to extract the <code class="literal">@timestamp</code> field from the log message so you can filter by when the logs and issues actually occurred.</p>
<p>To extract the timestamp, you need to:</p>
<div class="olist orderedlist">
<ol class="orderedlist">
<li class="listitem">
<a class="xref" href="logs-stream.html#logs-stream-ingest-pipeline" title="Use an ingest pipeline to extract the @timestamp">Use an ingest pipeline to extract the <code class="literal">@timestamp</code></a>
</li>
<li class="listitem">
<a class="xref" href="logs-stream.html#logs-stream-simulate-api" title="Test your pipeline with the simulate pipeline API">Test your pipeline with the simulate pipeline API</a>
</li>
<li class="listitem">
<a class="xref" href="logs-stream.html#logs-stream-index-template" title="Configure your data stream with an index template">Configure your data stream with an index template</a>
</li>
<li class="listitem">
<a class="xref" href="logs-stream.html#logs-stream-create-data-stream" title="Create your data stream">Create your data stream</a>
</li>
</ol>
</div>
<h5><a id="logs-stream-ingest-pipeline"></a>Use an ingest pipeline to extract the <code class="literal">@timestamp</code><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/observability-docs/edit/8.9/docs/en/observability/logs-stream.asciidoc">edit</a></h5>
<p>Ingest pipelines consist of a series of processors that perform common transformations on incoming documents before they are indexed. To extract the <code class="literal">@timestamp</code> field from the example log, use an ingest pipeline with a dissect processor. The <a href="/guide/en/elasticsearch/reference/8.9/dissect-processor.html" class="ulink" target="_top">dissect processor</a> extracts structured fields from unstructured log messages based on a pattern you set.</p>
<p>Elasticsearch can parse string timestamps that are in <code class="literal">yyyy-MM-dd'T'HH:mm:ss.SSSZ</code> and <code class="literal">yyyy-MM-dd</code> formats into date fields. Since the log example&#8217;s timestamp is in one of these formats, you don&#8217;t need additional processors. More complex or nonstandard timestamps require a <a href="/guide/en/elasticsearch/reference/8.9/date-processor.html" class="ulink" target="_top">date processor</a> to parse the timestamp into a date field. Date processors can also set the timezone, change the target field, and change the output format of the timestamp.</p>
<p>In the following command, the dissect processor extracts the timestamp from the <code class="literal">message</code> field to the <code class="literal">@timestamp</code> field and leaves the rest of the message in the <code class="literal">message</code> field:</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">PUT _ingest/pipeline/logs-example-default
{
  "description": "Extracts the timestamp from log",
  "processors": [
    {
      "dissect": {
        "field": "message",
        "pattern": "%{@timestamp} %{message}"
      }
    }
  ]
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/4.console"></div>
<p>The previous command sets the following values for your ingest pipeline:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">_ingest/pipeline/logs-example-default</code> – The name of the pipeline,<code class="literal">logs-example-default</code>, needs to match the name of your data stream. You&#8217;ll set up your data stream in the next section. See the <a href="/guide/en/fleet/8.9/data-streams.html#data-streams-naming-scheme" class="ulink" target="_top">data stream naming scheme</a> for more information.
</li>
<li class="listitem">
<code class="literal">field</code> – The field you&#8217;re extracting data from, <code class="literal">message</code> in this case.
</li>
<li class="listitem">
<code class="literal">pattern</code>– The pattern of the elements in your log data. The following pattern extracts the timestamp, <code class="literal">2023-08-08T13:45:12.123Z</code>, to the <code class="literal">@timestamp</code> field, while the rest of the message, <code class="literal">WARN 192.168.1.101 Disk usage exceeds 90%.</code>, stays in the <code class="literal">message</code> field. The dissect processor looks for the space as a separator defined by the pattern <code class="literal">%{timestamp} %{message}</code>.
</li>
</ul>
</div>
<h5><a id="logs-stream-simulate-api"></a>Test your pipeline with the simulate pipeline API<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/observability-docs/edit/8.9/docs/en/observability/logs-stream.asciidoc">edit</a></h5>
<p>The <a href="/guide/en/elasticsearch/reference/8.9/simulate-pipeline-api.html#ingest-verbose-param" class="ulink" target="_top">simulate pipeline API</a> runs the ingest pipeline without storing any documents. This lets you verify your pipeline works using multiple documents. Run the following command to test your ingest pipeline with the simulate pipeline API.</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">POST _ingest/pipeline/logs-example-default/_simulate
{
  "docs": [
    {
      "_source": {
        "message": "2023-08-08T13:45:12.123Z WARN 192.168.1.101 Disk usage exceeds 90%."
      }
    }
  ]
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/5.console"></div>
<p>The results should show the <code class="literal">@timestamp</code> field extracted from the <code class="literal">message</code> field:</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">{
  "docs": [
    {
      "doc": {
        "_index": "_index",
        "_id": "_id",
        "_version": "-3",
        "_source": {
          "message": "WARN 192.168.1.101 Disk usage exceeds 90%.",
          "@timestamp": "2023-08-08T13:45:12.123Z"
        },
        ...
      }
    }
  ]
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/6.console"></div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>Make sure you&#8217;ve created the index pipeline using the <code class="literal">PUT</code> command in the previous section before using the simulate pipeline API.</p>
</div>
</div>
<h5><a id="logs-stream-index-template"></a>Configure your data stream with an index template<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/observability-docs/edit/8.9/docs/en/observability/logs-stream.asciidoc">edit</a></h5>
<p>After creating your ingest pipeline, create an index template to point your log data to your pipeline using this command:</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">PUT _index_template/logs-example-default-template
{
  "index_patterns": [ "logs-example-*" ],
  "data_stream": { },
  "priority": 500,
  "template": {
    "settings": {
      "index.default_pipeline":"logs-example-default"
    }
  },
  "composed_of": [
    "logs-mappings",
    "logs-settings",
    "logs@custom",
    "ecs@dynamic_templates"
  ],
  "ignore_missing_component_templates": ["logs@custom"]
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/7.console"></div>
<p>The previous command sets the following values for your index template:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">index_patterns</code>– The index pattern needs to match your log data stream. Naming conventions for data streams are <code class="literal">&lt;type&gt;-&lt;dataset&gt;-&lt;namespace&gt;</code>. In this example, your logs data stream is named <code class="literal">logs-example-default</code>. Data that matches this pattern will go through your pipeline.
</li>
<li class="listitem">
<code class="literal">data_stream</code> – Enables data streams.
</li>
<li class="listitem">
<code class="literal">priority</code> – Index templates with higher priority take precedence over lower priority. If a data stream matches multiple index templates, Elasticsearch uses the template with the higher priority. Built-in templates have a priority of <code class="literal">200</code>, so use a priority higher than <code class="literal">200</code> for custom templates.
</li>
<li class="listitem">
<code class="literal">index.default_pipeline</code> – The name of your ingest pipeline. <code class="literal">logs-example-default</code> in this case.
</li>
<li class="listitem">
<code class="literal">composed_of</code> – Here you can set component templates. Component templates are building blocks for constructing index templates that specify index mappings, settings, and aliases. Elastic has several built-in templates that help when ingesting your data.
</li>
</ul>
</div>
<p>The component templates that are set in the previous index template are defined as follows:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">logs-mappings</code> – general mappings for logs data streams that includes disabling automatic date detection from <code class="literal">string</code> fields and specifying mappings for <a href="/guide/en/ecs/8.9/ecs-data_stream.html" class="ulink" target="_top"><code class="literal">data_stream</code> ECS fields</a>.
</li>
<li class="listitem">
<p><code class="literal">logs-settings</code> – Sets the general settings for logs data streams including the default lifecycle policy and default pipeline:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
The default lifecycle policy rolls over when the primary shard reaches 50 GB or after 30 days.
</li>
<li class="listitem">
<p>The default pipeline:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
Sets a <code class="literal">@timestamp</code> if there isn&#8217;t one using the ingest timestamp.
</li>
<li class="listitem">
Places a hook for the <code class="literal">logs@custom</code> pipeline. If a <code class="literal">logs@custom</code> pipeline is installed, it&#8217;s applied to logs ingested into this data stream.
</li>
</ul>
</div>
</li>
<li class="listitem">
Sets the <a href="/guide/en/elasticsearch/reference/8.9/ignore-malformed.html" class="ulink" target="_top"><code class="literal">ignore_malformed</code></a> flag to <code class="literal">true</code>. If a field in the log document contains an incorrect value type and the field&#8217;s mapping type supports this flag, the document is still processed.
</li>
</ul>
</div>
</li>
<li class="listitem">
<code class="literal">logs@custom</code> – a predefined component template that is not installed by default. Use this name to install a custom component template if you wish to override or extend any of the default mappings or settings.
</li>
<li class="listitem">
<code class="literal">ecs@dynamic_templates</code> – dynamic templates that automatically ensure your data stream mappings comply with the <a href="/guide/en/ecs/8.9/ecs-reference.html" class="ulink" target="_top">Elastic Common Schema (ECS)</a>.
</li>
</ul>
</div>
<h5><a id="logs-stream-create-data-stream"></a>Create your data stream<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/observability-docs/edit/8.9/docs/en/observability/logs-stream.asciidoc">edit</a></h5>
<p>Create your data stream using the <a href="/guide/en/fleet/8.9/data-streams.html#data-streams-naming-scheme" class="ulink" target="_top">data stream naming scheme</a>. Since the name needs to match the name of your pipeline, name the data stream <code class="literal">logs-example-default</code>. Post the example log to your data stream with this command:</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">POST logs-example-default/_doc
{
  "message": "2023-08-08T13:45:12.123Z WARN 192.168.1.101 Disk usage exceeds 90%."
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/8.console"></div>
<p>View your documents using this command:</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">GET /logs-example-default/_search</pre>
</div>
<div class="console_widget" data-snippet="snippets/9.console"></div>
<p>You should see the pipeline has extracted the <code class="literal">@timestamp</code> field:</p>
<div class="pre_wrapper lang-JSON">
<pre class="programlisting prettyprint lang-JSON">{
...
{
  ...
  "hits": {
    ...
    "hits": [
      {
        "_index": ".ds-logs-example-default-2023.08.09-000001",
        "_id": "RsWy3IkB8yCtA5VGOKLf",
        "_score": 1,
        "_source": {
          "message": "WARN 192.168.1.101 Disk usage exceeds 90%.",
          "@timestamp": "2023-08-08T13:45:12.123Z"
        }
      }
    ]
  }
}</pre>
</div>
<p>You can now use the <code class="literal">@timestamp</code> field to sort your logs by the date and time they happened.</p>
<h5><a id="logs-stream-timestamp-troubleshooting"></a>Troubleshoot your <code class="literal">@timestamp</code> field<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/observability-docs/edit/8.9/docs/en/observability/logs-stream.asciidoc">edit</a></h5>
<p>Check the following common issues and solutions with timestamps:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<span class="strong strong"><strong>Timestamp failure</strong></span> – If your data has inconsistent date formats, set <code class="literal">ignore_failure</code> to <code class="literal">true</code> for your date processor. This processes logs with correctly formatted dates and ignores those with issues.
</li>
<li class="listitem">
<span class="strong strong"><strong>Incorrect timezone</strong></span> – Set your timezone using the <code class="literal">timezone</code> option on the <a href="/guide/en/elasticsearch/reference/8.9/date-processor.html" class="ulink" target="_top">date processor</a>.
</li>
<li class="listitem">
<span class="strong strong"><strong>Incorrect timestamp format</strong></span> – Your timestamp can be a Java time pattern or one of the following formats: ISO8601, UNIX, UNIX_MS, or TAI64N. See the <a href="/guide/en/elasticsearch/reference/8.9/mapping-date-format.html" class="ulink" target="_top">mapping date format</a> for more information on timestamp formats.
</li>
</ul>
</div>
<h4><a id="logs-stream-extract-log-level"></a>Extract the <code class="literal">log.level</code> field<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/observability-docs/edit/8.9/docs/en/observability/logs-stream.asciidoc">edit</a></h4>
<p>Extracting the <code class="literal">log.level</code> field lets you filter by severity and focus on critical issues. This section shows you how to extract the <code class="literal">log.level</code> field from this example log:</p>
<div class="pre_wrapper lang-log">
<pre class="programlisting prettyprint lang-log">2023-08-08T13:45:12.123Z WARN 192.168.1.101 Disk usage exceeds 90%.</pre>
</div>
<p>To extract and use the <code class="literal">log.level</code> field:</p>
<div class="olist orderedlist">
<ol class="orderedlist">
<li class="listitem">
<a class="xref" href="logs-stream.html#logs-stream-log-level-pipeline" title="Add log.level to your ingest pipeline">Add the <code class="literal">log.level</code> field to the dissect processor pattern in your ingest pipeline.</a>
</li>
<li class="listitem">
<a class="xref" href="logs-stream.html#logs-stream-log-level-simulate" title="Test the pipeline with the simulate API">Test the pipeline with the simulate API.</a>
</li>
<li class="listitem">
<a class="xref" href="logs-stream.html#logs-stream-log-level-query" title="Query logs based on log.level">Query your logs based on the <code class="literal">log.level</code> field.</a>
</li>
</ol>
</div>
<h5><a id="logs-stream-log-level-pipeline"></a>Add <code class="literal">log.level</code> to your ingest pipeline<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/observability-docs/edit/8.9/docs/en/observability/logs-stream.asciidoc">edit</a></h5>
<p>Add the <code class="literal">%{log.level}</code> option to the dissect processor pattern in the ingest pipeline you created in the <a class="xref" href="logs-stream.html#logs-stream-ingest-pipeline" title="Use an ingest pipeline to extract the @timestamp">Extract the <code class="literal">@timestamp</code> field</a> section:</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">PUT _ingest/pipeline/logs-example-default
{
  "description": "Extracts the timestamp from log",
  "processors": [
    {
      "dissect": {
        "field": "message",
        "pattern": "%{@timestamp} %{log.level} %{message}"
      }
    }
  ]
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/10.console"></div>
<p>Now your pipeline will extract these fields:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
The <code class="literal">@timestamp</code> field – <code class="literal">2023-08-08T13:45:12.123Z</code>
</li>
<li class="listitem">
The <code class="literal">log.level</code> field – <code class="literal">WARN</code>
</li>
<li class="listitem">
The <code class="literal">message</code> field – <code class="literal">192.168.1.101 Disk usage exceeds 90%.</code>
</li>
</ul>
</div>
<p>After creating your pipeline, an index template points your log data to your pipeline. Use the index template you created in the <a class="xref" href="logs-stream.html#logs-stream-index-template" title="Configure your data stream with an index template">Extract the <code class="literal">@timestamp</code> field</a> section.</p>
<h5><a id="logs-stream-log-level-simulate"></a>Test the pipeline with the simulate API<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/observability-docs/edit/8.9/docs/en/observability/logs-stream.asciidoc">edit</a></h5>
<p>Test that your ingest pipeline works as expected with the <a href="/guide/en/elasticsearch/reference/8.9/simulate-pipeline-api.html#ingest-verbose-param" class="ulink" target="_top">simulate pipeline API</a>:</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">POST _ingest/pipeline/logs-example-default/_simulate
{
  "docs": [
    {
      "_source": {
        "message": "2023-08-08T13:45:12.123Z WARN 192.168.1.101 Disk usage exceeds 90%."
      }
    }
  ]
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/11.console"></div>
<p>The results should show the <code class="literal">@timestamp</code> and the <code class="literal">log.level</code> fields extracted from the <code class="literal">message</code> field:</p>
<div class="pre_wrapper lang-JSON">
<pre class="programlisting prettyprint lang-JSON">{
  "docs": [
    {
      "doc": {
        "_index": "_index",
        "_id": "_id",
        "_version": "-3",
        "_source": {
          "message": "192.168.1.101 Disk usage exceeds 90%.",
          "log": {
            "level": "WARN"
          },
          "@timestamp": "2023-8-08T13:45:12.123Z",
        },
        ...
      }
    }
  ]
}</pre>
</div>
<h5><a id="logs-stream-log-level-query"></a>Query logs based on <code class="literal">log.level</code><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/observability-docs/edit/8.9/docs/en/observability/logs-stream.asciidoc">edit</a></h5>
<p>Once you&#8217;ve extracted the <code class="literal">log.level</code> field, you can query for high-severity logs like <code class="literal">WARN</code> and <code class="literal">ERROR</code>, which may need immediate attention, and filter out less critical <code class="literal">INFO</code> and <code class="literal">DEBUG</code> logs.</p>
<p>Let&#8217;s say you have the following logs with varying severities:</p>
<div class="pre_wrapper lang-log">
<pre class="programlisting prettyprint lang-log">2023-08-08T13:45:12.123Z WARN 192.168.1.101 Disk usage exceeds 90%.
2023-08-08T13:45:14.003Z ERROR 192.168.1.103 Database connection failed.
2023-08-08T13:45:15.004Z DEBUG 192.168.1.104 Debugging connection issue.
2023-08-08T13:45:16.005Z INFO 192.168.1.102 User changed profile picture.</pre>
</div>
<p>Add them to your data stream using this command:</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">POST logs-example-default/_bulk
{ "create": {} }
{ "message": "2023-08-08T13:45:12.123Z WARN 192.168.1.101 Disk usage exceeds 90%." }
{ "create": {} }
{ "message": "2023-08-08T13:45:14.003Z ERROR 192.168.1.103 Database connection failed." }
{ "create": {} }
{ "message": "2023-08-08T13:45:15.004Z DEBUG 192.168.1.104 Debugging connection issue." }
{ "create": {} }
{ "message": "2023-08-08T13:45:16.005Z INFO 192.168.1.102 User changed profile picture." }</pre>
</div>
<div class="console_widget" data-snippet="snippets/12.console"></div>
<p>Then, query for documents with a log level of <code class="literal">WARN</code> or <code class="literal">ERROR</code> with this command:</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">GET logs-example-default/_search
{
  "query": {
    "terms": {
      "log.level": ["WARN", "ERROR"]
    }
  }
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/13.console"></div>
<p>You should see the following results showing only your high-severity logs:</p>
<div class="pre_wrapper lang-JSON">
<pre class="programlisting prettyprint lang-JSON">{
...
  },
  "hits": {
  ...
    "hits": [
      {
        "_index": ".ds-logs-example-default-2023.08.14-000001",
        "_id": "3TcZ-4kB3FafvEVY4yKx",
        "_score": 1,
        "_source": {
          "message": "192.168.1.101 Disk usage exceeds 90%.",
          "log": {
            "level": "WARN"
          },
          "@timestamp": "2023-08-08T13:45:12.123Z"
        }
      },
      {
        "_index": ".ds-logs-example-default-2023.08.14-000001",
        "_id": "3jcZ-4kB3FafvEVY4yKx",
        "_score": 1,
        "_source": {
          "message": "192.168.1.103 Database connection failed.",
          "log": {
            "level": "ERROR"
          },
          "@timestamp": "2023-08-08T13:45:14.003Z"
        }
      }
    ]
  }
}</pre>
</div>
<h4><a id="logs-stream-extract-host-ip"></a>Extract the <code class="literal">host.ip</code> field<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/observability-docs/edit/8.9/docs/en/observability/logs-stream.asciidoc">edit</a></h4>
<p>Extracting the <code class="literal">host.ip</code> field lets you filter logs by host IP addresses allowing you to focus on specific hosts that you’re having issues with or find disparities between hosts.</p>
<p>The <code class="literal">host.ip</code> field is part of the <a href="/guide/en/ecs/8.9/ecs-reference.html" class="ulink" target="_top">Elastic Common Schema (ECS)</a>. Through the ECS, the <code class="literal">host.ip</code> field is mapped as an <a href="/guide/en/elasticsearch/reference/8.9/ip.html" class="ulink" target="_top"><code class="literal">ip</code> field type</a>. <code class="literal">ip</code> field types allow range queries so you can find logs with IP addresses in a specific range. You can also query <code class="literal">ip</code> field types using CIDR notation to find logs from a particular network or subnet.</p>
<p>This section shows you how to extract the <code class="literal">host.ip</code> field from the following example logs and query based on the extracted fields:</p>
<div class="pre_wrapper lang-log">
<pre class="programlisting prettyprint lang-log">2023-08-08T13:45:12.123Z WARN 192.168.1.101 Disk usage exceeds 90%.
2023-08-08T13:45:14.003Z ERROR 192.168.1.103 Database connection failed.
2023-08-08T13:45:15.004Z DEBUG 192.168.1.104 Debugging connection issue.
2023-08-08T13:45:16.005Z INFO 192.168.1.102 User changed profile picture.</pre>
</div>
<p>To extract and use the <code class="literal">host.ip</code> field:</p>
<div class="olist orderedlist">
<ol class="orderedlist">
<li class="listitem">
<a class="xref" href="logs-stream.html#logs-stream-host-ip-pipeline" title="Add host.ip to your ingest pipeline">Add the <code class="literal">host.ip</code> field to your dissect processor in your ingest pipeline.</a>
</li>
<li class="listitem">
<a class="xref" href="logs-stream.html#logs-stream-host-ip-simulate" title="Test the pipeline with the simulate API">Test the pipeline with the simulate API.</a>
</li>
<li class="listitem">
<a class="xref" href="logs-stream.html#logs-stream-host-ip-query" title="Query logs based on host.ip">Query your logs based on the <code class="literal">host.ip</code> field.</a>
</li>
</ol>
</div>
<h5><a id="logs-stream-host-ip-pipeline"></a>Add <code class="literal">host.ip</code> to your ingest pipeline<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/observability-docs/edit/8.9/docs/en/observability/logs-stream.asciidoc">edit</a></h5>
<p>Add the <code class="literal">%{host.ip}</code> option to the dissect processor pattern in the ingest pipeline you created in the <a class="xref" href="logs-stream.html#logs-stream-ingest-pipeline" title="Use an ingest pipeline to extract the @timestamp">Extract the <code class="literal">@timestamp</code> field</a> section:</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">PUT _ingest/pipeline/logs-example-default
{
  "description": "Extracts the timestamp from log",
  "processors": [
    {
      "dissect": {
        "field": "message",
        "pattern": "%{@timestamp} %{log.level} %{host.ip} %{message}"
      }
    }
  ]
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/14.console"></div>
<p>Your pipeline will extract these fields:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
The <code class="literal">@timestamp</code> field – <code class="literal">2023-08-08T13:45:12.123Z</code>
</li>
<li class="listitem">
The <code class="literal">log.level</code> field – <code class="literal">WARN</code>
</li>
<li class="listitem">
The <code class="literal">host.ip</code> field – <code class="literal">192.168.1.101</code>
</li>
<li class="listitem">
The <code class="literal">message</code> field – <code class="literal">Disk usage exceeds 90%.</code>
</li>
</ul>
</div>
<p>After creating your pipeline, an index template points your log data to your pipeline. Use the index template you created in the <a class="xref" href="logs-stream.html#logs-stream-index-template" title="Configure your data stream with an index template">Extract the <code class="literal">@timestamp</code> field</a> section.</p>
<h5><a id="logs-stream-host-ip-simulate"></a>Test the pipeline with the simulate API<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/observability-docs/edit/8.9/docs/en/observability/logs-stream.asciidoc">edit</a></h5>
<p>Test that your ingest pipeline works as expected with the <a href="/guide/en/elasticsearch/reference/8.9/simulate-pipeline-api.html#ingest-verbose-param" class="ulink" target="_top">simulate pipeline API</a>:</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">POST _ingest/pipeline/logs-example-default/_simulate
{
  "docs": [
    {
      "_source": {
        "message": "2023-08-08T13:45:12.123Z WARN 192.168.1.101 Disk usage exceeds 90%."
      }
    }
  ]
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/15.console"></div>
<p>The results should show the <code class="literal">host.ip</code>, <code class="literal">@timestamp</code>, and <code class="literal">log.level</code> fields extracted from the <code class="literal">message</code> field:</p>
<div class="pre_wrapper lang-JSON">
<pre class="programlisting prettyprint lang-JSON">{
  "docs": [
    {
      "doc": {
        ...
        "_source": {
          "host": {
            "ip": "192.168.1.101"
          },
          "@timestamp": "2023-08-08T13:45:12.123Z",
          "message": "Disk usage exceeds 90%.",
          "log": {
            "level": "WARN"
          }
        },
        ...
      }
    }
  ]
}</pre>
</div>
<h5><a id="logs-stream-host-ip-query"></a>Query logs based on <code class="literal">host.ip</code><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/observability-docs/edit/8.9/docs/en/observability/logs-stream.asciidoc">edit</a></h5>
<p>You can query your logs based on the <code class="literal">host.ip</code> field in different ways, including using CIDR notation and range queries.</p>
<p>Before querying your logs, add them to your data stream using this command:</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">POST logs-example-default/_bulk
{ "create": {} }
{ "message": "2023-08-08T13:45:12.123Z WARN 192.168.1.101 Disk usage exceeds 90%." }
{ "create": {} }
{ "message": "2023-08-08T13:45:14.003Z ERROR 192.168.1.103 Database connection failed." }
{ "create": {} }
{ "message": "2023-08-08T13:45:15.004Z DEBUG 192.168.1.104 Debugging connection issue." }
{ "create": {} }
{ "message": "2023-08-08T13:45:16.005Z INFO 192.168.1.102 User changed profile picture." }</pre>
</div>
<div class="console_widget" data-snippet="snippets/16.console"></div>
<h6><a id="logs-stream-ip-cidr"></a>CIDR notation<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/observability-docs/edit/8.9/docs/en/observability/logs-stream.asciidoc">edit</a></h6>
<p>You can use <a href="https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing#CIDR_notation" class="ulink" target="_top">CIDR notation</a> to query your log data using a block of IP addresses that fall within a certain network segment. CIDR notations uses the format of <code class="literal">[IP address]/[prefix length]</code>. The following command queries IP addresses in the <code class="literal">192.168.1.0/24</code> subnet meaning IP addresses from <code class="literal">192.168.1.0</code> to <code class="literal">192.168.1.255</code>.</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">GET logs-example-default/_search
{
  "query": {
    "term": {
      "host.ip": "192.168.1.0/24"
    }
  }
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/17.console"></div>
<p>Because all of the example logs are in this range, you&#8217;ll get the following results:</p>
<div class="pre_wrapper lang-JSON">
<pre class="programlisting prettyprint lang-JSON">{
  ...
  },
  "hits": {
    ...
      {
        "_index": ".ds-logs-example-default-2023.08.16-000001",
        "_id": "ak4oAIoBl7fe5ItIixuB",
        "_score": 1,
        "_source": {
          "host": {
            "ip": "192.168.1.101"
          },
          "@timestamp": "2023-08-08T13:45:12.123Z",
          "message": "Disk usage exceeds 90%.",
          "log": {
            "level": "WARN"
          }
        }
      },
      {
        "_index": ".ds-logs-example-default-2023.08.16-000001",
        "_id": "a04oAIoBl7fe5ItIixuC",
        "_score": 1,
        "_source": {
          "host": {
            "ip": "192.168.1.103"
          },
          "@timestamp": "2023-08-08T13:45:14.003Z",
          "message": "Database connection failed.",
          "log": {
            "level": "ERROR"
          }
        }
      },
      {
        "_index": ".ds-logs-example-default-2023.08.16-000001",
        "_id": "bE4oAIoBl7fe5ItIixuC",
        "_score": 1,
        "_source": {
          "host": {
            "ip": "192.168.1.104"
          },
          "@timestamp": "2023-08-08T13:45:15.004Z",
          "message": "Debugging connection issue.",
          "log": {
            "level": "DEBUG"
          }
        }
      },
      {
        "_index": ".ds-logs-example-default-2023.08.16-000001",
        "_id": "bU4oAIoBl7fe5ItIixuC",
        "_score": 1,
        "_source": {
          "host": {
            "ip": "192.168.1.102"
          },
          "@timestamp": "2023-08-08T13:45:16.005Z",
          "message": "User changed profile picture.",
          "log": {
            "level": "INFO"
          }
        }
      }
    ]
  }
}</pre>
</div>
<h6><a id="logs-stream-range-query"></a>Range queries<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/observability-docs/edit/8.9/docs/en/observability/logs-stream.asciidoc">edit</a></h6>
<p>Use <a href="/guide/en/elasticsearch/reference/8.9/query-dsl-range-query.html" class="ulink" target="_top">range queries</a> to query logs in a specific range.</p>
<p>The following command searches for IP addresses greater than or equal to <code class="literal">192.168.1.100</code> and less than or equal to <code class="literal">192.168.1.102</code>.</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">GET logs-example-default/_search
{
  "query": {
    "range": {
      "host.ip": {
        "gte": "192.168.1.100",
        "lte": "192.168.1.102"
      }
    }
  }
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/18.console"></div>
<p>You&#8217;ll get the following results matching the range you&#8217;ve set:</p>
<div class="pre_wrapper lang-JSON">
<pre class="programlisting prettyprint lang-JSON">{
  ...
  },
  "hits": {
    ...
      {
        "_index": ".ds-logs-example-default-2023.08.16-000001",
        "_id": "ak4oAIoBl7fe5ItIixuB",
        "_score": 1,
        "_source": {
          "host": {
            "ip": "192.168.1.101"
          },
          "@timestamp": "2023-08-08T13:45:12.123Z",
          "message": "Disk usage exceeds 90%.",
          "log": {
            "level": "WARN"
          }
        }
      },
      {
        "_index": ".ds-logs-example-default-2023.08.16-000001",
        "_id": "bU4oAIoBl7fe5ItIixuC",
        "_score": 1,
        "_source": {
          "host": {
            "ip": "192.168.1.102"
          },
          "@timestamp": "2023-08-08T13:45:16.005Z",
          "message": "User changed profile picture.",
          "log": {
            "level": "INFO"
          }
        }
      }
    ]
  }
}</pre>
</div>
<h5><a id="logs-stream-ip-ignore-malformed"></a>Ignore malformed IP addresses<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/observability-docs/edit/8.9/docs/en/observability/logs-stream.asciidoc">edit</a></h5>
<p>When you&#8217;re ingesting a large batch of log data, a single malformed IP address can cause the entire batch to fail. Prevent this by setting <code class="literal">ignore_malformed</code> to <code class="literal">true</code> for the <code class="literal">host.ip</code> field. Update the <code class="literal">host.ip</code> field to ignore malformed IPs using the <a href="/guide/en/elasticsearch/reference/8.9/indices-put-mapping.html" class="ulink" target="_top">update mapping API</a>:</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">PUT /logs-example-default/_mapping
{
  "properties": {
    "host.ip": {
      "type": "ip",
      "ignore_malformed": true
    }
  }
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/19.console"></div>
<h3><a id="logs-stream-reroute"></a>Reroute log data to specific data stream<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/observability-docs/edit/8.9/docs/en/observability/logs-stream.asciidoc">edit</a></h3>
<div class="warning admon">
<div class="icon"></div>
<div class="admon_content">
<p>This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.</p>
</div>
</div>
<p>By default, an ingest pipeline sends your log data to a single data stream. To simplify log data management, use a <a href="/guide/en/elasticsearch/reference/8.9/reroute-processor.html" class="ulink" target="_top">reroute processor</a> to route data from the generic data stream to a target data stream. For example, you might want to send high-severity logs to a specific data stream to help with categorization.</p>
<p>This section shows you how to use a reroute processor to send the high-severity logs (<code class="literal">WARN</code> or <code class="literal">ERROR</code>) from the following example logs to a specific data stream and keep the regular logs (<code class="literal">DEBUG</code> and <code class="literal">INFO</code>) in the default data stream:</p>
<div class="pre_wrapper lang-log">
<pre class="programlisting prettyprint lang-log">2023-08-08T13:45:12.123Z WARN 192.168.1.101 Disk usage exceeds 90%.
2023-08-08T13:45:14.003Z ERROR 192.168.1.103 Database connection failed.
2023-08-08T13:45:15.004Z DEBUG 192.168.1.104 Debugging connection issue.
2023-08-08T13:45:16.005Z INFO 192.168.1.102 User changed profile picture.</pre>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When routing data to different data streams, we recommend keeping the number of data streams relatively low to avoid oversharding. See <a href="/guide/en/elasticsearch/reference/8.9/size-your-shards.html" class="ulink" target="_top">Size your shards</a> for more information.</p>
</div>
</div>
<p>To use a reroute processor:</p>
<div class="olist orderedlist">
<ol class="orderedlist">
<li class="listitem">
<a class="xref" href="logs-stream.html#logs-stream-reroute-pipeline" title="Add a reroute processor to your ingest pipeline">Add a reroute processor to your ingest pipeline.</a>
</li>
<li class="listitem">
<a class="xref" href="logs-stream.html#logs-stream-reroute-add-logs" title="Add logs to your data stream">Add the example logs to your data stream.</a>
</li>
<li class="listitem">
<a class="xref" href="logs-stream.html#logs-stream-reroute-verify" title="Verify that the reroute processor worked">Query your logs and verify the high-severity logs were routed to the new data stream.</a>
</li>
</ol>
</div>
<h5><a id="logs-stream-reroute-pipeline"></a>Add a reroute processor to your ingest pipeline<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/observability-docs/edit/8.9/docs/en/observability/logs-stream.asciidoc">edit</a></h5>
<p>Add a reroute processor to your ingest pipeline with the following command:</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">PUT _ingest/pipeline/logs-example-default
{
  "description": "Extracts fields and reroutes WARN",
  "processors": [
    {
      "dissect": {
        "field": "message",
        "pattern": "%{@timestamp} %{log.level} %{host.ip} %{message}"
      },
      "reroute": {
        "tag": "high_severity_logs",
        "if" : "ctx.log?.level == 'WARN' || ctx.log?.level == 'ERROR'",
        "dataset": "critical"
      }
    }
  ]
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/20.console"></div>
<p>The previous command sets the following values for your reroute processor:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">tag</code> – Identifier for the processor that you can use for debugging and metrics. In the example, the tag is set to <code class="literal">high_severity_logs</code>.
</li>
<li class="listitem">
<code class="literal">if</code> – Conditionally runs the processor. In the example, <code class="literal">"ctx.log?.level == 'WARN' || ctx.log?.level == 'ERROR'",</code> means the processor runs when the <code class="literal">log.level</code> field is <code class="literal">WARN</code> or <code class="literal">ERROR</code>.
</li>
<li class="listitem">
<code class="literal">dataset</code> – the data stream dataset to route your document to if the previous condition is <code class="literal">true</code>. In the example, logs with a <code class="literal">log.level</code> of <code class="literal">WARN</code> or <code class="literal">ERROR</code> are routed to the <code class="literal">logs-critical-default</code> data stream.
</li>
</ul>
</div>
<p>After creating your pipeline, an index template points your log data to your pipeline. Use the index template you created in the <a class="xref" href="logs-stream.html#logs-stream-index-template" title="Configure your data stream with an index template">Extract the <code class="literal">@timestamp</code> field</a> section.</p>
<h5><a id="logs-stream-reroute-add-logs"></a>Add logs to your data stream<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/observability-docs/edit/8.9/docs/en/observability/logs-stream.asciidoc">edit</a></h5>
<p>Add the example logs to your data stream with this command:</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">POST logs-example-default/_bulk
{ "create": {} }
{ "message": "2023-08-08T13:45:12.123Z WARN 192.168.1.101 Disk usage exceeds 90%." }
{ "create": {} }
{ "message": "2023-08-08T13:45:14.003Z ERROR 192.168.1.103 Database connection failed." }
{ "create": {} }
{ "message": "2023-08-08T13:45:15.004Z DEBUG 192.168.1.104 Debugging connection issue." }
{ "create": {} }
{ "message": "2023-08-08T13:45:16.005Z INFO 192.168.1.102 User changed profile picture." }</pre>
</div>
<div class="console_widget" data-snippet="snippets/21.console"></div>
<h5><a id="logs-stream-reroute-verify"></a>Verify that the reroute processor worked<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/observability-docs/edit/8.9/docs/en/observability/logs-stream.asciidoc">edit</a></h5>
<p>The reroute processor should route any logs with a <code class="literal">log.level</code> of <code class="literal">WARN</code> or <code class="literal">ERROR</code> to the <code class="literal">logs-critical-default</code> data stream. Query the the data stream using the following command to verify the log data was routed as intended:</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">GET log-critical-default/_search</pre>
</div>
<div class="console_widget" data-snippet="snippets/22.console"></div>
<p>Your query should return similar results to the following:</p>
<div class="pre_wrapper lang-JSON">
<pre class="programlisting prettyprint lang-JSON">{
  ...
  "hits": {
    ...
    "hits": [
        ...
        "_source": {
          "host": {
            "ip": "192.168.1.101"
          },
          "@timestamp": "2023-08-08T13:45:12.123Z",
          "message": "Disk usage exceeds 90%.",
          "log": {
            "level": "WARN"
          },
          "data_stream": {
            "namespace": "default",
            "type": "logs",
            "dataset": "critical"
          },
          {
        ...
        "_source": {
          "host": {
            "ip": "192.168.1.103"
           },
          "@timestamp": "2023-08-08T13:45:14.003Z",
          "message": "Database connection failed.",
          "log": {
            "level": "ERROR"
          },
          "data_stream": {
            "namespace": "default",
            "type": "logs",
            "dataset": "critical"
          }
        }
      }
    ]
  }
}</pre>
</div>
<p>You can see the high-severity logs and that they&#8217;re now in the <code class="literal">critical</code> dataset.</p>
</div>
<div class="navfooter">
<span class="prev">
<a href="logs-checklist.html">« Logs resource guide</a>
</span>
<span class="next">
<a href="monitor-logs.html">Log monitoring »</a>
</span>
</div>
</div>
</body>
</html>
