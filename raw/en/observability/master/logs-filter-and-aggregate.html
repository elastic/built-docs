<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Filter and aggregate logs | Elastic Observability [master] | Elastic</title>
<meta class="elastic" name="content" content="Filter and aggregate logs | Elastic Observability [master]">

<link rel="home" href="index.html" title="Elastic Observability [master]"/>
<link rel="up" href="logs-checklist.html" title="Log monitoring"/>
<link rel="prev" href="logs-parse.html" title="Parse and organize logs"/>
<link rel="next" href="application-logs.html" title="Stream application logs"/>
<meta class="elastic" name="product_version" content="master"/>
<meta class="elastic" name="product_name" content="Observability"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/Observability/Guide/master"/>
<meta name="DC.subject" content="Observability"/>
<meta name="DC.identifier" content="master"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body>
<div class="page_header">
This documentation contains work-in-progress information for future Elastic Stack and Cloud releases. Use the version selector to view supported release docs. It also contains some Elastic Cloud serverless information. Check out our <a href="https://www.elastic.co/docs/current/serverless">serverless docs</a> for more details.
</div>
<div class="navheader">
<span class="prev">
<a href="logs-parse.html">« Parse and organize logs</a>
</span>
<span class="next">
<a href="application-logs.html">Stream application logs »</a>
</span>
</div>
<div class="book" lang="en">
<div class="titlepage">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Elastic Observability [master]</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="logs-checklist.html">Log monitoring</a></span>
</div>
<div>
<div><h1 class="title"><a id="id-1"></a>Filter and aggregate logs</h1><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/observability-docs/edit/main/docs/en/observability/logs-filter.asciidoc">edit</a></div>
</div>
<!--EXTRA-->
</div>
<div id="content">
<div class="section">
<div class="titlepage"><div><div>
<h2 class="title"><a id="logs-filter-and-aggregate"></a>Filter and aggregate logs<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/observability-docs/edit/main/docs/en/observability/logs-filter.asciidoc">edit</a></h2>
</div></div></div>
<p>Filter and aggregate your log data to find specific information, gain insight, and monitor your systems more efficiently. You can filter and aggregate based on structured fields like timestamps, log levels, and IP addresses that you&#8217;ve extracted from your log data.</p>
<p>This guide shows you how to:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<a class="xref" href="logs-filter-and-aggregate.html#logs-filter" title="Filter logs">Filter logs</a> — Narrow down your log data by applying specific criteria.
</li>
<li class="listitem">
<a class="xref" href="logs-filter-and-aggregate.html#logs-aggregate" title="Aggregate logs">Aggregate logs</a> — Analyze and summarize data to find patterns and gain insight.
</li>
</ul>
</div>
<h4><a id="logs-filter-and-aggregate-prereq"></a>Before you get started<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/observability-docs/edit/main/docs/en/observability/logs-filter.asciidoc">edit</a></h4>
<p>The examples on this page use the following ingest pipeline and index template, which you can set in <span class="strong strong"><strong>Dev Tools</strong></span>. If you haven&#8217;t used ingest pipelines and index templates to parse your log data and extract structured fields yet, start with the <a class="xref" href="logs-parse.html" title="Parse and organize logs">Parse and organize logs</a> documentation.</p>
<p>Set the ingest pipeline with the following command:</p>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">PUT _ingest/pipeline/logs-example-default
{
  "description": "Extracts the timestamp log level and host ip",
  "processors": [
    {
      "dissect": {
        "field": "message",
        "pattern": "%{@timestamp} %{log.level} %{host.ip} %{message}"
      }
    }
  ]
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/50.console"></div>
<p>Set the index template with the following command:</p>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">PUT _index_template/logs-example-default-template
{
  "index_patterns": [ "logs-example-*" ],
  "data_stream": { },
  "priority": 500,
  "template": {
    "settings": {
      "index.default_pipeline":"logs-example-default"
    }
  },
  "composed_of": [
    "logs-mappings",
    "logs-settings",
    "logs@custom",
    "ecs@dynamic_templates"
  ],
  "ignore_missing_component_templates": ["logs@custom"]
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/51.console"></div>
<h4><a id="logs-filter"></a>Filter logs<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/observability-docs/edit/main/docs/en/observability/logs-filter.asciidoc">edit</a></h4>
<p>Filter your data using the fields you&#8217;ve extracted so you can focus on log data with specific log levels, timestamp ranges, or host IPs. You can filter your log data in different ways:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<a class="xref" href="logs-filter-and-aggregate.html#logs-filter-logs-explorer" title="Filter logs in Log Explorer">Filter logs in Log Explorer</a> – Filter and visualize log data in Kibana using Log Explorer.
</li>
<li class="listitem">
<a class="xref" href="logs-filter-and-aggregate.html#logs-filter-qdsl" title="Filter logs with Query DSL">Filter logs with Query DSL</a> – Filter log data from Dev Tools using Query DSL.
</li>
</ul>
</div>
<h5><a id="logs-filter-logs-explorer"></a>Filter logs in Log Explorer<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/observability-docs/edit/main/docs/en/observability/logs-filter.asciidoc">edit</a></h5>
<p>Log Explorer is a Kibana tool that automatically provides views of your log data based on integrations and data streams. You can find Log Explorer in the Observability menu under <span class="strong strong"><strong>Logs</strong></span>.</p>
<p>From Log Explorer, you can use the <a href="/guide/en/kibana/master/kuery-query.html" class="ulink" target="_top">Kibana Query Language (KQL)</a> in the search bar to narrow down the log data displayed in Log Explorer.
For example, you might want to look into an event that occurred within a specific time range.</p>
<p>Add some logs with varying timestamps and log levels to your data stream:</p>
<div class="olist orderedlist">
<ol class="orderedlist">
<li class="listitem">
In Kibana, go to <span class="strong strong"><strong>Management</strong></span> &#8594; <span class="strong strong"><strong>Dev Tools</strong></span>.
</li>
<li class="listitem">
In the <span class="strong strong"><strong>Console</strong></span> tab, run the following command:
</li>
</ol>
</div>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">POST logs-example-default/_bulk
{ "create": {} }
{ "message": "2023-09-15T08:15:20.234Z WARN 192.168.1.101 Disk usage exceeds 90%." }
{ "create": {} }
{ "message": "2023-09-14T10:30:45.789Z ERROR 192.168.1.102 Critical system failure detected." }
{ "create": {} }
{ "message": "2023-09-10T14:20:45.789Z ERROR 192.168.1.105 Database connection lost." }
{ "create": {} }
{ "message": "2023-09-20T09:40:32.345Z INFO 192.168.1.106 User logout initiated." }</pre>
</div>
<div class="console_widget" data-snippet="snippets/52.console"></div>
<p>For this example, let&#8217;s look for logs with a <code class="literal">WARN</code> or <code class="literal">ERROR</code> log level that occurred on September 14th or 15th. From Log Explorer:</p>
<div class="olist orderedlist">
<ol class="orderedlist">
<li class="listitem">
<p>Add the following KQL query in the search bar to filter for logs with log levels of <code class="literal">WARN</code> or <code class="literal">ERROR</code>:</p>
<div class="pre_wrapper lang-text">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-text">log.level: ("ERROR" or "WARN")</pre>
</div>
</li>
<li class="listitem">
<p>Click the current time range, select <span class="strong strong"><strong>Absolute</strong></span>, and set the <span class="strong strong"><strong>Start date</strong></span> to <code class="literal">Sep 14, 2023 @ 00:00:00.000</code>.</p>
<div class="imageblock screenshot">
<div class="content">
<img src="images/logs-start-date.png" alt="Set the start date for your time range" width="50%">
</div>
</div>
</li>
<li class="listitem">
<p>Click the end of the current time range, select <span class="strong strong"><strong>Absolute</strong></span>, and set the <span class="strong strong"><strong>End date</strong></span> to <code class="literal">Sep 15, 2023 @ 23:59:59.999</code>.</p>
<div class="imageblock screenshot">
<div class="content">
<img src="images/logs-end-date.png" alt="Set the end date for your time range" width="50%">
</div>
</div>
</li>
</ol>
</div>
<p>Under the <span class="strong strong"><strong>Documents</strong></span> tab, you&#8217;ll see the filtered log data matching your query.</p>
<div class="imageblock screenshot">
<div class="content">
<img src="images/logs-kql-filter.png" alt="Filter data by log level using KQL">
</div>
</div>
<p>For more on using Log Explorer, refer to the <a href="/guide/en/kibana/master/discover.html" class="ulink" target="_top">Discover</a> documentation.</p>
<h5><a id="logs-filter-qdsl"></a>Filter logs with Query DSL<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/observability-docs/edit/main/docs/en/observability/logs-filter.asciidoc">edit</a></h5>
<p><a href="/guide/en/elasticsearch/reference/master/query-dsl.html" class="ulink" target="_top">Query DSL</a> is a JSON-based language that sends requests and retrieves data from indices and data streams. You can filter your log data using Query DSL from <span class="strong strong"><strong>Developer Tools</strong></span>.</p>
<p>For example, you might want to troubleshoot an issue that happened on a specific date or at a specific time. To do this, use a boolean query with a <a href="/guide/en/elasticsearch/reference/master/query-dsl-range-query.html" class="ulink" target="_top">range query</a> to filter for the specific timestamp range and a <a href="/guide/en/elasticsearch/reference/master/query-dsl-term-query.html" class="ulink" target="_top">term query</a> to filter for <code class="literal">WARN</code> and <code class="literal">ERROR</code> log levels.</p>
<p>First, from <span class="strong strong"><strong>Dev Tools</strong></span>, add some logs with varying timestamps and log levels to your data stream with the following command:</p>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">POST logs-example-default/_bulk
{ "create": {} }
{ "message": "2023-09-15T08:15:20.234Z WARN 192.168.1.101 Disk usage exceeds 90%." }
{ "create": {} }
{ "message": "2023-09-14T10:30:45.789Z ERROR 192.168.1.102 Critical system failure detected." }
{ "create": {} }
{ "message": "2023-09-10T14:20:45.789Z ERROR 192.168.1.105 Database connection lost." }
{ "create": {} }
{ "message": "2023-09-20T09:40:32.345Z INFO 192.168.1.106 User logout initiated." }</pre>
</div>
<div class="console_widget" data-snippet="snippets/53.console"></div>
<p>Let&#8217;s say you want to look into an event that occurred between September 14th and 15th. The following boolean query filters for logs with timestamps during those days that also have a log level of <code class="literal">ERROR</code> or <code class="literal">WARN</code>.</p>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">POST /logs-example-default/_search
{
  "query": {
    "bool": {
      "filter": [
        {
          "range": {
            "@timestamp": {
              "gte": "2023-09-14T00:00:00",
              "lte": "2023-09-15T23:59:59"
            }
          }
        },
        {
          "terms": {
            "log.level": ["WARN", "ERROR"]
          }
        }
      ]
    }
  }
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/54.console"></div>
<p>The filtered results should show <code class="literal">WARN</code> and <code class="literal">ERROR</code> logs that occurred within the timestamp range:</p>
<div class="pre_wrapper lang-JSON">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-JSON">{
  ...
  "hits": {
    ...
    "hits": [
      {
        "_index": ".ds-logs-example-default-2023.09.25-000001",
        "_id": "JkwPzooBTddK4OtTQToP",
        "_score": 0,
        "_source": {
          "message": "192.168.1.101 Disk usage exceeds 90%.",
          "log": {
            "level": "WARN"
          },
          "@timestamp": "2023-09-15T08:15:20.234Z"
        }
      },
      {
        "_index": ".ds-logs-example-default-2023.09.25-000001",
        "_id": "A5YSzooBMYFrNGNwH75O",
        "_score": 0,
        "_source": {
          "message": "192.168.1.102 Critical system failure detected.",
          "log": {
            "level": "ERROR"
          },
          "@timestamp": "2023-09-14T10:30:45.789Z"
        }
      }
    ]
  }
}</pre>
</div>
<h4><a id="logs-aggregate"></a>Aggregate logs<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/observability-docs/edit/main/docs/en/observability/logs-filter.asciidoc">edit</a></h4>
<p>Use aggregation to analyze and summarize your log data to find patterns and gain insight. <a href="/guide/en/elasticsearch/reference/master/search-aggregations-bucket.html" class="ulink" target="_top">Bucket aggregations</a> organize log data into meaningful groups making it easier to identify patterns, trends, and anomalies within your logs.</p>
<p>For example, you might want to understand error distribution by analyzing the count of logs per log level.</p>
<p>First, from <span class="strong strong"><strong>Dev Tools</strong></span>, add some logs with varying log levels to your data stream using the following command:</p>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">POST logs-example-default/_bulk
{ "create": {} }
{ "message": "2023-09-15T08:15:20.234Z WARN 192.168.1.101 Disk usage exceeds 90%." }
{ "create": {} }
{ "message": "2023-09-14T10:30:45.789Z ERROR 192.168.1.102 Critical system failure detected." }
{ "create": {} }
{ "message": "2023-09-15T12:45:55.123Z INFO 192.168.1.103 Application successfully started." }
{ "create": {} }
{ "message": "2023-09-14T15:20:10.789Z WARN 192.168.1.104 Network latency exceeding threshold." }
{ "create": {} }
{ "message": "2023-09-10T14:20:45.789Z ERROR 192.168.1.105 Database connection lost." }
{ "create": {} }
{ "message": "2023-09-20T09:40:32.345Z INFO 192.168.1.106 User logout initiated." }
{ "create": {} }
{ "message": "2023-09-21T15:20:55.678Z DEBUG 192.168.1.102 Database connection established." }</pre>
</div>
<div class="console_widget" data-snippet="snippets/55.console"></div>
<p>Next, run this command to aggregate your log data using the <code class="literal">log.level</code> field:</p>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">POST logs-example-default/_search?size=0&amp;filter_path=aggregations
{
"size": 0,<a id="CO79-1"></a><i class="conum" data-value="1"></i>
"aggs": {
    "log_level_distribution": {
      "terms": {
        "field": "log.level"
      }
    }
  }
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/56.console"></div>
<div class="calloutlist">
<table border="0" summary="Callout list">
<tr>
<td align="left" valign="top" width="5%">
<p><a href="#CO79-1"><i class="conum" data-value="1"></i></a></p>
</td>
<td align="left" valign="top">
<p>Searches with an aggregation return both the query results and the aggregation, so you would see the logs matching the data and the aggregation. Setting <code class="literal">size</code> to <code class="literal">0</code> limits the results to aggregations.</p>
</td>
</tr>
</table>
</div>
<p>The results should show the number of logs in each log level:</p>
<div class="pre_wrapper lang-JSON">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-JSON">{
  "aggregations": {
    "error_distribution": {
      "doc_count_error_upper_bound": 0,
      "sum_other_doc_count": 0,
      "buckets": [
        {
          "key": "ERROR",
          "doc_count": 2
        },
        {
          "key": "INFO",
          "doc_count": 2
        },
        {
          "key": "WARN",
          "doc_count": 2
        },
        {
          "key": "DEBUG",
          "doc_count": 1
        }
      ]
    }
  }
}</pre>
</div>
<p>You can also combine aggregations and queries. For example, you might want to limit the scope of the previous aggregation by adding a range query:</p>
<div class="pre_wrapper lang-console">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-console">GET /logs-example-default/_search
{
  "size": 0,
  "query": {
    "range": {
      "@timestamp": {
        "gte": "2023-09-14T00:00:00",
        "lte": "2023-09-15T23:59:59"
      }
    }
  },
  "aggs": {
    "my-agg-name": {
      "terms": {
        "field": "log.level"
      }
    }
  }
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/57.console"></div>
<p>The results should show an aggregate of logs that occurred within your timestamp range:</p>
<div class="pre_wrapper lang-JSON">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-JSON">{
  ...
  "hits": {
    ...
    "hits": []
  },
  "aggregations": {
    "my-agg-name": {
      "doc_count_error_upper_bound": 0,
      "sum_other_doc_count": 0,
      "buckets": [
        {
          "key": "WARN",
          "doc_count": 2
        },
        {
          "key": "ERROR",
          "doc_count": 1
        },
        {
          "key": "INFO",
          "doc_count": 1
        }
      ]
    }
  }
}</pre>
</div>
<p>For more on aggregation types and available aggregations, refer to the <a href="/guide/en/elasticsearch/reference/master/search-aggregations.html" class="ulink" target="_top">Aggregations</a> documentation.</p>
</div>
</div>
</div><div class="navfooter">
<span class="prev">
<a href="logs-parse.html">« Parse and organize logs</a>
</span>
<span class="next">
<a href="application-logs.html">Stream application logs »</a>
</span>
</div>
</body>
</html>
