<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Machine Learning Detected a Suspicious Windows Event with a High Malicious Probability Score | Elastic Security Solution [8.16] | Elastic</title>
<meta class="elastic" name="content" content="Machine Learning Detected a Suspicious Windows Event with a High Malicious Probability Score | Elastic Security Solution [8.16]">

<link rel="home" href="index.html" title="Elastic Security Solution [8.16]"/>
<link rel="up" href="prebuilt-rule-8-16-6-prebuilt-rules-8-16-6-appendix.html" title="Appendix Y: Downloadable rule update v8.16.6"/>
<link rel="prev" href="prebuilt-rule-8-16-6-unusual-process-spawned-by-a-user.html" title="Unusual Process Spawned by a User"/>
<link rel="next" href="prebuilt-rule-8-16-6-machine-learning-detected-a-suspicious-windows-event-with-a-low-malicious-probability-score.html" title="Machine Learning Detected a Suspicious Windows Event with a Low Malicious Probability Score"/>
<meta class="elastic" name="product_version" content="8.16"/>
<meta class="elastic" name="product_name" content="Security"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/Security/Guide/8.16"/>
<meta name="DC.subject" content="Security"/>
<meta name="DC.identifier" content="8.16"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body>
<div class="page_header">
<strong>IMPORTANT</strong>: No additional bug fixes or documentation updates
will be released for this version. For the latest information, see the
<a href="../current/index.html">current release documentation</a>.
</div>
<div class="navheader">
<span class="prev">
<a href="prebuilt-rule-8-16-6-unusual-process-spawned-by-a-user.html">« Unusual Process Spawned by a User</a>
</span>
<span class="next">
<a href="prebuilt-rule-8-16-6-machine-learning-detected-a-suspicious-windows-event-with-a-low-malicious-probability-score.html">Machine Learning Detected a Suspicious Windows Event with a Low Malicious Probability Score »</a>
</span>
</div>
<div class="book" lang="en">
<div class="titlepage">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Elastic Security Solution [8.16]</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="prebuilt-rule-8-16-6-prebuilt-rules-8-16-6-appendix.html">Downloadable rule update v8.16.6</a></span>
</div>
<div>
<div><h1 class="title"><a id="id-1"></a>Machine Learning Detected a Suspicious Windows Event with a High Malicious Probability Score</h1><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/security-docs/edit/8.16/docs/detections/prebuilt-rules/downloadable-packages/8-16-6/prebuilt-rule-8-16-6-machine-learning-detected-a-suspicious-windows-event-with-a-high-malicious-probability-score.asciidoc">edit</a></div>
</div>
<!--EXTRA-->
</div>
<div id="content">
<div id="url-to-v3" class="version-warning">
    <strong>IMPORTANT</strong>: This documentation is no longer updated. Refer to <a href="https://www.elastic.co/support/eol">Elastic's version policy</a> and the <a href="https://www.elastic.co/docs">latest documentation</a>.
</div>
<div class="section">
<div class="titlepage"><div><div>
<div class="position-relative"><h2 class="title"><a id="prebuilt-rule-8-16-6-machine-learning-detected-a-suspicious-windows-event-with-a-high-malicious-probability-score"></a>Machine Learning Detected a Suspicious Windows Event with a High Malicious Probability Score</h2><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/security-docs/edit/8.16/docs/detections/prebuilt-rules/downloadable-packages/8-16-6/prebuilt-rule-8-16-6-machine-learning-detected-a-suspicious-windows-event-with-a-high-malicious-probability-score.asciidoc">edit</a></div>
</div></div></div>
<p>A supervised machine learning model (ProblemChild) has identified a suspicious Windows process event with high probability of it being malicious activity. Alternatively, the model&#8217;s blocklist identified the event as being malicious.</p>
<p><span class="strong strong"><strong>Rule type</strong></span>: eql</p>
<p><span class="strong strong"><strong>Rule indices</strong></span>:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
endgame-*
</li>
<li class="listitem">
logs-endpoint.events.process-*
</li>
<li class="listitem">
winlogbeat-*
</li>
</ul>
</div>
<p><span class="strong strong"><strong>Severity</strong></span>: high</p>
<p><span class="strong strong"><strong>Risk score</strong></span>: 73</p>
<p><span class="strong strong"><strong>Runs every</strong></span>: 5m</p>
<p><span class="strong strong"><strong>Searches indices from</strong></span>: now-10m (<a href="/guide/en/elasticsearch/reference/8.16/common-options.html#date-math" class="ulink" target="_top">Date Math format</a>, see also <a class="xref" href="rules-ui-create.html#rule-schedule" title="Set the rule&#8217;s schedule"><code class="literal">Additional look-back time</code></a>)</p>
<p><span class="strong strong"><strong>Maximum alerts per execution</strong></span>: 100</p>
<p><span class="strong strong"><strong>References</strong></span>:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<a href="/guide/en/security/current/prebuilt-ml-jobs.html" class="ulink" target="_top">https://www.elastic.co/guide/en/security/current/prebuilt-ml-jobs.html</a>
</li>
<li class="listitem">
<a href="https://docs.elastic.co/en/integrations/problemchild" class="ulink" target="_top">https://docs.elastic.co/en/integrations/problemchild</a>
</li>
<li class="listitem">
<a href="/security-labs/detecting-living-off-the-land-attacks-with-new-elastic-integration" class="ulink" target="_top">https://www.elastic.co/security-labs/detecting-living-off-the-land-attacks-with-new-elastic-integration</a>
</li>
</ul>
</div>
<p><span class="strong strong"><strong>Tags</strong></span>:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
OS: Windows
</li>
<li class="listitem">
Data Source: Elastic Endgame
</li>
<li class="listitem">
Use Case: Living off the Land Attack Detection
</li>
<li class="listitem">
Rule Type: ML
</li>
<li class="listitem">
Rule Type: Machine Learning
</li>
<li class="listitem">
Tactic: Defense Evasion
</li>
<li class="listitem">
Data Source: Elastic Defend
</li>
<li class="listitem">
Resources: Investigation Guide
</li>
</ul>
</div>
<p><span class="strong strong"><strong>Version</strong></span>: 111</p>
<p><span class="strong strong"><strong>Rule authors</strong></span>:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
Elastic
</li>
</ul>
</div>
<p><span class="strong strong"><strong>Rule license</strong></span>: Elastic License v2</p>
<div class="section">
<div class="titlepage"><div><div>
<div class="position-relative"><h3 class="title"><a id="_investigation_guide_4422"></a>Investigation guide</h3><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/security-docs/edit/8.16/docs/detections/prebuilt-rules/downloadable-packages/8-16-6/prebuilt-rule-8-16-6-machine-learning-detected-a-suspicious-windows-event-with-a-high-malicious-probability-score.asciidoc">edit</a></div>
</div></div></div>
<p><span class="strong strong"><strong>Triage and analysis</strong></span></p>
<div class="quoteblock">
<blockquote>
<p><span class="strong strong"><strong>Disclaimer</strong></span>:
This investigation guide was created using generative AI technology and has been reviewed to improve its accuracy and relevance. While every effort has been made to ensure its quality, we recommend validating the content and adapting it to suit your specific environment and operational needs.</p>
</blockquote>
</div>
<p><span class="strong strong"><strong>Investigating Machine Learning Detected a Suspicious Windows Event with a High Malicious Probability Score</strong></span></p>
<p>The detection leverages a machine learning model, ProblemChild, to identify potentially malicious Windows processes by analyzing patterns and assigning a high probability score to suspicious activities. Adversaries may exploit legitimate processes to evade detection, often using techniques like masquerading. This rule flags high-risk events by focusing on processes with a high malicious probability score or those identified by a blocklist, excluding known benign activities.</p>
<p><span class="strong strong"><strong>Possible investigation steps</strong></span></p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
Review the process details flagged by the ProblemChild model, focusing on those with a prediction probability greater than 0.98 or identified by the blocklist.
</li>
<li class="listitem">
Examine the command-line arguments of the suspicious process to identify any unusual or unexpected patterns, excluding those matching known benign patterns like "<span class="strong strong"><strong>C:\WINDOWS\temp\nessus_</strong></span>.txt*" or "<span class="strong strong"><strong>C:\WINDOWS\temp\nessus_</strong></span>.tmp*".
</li>
<li class="listitem">
Check the parent process of the flagged event to determine if it is a legitimate process or if it has been potentially compromised.
</li>
<li class="listitem">
Investigate the user account associated with the process to assess if it has been involved in any other suspicious activities or if it has elevated privileges that could be exploited.
</li>
<li class="listitem">
Correlate the event with other security alerts or logs to identify any related activities or patterns that could indicate a broader attack campaign.
</li>
<li class="listitem">
Consult threat intelligence sources to determine if the process or its associated indicators are linked to known malicious activities or threat actors.
</li>
</ul>
</div>
<p><span class="strong strong"><strong>False positive analysis</strong></span></p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
Nessus scan files in the Windows temp directory may trigger false positives due to their temporary nature and frequent legitimate use. Users can mitigate this by adding exceptions for file paths like C:\WINDOWS\temp\nessus_*.txt and C:\WINDOWS\temp\nessus_*.tmp.
</li>
<li class="listitem">
Legitimate software updates or installations might be flagged if they mimic known malicious patterns. Users should review the process details and whitelist trusted software update processes.
</li>
<li class="listitem">
System administration tools that perform actions similar to those used in attacks could be misidentified. Users should verify the legitimacy of these tools and exclude them from the rule if they are part of regular administrative tasks.
</li>
<li class="listitem">
Custom scripts or automation tools that are not widely recognized might be flagged. Users should ensure these scripts are secure and add them to an allowlist if they are part of routine operations.
</li>
<li class="listitem">
Frequent false positives from specific processes can be managed by adjusting the threshold of the machine learning model or refining the blocklist to better distinguish between benign and malicious activities.
</li>
</ul>
</div>
<p><span class="strong strong"><strong>Response and remediation</strong></span></p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
Isolate the affected system from the network to prevent further spread of potential malicious activity.
</li>
<li class="listitem">
Terminate the suspicious process identified by the ProblemChild model to halt any ongoing malicious actions.
</li>
<li class="listitem">
Conduct a thorough scan of the affected system using updated antivirus and anti-malware tools to identify and remove any additional threats.
</li>
<li class="listitem">
Review and analyze the process execution history and associated files to understand the scope of the compromise and identify any persistence mechanisms.
</li>
<li class="listitem">
Restore any altered or deleted files from backups, ensuring that the backup is clean and free from malware.
</li>
<li class="listitem">
Escalate the incident to the security operations center (SOC) or incident response team for further investigation and to determine if additional systems are affected.
</li>
<li class="listitem">
Implement enhanced monitoring and logging for similar processes and activities to detect and respond to future attempts at masquerading or defense evasion.
</li>
</ul>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<div class="position-relative"><h3 class="title"><a id="_setup_1224"></a>Setup</h3><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/security-docs/edit/8.16/docs/detections/prebuilt-rules/downloadable-packages/8-16-6/prebuilt-rule-8-16-6-machine-learning-detected-a-suspicious-windows-event-with-a-high-malicious-probability-score.asciidoc">edit</a></div>
</div></div></div>
<p><span class="strong strong"><strong>Setup</strong></span></p>
<p>The rule requires the Living off the Land (LotL) Attack Detection integration assets to be installed, as well as Windows process events collected by integrations such as Elastic Defend or Winlogbeat.</p>
<p><span class="strong strong"><strong>LotL Attack Detection Setup</strong></span></p>
<p>The LotL Attack Detection integration detects living-off-the-land activity in Windows process events.</p>
<p><span class="strong strong"><strong>Prerequisite Requirements:</strong></span></p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
Fleet is required for LotL Attack Detection.
</li>
<li class="listitem">
To configure Fleet Server refer to the <a href="/guide/en/fleet/current/fleet-server.html" class="ulink" target="_top">documentation</a>.
</li>
<li class="listitem">
Windows process events collected by the <a href="https://docs.elastic.co/en/integrations/endpoint" class="ulink" target="_top">Elastic Defend</a> integration or Winlogbeat(<a href="/guide/en/beats/winlogbeat/current/_winlogbeat_overview.html" class="ulink" target="_top">https://www.elastic.co/guide/en/beats/winlogbeat/current/_winlogbeat_overview.html</a>).
</li>
<li class="listitem">
To install Elastic Defend, refer to the <a href="/guide/en/security/current/install-endpoint.html" class="ulink" target="_top">documentation</a>.
</li>
<li class="listitem">
To set up and run Winlogbeat, follow <a href="/guide/en/beats/winlogbeat/current/winlogbeat-installation-configuration.html" class="ulink" target="_top">this</a> guide.
</li>
</ul>
</div>
<p><span class="strong strong"><strong>The following steps should be executed to install assets associated with the LotL Attack Detection integration:</strong></span></p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
Go to the Kibana homepage. Under Management, click Integrations.
</li>
<li class="listitem">
In the query bar, search for Living off the Land Attack Detection and select the integration to see more details about it.
</li>
<li class="listitem">
Follow the instructions under the <span class="strong strong"><strong>Installation</strong></span> section.
</li>
<li class="listitem">
For this rule to work, complete the instructions through <span class="strong strong"><strong>Configure the ingest pipeline</strong></span>.
</li>
</ul>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<div class="position-relative"><h3 class="title"><a id="_rule_query_5498"></a>Rule query</h3><a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/security-docs/edit/8.16/docs/detections/prebuilt-rules/downloadable-packages/8-16-6/prebuilt-rule-8-16-6-machine-learning-detected-a-suspicious-windows-event-with-a-high-malicious-probability-score.asciidoc">edit</a></div>
</div></div></div>
<div class="pre_wrapper lang-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js">process where ((problemchild.prediction == 1 and problemchild.prediction_probability &gt; 0.98) or
blocklist_label == 1) and not process.args : ("*C:\\WINDOWS\\temp\\nessus_*.txt*", "*C:\\WINDOWS\\temp\\nessus_*.tmp*")</pre>
</div>
<p><span class="strong strong"><strong>Framework</strong></span>: MITRE ATT&amp;CK<sup>TM</sup></p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<p>Tactic:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
Name: Defense Evasion
</li>
<li class="listitem">
ID: TA0005
</li>
<li class="listitem">
Reference URL: <a href="https://attack.mitre.org/tactics/TA0005/" class="ulink" target="_top">https://attack.mitre.org/tactics/TA0005/</a>
</li>
</ul>
</div>
</li>
<li class="listitem">
<p>Technique:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
Name: Masquerading
</li>
<li class="listitem">
ID: T1036
</li>
<li class="listitem">
Reference URL: <a href="https://attack.mitre.org/techniques/T1036/" class="ulink" target="_top">https://attack.mitre.org/techniques/T1036/</a>
</li>
</ul>
</div>
</li>
<li class="listitem">
<p>Sub-technique:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
Name: Masquerade Task or Service
</li>
<li class="listitem">
ID: T1036.004
</li>
<li class="listitem">
Reference URL: <a href="https://attack.mitre.org/techniques/T1036/004/" class="ulink" target="_top">https://attack.mitre.org/techniques/T1036/004/</a>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>

</div>
</div>
</div><div class="navfooter">
<span class="prev">
<a href="prebuilt-rule-8-16-6-unusual-process-spawned-by-a-user.html">« Unusual Process Spawned by a User</a>
</span>
<span class="next">
<a href="prebuilt-rule-8-16-6-machine-learning-detected-a-suspicious-windows-event-with-a-low-malicious-probability-score.html">Machine Learning Detected a Suspicious Windows Event with a Low Malicious Probability Score »</a>
</span>
</div>
</body>
</html>
