<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Unusual High Confidence Content Filter Blocks Detected | Elastic Security [8.19] | Elastic</title>
<meta class="elastic" name="content" content="Unusual High Confidence Content Filter Blocks Detected | Elastic Security [8.19]">

<link rel="home" href="index.html" title="Elastic Security [8.19]"/>
<link rel="up" href="prebuilt-rule-8-19-4-prebuilt-rules-8-19-4-appendix.html" title="Appendix W: Downloadable rule update v8.19.4"/>
<link rel="prev" href="prebuilt-rule-8-19-4-aws-bedrock-guardrails-detected-multiple-policy-violations-within-a-single-blocked-request.html" title="AWS Bedrock Guardrails Detected Multiple Policy Violations Within a Single Blocked Request"/>
<link rel="next" href="prebuilt-rule-8-19-4-potential-abuse-of-resources-by-high-token-count-and-large-response-sizes.html" title="Potential Abuse of Resources by High Token Count and Large Response Sizes"/>
<meta class="elastic" name="product_version" content="8.19"/>
<meta class="elastic" name="product_name" content="Security"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/Security/Guide/8.19"/>
<meta name="DC.subject" content="Security"/>
<meta name="DC.identifier" content="8.19"/>
</head>
<body>
<div class="navheader">
<span class="prev">
<a href="prebuilt-rule-8-19-4-aws-bedrock-guardrails-detected-multiple-policy-violations-within-a-single-blocked-request.html">« AWS Bedrock Guardrails Detected Multiple Policy Violations Within a Single Blocked Request</a>
</span>
<span class="next">
<a href="prebuilt-rule-8-19-4-potential-abuse-of-resources-by-high-token-count-and-large-response-sizes.html">Potential Abuse of Resources by High Token Count and Large Response Sizes »</a>
</span>
</div>
<div class="book" lang="en">
<div class="titlepage">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Elastic Security [8.19]</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="prebuilt-rule-8-19-4-prebuilt-rules-8-19-4-appendix.html">Downloadable rule update v8.19.4</a></span>
</div>
<div>
<div><h1 class="title"><a id="id-1"></a>Unusual High Confidence Content Filter Blocks Detected</h1><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/security-docs/edit/8.19/docs/detections/prebuilt-rules/downloadable-packages/8-19-4/prebuilt-rule-8-19-4-unusual-high-confidence-content-filter-blocks-detected.asciidoc">edit</a></div>
</div>
<!--EXTRA-->
</div>
<div id="content">
<div id="url-to-v3" class="version-warning">
    <strong>IMPORTANT</strong>: This documentation is no longer updated. Refer to <a href="https://www.elastic.co/support/eol">Elastic's version policy</a> and the <a href="https://www.elastic.co/docs">latest documentation</a>.
</div>
<div class="section">
<div class="titlepage"><div><div>
<div class="position-relative"><h2 class="title"><a id="prebuilt-rule-8-19-4-unusual-high-confidence-content-filter-blocks-detected"></a>Unusual High Confidence Content Filter Blocks Detected</h2><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/security-docs/edit/8.19/docs/detections/prebuilt-rules/downloadable-packages/8-19-4/prebuilt-rule-8-19-4-unusual-high-confidence-content-filter-blocks-detected.asciidoc">edit</a></div>
</div></div></div>
<p>Detects repeated high-confidence <em>BLOCKED</em> actions coupled with specific <em>Content Filter</em> policy violation having codes such as <em>MISCONDUCT</em>, <em>HATE</em>, <em>SEXUAL</em>, INSULTS', <em>PROMPT_ATTACK</em>, <em>VIOLENCE</em> indicating persistent misuse or attempts to probe the model&#8217;s ethical boundaries.</p>
<p><span class="strong strong"><strong>Rule type</strong></span>: esql</p>
<p><span class="strong strong"><strong>Rule indices</strong></span>: None</p>
<p><span class="strong strong"><strong>Severity</strong></span>: medium</p>
<p><span class="strong strong"><strong>Risk score</strong></span>: 47</p>
<p><span class="strong strong"><strong>Runs every</strong></span>: 10m</p>
<p><span class="strong strong"><strong>Searches indices from</strong></span>: now-60m (<a href="/guide/en/elasticsearch/reference/8.19/common-options.html#date-math" class="ulink" target="_top">Date Math format</a>, see also <a class="xref" href="rules-ui-create.html#rule-schedule" title="Set the rule&#8217;s schedule"><code class="literal">Additional look-back time</code></a>)</p>
<p><span class="strong strong"><strong>Maximum alerts per execution</strong></span>: 100</p>
<p><span class="strong strong"><strong>References</strong></span>:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<a href="https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails-components.html" class="ulink" target="_top">https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails-components.html</a>
</li>
<li class="listitem">
<a href="https://atlas.mitre.org/techniques/AML.T0051" class="ulink" target="_top">https://atlas.mitre.org/techniques/AML.T0051</a>
</li>
<li class="listitem">
<a href="https://atlas.mitre.org/techniques/AML.T0054" class="ulink" target="_top">https://atlas.mitre.org/techniques/AML.T0054</a>
</li>
<li class="listitem">
<a href="/security-labs/elastic-advances-llm-security" class="ulink" target="_top">https://www.elastic.co/security-labs/elastic-advances-llm-security</a>
</li>
</ul>
</div>
<p><span class="strong strong"><strong>Tags</strong></span>:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
Domain: LLM
</li>
<li class="listitem">
Data Source: AWS Bedrock
</li>
<li class="listitem">
Data Source: AWS S3
</li>
<li class="listitem">
Use Case: Policy Violation
</li>
<li class="listitem">
Mitre Atlas: T0051
</li>
<li class="listitem">
Mitre Atlas: T0054
</li>
<li class="listitem">
Resources: Investigation Guide
</li>
</ul>
</div>
<p><span class="strong strong"><strong>Version</strong></span>: 7</p>
<p><span class="strong strong"><strong>Rule authors</strong></span>:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
Elastic
</li>
</ul>
</div>
<p><span class="strong strong"><strong>Rule license</strong></span>: Elastic License v2</p>
<div class="section">
<div class="titlepage"><div><div>
<div class="position-relative"><h3 class="title"><a id="_investigation_guide_4242"></a>Investigation guide</h3><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/security-docs/edit/8.19/docs/detections/prebuilt-rules/downloadable-packages/8-19-4/prebuilt-rule-8-19-4-unusual-high-confidence-content-filter-blocks-detected.asciidoc">edit</a></div>
</div></div></div>
<p><span class="strong strong"><strong>Triage and analysis</strong></span></p>
<p><span class="strong strong"><strong>Investigating Unusual High Confidence Content Filter Blocks Detected</strong></span></p>
<p>Amazon Bedrock Guardrail is a set of features within Amazon Bedrock designed to help businesses apply robust safety and privacy controls to their generative AI applications.</p>
<p>It enables users to set guidelines and filters that manage content quality, relevancy, and adherence to responsible AI practices.</p>
<p>Through Guardrail, organizations can enable Content filter for Hate, Insults, Sexual Violence and Misconduct along with Prompt Attack filters prompts
to prevent the model from generating content on specific, undesired subjects, and they can establish thresholds for harmful content categories.</p>
<p><span class="strong strong"><strong>Possible investigation steps</strong></span></p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
Identify the user account whose prompts caused high confidence content filter blocks and whether it should perform this kind of action.
</li>
<li class="listitem">
Investigate other alerts associated with the user account during the past 48 hours.
</li>
<li class="listitem">
Consider the time of day. If the user is a human (not a program or script), did the activity take place during a normal time of day?
</li>
<li class="listitem">
Examine the account&#8217;s prompts and responses in the last 24 hours.
</li>
<li class="listitem">
If you suspect the account has been compromised, scope potentially compromised assets by tracking Amazon Bedrock model access, prompts generated, and responses to the prompts by the account in the last 24 hours.
</li>
</ul>
</div>
<p><span class="strong strong"><strong>False positive analysis</strong></span></p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
Verify the user account that queried denied topics, is not testing any new model deployments or updated compliance policies in Amazon Bedrock guardrails.
</li>
</ul>
</div>
<p><span class="strong strong"><strong>Response and remediation</strong></span></p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
Initiate the incident response process based on the outcome of the triage.
</li>
<li class="listitem">
Disable or limit the account during the investigation and response.
</li>
<li class="listitem">
Identify the possible impact of the incident and prioritize accordingly; the following actions can help you gain context:
</li>
<li class="listitem">
Identify the account role in the cloud environment.
</li>
<li class="listitem">
Identify if the attacker is moving laterally and compromising other Amazon Bedrock Services.
</li>
<li class="listitem">
Identify any regulatory or legal ramifications related to this activity.
</li>
<li class="listitem">
Review the permissions assigned to the implicated user group or role behind these requests to ensure they are authorized and expected to access bedrock and ensure that the least privilege principle is being followed.
</li>
<li class="listitem">
Determine the initial vector abused by the attacker and take action to prevent reinfection via the same vector.
</li>
<li class="listitem">
Using the incident response data, update logging and audit policies to improve the mean time to detect (MTTD) and the mean time to respond (MTTR).
</li>
</ul>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<div class="position-relative"><h3 class="title"><a id="_setup_947"></a>Setup</h3><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/security-docs/edit/8.19/docs/detections/prebuilt-rules/downloadable-packages/8-19-4/prebuilt-rule-8-19-4-unusual-high-confidence-content-filter-blocks-detected.asciidoc">edit</a></div>
</div></div></div>
<p><span class="strong strong"><strong>Setup</strong></span></p>
<p>This rule requires that guardrails are configured in AWS Bedrock. For more information, see the AWS Bedrock documentation:</p>
<p><a href="https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails-create.html" class="ulink" target="_top">https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails-create.html</a></p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<div class="position-relative"><h3 class="title"><a id="_rule_query_5116"></a>Rule query</h3><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/security-docs/edit/8.19/docs/detections/prebuilt-rules/downloadable-packages/8-19-4/prebuilt-rule-8-19-4-unusual-high-confidence-content-filter-blocks-detected.asciidoc">edit</a></div>
</div></div></div>
<div class="pre_wrapper lang-js">
<div class="console_code_copy" title="Copy to clipboard"></div>
<pre class="programlisting prettyprint lang-js">from logs-aws_bedrock.invocation-*

// Expand multi-value fields
| mv_expand gen_ai.compliance.violation_code
| mv_expand gen_ai.policy.confidence
| mv_expand gen_ai.policy.name

// Filter for high-confidence content policy blocks with targeted violations
| where
  gen_ai.policy.action == "BLOCKED"
  and gen_ai.policy.name == "content_policy"
  and gen_ai.policy.confidence like "HIGH"
  and gen_ai.compliance.violation_code in ("HATE", "MISCONDUCT", "SEXUAL", "INSULTS", "PROMPT_ATTACK", "VIOLENCE")

// keep ECS + compliance fields
| keep
  user.id,
  gen_ai.compliance.violation_code

// count blocked violations per user per violation type
| stats
    Esql.ml_policy_blocked_violation_count = count()
  by
    user.id,
    gen_ai.compliance.violation_code

// Aggregate all violation types per user
| stats
    Esql.ml_policy_blocked_violation_total_count = sum(Esql.ml_policy_blocked_violation_count)
  by
    user.id

// Filter for users with more than 5 total violations
| where Esql.ml_policy_blocked_violation_total_count &gt; 5

// sort by violation volume
| sort Esql.ml_policy_blocked_violation_total_count desc</pre>
</div>
</div>

</div>
</div>
</div><div class="navfooter">
<span class="prev">
<a href="prebuilt-rule-8-19-4-aws-bedrock-guardrails-detected-multiple-policy-violations-within-a-single-blocked-request.html">« AWS Bedrock Guardrails Detected Multiple Policy Violations Within a Single Blocked Request</a>
</span>
<span class="next">
<a href="prebuilt-rule-8-19-4-potential-abuse-of-resources-by-high-token-count-and-large-response-sizes.html">Potential Abuse of Resources by High Token Count and Large Response Sizes »</a>
</span>
</div>
</body>
</html>
