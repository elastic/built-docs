<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="description" content="">
<title>Trained model autoscaling | Serverless | Elastic</title>
<meta class="elastic" name="content" content="Trained model autoscaling | Serverless">

<link rel="home" href="index.html" title="Serverless"/>
<link rel="up" href="project-and-management-settings.html" title="Manage your project"/>
<link rel="prev" href="project-and-management-settings.html" title="Manage your project"/>
<link rel="next" href="elasticsearch-manage-project.html" title="Manage performance and general settings"/>
<meta class="elastic" name="product_version" content="main"/>
<meta class="elastic" name="product_name" content="Serverless"/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/Serverless/Guide"/>
<meta name="DC.subject" content="Serverless"/>
<meta name="DC.identifier" content="main"/>
</head>
<body>
<div class="navheader">
<span class="prev">
<a href="project-and-management-settings.html">« Manage your project</a>
</span>
<span class="next">
<a href="elasticsearch-manage-project.html">Manage performance and general settings »</a>
</span>
</div>
<div class="book" lang="en">
<div class="titlepage">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Serverless</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="project-and-management-settings.html">Manage your project</a></span>
</div>
<div>
<div><h1 class="title"><a id="id-1"></a>Trained model autoscaling</h1><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/docs-content/edit/main/serverless/pages/ml-nlp-auto-scale.asciidoc">edit</a></div>
</div>
<!--EXTRA-->
</div>
<div id="content">
<div class="section">
<div class="titlepage"><div><div>
<div class="position-relative"><h2 class="title"><a id="general-ml-nlp-auto-scale"></a>Trained model autoscaling</h2><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/docs-content/edit/main/serverless/pages/ml-nlp-auto-scale.asciidoc">edit</a></div>
</div></div></div>
<p>This content applies to: <a class="xref" href="what-is-elasticsearch-serverless.html" title="Elasticsearch Serverless"><span class="image"><img src="images/es-badge.svg" alt="Elasticsearch"></span></a> <a class="xref" href="what-is-observability-serverless.html" title="Elastic Observability serverless"><span class="image"><img src="images/obs-badge.svg" alt="Observability"></span></a> <a class="xref" href="what-is-security-serverless.html" title="Elastic Security serverless"><span class="image"><img src="images/sec-badge.svg" alt="Security"></span></a></p>
<p>You can enable autoscaling for each of your trained model deployments.
Autoscaling allows Elasticsearch to automatically adjust the resources the model deployment can use based on the workload demand.</p>
<p>There are two ways to enable autoscaling:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
through APIs by enabling adaptive allocations
</li>
<li class="listitem">
in Kibana by enabling adaptive resources
</li>
</ul>
</div>
<p>Trained model autoscaling is available for both serverless and Cloud deployments. In serverless deployments, processing power is managed differently across Search, Observability, and Security projects, which impacts their costs and resource limits.</p>
<p>Security and Observability projects are only charged for data ingestion and retention. They are not charged for processing power (VCU usage), which is used for more complex operations, like running advanced search models. For example, in Search projects, models such as ELSER require significant processing power to provide more accurate search results.</p>
<div class="position-relative"><h4><a id="enabling-autoscaling-through-apis-adaptive-allocations"></a>Enabling autoscaling through APIs - adaptive allocations</h4><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/docs-content/edit/main/serverless/pages/ml-nlp-auto-scale.asciidoc">edit</a></div>
<p>Model allocations are independent units of work for NLP tasks.
If you set a static number of allocations, they remain constant even when not all the available resources are fully used or when the load on the model requires more resources.
Instead of setting the number of allocations manually, you can enable adaptive allocations to set the number of allocations based on the load on the process.
This can help you to manage performance and cost more easily.
(Refer to the <a href="https://cloud.elastic.co/pricing" class="ulink" target="_top">pricing calculator</a> to learn more about the possible costs.)</p>
<p>When adaptive allocations are enabled, the number of allocations of the model is set automatically based on the current load.
When the load is high, additional model allocations are automatically created as needed.
When the load is low, a model allocation is automatically removed.
You can explicitly set the minimum and maximum number of allocations; autoscaling will occur within these limits.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>If you set the minimum number of allocations to 1, you will be charged even if the system is not using those resources.</p>
</div>
</div>
<p>You can enable adaptive allocations by using:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
the create inference endpoint API for <a href="/guide/en/elasticsearch/reference/master/infer-service-elser.html" class="ulink" target="_top">ELSER</a>, <a href="/guide/en/elasticsearch/reference/master/infer-service-elasticsearch.html" class="ulink" target="_top">E5 and models uploaded through Eland</a> that are used as inference services.
</li>
<li class="listitem">
the <a href="/guide/en/elasticsearch/reference/master/start-trained-model-deployment.html" class="ulink" target="_top">start trained model deployment</a> or <a href="/guide/en/elasticsearch/reference/master/update-trained-model-deployment.html" class="ulink" target="_top">update trained model deployment</a> APIs for trained models that are deployed on machine learning nodes.
</li>
</ul>
</div>
<p>If the new allocations fit on the current machine learning nodes, they are immediately started.
If more resource capacity is needed for creating new model allocations, then your machine learning node will be scaled up if machine learning autoscaling is enabled to provide enough resources for the new allocation.
The number of model allocations can be scaled down to 0.
They cannot be scaled up to more than 32 allocations, unless you explicitly set the maximum number of allocations to more.
Adaptive allocations must be set up independently for each deployment and <a href="/guide/en/elasticsearch/reference/master/put-inference-api.html" class="ulink" target="_top">inference endpoint</a>.</p>
<p>When you create inference endpoints on Serverless using Kibana, adaptive allocations are automatically turned on, and there is no option to disable them.</p>
<div class="position-relative"><h5><a id="optimizing-for-typical-use-cases"></a>Optimizing for typical use cases</h5><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/docs-content/edit/main/serverless/pages/ml-nlp-auto-scale.asciidoc">edit</a></div>
<p>You can optimize your model deployment for typical use cases, such as search and ingest.
When you optimize for ingest, the throughput will be higher, which increases the number of inference requests that can be performed in parallel.
When you optimize for search, the latency will be lower during search processes.</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
If you want to optimize for ingest, set the number of threads to <code class="literal">1</code> (<code class="literal">"threads_per_allocation": 1</code>).
</li>
<li class="listitem">
If you want to optimize for search, set the number of threads to greater than <code class="literal">1</code>.
Increasing the number of threads will make the search processes more performant.
</li>
</ul>
</div>
<div class="position-relative"><h4><a id="enabling-autoscaling-in-kibana-adaptive-resources"></a>Enabling autoscaling in Kibana - adaptive resources</h4><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/docs-content/edit/main/serverless/pages/ml-nlp-auto-scale.asciidoc">edit</a></div>
<p>You can enable adaptive resources for your models when starting or updating the model deployment.
Adaptive resources make it possible for Elasticsearch to scale up or down the available resources based on the load on the process.
This can help you to manage performance and cost more easily.
When adaptive resources are enabled, the number of VCUs that the model deployment uses is set automatically based on the current load.
When the load is high, the number of VCUs that the process can use is automatically increased.
When the load is low, the number of VCUs that the process can use is automatically decreased.</p>
<p>You can choose from three levels of resource usage for your trained model deployment; autoscaling will occur within the selected level&#8217;s range.</p>
<p>Refer to the tables in the auto-scaling-matrix section to find out the settings for the level you selected.</p>
<div class="imageblock">
<div class="content">
<img src="images/ml-nlp-deployment.png" alt="ML model deployment with adaptive resources enabled.">
</div>
</div>
<p>Search projects are given access to more processing resources, while Security and Observability projects have lower limits. This difference is reflected in the UI configuration: Search projects have higher resource limits compared to Security and Observability projects to accommodate their more complex operations.</p>
<p>On Serverless, adaptive allocations are automatically enabled for all project types.
However, the "Adaptive resources" control is not displayed in Kibana for Observability and Security projects.</p>
<div class="position-relative"><h4><a id="model-deployment-resource-matrix"></a>Model deployment resource matrix</h4><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/docs-content/edit/main/serverless/pages/ml-nlp-auto-scale.asciidoc">edit</a></div>
<p>The used resources for trained model deployments depend on three factors:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
your cluster environment (Serverless, Cloud, or on-premises)
</li>
<li class="listitem">
the use case you optimize the model deployment for (ingest or search)
</li>
<li class="listitem">
whether model autoscaling is enabled with adaptive allocations/resources to have dynamic resources, or disabled for static resources
</li>
</ul>
</div>
<p>The following tables show you the number of allocations, threads, and VCUs available on Serverless when adaptive resources are enabled or disabled.</p>
<div class="position-relative"><h5><a id="deployments-on-serverless-optimized-for-ingest"></a>Deployments on serverless optimized for ingest</h5><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/docs-content/edit/main/serverless/pages/ml-nlp-auto-scale.asciidoc">edit</a></div>
<p>In case of ingest-optimized deployments, we maximize the number of model allocations.</p>
<div class="position-relative"><h6><a id="adaptive-resources-enabled"></a>Adaptive resources enabled</h6><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/docs-content/edit/main/serverless/pages/ml-nlp-auto-scale.asciidoc">edit</a></div>
<div class="informaltable">
<table border="1" cellpadding="4px">
<colgroup>
<col class="col_1"/>
<col class="col_2"/>
<col class="col_3"/>
<col class="col_4"/>
</colgroup>
<thead>
<tr>
<th align="left" valign="top">Level</th>
<th align="left" valign="top">Allocations</th>
<th align="left" valign="top">Threads</th>
<th align="left" valign="top">VCUs</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" valign="top"><p>Low</p></td>
<td align="left" valign="top"><p>0 to 2 dynamically</p></td>
<td align="left" valign="top"><p>1</p></td>
<td align="left" valign="top"><p>0 to 16 dynamically</p></td>
</tr>
<tr>
<td align="left" valign="top"><p>Medium</p></td>
<td align="left" valign="top"><p>1 to 32 dynamically</p></td>
<td align="left" valign="top"><p>1</p></td>
<td align="left" valign="top"><p>8 to 256 dynamically</p></td>
</tr>
<tr>
<td align="left" valign="top"><p>High</p></td>
<td align="left" valign="top">
<p>1 to 512 for Search<br>
1 to 128 for Security and Observability</p>
</td>
<td align="left" valign="top"><p>1</p></td>
<td align="left" valign="top">
<p>8 to 4096 for Search<br>
8 to 1024 for Security and Observability</p>
</td>
</tr>
</tbody>
</table>
</div>
<div class="position-relative"><h6><a id="adaptive-resources-disabled-search-only"></a>Adaptive resources disabled (Search only)</h6><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/docs-content/edit/main/serverless/pages/ml-nlp-auto-scale.asciidoc">edit</a></div>
<div class="informaltable">
<table border="1" cellpadding="4px">
<colgroup>
<col class="col_1"/>
<col class="col_2"/>
<col class="col_3"/>
<col class="col_4"/>
</colgroup>
<thead>
<tr>
<th align="left" valign="top">Level</th>
<th align="left" valign="top">Allocations</th>
<th align="left" valign="top">Threads</th>
<th align="left" valign="top">VCUs</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" valign="top"><p>Low</p></td>
<td align="left" valign="top"><p>Exactly 2</p></td>
<td align="left" valign="top"><p>1</p></td>
<td align="left" valign="top"><p>16</p></td>
</tr>
<tr>
<td align="left" valign="top"><p>Medium</p></td>
<td align="left" valign="top"><p>Exactly 32</p></td>
<td align="left" valign="top"><p>1</p></td>
<td align="left" valign="top"><p>256</p></td>
</tr>
<tr>
<td align="left" valign="top"><p>High</p></td>
<td align="left" valign="top">
<p>512 for Search<br>
No static allocations for Security and Observability</p>
</td>
<td align="left" valign="top"><p>1</p></td>
<td align="left" valign="top">
<p>4096 for Search<br>
No static allocations for Security and Observability</p>
</td>
</tr>
</tbody>
</table>
</div>
<div class="position-relative"><h5><a id="deployments-on-serverless-optimized-for-search"></a>Deployments on serverless optimized for Search</h5><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/docs-content/edit/main/serverless/pages/ml-nlp-auto-scale.asciidoc">edit</a></div>
<div class="position-relative"><h6><a id="adaptive-resources-enabled-for-search"></a>Adaptive resources enabled</h6><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/docs-content/edit/main/serverless/pages/ml-nlp-auto-scale.asciidoc">edit</a></div>
<div class="informaltable">
<table border="1" cellpadding="4px">
<colgroup>
<col class="col_1"/>
<col class="col_2"/>
<col class="col_3"/>
<col class="col_4"/>
</colgroup>
<thead>
<tr>
<th align="left" valign="top">Level</th>
<th align="left" valign="top">Allocations</th>
<th align="left" valign="top">Threads</th>
<th align="left" valign="top">VCUs</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" valign="top"><p>Low</p></td>
<td align="left" valign="top"><p>0 to 1 dynamically</p></td>
<td align="left" valign="top"><p>Always 2</p></td>
<td align="left" valign="top"><p>0 to 16 dynamically</p></td>
</tr>
<tr>
<td align="left" valign="top"><p>Medium</p></td>
<td align="left" valign="top"><p>1 to 2 (if threads=16), dynamically</p></td>
<td align="left" valign="top"><p>Maximum (for example, 16)</p></td>
<td align="left" valign="top"><p>8 to 256 dynamically</p></td>
</tr>
<tr>
<td align="left" valign="top"><p>High</p></td>
<td align="left" valign="top">
<p>1 to 32 (if threads=16), dynamically<br>
1 to 128 for Security and Observability</p>
</td>
<td align="left" valign="top"><p>Maximum (for example, 16)</p></td>
<td align="left" valign="top">
<p>8 to 4096 for Search<br>
8 to 1024 for Security and Observability</p>
</td>
</tr>
</tbody>
</table>
</div>
<div class="position-relative"><h6><a id="adaptive-resources-disabled-for-search"></a>Adaptive resources disabled</h6><a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/docs-content/edit/main/serverless/pages/ml-nlp-auto-scale.asciidoc">edit</a></div>
<div class="informaltable">
<table border="1" cellpadding="4px">
<colgroup>
<col class="col_1"/>
<col class="col_2"/>
<col class="col_3"/>
<col class="col_4"/>
</colgroup>
<thead>
<tr>
<th align="left" valign="top">Level</th>
<th align="left" valign="top">Allocations</th>
<th align="left" valign="top">Threads</th>
<th align="left" valign="top">VCUs</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" valign="top"><p>Low</p></td>
<td align="left" valign="top"><p>1 statically</p></td>
<td align="left" valign="top"><p>Always 2</p></td>
<td align="left" valign="top"><p>16</p></td>
</tr>
<tr>
<td align="left" valign="top"><p>Medium</p></td>
<td align="left" valign="top"><p>2 statically (if threads=16)</p></td>
<td align="left" valign="top"><p>Maximum (for example, 16)</p></td>
<td align="left" valign="top"><p>256</p></td>
</tr>
<tr>
<td align="left" valign="top"><p>High</p></td>
<td align="left" valign="top">
<p>32 statically (if threads=16) for Search<br>
No static allocations for Security and Observability</p>
</td>
<td align="left" valign="top"><p>Maximum (for example, 16)</p></td>
<td align="left" valign="top">
<p>4096 for Search<br>
No static allocations for Security and Observability</p>
</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div><div class="navfooter">
<span class="prev">
<a href="project-and-management-settings.html">« Manage your project</a>
</span>
<span class="next">
<a href="elasticsearch-manage-project.html">Manage performance and general settings »</a>
</span>
</div>
</body>
</html>
