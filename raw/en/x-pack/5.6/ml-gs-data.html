<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Identifying Data for Analysis | X-Pack for the Elastic Stack [5.6] | Elastic</title>
<link rel="home" href="index.html" title="X-Pack for the Elastic Stack [5.6]"/>
<link rel="up" href="ml-getting-started.html" title="Getting Started"/>
<link rel="prev" href="ml-getting-started.html" title="Getting Started"/>
<link rel="next" href="ml-gs-jobs.html" title="Creating Single Metric Jobs"/>
<meta name="DC.type" content="Learn/Docs/Legacy/XPack/Reference/5.6"/>
<meta name="DC.subject" content="X-Pack"/>
<meta name="DC.identifier" content="5.6"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body><div class="page_header">
<p>
  <strong>WARNING</strong>: Version 5.6 of the Elastic Stack has passed its 
  <a href="https://www.elastic.co/support/eol">EOL date</a>. 
</p>  
<p>
  This documentation is no longer being maintained and may be removed. 
  If you are running this version, we strongly advise you to upgrade. 
  For the latest information, see the 
<a href="https://www.elastic.co/guide/index.html">current release documentation</a>.
</p>
</div>
<div id="content">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="index.html">X-Pack for the Elastic Stack [5.6]</a></span>
»
<span class="breadcrumb-link"><a href="xpack-ml.html">Machine Learning in the Elastic Stack</a></span>
»
<span class="breadcrumb-link"><a href="ml-getting-started.html">Getting Started</a></span>
»
<span class="breadcrumb-node">Identifying Data for Analysis</span>
</div>
<div class="navheader">
<span class="prev">
<a href="ml-getting-started.html">« Getting Started</a>
</span>
<span class="next">
<a href="ml-gs-jobs.html">Creating Single Metric Jobs »</a>
</span>
</div>
<div class="section">
<div class="titlepage"><div><div>
<h2 class="title"><a id="ml-gs-data"></a>Identifying Data for Analysis<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/x-pack-elasticsearch/edit/5.6/docs/en/ml/getting-started-data.asciidoc">edit</a></h2>
</div></div></div>
<p>For the purposes of this tutorial, we provide sample data that you can play with
and search in Elasticsearch. When you consider your own data, however, it&#8217;s important to
take a moment and think about where the X-Pack machine learning features will be most
impactful.</p>
<p>The first consideration is that it must be time series data. The machine learning features
are designed to model and detect anomalies in time series data.</p>
<p>The second consideration, especially when you are first learning to use machine learning,
is the importance of the data and how familiar you are with it. Ideally, it is
information that contains key performance indicators (KPIs) for the health,
security, or success of your business or system. It is information that you need
to monitor and act on when anomalous behavior occurs. You might even have Kibana
dashboards that you&#8217;re already using to watch this data. The better you know the
data, the quicker you will be able to create machine learning jobs that generate useful
insights.</p>
<p>The final consideration is where the data is located. This tutorial assumes that
your data is stored in Elasticsearch. It guides you through the steps required to create
a <em>datafeed</em> that passes data to a job. If your own data is outside of Elasticsearch,
analysis is still possible by using a post data API.</p>
<div class="important admon">
<div class="icon"></div>
<div class="admon_content">
<p>If you want to create machine learning jobs in Kibana, you must use datafeeds.
That is to say, you must store your input data in Elasticsearch. When you create
a job, you select an existing index pattern and Kibana configures the datafeed
for you under the covers.</p>
</div>
</div>
<h4><a id="ml-gs-sampledata"></a>Obtaining a Sample Data Set<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/x-pack-elasticsearch/edit/5.6/docs/en/ml/getting-started-data.asciidoc">edit</a></h4>
<p>In this step we will upload some sample data to Elasticsearch. This is standard
Elasticsearch functionality, and is needed to set the stage for using machine learning.</p>
<p>The sample data for this tutorial contains information about the requests that
are received by various applications and services in a system. A system
administrator might use this type of information to track the total number of
requests across all of the infrastructure. If the number of requests increases
or decreases unexpectedly, for example, this might be an indication that there
is a problem or that resources need to be redistributed. By using the X-Pack
machine learning features to model the behavior of this data, it is easier to identify
anomalies and take appropriate action.</p>
<p>Download the sample data and scripts by clicking here:
<a href="https://download.elastic.co/demos/machine_learning/gettingstarted/server_metrics.tar.gz" class="ulink" target="_top">server_metrics.tar.gz</a></p>
<p>Use the following command to extract the files:</p>
<div class="pre_wrapper lang-shell">
<pre class="programlisting prettyprint lang-shell">tar -zxvf server_metrics.tar.gz</pre>
</div>
<p>Each document in the server-metrics data set has the following schema:</p>
<div class="pre_wrapper lang-js">
<pre class="programlisting prettyprint lang-js">{
  "index":
  {
    "_index":"server-metrics",
    "_type":"metric",
    "_id":"1177"
  }
}
{
  "@timestamp":"2017-03-23T13:00:00",
  "accept":36320,
  "deny":4156,
  "host":"server_2",
  "response":2.4558210155,
  "service":"app_3",
  "total":40476
}</pre>
</div>
<div class="tip admon">
<div class="icon"></div>
<div class="admon_content">
<p>The sample data sets include summarized data. For example, the <code class="literal">total</code>
value is a sum of the requests that were received by a specific service at a
particular time. If your data is stored in Elasticsearch, you can generate
this type of sum or average by using aggregations. One of the benefits of
summarizing data this way is that Elasticsearch automatically distributes
these calculations across your cluster. You can then feed this summarized data
into X-Pack machine learning instead of raw results, which reduces the volume
of data that must be considered while detecting anomalies. For the purposes of
this tutorial, however, these summary values are stored in Elasticsearch. For more
information, see <a class="xref" href="ml-configuring-aggregation.html" title="Aggregating Data For Faster Performance">Aggregating Data For Faster Performance</a>.</p>
</div>
</div>
<p>Before you load the data set, you need to set up <a href="/guide/en/elasticsearch/reference/5.6/mapping.html" class="ulink" target="_top"><em>mappings</em></a>
for the fields. Mappings divide the documents in the index into logical groups
and specify a field&#8217;s characteristics, such as the field&#8217;s searchability or
whether or not it&#8217;s <em>tokenized</em>, or broken up into separate words.</p>
<p>You can use scripts to create the mappings and load the data set. If X-Pack security
is enabled, use the <code class="literal">upload_server_metrics.sh</code> script. Before you run it,
however, you must edit the USERNAME and PASSWORD variables with your actual user
ID and password. If X-Pack security is not enabled, use the
<code class="literal">upload_server_metrics_noauth.sh</code> script instead.</p>
<p>The scripts run a <code class="literal">curl</code> command that makes the following create index API
request:</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">PUT server-metrics
{
   "settings":{
      "number_of_shards":1,
      "number_of_replicas":0
   },
   "mappings":{
      "metric":{
         "properties":{
            "@timestamp":{
               "type":"date"
            },
            "accept":{
               "type":"long"
            },
            "deny":{
               "type":"long"
            },
            "host":{
               "type":"keyword"
            },
            "response":{
               "type":"float"
            },
            "service":{
               "type":"keyword"
            },
            "total":{
               "type":"long"
            }
         }
      }
   }
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/68.console"></div>
<p>To learn more about mappings and data types, see <a href="/guide/en/elasticsearch/reference/5.6/mapping.html" class="ulink" target="_top">Mapping</a>.</p>
<p>You can then use the <code class="literal">bulk</code> API to load the sample data set. The scripts run
commands similar to the following example:</p>
<div class="pre_wrapper lang-shell">
<pre class="programlisting prettyprint lang-shell">curl -X POST -H "Content-Type: application/json"
http://localhost:9200/server-metrics/_bulk --data-binary "@server-metrics_1.json"</pre>
</div>
<p>There are twenty data files. The commands might take some time to run, depending
on the computing resources available.</p>
<p>You can verify that the data was loaded successfully by running the cat indices
API:</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">GET _cat/indices?v</pre>
</div>
<div class="console_widget" data-snippet="snippets/69.console"></div>
<p>You should see output similar to the following:</p>
<div class="pre_wrapper lang-shell">
<pre class="programlisting prettyprint lang-shell">health status index ... pri rep docs.count  ...
green  open   server-metrics ... 1 0 905940  ...</pre>
</div>
<p>Next, you must define an index pattern for this data set:</p>
<div class="olist orderedlist">
<ol class="orderedlist">
<li class="listitem">
Open Kibana in your web browser. If you are running Kibana
locally, go to <code class="literal">http://localhost:5601/</code>.
</li>
<li class="listitem">
Click the <span class="strong strong"><strong>Management</strong></span> tab, then <span class="strong strong"><strong>Index Patterns</strong></span>.
</li>
<li class="listitem">
If you already have index patterns, click the plus sign (+) to define a new
one. Otherwise, the <span class="strong strong"><strong>Configure an index pattern</strong></span> wizard is already open.
</li>
<li class="listitem">
For this tutorial, any pattern that matches the name of the index you&#8217;ve
loaded will work. For example, enter <code class="literal">server-metrics*</code> as the index pattern.
</li>
<li class="listitem">
Verify that the <span class="strong strong"><strong>Index contains time-based events</strong></span> is checked.
</li>
<li class="listitem">
Select the <code class="literal">@timestamp</code> field from the <span class="strong strong"><strong>Time-field name</strong></span> list.
</li>
<li class="listitem">
Click <span class="strong strong"><strong>Create</strong></span>.
</li>
</ol>
</div>
<p>This data set can now be analyzed in machine learning jobs in Kibana.</p>
</div>
<div class="navfooter">
<span class="prev">
<a href="ml-getting-started.html">« Getting Started</a>
</span>
<span class="next">
<a href="ml-gs-jobs.html">Creating Single Metric Jobs »</a>
</span>
</div>
</div>
</body>
</html>
